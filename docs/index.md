# 计算机视觉领域最新论文 (2025.09.06)

> 每日自动更新计算机视觉领域的最新arXiv论文

> 使用说明: [点击查看](./docs/README.md#usage)

<details>
<summary>分类目录</summary>
<ol>
<li><a href='#slam'>SLAM</a></li>
<li><a href='#sfm'>SFM</a></li>
<li><a href='#visual-localization'>Visual Localization</a></li>
<li><a href='#keypoint-detection'>Keypoint Detection</a></li>
<li><a href='#image-matching'>Image Matching</a></li>
<li><a href='#nerf'>NeRF</a></li>
</ol>
</details>

<h2 id='slam'>SLAM</h2>

<div class="table-container">
<table>
<thead><tr><th>日期</th><th>标题</th><th>论文与代码</th><th>摘要</th></tr></thead>
<tbody>
<tr><td>2025-09-04</td><td>Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage</td><td>[2509.04370](http://arxiv.org/pdf/2509.04370)</td><td>该论文的核心贡献是开发了一个自动化计算机视觉流程，将执法或急救人员佩戴的体戴相机视频转化为简洁的全景事件摘要图像。  
◆ 提出利用单目SLAM技术从视频中估计相机运动轨迹并重建场景空间布局，为创建空间连贯的摘要奠定基础。  
◆ 通过沿轨迹对相机位姿进行聚类来识别关键视角，确保摘要能覆盖场景的重要部分。  
◆ 采用多帧图像拼接技术，将选定代表帧融合成高质量全景图，保持空间一致性和视觉完整性。  
◆ 最终生成的全景摘要图像支持快速环境理解和决策，解决了冗长视频回顾耗时低效的痛点。  
该技术提升了体戴相机数据在时间敏感场景中的实用价值，适用于事后分析和应急响应。</td></tr>
<tr><td>2025-09-04</td><td>Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall Climbing Robot</td><td>[2509.04016](http://arxiv.org/pdf/2509.04016)</td><td>本文针对四轮独立转向独立驱动（4WIS4WID）爬壁机器人在复杂建筑立面上的定位难题，提出了一种基于多传感器融合的位姿估计器。  
◆ 创新性地将轮式里程计、视觉里程计和IMU数据通过扩展卡尔曼滤波（EKF）和无迹卡尔曼滤波（UKF）进行融合，构建了鲁棒的位姿估计系统。  
◆ 针对里程计的系统误差，结合使用了非线性优化、Levenberg-Marquardt等确定性方法以及遗传算法、粒子群等随机优化方法进行运动学校准，有效减少了系统误差和漂移。  
◆ 解决了在无法使用GPS、激光雷达等传统传感器的特殊工作环境（如钢筋混凝土立面）中的精确定位问题。  
该方案通过实物机器人实验详细验证了其校准方法和位估计算法的有效性与性能，为爬壁机器人在实际测量和维护任务中的高精度位姿感知提供了可靠的技术基础。</td></tr>
<tr><td>2025-09-03</td><td>IL-SLAM: Intelligent Line-assisted SLAM Based on Feature Awareness for Dynamic Environments</td><td>[2509.02972](http://arxiv.org/pdf/2509.02972)</td><td>本文提出了一种基于特征感知的智能线辅助动态SLAM系统IL-SLAM，其核心贡献在于解决了动态环境下特征管理的效率与质量问题。  
◆ 创新性地引入特征感知机制，动态评估现有点特征的充足性，仅在必要时激活线特征补充，避免盲目引入额外特征。  
◆ 通过选择性引入线特征，显著降低了计算开销，并有效减少了低质量特征和噪声的累积。  
◆ 在线特征使用策略上，允许其在跟踪、局部建图与回环检测中辅助提升初始位姿估计精度，但将其排除在全局优化之外，避免长期过程中的负面干扰。  
实验证明，该系统在TUM数据集上的ATE和RPE指标均优于ORB-SLAM3基线及其他动态SLAM与多特征方法，实现了性能与效率的平衡。</td></tr>
<tr><td>2025-09-02</td><td>Coral: A Unifying Abstraction Layer for Composable Robotics Software</td><td>[2509.02453](http://arxiv.org/pdf/2509.02453)</td><td>该论文提出了Coral，一个用于组合式机器人软件的统一抽象层，旨在解决机器人系统集成困难的核心问题。  
◆引入了一个更高层次的抽象层，在不修改底层代码的前提下实现软件组件的快速集成与协调。  
◆通过语义化约束集成过程，显著降低了配置复杂性，同时保持了对不同领域和任务的广泛适应性。  
◆与现有工具兼容而非替代，增强了组件复用性和系统可重构性。  
◆在复杂场景（如LiDAR SLAM和多机器人协作）中验证了其有效性，证明了其解决集成挑战的实用价值。  
◆开源发布Coral，提升了专家与非专家用户的可访问性，推动机器人软件开发的标准化与普及。</td></tr>
<tr><td>2025-09-02</td><td>Doctoral Thesis: Geometric Deep Learning For Camera Pose Prediction, Registration, Depth Estimation, and 3D Reconstruction</td><td>[2509.01873](http://arxiv.org/pdf/2509.01873)</td><td>该论文的核心贡献是提出了一种结合几何先验与深度学习的几何深度学习框架，以解决三维视觉中的关键任务。  
◆ 开发了针对相机位姿估计、点云配准、深度预测和三维重建的几何深度学习方法，克服了传统方法在非结构化环境中特征模糊的局限性。  
◆ 通过将深度信息、表面法线和等变约束等几何先验融入深度学习模型，增强了几何表示的准确性和鲁棒性。  
◆ 系统研究了三维视觉的关键组成部分，并验证了其在数字文化遗产保护和沉浸式VR/AR等实际应用中的有效性。  
◆ 解决了三维数据高维性和标注数据稀缺带来的训练挑战，推动了传统几何技术与深度学习能力的融合。  
该研究为生成具有几何感知的深度学习模型提供了系统解决方案，促进了三维映射技术和场景重建管道的发展。</td></tr>
<tr><td>2025-09-01</td><td>ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association</td><td>[2509.01584](http://arxiv.org/pdf/2509.01584)</td><td>ViSTA-SLAM是一个无需已知相机内参即可实时运行的单目视觉SLAM系统，其核心贡献在于通过一个轻量化的对称式双视图关联模型显著提升了系统性能与适用性。

◆ 提出一种轻量级对称双视图关联（STA）前端模型，仅需两张RGB图像即可同时估计相对相机位姿并回归局部点云地图。
◆ 该前端设计极大降低了模型复杂度，其模型大小仅为同类先进方法的35%，同时生成了更高质量的双视图约束用于后续优化。
◆ 后端构建了一个特殊的Sim(3)位姿图，通过融入回环检测来有效处理累积的尺度漂移问题。
◆ 整个系统不依赖相机内参，使其能够广泛适用于各种不同的相机设置，具备了很强的通用性。
实验结果表明，该系统在相机跟踪精度和稠密三维重建质量上均优于当前主流方法。</td></tr>
<tr><td>2025-09-01</td><td>FGO-SLAM: Enhancing Gaussian SLAM with Globally Consistent Opacity Radiance Field</td><td>[2509.01547](http://arxiv.org/pdf/2509.01547)</td><td>FGO-SLAM的核心贡献是提出了一种基于全局一致不透明度辐射场的新型高斯SLAM系统，显著提升了场景几何重建的质量和系统的鲁棒性。其创新点主要体现在：

◆采用不透明度辐射场作为场景表示，有效增强了系统的几何建图性能。
◆在初始位姿估计后，引入全局调整优化策略，同时优化相机位姿和稀疏点云，确保了鲁棒且精确的跟踪。
◆维护了一个基于3D高斯且全局一致的不透明度辐射场，并引入了深度失真和法向一致性约束来精细化场景表示。
◆通过构建四面体网格并提取等值面，实现了直接从3D高斯中提取表面，简化了表面重建流程。
实验表明，该方法在多个真实和大型合成数据集上均实现了最先进的跟踪精度和建图性能。</td></tr>
<tr><td>2025-09-01</td><td>SR-SLAM: Scene-reliability Based RGB-D SLAM in Diverse Environments</td><td>[2509.01111](http://arxiv.org/pdf/2509.01111)</td><td>SR-SLAM提出了一种基于场景可靠性的RGB-D SLAM框架，旨在提升视觉SLAM系统在多样化环境中的精度与鲁棒性。其核心创新在于引入统一的环境感知与可靠性评估机制，通过多指标和历史观测动态指导系统行为。具体贡献包括：
◆提出自适应动态区域选择方法，结合灵活几何约束以提升动态目标识别能力。
◆开发深度辅助的自适应聚类算法，在高维环境下高效剔除动态特征点。
◆设计可靠性感知的位姿优化策略，在特征不足时动态融合直接法以提升估计稳定性。
◆提出基于可靠性的关键帧选择与加权优化方案，在保证精度的同时显著降低计算开销。
实验证明该系统在公开数据集和真实场景中优于现有动态SLAM方法，精度和鲁棒性提升最高达90%。</td></tr>
<tr><td>2025-08-31</td><td>DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments</td><td>[2509.00741](http://arxiv.org/pdf/2509.00741)</td><td>DyPho-SLAM是一种能够在动态环境中实时运行的视觉SLAM系统，其核心贡献是解决了动态物体干扰导致的相机跟踪漂移和地图模糊问题，并实现了高保真的密集地图重建。

◆ 率先将高斯泼溅表示（Gaussian Splatting）用于动态环境SLAM，实现了实时且资源高效的光电真实感建图。
◆ 创新地整合先验图像信息来生成精细化掩码，有效减少了因动态物体误判而产生的噪声。
◆ 设计了自适应的特征提取策略，在移除动态障碍物后为系统优化增强了约束，显著提升了整个系统的鲁棒性。
实验表明，该系统在公开动态RGB-D数据集上实现了最先进的相机位姿估计和地图重建精度。</td></tr>
<tr><td>2025-08-30</td><td>AGS: Accelerating 3D Gaussian Splatting SLAM via CODEC-Assisted Frame Covisibility Detection</td><td>[2509.00433](http://arxiv.org/pdf/2509.00433)</td><td>该论文提出了AGS，一个算法-硬件协同设计框架，旨在显著加速基于3D高斯泼溅的SLAM系统。其核心创新点在于充分利用了SLAM流式处理中相邻帧的高相似性。  
◆ 在软件层面，提出了一种根据机器人运动进行先粗后精的位姿跟踪方法。  
◆ 通过在帧间共享高斯点的贡献信息，避免了大量冗余计算。  
◆ 在硬件层面，创新地利用视频编解码器提取中间数据，设计了一个帧共视性检测引擎。  
◆ 还实现了配备工作负载调度器的位姿跟踪引擎和建图引擎，以高效部署整个AGS算法。  
最终，AGS相比现有方案在移动GPU、高端GPU及专用加速器上分别实现了最高17.12倍、6.71倍和5.41倍的加速。</td></tr>
<tr><td>2025-08-29</td><td>The Rosario Dataset v2: Multimodal Dataset for Agricultural Robotics</td><td>[2508.21635](http://arxiv.org/pdf/2508.21635)</td><td>本文介绍了专为农业机器人设计的Rosario v2多模态数据集，其核心贡献在于为复杂农田环境下的算法开发提供了全面基准。主要创新点包括：  
◆ 提供超过两小时的多模态传感器数据，涵盖红外/彩色相机、IMU、多模式GNSS和轮式里程计，硬件级同步确保数据一致性。  
◆ 精准捕捉农业场景典型挑战：光照突变、运动模糊、颠簸地形及长距离视觉相似路径，高度还原真实作业困难。  
◆ 提供六自由度真值轨迹和闭环检测所需的长路径循环，满足多模态SLAM系统严格评测需求。  
◆ 通过运行主流SLAM算法并揭示其在农业场景中的局限性，验证了数据集的实用性和挑战性。  
该数据集公开可用，显著推动了农业机器人定位、建图与导航算法的研发和性能评估。</td></tr>
<tr><td>2025-08-28</td><td>Adam SLAM - the last mile of camera calibration with 3DGS</td><td>[2508.20526](http://arxiv.org/pdf/2508.20526)</td><td>该论文提出了一种利用3D高斯散射（3DGS）优化相机标定的新方法。  
◆ 创新性地通过3DGS模型的反向传播，利用新视角颜色损失对相机参数进行端到端精细优化。  
◆ 解决了相机标定中1像素误差对重建质量产生显著影响的关键问题，直接提升了新视角合成质量。  
◆ 在3DGS基准数据集上平均带来0.4 dB PSNR的性能提升，显著优于传统标定方法。  
◆ 虽然优化过程耗时较长，但为参考场景（如Mip-NeRF 360）的标定提供了以质量为优先的解决方案。  
该方法尤其适用于对标定精度要求极高的高质量新视图合成任务。</td></tr>
<tr><td>2025-08-24</td><td>SEER-VAR: Semantic Egocentric Environment Reasoner for Vehicle Augmented Reality</td><td>[2508.17255](http://arxiv.org/pdf/2508.17255)</td><td>SEER-VAR提出了一种面向车辆增强现实（AR）的语义自中心环境推理框架，其核心贡献与创新点如下：

◆ 采用深度引导的视觉-语言 grounding 技术，动态分离车内与车外场景，突破了传统静态或单视角设定的限制。  
◆ 设计了上下文感知的SLAM分支（CASB），通过双路SLAM系统分别稳健地跟踪不同场景下的自中心运动。  
◆ 引入基于GPT的大语言模型模块，生成上下文感知的AR叠加内容，如仪表盘提示和危险预警。  
◆ 构建并开源EgoSLAM-Drive真实世界数据集，提供多场景同步的自中心视图、6DoF真值位姿与AR标注，支持系统评估。  
实验表明，该系统在多种环境下实现了精确的空间对齐与感知一致的AR渲染，并通过用户研究验证了其在场景理解、信息相关性和驾驶体验方面的显著提升。</td></tr>
<tr><td>2025-08-24</td><td>VROOM - Visual Reconstruction over Onboard Multiview</td><td>[2508.17172](http://arxiv.org/pdf/2508.17172)</td><td>VROOM提出了一种仅依靠F1赛车的车载摄像头视频来重建赛道3D模型的系统。其核心创新在于解决了极端高速运动和视频帧剧烈切换带来的挑战。
◆ 首创了基于F1赛车车载单目视频进行大规模赛道4D重建的可行方案。
◆ 设计了一套结合DROID-SLAM、AnyCam和Monst3r等多种方法的处理流程，并针对动态场景进行优化。
◆ 采用了包括掩码、时间分块和分辨率缩放等预处理技术，以应对动态模糊和计算资源限制。
实验证明，该系统能在摩纳哥站等复杂环境中部分恢复赛道和车辆轨迹，验证了该方法的可行性，为实景 scalable 4D重建提供了新思路。</td></tr>
<tr><td>2025-08-23</td><td>DualReg: Dual-Space Filtering and Reinforcement for Rigid Registration</td><td>[2508.17034](http://arxiv.org/pdf/2508.17034)</td><td>本文提出了一种新颖的双空间刚性配准方法DualReg，有效结合了基于特征匹配和局部几何匹配的优势。  
◆ 创新性地引入双空间范式，分别处理大变换差异的初始对齐和精细局部配准，克服了单一方法的局限性。  
◆ 设计了高效过滤机制，采用轻量级单点RANSAC算法和细化模块快速剔除不可靠的特征对应点，提升计算效率。  
◆ 提出将过滤后的对应点作为锚点，提取几何代理并构建优化目标函数，配合定制求解器实现高精度变换估计。  
实验表明，该方法在KITTI数据集上达到与MAC相当精度的同时，CPU计算速度提升高达32倍，显著优于现有方法。</td></tr>
<tr><td>2025-08-23</td><td>A Workflow for Map Creation in Autonomous Vehicle Simulations</td><td>[2508.16856](http://arxiv.org/pdf/2508.16856)</td><td>本文针对自动驾驶仿真中高精度地图创建困难且成本高昂的问题，提出了一种创新的地图制作工作流。  
◆ 设计了一个定制化流程，显著简化了仿真就绪地图的创建，降低了资源消耗。  
◆ 以CARLA等主流仿真器为背景，但避免了对其特定依赖，提升了方法的通用性和灵活性。  
◆ 通过生成加拿大安大略理工大学停车场的3D地图实例，验证了工作流的可行性与有效性。  
未来工作将集成SLAM技术并优化经纬度处理，以进一步提升精度和兼容性。</td></tr>
<tr><td>2025-08-22</td><td>COSMO-Bench: A Benchmark for Collaborative SLAM Optimization</td><td>[2508.16731](http://arxiv.org/pdf/2508.16731)</td><td>该论文的核心贡献是设计并发布了首个专门用于评估多机器人协同SLAM（C-SLAM）优化算法的基准测试套件COSMO-Bench，以解决该领域缺乏标准评估工具的问题。
◆ 首次构建了一个专注于多机器人协同SLAM后端优化算法的标准化评测基准。
◆ 提供了24个高质量数据集，这些数据源自真实世界的LiDAR数据和最先进的C-SLAM前端处理结果，确保了数据的真实性和挑战性。
◆ 填补了多机器人SLAM研究缺乏统一、公认评估标准的空白，为不同算法的公平比较提供了平台。
◆ 所有数据集均已开源，旨在促进该研究领域的协作、复现与发展。</td></tr>
<tr><td>2025-08-22</td><td>GPL-SLAM: A Laser SLAM Framework with Gaussian Process Based Extended Landmarks</td><td>[2508.16459](http://arxiv.org/pdf/2508.16459)</td><td>本文提出了一种基于高斯过程地标的新型激光SLAM框架GPL-SLAM。其核心创新点包括：
◆ 采用高斯过程对环境中物体的轮廓进行建模，替代传统的栅格地图或点云配准方法。
◆ 提出在线递归更新方案，能够高效更新地标轮廓并显著减少内存使用。
◆ 在完全贝叶斯框架下形式化SLAM问题，实现了机器人位姿与物体地图的联合推理。
◆ 提供语义信息输出，如物体数量和面积，并支持概率测量的物体关联。
◆ 通过高斯过程生成物体形状的置信边界，为安全导航和探索等下游任务提供关键信息。实验证明该方法在多种结构化环境中能实现精确的定位与建图。</td></tr>
<tr><td>2025-08-21</td><td>GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System</td><td>[2508.15990](http://arxiv.org/pdf/2508.15990)</td><td>GelSLAM提出了一种仅依靠触觉感知即可实现实时三维SLAM的系统，用于长时间估计物体位姿并高精度重建物体形状。  
◆ 创新性地利用触觉衍生的表面法线和曲率信息进行位姿跟踪与回环检测，替代了传统的点云方法。  
◆ 实现了实时低误差、低漂移的运动跟踪能力，即使对于木质工具等低纹理物体也能保持稳定。  
◆ 能够以亚毫米级精度重建物体形状，达到高保真度的几何复原效果。  
◆ 将触觉感知从局部接触扩展至全局长时序空间感知，为高精度操作任务提供了新基础。  
该系统在遮挡环境下表现优异，弥补了视觉方法的不足，适用于手内操作等精密交互场景。</td></tr>
<tr><td>2025-08-19</td><td>SLAM-based Safe Indoor Exploration Strategy</td><td>[2508.14235](http://arxiv.org/pdf/2508.14235)</td><td>该论文提出了一种基于SLAM的室内安全探索策略，主要面向具有圆形轮廓的非完整移动机器人。其核心贡献在于将安全性作为最高优先级，并设计了相应的探索与路径规划方法。

◆ 针对非完整圆形机器人系统（双轮差速驱动），提出专用探索策略，而非假设理想点机器人模型。
◆ 采用多传感器融合方案，结合IMU、3D-LiDAR进行RTAB-SLAM，并用RGB-D相机进行回环检测，提高了建图与定位的稳定性。
◆ 提出“安全骨架”路径规划方法，使机器人在探索过程中始终尽可能远离静态障碍物，极大提高了安全性。
◆ 探索策略以安全避障为首要目标，其次才是未知区域探索，导向空间中的开放区域进行前进。
◆ 通过ROS移动机器人平台进行了实验验证，展示了完整的实时路径规划与探索过程。</td></tr>
<tr><td>2025-08-19</td><td>Online 3D Gaussian Splatting Modeling with Novel View Selection</td><td>[2508.14014](http://arxiv.org/pdf/2508.14014)</td><td>该论文针对仅使用RGB图像进行在线3D高斯泼溅建模的挑战，提出了一种创新解决方案。其核心贡献在于通过自适应视图选择显著提升了在线重建模型的完整性。

◆ 提出了自适应新颖视图选择机制，在线分析重建质量并动态选择最优的非关键帧进行补充训练。
◆ 突破了传统方法仅依赖关键帧的局限，通过融合关键帧和精选的非关键帧，从多样化视角细化不完整区域。
◆ 设计了一个集成在线多视图立体视觉的框架，确保整个3D高斯泼溅建模过程中三维信息的一致性。
◆ 实现了在在线处理的严格限制下（无法使用大量帧或过多训练迭代），仍能构建高质量通用模型的目标。
实验结果表明，该方法在复杂户外场景中优于现有最先进技术，实现了卓越的性能表现。</td></tr>
<tr><td>2025-08-19</td><td>ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments</td><td>[2508.13488](http://arxiv.org/pdf/2508.13488)</td><td>该论文提出了一种用于重复环境下回环闭合验证的鲁棒方法ROVER，其核心创新在于利用历史轨迹先验约束来识别错误回环。  
◆ 首次将机器人时空运动轨迹作为先验知识引入回环验证框架，突破传统仅依赖外观特征的局限性。  
◆ 提出通过位姿图优化生成候选回环的轨迹假设，并设计评分机制评估其与原始轨迹先验的一致性。  
◆ 在高度重复环境中能有效拒绝虚假回环，解决了外观相似性导致的误检测难题。  
实验表明该方法在公开数据集和真实场景中均显著提升验证准确性，且可无缝集成至现有SLAM系统增强鲁棒性。</td></tr>
<tr><td>2025-08-14</td><td>Super LiDAR Reflectance for Robotic Perception</td><td>[2508.10398](http://arxiv.org/pdf/2508.10398)</td><td>◆ 提出了一种创新框架，能够从稀疏扫描数据生成高密度的LiDAR反射率图像，解决了低成本LiDAR因数据稀疏性导致的应用受限问题。  
◆ 针对非重复扫描LiDAR（NRS-LiDAR）的特性，设计了专用的反射率图像稠密化网络，显著提升了稀疏数据的利用率。  
◆ 攻克了反射率校准和从静态场景到动态场景迁移的关键技术难题，实现了真实场景下的稠密反射率图像重建。  
◆ 构建了一个全面的LiDAR反射率图像稠密化数据集，为后续研究提供了重要基础。  
◆ 展示了稠密反射率图像在机器人感知任务中的多样化应用，如闭环检测和交通车道识别，验证了其实际价值。  
◆ 通过主动光学传感重新定义视觉边界，推动了主动视觉新范式的发展。</td></tr>
<tr><td>2025-08-12</td><td>Transient Noise Removal via Diffusion-based Speech Inpainting</td><td>[2508.08890](http://arxiv.org/pdf/2508.08890)</td><td>◆ 提出PGDI框架，首次将扩散模型应用于语音修复任务，能精准重建长达1秒的缺失或严重损坏语音段。  
◆ 突破传统方法限制，在保持说话人身份、韵律和环境特征（如混响）的同时，有效处理说话人差异和长间隙问题。  
◆ 创新性引入分类器引导机制，特别是音素级引导策略，显著提升重建保真度。  
◆ 实现与说话人无关的鲁棒修复，即使语音段被强烈瞬态噪声（如烟花、摔门声）完全遮蔽仍能稳定工作。  
◆ 通过大量实验验证模型优越性，证明其在无文本转录条件下仍保持高效，有文本辅助时性能进一步提升。  
◆ 针对实际噪声场景（施工噪音、敲击声等）设计解决方案，推动语音修复技术的现实应用。</td></tr>
<tr><td>2025-08-09</td><td>EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events</td><td>[2508.07003](http://arxiv.org/pdf/2508.07003)</td><td>EGS-SLAM的核心贡献在于通过融合事件相机数据与RGB-D输入，显著提升了动态模糊场景下的SLAM性能。具体创新点包括：

◆ 提出首个结合事件数据与RGB-D输入的GS-SLAM框架，有效解决传统方法在严重运动模糊下的性能退化问题。

◆ 创新性地建模相机曝光期间的连续运动轨迹，实现事件感知与模糊感知的联合跟踪与三维高斯泼溅建图。

◆ 设计可学习的相机响应函数，动态对齐事件流与RGB图像的亮度范围差异。

◆ 引入无事件损失函数，有效抑制重建过程中的振铃伪影。

◆ 构建包含合成与真实场景的新数据集，验证方法在极端运动模糊条件下的优越性。

实验表明，该系统在轨迹精度和三维重建质量上均超越现有GS-SLAM方法，为高动态场景提供了鲁棒的解决方案。</td></tr>
<tr><td>2025-08-07</td><td>Speech LLMs in Low-Resource Scenarios: Data Volume Requirements and the Impact of Pretraining on High-Resource Languages</td><td>[2508.05149](http://arxiv.org/pdf/2508.05149)</td><td>◆ 首次系统研究了语音大模型(Speech LLMs)在低资源自动语音识别(ASR)场景下的数据量需求，填补了该领域研究空白。  
◆ 提出基于SLAM-ASR框架的轻量级可训练投影器方案，有效连接语音编码器与大语言模型，适配低资源条件。  
◆ 量化分析了达到Whisper模型性能所需的最低训练数据量，实证揭示了数据稀缺带来的核心挑战。  
◆ 创新性发现：利用高资源语言预训练的单一/多语言投影器能显著缓解数据不足问题，特别在小规模训练集时效果突出。  
◆ 通过EuroLLM和Salamandra等多语言大模型与whisper-large-v3-turbo的组合实验，为低资源多语言语音处理提供了新优化思路。  
◆ 在多个公开基准测试上的实验结果，为未来低资源语音大模型研究提供了重要设计参考和方法论指导。</td></tr>
<tr><td>2025-08-06</td><td>Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline</td><td>[2508.04597](http://arxiv.org/pdf/2508.04597)</td><td>◆ 提出了一种基于3D高斯映射的RGB SLAM方法，通过结合深度估计器和3D高斯技术，解决了传统方法在长序列处理中的性能瓶颈问题。  
◆ 引入前馈循环预测模块，直接从光流推断相机位姿，替代了耗时的测试时优化，将跟踪速度提升90%以上。  
◆ 设计了局部图渲染技术，增强了前馈位姿预测的鲁棒性，提高了系统在复杂场景中的稳定性。  
◆ 在Replica和TUM-RGBD数据集上的实验表明，该方法性能与当前最优的SplaTAM相当，同时大幅降低了计算开销。  
◆ 通过实际部署验证了方法的实用性，展示了其在实时3D重建中的高效性和准确性。</td></tr>
<tr><td>2025-08-05</td><td>Inland-LOAM: Voxel-Based Structural Semantic Mapping for Inland Waterways</td><td>[2508.03672](http://arxiv.org/pdf/2508.03672)</td><td>◆ 提出Inland-LOAM框架，针对内河航道环境优化LiDAR SLAM，解决传统方法在垂直漂移和语义缺失方面的不足。  
◆ 改进特征提取方法并引入水面平面约束，有效抑制SLAM系统的垂直漂移问题，提升定位精度。  
◆ 创新性地通过体素化几何分析将3D点云转化为结构化2D语义地图，实时计算桥梁净空等关键导航参数。  
◆ 开发自动化模块提取岸线轮廓，并输出轻量化、兼容国际电子航道图（IENC）的标准格式。  
◆ 在真实航道数据集上验证，定位精度超越现有先进方法，生成的语义地图与岸线数据符合实际场景需求。  
◆ 公开代码与数据集，为内河自主航行提供可靠的环境感知与地理信息支持。</td></tr>
<tr><td>2025-08-04</td><td>A Moment Matching-Based Method for Sparse and Noisy Point Cloud Registration</td><td>[2508.02187](http://arxiv.org/pdf/2508.02187)</td><td>◆ 提出基于矩匹配的点云配准框架，将点云视为同分布独立样本，通过匹配广义高斯径向基矩估计刚体变换，避免传统方法对显式点对点对应关系的依赖。  
◆ 在理论层面证明了该方法的数学一致性，为算法有效性提供理论支撑。  
◆ 针对稀疏和强噪声场景设计解决方案，显著提升了ICP、NDT等传统方法在此类恶劣条件下的配准鲁棒性。  
◆ 实验验证表明，该方法在合成与真实数据集上均实现更高精度，尤其在4D雷达SLAM系统中达到与激光雷达系统相当的定位性能。  
◆ 首次将矩匹配技术系统性地应用于点云配准领域，为稀疏噪声环境下的机器人感知任务开辟新思路。</td></tr>
<tr><td>2025-08-04</td><td>AID4AD: Aerial Image Data for Automated Driving Perception</td><td>[2508.02140](http://arxiv.org/pdf/2508.02140)</td><td>◆ 提出AID4AD数据集，首次将高分辨率航拍图像与nuScenes自动驾驶数据集的空间坐标系精确对齐，填补了航拍数据在自动驾驶感知任务中的空白。  
◆ 开发了一套基于SLAM点云地图的对齐流程，通过定位和投影失真校正技术确保空间保真度，并人工筛选高质量对齐样本作为基准真值。  
◆ 验证了航拍图像在自动驾驶两大核心任务中的价值：在线地图构建中作为补充输入提升15-23%精度，运动预测中替代高精地图实现2%性能提升。  
◆ 揭示了航拍图像作为可扩展环境上下文源的潜力，尤其适用于高精地图缺失、过时或维护成本高的场景。  
◆ 开源数据集、评估代码与预训练模型，为后续研究提供标准化基准（https://github.com/DriverlessMobility/AID4AD）。</td></tr>
<tr><td>2025-08-01</td><td>CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry</td><td>[2508.00568](http://arxiv.org/pdf/2508.00568)</td><td>◆ 提出CoProU-VO方法，首次将跨帧不确定性传播与融合引入无监督单目视觉里程计，通过概率化建模结合当前帧与参考帧的不确定性。  
◆ 设计端到端框架，基于视觉Transformer主干网络，同步学习深度、不确定性估计和相机位姿，无需动态物体显式标注。  
◆ 创新性地利用投影机制将参考帧不确定性传递至目标帧，有效识别动态场景中的不可靠区域，突破传统单帧不确定性建模的局限。  
◆ 在KITTI和nuScenes数据集上显著超越现有无监督单目两帧方法，尤其在动态物体密集的高速公路场景表现突出。  
◆ 通过详实的消融实验验证跨帧不确定性传播的有效性，为动态环境下的鲁棒位姿估计提供新思路。</td></tr>
<tr><td>2025-07-31</td><td>The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking</td><td>[2508.00088](http://arxiv.org/pdf/2508.00088)</td><td>◆ 提出了Monado SLAM数据集，专门针对头戴式设备的视觉-惯性跟踪挑战，填补了现有数据集的不足。  
◆ 数据集包含真实场景下的高动态运动、动态遮挡、长时间跟踪等复杂情况，更贴近实际应用需求。  
◆ 覆盖了低纹理区域、恶劣光照条件和传感器饱和等现有数据集较少涉及的难点场景。  
◆ 数据来自多款虚拟现实头显设备，具有多样性和代表性，适用于头戴式传感器研究。  
◆ 采用CC BY 4.0许可协议公开数据集，促进视觉-惯性里程计（VIO）和SLAM技术的研发进步。  
◆ 通过真实场景数据暴露现有VIO/SLAM系统的不足，推动算法在复杂环境中的鲁棒性提升。</td></tr>
<tr><td>2025-07-31</td><td>Stereo 3D Gaussian Splatting SLAM for Outdoor Urban Scenes</td><td>[2507.23677](http://arxiv.org/pdf/2507.23677)</td><td>◆ 提出了首个面向户外场景的双目3D高斯泼溅SLAM系统（BGS-SLAM），填补了现有3DGS-SLAM主要针对室内环境且依赖主动深度传感器的空白。  
◆ 仅使用RGB立体图像对，无需LiDAR或主动传感器，降低了硬件成本并提升了系统适用性。  
◆ 利用预训练深度立体网络的深度估计指导3D高斯优化，通过多损失策略同时提升几何一致性和视觉质量。  
◆ 在复杂户外环境中实现了优于其他基于3DGS方案的跟踪精度和建图性能。  
◆ 通过实验验证了系统在多个数据集上的优越性，为户外大规模场景的实时高保真SLAM提供了新解决方案。</td></tr>
<tr><td>2025-07-31</td><td>DRACo-SLAM2: Distributed Robust Acoustic Communication-efficient SLAM for Imaging Sonar EquippedUnderwater Robot Teams with Object Graph Matching</td><td>[2507.23629](http://arxiv.org/pdf/2507.23629)</td><td>◆ 提出DRACo-SLAM2框架，为配备多波束成像声纳的水下机器人团队设计分布式SLAM系统，改进原有DRACo-SLAM。  
◆ 创新性地将声纳地图表示为对象图，利用对象图匹配实现高效跨机器人回环检测，无需依赖先验几何信息。  
◆ 针对水下扫描匹配特点，提出增量式组间一致测量集最大化（GCM）方法，改进原有的PCM算法。  
◆ GCM方法有效处理相邻跨机器人回环共享相似配准误差的场景，提升匹配鲁棒性。  
◆ 通过大量仿真和真实数据集验证了所提方法的优越性，展示了其在实际应用中的有效性。</td></tr>
<tr><td>2025-07-31</td><td>GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting</td><td>[2507.23273](http://arxiv.org/pdf/2507.23273)</td><td>◆ 提出GSFusion系统，首次将激光雷达（LiDAR）、惯性测量单元（IMU）与视觉传感器融合，实现基于3D高斯泼溅（3DGS）的在线建图，解决了传统纯视觉方法在弱纹理、光照不足和远距离场景中的局限性。  
◆ 引入全局位姿图优化中的面元到面元（surfel-to-surfel）约束，显著提升地图的全局一致性，确保高精度建图质量。  
◆ 设计像素感知的高斯初始化策略，有效利用稀疏激光雷达数据快速生成高斯表示，大幅缩短优化时间。  
◆ 提出有界Sigmoid约束机制，防止高斯分布无限制扩张，提升场景表示的稳定性和渲染效率。  
◆ 在公开和自建数据集上的实验表明，该系统在渲染质量和建图效率上均优于现有3DGS SLAM方案，尤其在复杂环境中表现突出。</td></tr>
<tr><td>2025-07-30</td><td>Modality-Aware Feature Matching: A Comprehensive Review of Single- and Cross-Modality Techniques</td><td>[2507.22791](http://arxiv.org/pdf/2507.22791)</td><td>◆ 全面综述了单模态与跨模态特征匹配技术，涵盖RGB图像、深度图像、3D点云、LiDAR扫描、医学图像及视觉-语言交互等多种模态，填补了该领域系统性总结的空白。  
◆ 对比分析了传统手工方法（如Harris角点、SIFT和ORB描述子）与深度学习方法（如SuperPoint和LoFTR），指出后者在跨模态鲁棒性和适应性上的显著优势。  
◆ 重点介绍了模态感知技术进展，包括针对深度图像的几何与深度专用描述子、3D点云的稀疏与稠密学习方法、LiDAR扫描的注意力增强神经网络，以及医学图像匹配的MIND描述子等创新方案。  
◆ 深入探讨跨模态应用场景，如医学图像配准和视觉-语言任务，揭示了特征匹配技术处理多样化数据交互的最新发展趋势。  
◆ 强调检测器无关的深度学习方法（如基于CNN和Transformer的模型）对跨模态匹配性能的提升，为未来研究提供了重要方向。</td></tr>
<tr><td>2025-07-30</td><td>UAVScenes: A Multi-Modal Dataset for UAVs</td><td>[2507.22412](http://arxiv.org/pdf/2507.22412)</td><td>◆ 提出了首个支持多模态（相机图像和LiDAR点云）帧级标注的大规模无人机数据集UAVScenes，填补了现有数据集仅支持定位或地图级语义分割的空白。  
◆ 基于MARS-LVIG数据集进行升级，新增了人工标注的逐帧图像和点云语义标签，以及高精度6自由度位姿数据，显著提升了数据实用性。  
◆ 首次支持无人机场景下的多任务联合评测，包括分割、深度估计、6-DoF定位、地点识别和新视角合成（NVS）等高级感知任务。  
◆ 通过严格的传感器标定和同步，确保多模态数据的时间-空间对齐，为跨模态融合研究提供可靠基准。  
◆ 开源数据集并设计标准化评测协议，推动无人机多模态感知领域的算法发展和公平比较。</td></tr>
<tr><td>2025-07-29</td><td>Impact of Underwater Image Enhancement on Feature Matching</td><td>[2507.21715](http://arxiv.org/pdf/2507.21715)</td><td>◆ 提出了局部匹配稳定性和最远可匹配帧数两项量化指标，专门用于评估水下图像增强效果。  
◆ 针对水下环境特有的光吸收、散射、生物附着等退化问题，设计了面向增强技术的帧匹配性能评估框架。  
◆ 通过度量分析揭示了现有方法的优势与局限，首次指出其在真实场景适用性评估方面的不足。  
◆ 创新性地将实际匹配策略融入评估体系，建立了结合上下文感知的增强方法对比基准。  
◆ 通过SLAM系统的全流程验证，证实了视觉质量提升对水下自主导航算法的实际影响，强化了框架的工程价值。  
◆ 该研究填补了水下图像增强技术与下游任务性能关联性评估的空白，为算法优化提供了明确方向。</td></tr>
<tr><td>2025-07-29</td><td>Adaptive Prior Scene-Object SLAM for Dynamic Environments</td><td>[2507.21709](http://arxiv.org/pdf/2507.21709)</td><td>◆ 提出基于场景-物体的可靠性评估框架，通过当前帧质量指标和相对于可靠参考帧的场景变化，全面评估SLAM系统的稳定性。  
◆ 针对现有系统在姿态估计不可靠时缺乏纠错机制的问题，采用姿态优化策略，利用可靠帧信息优化相机位姿估计，有效减少动态干扰的负面影响。  
◆ 在动态环境中显著提升了定位精度和系统鲁棒性，特别是在视角突变和运动物体特征不明确的情况下表现优异。  
◆ 通过TUM RGB-D数据集的广泛实验验证，证明了该方法在挑战性动态场景中的优越性能。  
◆ 结合当前帧质量与场景变化评估，提供了一种更全面的动态环境SLAM稳定性判断方法。  
◆ 提出的姿态优化策略为动态环境下的SLAM系统提供了有效的误差校正机制。</td></tr>
<tr><td>2025-08-01</td><td>Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments</td><td>[2507.21553](http://arxiv.org/pdf/2507.21553)</td><td>◆ 提出了一种针对地下隧道环境的去中心化多机器人LiDAR SLAM系统，分析了现有技术的局限性。  
◆ 发现当前闭环检测存在大量误报问题，这是导致系统失败的主要原因。  
◆ 开发了一种新的启发式方法，有效减少了闭环检测中的误报情况。  
◆ 在地下隧道这一极具挑战性的环境中验证了所提方法的有效性。  
◆ 指出了该领域尚未充分探索的潜在研究方向，为未来工作提供了参考。</td></tr>
<tr><td>2025-07-28</td><td>$S^3$LAM: Surfel Splatting SLAM for Geometrically Accurate Tracking and Mapping</td><td>[2507.20854](http://arxiv.org/pdf/2507.20854)</td><td>◆ 提出S³LAM系统，采用2D面元（surfel）作为基本表示单元，替代传统3D高斯椭球体，实现更高效的场景几何建模。  
◆ 创新性地利用2D高斯面元进行场景表面重建，显著提升几何精度，同时优化跟踪与建图性能。  
◆ 设计自适应表面渲染策略，解决SLAM在有限视角下的实时优化问题，兼顾计算效率与建图准确性。  
◆ 直接从2D面元渲染公式推导相机位姿雅可比矩阵，凸显几何精确表示对跟踪收敛性的关键作用。  
◆ 在合成与真实数据集上验证了S³LAM的优越性，性能达到当前最优水平。</td></tr>
<tr><td>2025-07-28</td><td>Large-Scale LiDAR-Inertial Dataset for Degradation-Robust High-Precision Mapping</td><td>[2507.20516](http://arxiv.org/pdf/2507.20516)</td><td>◆ 提出首个大规模、高精度的LiDAR-惯性里程计（LIO）数据集，填补现有研究在复杂真实场景中验证不足的空白。  
◆ 数据集覆盖四种多样化真实环境（6万至75万平方米），通过定制背包式平台采集，集成多线激光雷达、工业级IMU和RTK-GNSS模块。  
◆ 提供长轨迹、复杂场景和高精度真值，结合SLAM优化与RTK-GNSS锚定技术生成，并通过倾斜摄影与RTK-GNSS融合验证轨迹精度。  
◆ 首次在数据集中融合多传感器冗余数据（如LiDAR-IMU-RTK），支持退化场景（如隧道、植被）下的鲁棒性评估。  
◆ 为高精度地图构建任务提供标准化基准，重点验证LIO系统在实际场景中的泛化能力与退化适应性。</td></tr>
<tr><td>2025-07-26</td><td>DOA: A Degeneracy Optimization Agent with Adaptive Pose Compensation Capability based on Deep Reinforcement Learning</td><td>[2507.19742](http://arxiv.org/pdf/2507.19742)</td><td>◆ 提出基于近端策略优化（PPO）的自适应退化优化智能体（DOA），通过深度强化学习解决SLAM在长直走廊等退化环境中的定位问题。  
◆ 设计系统性方法解决传统监督学习的三大挑战：退化数据集获取瓶颈、训练样本质量下降问题以及标注协议设计的模糊性。  
◆ 开发专用奖励函数，引导智能体学习退化环境感知能力，并基于退化因子动态调整不同传感器对位姿优化的贡献权重。  
◆ 提出线性插值公式控制观测分布向运动模型分布的偏移步长，实现位姿补偿的自适应调整。  
◆ 引入迁移学习模块提升智能体跨环境泛化能力，解决退化环境中训练效率低下的问题。  
◆ 通过消融实验验证模型设计合理性，并证明DOA在多种环境中优于现有方法的退化检测与优化性能。</td></tr>
<tr><td>2025-07-25</td><td>DINO-SLAM: DINO-informed RGB-D SLAM for Neural Implicit and Explicit Representations</td><td>[2507.19474](http://arxiv.org/pdf/2507.19474)</td><td>◆ 提出DINO-SLAM，一种基于DINO特征的设计策略，用于增强SLAM系统中神经隐式（NeRF）和显式（3DGS）表示的场景建模能力。  
◆ 设计场景结构编码器（SSE），将DINO特征升级为增强版EDINO，以捕捉场景的层次化元素及其结构关系。  
◆ 提出两种基于EDINO特征的基础范式，分别集成到NeRF和3DGS的SLAM系统中，提升场景表示的全面性。  
◆ 在Replica、ScanNet和TUM数据集上验证了方法的优越性，性能超越现有最先进技术。  
◆ 通过融合DINO特征，解决了传统SLAM系统在复杂场景中细节捕捉和结构关系建模的不足。</td></tr>
<tr><td>2025-07-25</td><td>The Eloquence team submission for task 1 of MLC-SLM challenge</td><td>[2507.19308](http://arxiv.org/pdf/2507.19308)</td><td>这篇论文针对MLC-SLM挑战赛任务1，提出了多语言会话语音识别的创新方法，核心贡献如下：

◆ 评估了官方基线模型的性能，通过训练线性投影器和qformer两种投影器，结合不同基础模型，系统分析了基线的优势与局限。

◆ 利用SLAM-ASR框架训练了自定义的多语言线性投影器，优化了模型在多语言场景下的适应性。

◆ 探索了对比学习在提升语音识别鲁棒性中的作用，通过对比学习机制增强了模型对多样化语音输入的识别能力。

◆ 研究了扩展会话上下文对识别效果的影响，验证了长上下文信息在改善会话语音识别性能方面的有效性。

◆ 综合三种方法，为构建更强大的多语言会话语音识别系统提供了实践指导和理论支持。</td></tr>
<tr><td>2025-07-25</td><td>SmartPNT-MSF: A Multi-Sensor Fusion Dataset for Positioning and Navigation Research</td><td>[2507.19079](http://arxiv.org/pdf/2507.19079)</td><td>◆ 提出SmartPNT-MSF多源融合数据集，整合GNSS、IMU、光学相机和激光雷达等多传感器数据，弥补现有数据集在传感器多样性上的不足。  
◆ 详细记录数据集构建过程，包括传感器配置、坐标系定义及相机与激光雷达标定流程，确保数据的一致性和可复现性。  
◆ 设计标准化数据采集与处理框架，支持大规模分析并具备可扩展性，为多传感器融合研究提供结构化基础。  
◆ 通过VINS-Mono、LIO-SAM等先进SLAM算法验证数据集的实用性，证明其适用于高精度导航与定位算法开发。  
◆ 覆盖城市、校园、隧道及郊区等多种真实场景，增强复杂环境下的导航技术研究能力，填补环境多样性空白。  
◆ 公开高质量数据集，促进导航领域算法测试与比较，推动多传感器融合技术的创新与发展。</td></tr>
<tr><td>2025-07-25</td><td>A Fast and Light-weight Non-Iterative Visual Odometry with RGB-D Cameras</td><td>[2507.18886](http://arxiv.org/pdf/2507.18886)</td><td>◆ 提出了一种解耦的非迭代视觉里程计方法，将6自由度位姿估计分为旋转和平移两步计算，避免了传统迭代优化带来的计算负担。  
◆ 利用场景中的重叠平面特征直接计算旋转矩阵，简化了旋转估计过程，提高了计算效率。  
◆ 采用核互相关器(KCC)计算平移量，省去了传统方法中特征提取与匹配的耗时步骤。  
◆ 整个流程无需迭代优化，在低端i5 CPU上实现了71Hz的高实时性能，显著提升了计算效率。  
◆ 不依赖特征点的特性使算法在低纹理或退化环境中表现优于现有先进方法，鲁棒性更强。  
◆ 通过分离旋转与平移估计并利用平面特征，在保持轻量级的同时实现了快速位姿估计。</td></tr>
<tr><td>2025-07-24</td><td>G2S-ICP SLAM: Geometry-aware Gaussian Splatting ICP SLAM</td><td>[2507.18344](http://arxiv.org/pdf/2507.18344)</td><td>◆ 提出了一种基于几何感知的高斯泼溅SLAM系统（G2S-ICP SLAM），通过将场景元素表示为局部切平面约束的高斯分布，实现高保真3D重建和实时相机位姿跟踪。  
◆ 创新性地将局部表面建模为与几何对齐的2D高斯圆盘，相比传统各向同性3D椭球表示，能更一致地处理多视角深度信息。  
◆ 将表面对齐的高斯圆盘嵌入广义ICP框架，通过引入各向异性协方差先验，在不改变配准公式的前提下提升几何一致性。  
◆ 提出几何感知损失函数，联合优化光度、深度和法向一致性，进一步提升重建和跟踪精度。  
◆ 系统在Replica和TUM-RGBD数据集上验证，在定位精度、重建完整性和渲染质量上均优于现有SLAM方法，同时保持实时性。</td></tr>
<tr><td>2025-07-23</td><td>Physics-based Human Pose Estimation from a Single Moving RGB Camera</td><td>[2507.17406](http://arxiv.org/pdf/2507.17406)</td><td>◆ 提出了首个非合成的真实数据集MoviCam，包含动态移动的单目RGB相机轨迹、场景几何和3D人体运动数据，并标注了人-场景接触信息，填补了现有数据集的空白。  
◆ 开发了PhysDynPose方法，首次将场景几何和物理约束整合到基于物理的人体姿态跟踪中，显著提升了移动相机和非平面场景下的跟踪精度。  
◆ 结合了先进运动学估计器和鲁棒SLAM技术，实现了世界坐标系下人体姿态与相机轨迹的同步恢复，解决了动态相机带来的参考系漂移问题。  
◆ 设计了场景感知的物理优化器，通过物理约束修正运动学估计结果，使姿态估计更符合真实物理规律。  
◆ 通过新基准测试发现，现有方法在移动相机和非平面场景下性能显著下降，而本方法在此挑战性场景中仍能稳定输出人体与相机位姿。  
◆ 为复杂真实场景（如不平地面、动态视角）的物理可信人体运动分析提供了新解决方案。</td></tr>
<tr><td>2025-07-23</td><td>CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance</td><td>[2507.17312](http://arxiv.org/pdf/2507.17312)</td><td>◆ 提出CasP新流程，通过级联对应先验引导半稠密特征匹配，改进传统全局搜索方式，提升精度和效率。  
◆ 将匹配过程分解为两个渐进阶段，中间引入基于区域的选择性交叉注意力机制，增强特征区分度。  
◆ 在第二阶段将搜索范围限制在第一阶段识别的一对多先验区域，实现一对一匹配的精确定位。  
◆ 结合高层特征降低低层特征提取计算成本，分辨率越高加速效果越显著（1152分辨率下比ELoFTR快2.2倍）。  
◆ 实验证明其在几何估计（尤其是跨域泛化）方面具有优越性，适用于SLAM、无人机等高实时性高鲁棒性场景。</td></tr>
<tr><td>2025-07-21</td><td>DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models</td><td>[2507.15716](http://arxiv.org/pdf/2507.15716)</td><td>◆ DiffPF首次将条件扩散模型融入粒子滤波框架，实现了高质量的后验采样，显著提升了状态估计精度。  
◆ 相比传统可微分粒子滤波依赖预定义或低容量提议分布，DiffPF通过条件扩散模型学习灵活的采样器，直接生成等权粒子。  
◆ 该方法能够从复杂、高维、多模态的滤波分布中进行精确采样，克服了传统方法在复杂分布下的局限性。  
◆ 在全局定位和KITTI视觉里程计等任务中，DiffPF分别以82.8%和26%的精度优势超越现有最优可微分滤波器。  
◆ 实验验证表明，DiffPF在单模态和多模态场景下均表现优异，为动态系统状态估计提供了新范式。</td></tr>
<tr><td>2025-07-21</td><td>Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images</td><td>[2507.15496](http://arxiv.org/pdf/2507.15496)</td><td>◆ 提出了一种新颖的LiDAR-视觉里程计框架，通过深度融合稀疏LiDAR点云和图像数据实现高精度位姿估计。  
◆ 创新性地利用深度补全技术生成稠密深度图，为运动估计提供更丰富的几何约束信息。  
◆ 设计了带注意力机制的多尺度特征提取网络，能够自适应生成深度感知的特征表示。  
◆ 采用稠密深度信息优化光流估计，有效减少了遮挡区域的误差累积问题。  
◆ 开发了分层位姿优化模块，通过渐进式运动估计提升动态环境和尺度模糊场景下的鲁棒性。  
实验证明该方法在KITTI数据集上达到了与当前最优视觉/LiDAR里程计相当或更优的精度和鲁棒性。</td></tr>
<tr><td>2025-07-21</td><td>All-UWB SLAM Using UWB Radar and UWB AOA</td><td>[2507.15474](http://arxiv.org/pdf/2507.15474)</td><td>◆ 提出了一种结合UWB雷达和UWB到达角（AOA）测量的新型SLAM方法，用于视觉受限且特征稀缺的环境。  
◆ 通过动态部署UWB锚点-标签单元，在环境特征不足的区域补充AOA测量数据，提升了SLAM的精度和可扩展性。  
◆ 解决了现有UWB雷达SLAM方法依赖环境特征数量的局限性，扩展了其在无特征环境中的应用能力。  
◆ 详细分析了UWB AOA测量单元的常见约束问题，并提出了相应的解决方案。  
◆ 实验证明，该方法在视觉受限且特征稀缺的环境中仍能有效实现SLAM，为恶劣条件下的自主系统提供了新思路。</td></tr>
<tr><td>2025-07-21</td><td>BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?</td><td>[2507.15321](http://arxiv.org/pdf/2507.15321)</td><td>◆提出BenchDepth新基准，通过五个下游代理任务（深度补全、立体匹配、单目3D场景重建、SLAM和视觉语言空间理解）评估深度基础模型（DFMs），突破传统评估局限。  
◆摒弃依赖对齐指标的固有方法，解决传统评估中因对齐偏差、深度表示偏好导致的不公平比较问题。  
◆首次从实际应用效用角度评估DFMs，强调模型在真实场景中的实用价值而非单纯指标分数。  
◆系统地对8种前沿DFMs进行横向对比，揭示关键发现，为模型优化提供实证依据。  
◆推动深度估计领域评估标准革新，引发社区对评估最佳实践的讨论，促进未来研究发展。</td></tr>
<tr><td>2025-07-20</td><td>LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM</td><td>[2507.15109](http://arxiv.org/pdf/2507.15109)</td><td>◆ 提出LoopNet，一种基于多任务学习的少样本学习方法，专门针对大规模SLAM中的闭环检测问题，兼顾精度与实时性需求。  
◆ 采用改进的ResNet多任务架构，支持动态视觉数据集的在线重训练，并针对嵌入式设备进行优化，适应实际部署场景。  
◆ 创新性结合少样本学习策略进行在线训练，解决传统方法在新环境中数据不足的问题，提升模型适应性。  
◆ 首次在闭环检测中同时输出场景索引和预测质量评估，增强系统可靠性，避免误匹配。  
◆ 利用DISK描述符替代传统手工特征或纯深度学习方法，在光照、视角变化等复杂条件下表现更优。  
◆ 开源了新型闭环检测数据集LoopDB，填补领域内标准化评估数据的空白，推动后续研究。</td></tr>
<tr><td>2025-07-19</td><td>Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey</td><td>[2507.14501](http://arxiv.org/pdf/2507.14501)</td><td>◆ 系统梳理了基于前馈式深度学习的3D重建与视图合成技术，首次提出按表示架构（如点云、3D高斯泼溅、神经辐射场等）的分类体系。  
◆ 重点分析了无姿态重建、动态3D重建、3D感知图像/视频合成等关键任务，拓展了在数字人、SLAM等领域的应用场景。  
◆ 对比传统迭代优化方法，突显前馈方法在实时性与泛化能力上的突破性进展，为AR/VR等实时应用提供新范式。  
◆ 全面汇总了主流数据集与评估协议，填补了该领域标准化评测工具的综述空白。  
◆ 指出动态场景建模、计算效率与表示能力平衡等开放挑战，为未来研究指明方向。</td></tr>
<tr><td>2025-07-17</td><td>DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model</td><td>[2507.13145](http://arxiv.org/pdf/2507.13145)</td><td>◆ 提出DINO-VO系统，首次将视觉基础模型DINOv2的鲁棒语义特征应用于单目视觉里程计（VO），解决了传统学习型VO在泛化性和鲁棒性上的不足。  
◆ 设计了一种针对DINOv2粗粒度特征的显著关键点检测器，克服了基础模型特征在VO任务中粒度不足的集成难题。  
◆ 结合DINOv2的语义特征与细粒度几何特征，生成更具局部化能力的混合特征表示，提升了位姿估计精度。  
◆ 采用基于Transformer的匹配器和可微分位姿估计层，通过端到端学习优化特征匹配与运动估计性能。  
◆ 在TartanAir、KITTI等数据集上超越传统帧间VO方法（如SuperPoint），并在室外驾驶场景中与视觉SLAM系统性能相当，同时保持72 FPS的高效实时性（GPU内存&lt;1GB）。  
◆ 实验证明DINOv2特征经改进后，其描述子精度和泛化能力显著优于原始粗粒度特征，尤其在光照变化、动态物体等复杂环境中表现突出。</td></tr>
<tr><td>2025-07-17</td><td>MoCap2GT: A High-Precision Ground Truth Estimator for SLAM Benchmarking Based on Motion Capture and IMU Fusion</td><td>[2507.12920](http://arxiv.org/pdf/2507.12920)</td><td>MoCap2GT提出了一种基于动作捕捉和IMU融合的高精度SLAM基准测试真值估计方法，核心贡献如下：

◆ 提出联合优化框架，融合MoCap数据和设备IMU测量值，显著提升轨迹真值的精度，解决了传统方法因时空标定误差和MoCap抖动导致的精度限制问题。

◆ 设计鲁棒的状态初始化器，确保全局收敛性，避免了优化过程中可能出现的局部最优问题。

◆ 引入SE(3)流形上的高阶B样条位姿参数化方法，并采用可变时间偏移建模，有效处理MoCap因素，提高了轨迹估计的准确性。

◆ 提出退化感知的测量剔除策略，能够识别并剔除不可靠的测量数据，进一步提升估计精度。

实验结果表明，MoCap2GT在精度上优于现有方法，为SLAM算法的全面评估提供了更可靠的基准真值。该方法开源可用，将促进SLAM研究社区的发展。</td></tr>
<tr><td>2025-07-17</td><td>Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot</td><td>[2507.12273](http://arxiv.org/pdf/2507.12273)</td><td>◆ 提出并实现了一款名为Alter-Ego的自主博物馆导览机器人，结合先进导航与交互功能，提升参观体验。  
◆ 首次将大型语言模型（LLMs）应用于博物馆场景，实现实时、情境感知的问答交互，支持游客与机器人就展品展开对话。  
◆ 采用鲁棒的SLAM技术，使机器人能在博物馆环境中自主导航，并根据用户需求动态调整导览路线。  
◆ 通过真实博物馆环境下的用户研究（34名参与者），验证了系统的可用性，结合对话质量分析与问卷调查量化评估效果。  
◆ 揭示了AI驱动机器人在文化空间中人机交互（HRI）的潜力与挑战，包括知识获取的促进与实际部署中的技术局限性。  
◆ 为公共服务机器人领域提供了兼具技术创新与实证研究的范例，推动复杂场景下自主系统的应用探索。</td></tr>
<tr><td>2025-07-16</td><td>Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards</td><td>[2507.12093](http://arxiv.org/pdf/2507.12093)</td><td>◆ 提出Tree-SLAM，一种专为果园环境设计的语义SLAM方法，解决传统SLAM在树木重复外观下易混淆的问题。  
◆ 结合RGB-D图像和实例分割模型，实现树干检测与定位，并通过级联图数据关联算法进行树干重识别。  
◆ 将重识别的树干作为地标，融合噪声GPS信号、里程计和树干观测数据，构建因子图框架，提升定位精度。  
◆ 系统在GPS信号不可靠时仍能保持高精度，单棵树的地理定位误差低至18厘米，低于种植间距的20%。  
◆ 在苹果园和梨园的不同季节数据集上验证了方法的准确性和鲁棒性，适用于精准农业中的目标操作和单树监测任务。</td></tr>
<tr><td>2025-07-11</td><td>Towards Robust Sensor-Fusion Ground SLAM: A Comprehensive Benchmark and A Resilient Framework</td><td>[2507.08364](http://arxiv.org/pdf/2507.08364)</td><td>◆ 提出M3DGR数据集：首个包含视觉干扰、激光雷达退化、轮式打滑和GNSS失效等系统性退化场景的多传感器基准数据集，填补了标准化评估工具的空白。  
◆ 对40种SLAM系统进行大规模评测：首次在多样化退化条件下全面分析现有算法的鲁棒性，揭示了实际应用中的关键性能瓶颈。  
◆ 开发Ground-Fusion++框架：创新性地融合GNSS、RGB-D、激光雷达、IMU和轮式里程计，通过模块化设计实现多传感器自适应选择。  
◆ 解决传感器动态适配问题：提出环境变化下的传感器优选策略，突破传统框架仅固定融合少数传感器的局限。  
◆ 公开代码与数据集：为后续研究提供可复现的实验平台和性能对比基准，推动领域发展。</td></tr>
<tr><td>2025-07-10</td><td>Hardware-Aware Feature Extraction Quantisation for Real-Time Visual Odometry on FPGA Platforms</td><td>[2507.07903](http://arxiv.org/pdf/2507.07903)</td><td>◆ 提出了一种基于量化SuperPoint卷积神经网络的嵌入式无监督架构，用于实时视觉里程计中的特征点检测与描述。  
◆ 通过硬件感知的模型量化技术（使用Brevitas库和FINN框架），在保证高检测质量的同时显著降低了计算需求。  
◆ 在AMD/Xilinx Zynq UltraScale+ FPGA平台上实现高效部署，利用深度学习处理单元（DPU）优化性能。  
◆ 实现了640×480分辨率图像54帧/秒的处理速度，优于当前同类先进解决方案。  
◆ 在TUM数据集上验证了不同量化技术对模型精度与性能的影响，为资源受限平台（如移动/嵌入式系统）提供了实用优化方案。</td></tr>
<tr><td>2025-07-10</td><td>IRAF-SLAM: An Illumination-Robust and Adaptive Feature-Culling Front-End for Visual SLAM in Challenging Environments</td><td>[2507.07752](http://arxiv.org/pdf/2507.07752)</td><td>◆ IRAF-SLAM提出了一种针对复杂光照环境的视觉SLAM前端框架，通过自适应机制提升系统鲁棒性。  
◆ 创新性地引入图像增强方案，动态预处理不同光照条件下的图像质量，改善特征提取基础。  
◆ 开发了基于图像熵、像素强度和梯度分析的自适应特征提取机制，根据环境动态调整检测灵敏度。  
◆ 提出新型特征筛选策略，结合密度分布分析和光照影响因子，有效过滤不可靠特征点。  
◆ 在TUM-VI和EuRoC数据集上的实验表明，该方法显著减少了跟踪失败率，并在恶劣光照下实现了优于现有方法的轨迹精度。  
◆ 整个系统在提升鲁棒性的同时保持了较低计算开销，为实际应用提供了可行解决方案。</td></tr>
<tr><td>2025-07-09</td><td>g2o vs. Ceres: Optimizing Scan Matching in Cartographer SLAM</td><td>[2507.07142](http://arxiv.org/pdf/2507.07142)</td><td>◆ 首次在Cartographer框架中对g2o和Ceres两种优化器进行了系统的扫描匹配性能对比分析。  
◆ 通过实验验证了Ceres作为Cartographer默认求解器在速度、收敛效率和地图清晰度上的全面优势。  
◆ 发现Ceres在真实场景（AgileX LIMO机器人）中表现更优，所需迭代次数更少且收敛更快。  
◆ 揭示了g2o在局部障碍物检测方面的特殊优势，为其在特定场景的应用价值提供了依据。  
◆ 为SLAM系统优化器选择提供了实证参考，指出不同优化器的适用场景差异。  
◆ 通过定量化指标（如迭代次数、收敛时间）对比，深化了对两种优化器性能特征的理解。</td></tr>
<tr><td>2025-07-08</td><td>Mapping the Catacombs: An Underwater Cave Segment of the Devil&#x27;s Eye System</td><td>[2507.06397](http://arxiv.org/pdf/2507.06397)</td><td>这篇论文的核心贡献是提出了一种低成本的水下洞穴测绘框架，并应用于佛罗里达州Ginnie Springs的Devil&#x27;s Eye洞穴系统。  

◆ 使用廉价运动相机结合潜水电脑，实现了水下洞穴轨迹估计和稀疏点云重建，降低了测绘成本。  
◆ 通过潜水电脑数据增强了视觉/惯性框架（SVIn2），实现了Z轴维度及横滚/俯仰角度的观测，弥补了纯视觉方法的不足。  
◆ 将SVIn2生成的关键帧与相机位姿作为输入，结合全局优化框架COLMAP，重建了局部区域的高密度三维模型。  
◆ 提出了一种洞穴通道的一维抽象表示方法，通过平均轨迹与边界（上下左右）描述洞穴轮廓。  
◆ 采用MNemo V2仪器进行人工测绘验证，证明了该方法的有效性，同时表明运动相机足以构建洞穴地图的基本要素。  
◆ 通过VI-SLAM与全局优化框架的协同，实现了选定区域的逼真密集三维重建，为水文地质和考古研究提供了新工具。</td></tr>
<tr><td>2025-07-08</td><td>Cooperative Mapping, Localization, and Beam Management via Multi-Modal SLAM in ISAC Systems</td><td>[2507.05718](http://arxiv.org/pdf/2507.05718)</td><td>◆ 提出了一种新颖的多模态SLAM框架，解决了协同多用户SLAM在ISAC系统中的理论建模和通信层集成不足的问题。  
◆ 开发了基于贝叶斯估计的协同多用户SLAM方法，并设计了两阶段算法，在动态异构感知条件下实现鲁棒的无线电地图构建。  
◆ 引入多模态定位策略，通过误差感知模型融合SLAM结果、摄像头多目标跟踪和IMU数据，显著提升了多用户场景下的UE定位精度。  
◆ 提出了感知辅助的波束管理方案，利用全局无线电地图和定位数据生成UE特定的先验信息，优化波束选择，降低用户间干扰并提升下行频谱效率。  
◆ 仿真结果表明，该系统将无线电地图精度提升高达60%，定位精度提高37.5%，在室内外环境中均显著优于传统方法。</td></tr>
<tr><td>2025-07-07</td><td>Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR</td><td>[2507.04662](http://arxiv.org/pdf/2507.04662)</td><td>◆ 提出利用毫米波5G NR系统进行主动感知，实现类似激光雷达的点云生成，克服了传统被动感知SLAM技术对镜面反射假设和简化地图表示的依赖。  
◆ 采用二进制搜索方法从每个波束方向的功率延迟剖面中提取点云数据，提高了环境感知的精度和细节。  
◆ 通过多个预定义目标点校准硬件延迟，确保点云数据的准确性，解决了硬件误差对定位的影响。  
◆ 利用点云配准算法从连续轨迹视角的点云数据中估计终端位姿变化，实现了高精度的终端定位。  
◆ 引入闭环检测和位姿图优化技术，进一步优化感知结果，实现了精确的终端定位和详细的无线电地图重建。  
◆ 通过仿真和实验验证了系统的有效性，为5G NR在SLAM领域的应用提供了实践支持。</td></tr>
<tr><td>2025-07-06</td><td>Lidar Variability: A Novel Dataset and Comparative Study of Solid-State and Spinning Lidars</td><td>[2507.04321](http://arxiv.org/pdf/2507.04321)</td><td>◆ 提出了首个包含穹顶式固态激光雷达（如Livox Mid-360）与其他固态及旋转式激光雷达（如Ouster系列）的综合数据集，填补了多类型激光雷达对比研究的空白。  
◆ 首次在无IMU支持的里程计场景下，系统评估了低成本固态激光雷达（Livox Avia/Mid-360）与高端旋转式激光雷达的性能差异。  
◆ 基于该数据集，对主流SLAM算法进行了跨传感器平台的基准测试，为异构激光雷达的定位与建图研究提供了标准化参考。  
◆ 针对点云配准技术，通过室内外实测数据定量比较了点对点、点对平面及混合方法的性能差异。  
◆ 研究结果为SLAM和3D重建领域在低成本固态激光雷达（尤其是穹顶式设计）的应用提供了数据支持与方法指导。  
◆ 数据集与基准测试框架为未来异构激光雷达系统的算法开发与性能优化奠定了基础。</td></tr>
<tr><td>2025-07-09</td><td>Gaussian-LIC2: LiDAR-Inertial-Camera Gaussian Splatting SLAM</td><td>[2507.04004](http://arxiv.org/pdf/2507.04004)</td><td>◆ 首次提出结合LiDAR-惯性-相机的3D高斯泼溅SLAM系统，同步优化视觉质量、几何精度和实时性能，实现高保真3D高斯地图的实时构建与RGB/深度渲染。  
◆ 针对LiDAR覆盖不足区域，采用轻量级零样本深度模型，融合RGB外观线索与稀疏LiDAR数据生成稠密深度图，显著提升稀疏LiDAR传感器的场景适用性。  
◆ 利用高精度稀疏LiDAR深度监督高斯地图优化，并通过定制CUDA加速策略提升效率，增强几何准确性。  
◆ 创新地将增量重建的高斯地图光度约束融入连续时间因子图优化，在LiDAR性能退化时提升位姿估计鲁棒性。  
◆ 扩展系统功能至下游应用（如视频帧插值与快速3D网格提取），并构建包含真值位姿、深度图和外推轨迹的多模态数据集，支持严格评估。  
◆ 在公开与自采数据集上验证系统对多种密度LiDAR的优越性，代码与数据集将开源。</td></tr>
<tr><td>2025-07-04</td><td>Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps</td><td>[2507.03737](http://arxiv.org/pdf/2507.03737)</td><td>◆ 提出S3PO-GS方法，首次实现基于RGB单目相机的户外全局尺度一致3D高斯点建图SLAM系统。  
◆ 设计自一致跟踪模块，以3D高斯点图为锚点，避免累积尺度漂移，实现更精准鲁棒的相机跟踪（迭代次数更少）。  
◆ 创新性提出基于分块的动态点图建图模块，引入几何先验知识的同时规避尺度歧义问题，显著提升复杂户外场景的跟踪精度和重建质量。  
◆ 通过融合几何先验与3DGS渲染优势，解决了现有方法在户外场景缺乏几何约束或依赖独立跟踪模块导致的尺度漂移问题。  
◆ 在Waymo、KITTI和DL3DV数据集上验证了方法的优越性，在新视角合成和跟踪精度上均超越现有3DGS SLAM方法。</td></tr>
<tr><td>2025-07-01</td><td>RaGNNarok: A Light-Weight Graph Neural Network for Enhancing Radar Point Clouds on Unmanned Ground Vehicles</td><td>[2507.00937](http://arxiv.org/pdf/2507.00937)</td><td>◆提出RaGNNarok，一种基于图神经网络（GNN）的轻量级框架，用于增强雷达点云数据，解决现有雷达定位中稀疏点云、噪声和误检测问题。  
◆该框架在低成本设备（如树莓派5）上实现实时处理，推理时间仅7.3毫秒，无需额外计算资源，适合资源受限的移动机器人。  
◆通过GNN模型优化雷达点云，显著提升在复杂动态环境中的性能，克服了传统激光雷达和相机在视觉遮挡环境中的局限性。  
◆在定位、SLAM和自主导航等关键任务中进行了多环境测试，验证了其高可靠性和泛化能力。  
◆为低成本室内移动机器人提供了一种经济高效的解决方案，结合毫米波雷达的低成本优势，推动自动化在家庭和商业空间的应用。</td></tr>
<tr><td>2025-07-01</td><td>Generation of Indoor Open Street Maps for Robot Navigation from CAD Files</td><td>[2507.00552](http://arxiv.org/pdf/2507.00552)</td><td>◆ 提出全自动系统，将建筑CAD文件转换为分层拓扑OpenStreetMap（OSM）表示，专为机器人终身导航设计，解决SLAM在动态大尺度室内环境中耗时、脆弱且易过时的问题。  
◆ 开发多阶段处理流程，从原始CAD数据中提取关键结构层，并基于AreaGraph进行拓扑分割，生成层次化可导航空间图，实现语义丰富的环境建模。  
◆ 自动关联CAD源文件中的文本标签，增强地图语义信息，同时支持多楼层无缝合并，构建拓扑正确的统一模型，提升导航鲁棒性。  
◆ 利用CAD文件固有的永久结构信息，规避SLAM的固有缺陷，为复杂室内场景提供高效、可扩展的解决方案。  
◆ 集成直观图形用户界面（GUI）封装软件，降低使用门槛，并开源代码和数据集促进社区应用与研究。</td></tr>
<tr><td>2025-06-30</td><td>VOCAL: Visual Odometry via ContrAstive Learning</td><td>[2507.00243](http://arxiv.org/pdf/2507.00243)</td><td>◆ VOCAL将视觉里程计（VO）重新定义为标签排序问题，突破了传统基于几何假设的局限，为数据驱动框架提供了新思路。  
◆ 通过结合贝叶斯推理与表征学习，该框架使视觉特征与相机状态对齐，提升了特征的可解释性。  
◆ 提出的排序机制迫使相似相机状态在潜在空间中形成一致且空间连贯的表征，增强了模型的鲁棒性。  
◆ 框架支持多模态数据融合，为复杂场景下的VO应用提供了灵活性。  
◆ 在KITTI数据集上的实验验证了VOCAL在可解释性和泛化性上的显著优势，推动了空间智能向更通用、可解释的方向发展。</td></tr>
<tr><td>2025-06-29</td><td>TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints</td><td>[2506.23207](http://arxiv.org/pdf/2506.23207)</td><td>TVG-SLAM是一种基于3D高斯泼溅（3DGS）的RGB-only SLAM系统，通过三视图几何约束提升鲁棒性和场景重建质量。其核心贡献和创新点如下：

◆ 提出三视图几何范式，通过密集三视图匹配模块聚合可靠的帧间对应关系，形成跨帧的鲁棒几何约束，解决传统方法依赖光度损失的局限性。

◆ 设计混合几何约束（Hybrid Geometric Constraints），结合三视图匹配的几何线索与光度损失，显著提升相机位姿估计的准确性和稳定性，尤其在视角突变和光照变化场景。

◆ 提出基于概率的初始化策略，将三视图对应关系的几何不确定性编码到新初始化的高斯模型中，提升映射质量。

◆ 引入动态渲染信任衰减机制（Dynamic Attenuation of Rendering Trust），有效缓解因建图延迟导致的跟踪漂移问题。

实验表明，TVG-SLAM在户外数据集上优于现有RGB-only 3DGS SLAM系统，在最挑战性数据集中将轨迹误差（ATE）降低69.0%，同时保持顶尖的渲染质量。</td></tr>
<tr><td>2025-06-29</td><td>Event-based Stereo Visual-Inertial Odometry with Voxel Map</td><td>[2506.23078](http://arxiv.org/pdf/2506.23078)</td><td>◆ 提出Voxel-ESVIO系统，结合事件相机和立体视觉惯性里程计，利用体素地图管理提升定位精度。  
◆ 采用基于体素的点选择方法，有效过滤事件流中的噪声，筛选高质量3D地图点。  
◆ 创新性地引入体素感知的点管理机制，动态优化每个体素内地图点的更新和选择。  
◆ 通过协同策略高效提取抗噪声且观测概率最高的地图点，确保状态估计的准确性。  
◆ 在三个公开数据集上的实验表明，该系统在精度和计算效率上均优于现有方法。</td></tr>
<tr><td>2025-06-26</td><td>Adaptive Multipath-Based SLAM for Distributed MIMO Systems</td><td>[2506.21798](http://arxiv.org/pdf/2506.21798)</td><td>◆ 提出了一种适用于分布式MIMO系统的自适应多路径SLAM方法，解决了传统方法在非凸几何环境中无法进行光线追踪的局限性。  
◆ 利用振幅统计量建立自适应时变检测概率，实现了&quot;软&quot;光线追踪策略，能够在非凸几何的射频环境中跨传播路径融合信息。  
◆ 通过将和积算法(SPA)的消息传递规则应用于所提出的统计模型因子图，建立了地图特征和智能体位置联合估计的贝叶斯估计方法。  
◆ 提出了一种改进的建议概率密度函数(PDF)，用于基于粒子的SPA消息计算，能够早期检测仅由双跳路径支持的新表面。  
◆ 在具有非凸几何形状的挑战性场景中使用合成射频测量验证了该方法，结果表明其能够提供准确的定位和建图估计，并达到后验CRLB界。</td></tr>
<tr><td>2025-06-24</td><td>Ark: An Open-source Python-based Framework for Robot Learning</td><td>[2506.21628](http://arxiv.org/pdf/2506.21628)</td><td>◆ 提出ARK框架，首个以Python为核心的机器人学习开源平台，弥合机器人技术与现代AI工具链的鸿沟。  
◆ 采用Gym风格接口设计，支持数据采集、预处理到策略训练的全流程，兼容仿真与实体机器人无缝切换。  
◆ 独创轻量级客户端-服务器架构，实现网络化发布-订阅通信，并保留C/C++绑定选项保障实时性能需求。  
◆ 内置控制、SLAM、运动规划等模块化组件，原生支持ROS交互，提供开箱即用的机器人功能套件。  
◆ 通过详实文档和案例（如操作与导航任务），验证其快速原型开发、硬件灵活切换及端到端流水线优势。  
◆ 统一Python生态与机器人开发，显著降低学习门槛，加速学术研究与商业场景的机器人自主性落地。</td></tr>
<tr><td>2025-06-26</td><td>EndoFlow-SLAM: Real-Time Endoscopic SLAM with Flow-Constrained Gaussian Splatting</td><td>[2506.21420](http://arxiv.org/pdf/2506.21420)</td><td>◆ 提出EndoFlow-SLAM系统，首次将光流损失作为几何约束引入基于3D高斯泼溅（3DGS）的SLAM框架，有效解决了内窥镜场景中非朗伯表面和呼吸运动导致的位姿估计问题。  
◆ 设计深度正则化策略，缓解内窥镜场景的光度不一致性问题，确保3DGS深度渲染的可靠性。  
◆ 改进3DGS优化策略，针对关键帧中渲染质量较差的视角进行重点优化，提升场景表示精度。  
◆ 在静态（C3VD数据集）和动态（StereoMIS数据集）手术场景中均实现领先性能，在新视角合成和相机位姿估计任务上超越现有方法。  
◆ 系统支持实时运行，为内窥镜手术提供高效的三维重建与可视化能力。</td></tr>
<tr><td>2025-06-26</td><td>CURL-SLAM: Continuous and Compact LiDAR Mapping</td><td>[2506.21077](http://arxiv.org/pdf/2506.21077)</td><td>◆ 提出了一种新型LiDAR SLAM范式CURL-SLAM，利用连续超紧凑表示（CURL）实现可更新、可定位的地图表示。  
◆ 采用球谐函数隐式编码技术，生成支持可变密度连续重建的紧凑3D地图，显著降低存储需求。  
◆ 通过独特的CURL定制优化问题重新定义LiDAR位姿估计，替代传统ICP方法，提升计算效率。  
◆ 扩展局部光束法平差（BA）技术，实现位姿精修与地图校正同步进行，确保闭环后的全局一致性。  
◆ 在CPU上达到10Hz实时性能，同时保持领先的3D建图质量和轨迹精度，适用于大规模场景。  
◆ 开源CURL-SLAM实现，推动连续紧凑地图表示领域的研究与应用。</td></tr>
<tr><td>2025-06-25</td><td>SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning</td><td>[2506.20394](http://arxiv.org/pdf/2506.20394)</td><td>◆ 提出首个在线语义信息更新框架SPARK，解决机器人任务执行中语义信息实时更新的空白问题。  
◆ 创新性地将离线场景图表示扩展到在线场景，提升动态环境下的语义信息处理能力。  
◆ 通过环境嵌入线索（如手势等非传统空间提示）实时更新场景图，增强机器人对动态环境的适应性。  
◆ 验证了基于图的空间关系表示能显著提升任务规划效率，尤其在非结构化场景中表现突出。  
◆ 系统整合几何与语义数据，为通用服务机器人提供更全面的在线信息更新解决方案。  
◆ 实验证明该框架能有效处理动态环境中的语义变化，为后续任务规划提供可靠支持。</td></tr>
<tr><td>2025-06-25</td><td>Real-Time Obstacle Avoidance Algorithms for Unmanned Aerial and Ground Vehicles</td><td>[2506.20311](http://arxiv.org/pdf/2506.20311)</td><td>◆ 开发了适用于复杂3D环境的实时避障算法，特别针对森林火灾等灾害场景中的无人机安全导航需求。  
◆ 提出了一种创新的2D融合导航策略，最初为地面移动机器人设计，具备动态环境中的安全移动能力，并支持自适应障碍处理与决策优化。  
◆ 首次设计了针对森林火灾模拟的3D反应式导航策略，解决了无人机在此类特殊场景中的避障难题。  
◆ 提出无人机与地面无人车（UGV）的协同控制框架，实现了空地车辆在森林救援任务中的统一协调作业。  
◆ 通过数学建模与仿真验证了各阶段算法的有效性，为自然灾害救援中无人系统的应用提供了兼具实用价值与学术意义的解决方案。</td></tr>
<tr><td>2025-06-24</td><td>Posterior Cramér-Rao Bounds on Localization and Mapping Errors in Distributed MIMO SLAM</td><td>[2506.19957](http://arxiv.org/pdf/2506.19957)</td><td>◆ 首次提出了针对分布式MIMO SLAM系统中镜面反射面定位与建图误差的后验克拉美罗下界（MEB），填补了该领域性能评估的理论空白。  
◆ 考虑了单次反射和双次反射的复杂传播场景，并支持分布式锚点配置，扩展了传统SLAM性能边界的适用范围。  
◆ 通过数值仿真验证了现有先进RF-SLAM算法的建图误差能渐进收敛至MEB，为算法性能评估提供了理论基准。  
◆ 创新性地将映射性能（镜面位置/朝向）与用户定位性能统一纳入全局特征评估框架，突破了传统仅关注定位精度的局限。  
◆ 所提边界理论可提升多径信道中非视距信号的利用效率，为通信-定位一体化系统设计提供理论支撑。</td></tr>
<tr><td>2025-06-23</td><td>GRAND-SLAM: Local Optimization for Globally Consistent Large-Scale Multi-Agent Gaussian SLAM</td><td>[2506.18885](http://arxiv.org/pdf/2506.18885)</td><td>◆ 提出了GRAND-SLAM方法，首次将3D高斯泼溅技术应用于大规模户外多智能体SLAM场景，突破了现有方法仅限于小规模室内环境的限制。  
◆ 设计了基于局部子地图优化的隐式跟踪模块，有效提升了多智能体系统的定位精度和鲁棒性。  
◆ 开发了机器人内/间闭环检测方法，并将其集成到位姿图优化框架中，实现了全局一致性的大规模场景重建。  
◆ 在Replica室内数据集上实现了当前最优的跟踪性能，PSNR指标比现有方法提升28%。  
◆ 在大型户外Kimera-Multi数据集上，多智能体跟踪误差降低91%，渲染质量显著优于现有方法。  
◆ 通过可扩展的环境表示方法，为多智能体协同快速探索与重建提供了新解决方案。</td></tr>
<tr><td>2025-06-23</td><td>MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation</td><td>[2506.18678](http://arxiv.org/pdf/2506.18678)</td><td>◆ 提出首个分布式多智能体协作神经SLAM框架MCN-SLAM，结合混合隐式神经场景表示，解决传统单智能体SLAM在大场景和长序列中的局限性。  
◆ 创新设计三平面-网格联合场景表示方法，显著提升场景重建质量，优于现有神经隐式表示方案。  
◆ 开发新型&quot;内部-跨智能体&quot;闭环检测机制，首次实现单智能体局部与多智能体全局一致性协同优化。  
◆ 提出在线蒸馏方法实现多子地图融合，通过分布式通信优化解决NeRF类系统带宽受限问题。  
◆ 发布首个真实世界密集SLAM数据集DES，涵盖单/多智能体场景，提供连续轨迹与高精度3D网格真值，填补领域空白。  
实验证明该方法在建图、定位和通信效率上均优于现有技术，代码与数据集将开源推动SLAM与三维重建研究发展。</td></tr>
<tr><td>2025-06-24</td><td>Multimodal Fusion SLAM with Fourier Attention</td><td>[2506.18204](http://arxiv.org/pdf/2506.18204)</td><td>◆ 提出FMF-SLAM方法，通过快速傅里叶变换（FFT）提升多模态SLAM的算法效率，解决传统光流SLAM计算资源消耗大的问题。  
◆ 创新设计基于傅里叶的自注意力与跨注意力机制，有效融合RGB和深度信号的特征提取。  
◆ 引入多尺度跨模态知识蒸馏技术，增强多模态特征间的交互与互补性。  
◆ 结合GNSS-RTK全局定位模块与全局Bundle Adjustment，实现安全机器人的实时应用验证。  
◆ 在TUM、TartanAir及真实场景数据集上验证性能，在噪声、光照变化和黑暗条件下达到领先水平。  
◆ 公开代码与数据集，推动多模态SLAM领域的可复现研究。</td></tr>
<tr><td>2025-06-22</td><td>ADA-DPM: A Neural Descriptors-based Adaptive Noise Point Filtering Strategy for SLAM</td><td>[2506.18016](http://arxiv.org/pdf/2506.18016)</td><td>◆ 提出ADA-DPM自适应噪声过滤策略，在动态物体干扰和噪声环境下同时提升SLAM定位精度与系统鲁棒性。  
◆ 设计动态分割头（Dynamic Segmentation Head），通过预测特征点类别主动剔除动态特征点，减少动态干扰。  
◆ 引入全局重要性评分头（Global Importance Scoring Head），自适应筛选高贡献特征点并抑制噪声干扰，优化特征选择。  
◆ 构建跨层图内卷积模块（GLI-GCN），融合多尺度邻域结构，增强重叠特征的判别能力。  
◆ 在多个公开数据集上验证有效性，实验结果表明该方法性能优于现有技术。</td></tr>
<tr><td>2025-06-21</td><td>Optimizing Exploration with a New Uncertainty Framework for Active SLAM Systems</td><td>[2506.17775](http://arxiv.org/pdf/2506.17775)</td><td>◆提出不确定性地图（UM）框架，通过概率分布量化地图不确定性，为主动SLAM系统建立新型环境建模方法。  
◆定义不确定性边界（UF）作为探索-开发的关键目标与停止准则，解决传统方法中探索终止条件模糊的问题。  
◆创新性引入基于KL散度的符号相对熵（SiREn），首次实现覆盖度与不确定性的联合度量，仅需单一参数即可平衡探索与开发。  
◆设计传感器无关的通用架构，兼容相机、激光雷达及多传感器融合系统，突破现有方法对特定SLAM配置的依赖。  
◆结合UF的路径规划系统首次实现开放空间的自主探索能力，填补了主动SLAM文献中该行为的空白。  
◆开源ROS节点与完整数据集，推动方法验证与社区应用，增强研究可复现性。</td></tr>
<tr><td>2025-06-18</td><td>MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System</td><td>[2506.15402](http://arxiv.org/pdf/2506.15402)</td><td>◆ 提出MCOO-SLAM系统，首次将多相机全景配置引入物体级SLAM，解决传统单目或RGB-D系统视场窄、遮挡敏感和深度感知受限的问题。  
◆ 融合点特征与开放词汇语义增强的物体级地标，实现复杂户外场景中更鲁棒且语义丰富的建图。  
◆ 设计语义-几何-时序多模态融合策略，显著提升跨视角物体关联的准确性，改善物体建模一致性。  
◆ 创新全景闭环检测模块，通过场景级描述符实现视角无关的地点识别，增强系统在动态环境中的稳定性。  
◆ 构建分层3D场景图谱抽象地图，为机器人高层推理任务提供结构化语义支持。  
实验证明该系统在遮挡、位姿变化和复杂环境下的定位精度与可扩展性均优于现有方法。</td></tr>
<tr><td>2025-06-24</td><td>RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories</td><td>[2506.15242](http://arxiv.org/pdf/2506.15242)</td><td>◆ 提出RA-NeRF方法，能够在复杂相机轨迹下实现高精度的相机位姿估计，解决了传统NeRF和3DGS依赖准确位姿先验的问题。  
◆ 采用增量式重建流程，结合光度一致性约束和光流驱动的位姿调节机制，提升了初始化和定位阶段的鲁棒性。  
◆ 创新性地引入隐式位姿滤波器，通过捕捉相机运动模式有效消除位姿估计中的噪声干扰。  
◆ 在Tanks&amp;Temple和NeRFBuster两个数据集上验证了方法的有效性，其中NeRFBuster包含极具挑战性的相机轨迹场景。  
◆ 实验结果表明，RA-NeRF在相机位姿估计精度和场景重建视觉质量上均达到最先进水平，尤其在复杂轨迹条件下表现突出。</td></tr>
<tr><td>2025-06-18</td><td>SHeRLoc: Synchronized Heterogeneous Radar Place Recognition for Cross-Modal Localization</td><td>[2506.15175](http://arxiv.org/pdf/2506.15175)</td><td>◆ 提出SHeRLoc，首个专为异构雷达设计的深度网络，填补了跨模态雷达定位研究的空白。  
◆ 采用RCS极坐标匹配技术，有效对齐多模态雷达数据，解决异构传感器数据融合难题。  
◆ 提出基于分层最优传输的特征聚合方法，生成具有旋转鲁棒性的多尺度描述符。  
◆ 结合FFT相似性数据挖掘和自适应边界三元组损失，实现视场感知的度量学习。  
◆ 在公开数据集上实现召回率@1从不足0.1提升至0.9，性能超越现有最佳方法一个数量级。  
◆ 扩展性强，可应用于LiDAR等传感器，为跨模态地点识别和异构SLAM开辟新途径。</td></tr>
<tr><td>2025-06-18</td><td>VIMS: A Visual-Inertial-Magnetic-Sonar SLAM System in Underwater Environments</td><td>[2506.15126](http://arxiv.org/pdf/2506.15126)</td><td>◆ 提出VIMS系统，首次将视觉-惯性-磁力-声纳多模态融合用于水下SLAM，解决传统视觉-惯性方法在水下环境中的尺度估计和闭环难题。  
◆ 创新性引入低成本单波束声纳，有效提升水下尺度估计精度，克服纯视觉方法因水体折射导致的尺度漂移问题。  
◆ 利用高采样率磁力计配合经济型磁场线圈生成磁特征，实现基于磁场指纹的场所识别，填补水下无纹理区域的感知空白。  
◆ 设计分层式视觉-磁力混合闭环检测框架，通过多模态数据互补增强闭环鲁棒性，显著降低误匹配率。  
◆ 优化前端计算负载，平衡局部特征跟踪与全局描述子匹配，在不增加前端负担的前提下实现高效闭环。  
◆ 实验验证系统在复杂水下环境中的优越性，相比传统方法定位精度提升30%以上，为低成本水下自主导航提供新方案。</td></tr>
<tr><td>2025-06-16</td><td>Slanted light-sheet array microscopy for large volume imaging at rates exceeding 100 Hz</td><td>[2506.13664](http://arxiv.org/pdf/2506.13664)</td><td>◆ 开发了倾斜光片阵列显微镜（SLAM），实现了超过100 Hz的超快速大体积成像，突破了传统成像速度限制。  
◆ 基于标准宽场复合显微镜进行简单改造，仅需对照明光路进行最小化修改，便于集成和推广。  
◆ 支持大范围多维度高分辨率成像（横向超过500像素，深度超过200层），同时保持光学切片和局部光化学能力。  
◆ 结合深度学习（条件去噪扩散概率模型），实现了各向同性分辨率提升，优化了图像质量。  
◆ 兼容常规生物样本制备协议，适用于多种生物医学研究场景，具有广泛的应用潜力。  
◆ 在高速成像的同时兼顾了空间分辨率、信噪比和大视场需求，为动态生物过程观测提供了新工具。</td></tr>
<tr><td>2025-06-16</td><td>Cognitive Synergy Architecture: SEGO for Human-Centric Collaborative Robots</td><td>[2506.13149](http://arxiv.org/pdf/2506.13149)</td><td>◆ 提出SEGO（语义图谱本体）认知映射架构，首次将几何感知、语义推理和解释生成整合为统一框架，实现人机协作机器人的认知协同。  
◆ 构建动态认知场景图，突破传统SLAM仅关注空间几何的局限，同时表征环境中的语义关系和本体一致性。  
◆ 创新性地融合基于SLAM的定位、深度学习物体检测跟踪与本体驱动推理三大模块，实现实时语义连贯的环境建模。  
◆ 通过本体论约束确保语义推理的逻辑一致性，使机器人能理解&quot;桌子上的杯子&quot;等复杂语义关系。  
◆ 支持可解释性输出，机器人可生成对人类友好的场景解释，显著提升人机协作的透明度和信任度。  
◆ 该架构为人类中心协作机器人提供标准化认知处理流程，在工业装配、家庭服务等场景展现应用潜力。</td></tr>
<tr><td>2025-06-16</td><td>A Novel ViDAR Device With Visual Inertial Encoder Odometry and Reinforcement Learning-Based Active SLAM Method</td><td>[2506.13100](http://arxiv.org/pdf/2506.13100)</td><td>◆ 提出了一种新型ViDAR设备，结合视觉、惯性和电机编码器，构建紧耦合的视觉-惯性-编码器里程计（VIEO），显著提升了SLAM系统的主动能力和视野范围。  
◆ 设计了ViDAR校准方法，确保VIEO算法的精确初始化，解决了多传感器融合中的标定难题。  
◆ 首次将电机编码器引入SLAM系统，以极低的成本和结构复杂度增强了跨帧共视关系，提高了状态估计精度。  
◆ 提出基于深度强化学习（DRL）的平台运动解耦主动SLAM方法，能够自主优化运动策略以增加特征点多样性。  
◆ 实验证明，所提VIEO算法相比传统VIO算法在共视关系和估计精度上均有显著提升，且DRL主动SLAM进一步优化了系统性能。  
◆ 为复杂环境下主动SLAM系统的平台设计和运动解耦方法提供了新思路，兼具理论创新和实用价值。</td></tr>
<tr><td>2025-06-16</td><td>SuperPoint-SLAM3: Augmenting ORB-SLAM3 with Deep Features, Adaptive NMS, and Learning-Based Loop Closure</td><td>[2506.13089](http://arxiv.org/pdf/2506.13089)<br><a href=''>[代码]</a></td><td>◆ 用自监督的SuperPoint特征检测-描述子替代传统ORB特征，提升了在极端视角、尺度和光照变化下的鲁棒性。  
◆ 引入自适应非极大值抑制(ANMS)技术，实现空间分布更均匀的关键点提取，增强场景覆盖度。  
◆ 集成轻量级NetVLAD模块作为学习式回环检测器，显著改善了传统词袋模型的识别能力。  
◆ 在KITTI数据集上将平均平移误差从4.15%降至0.34%，旋转误差从0.0027度/米降至0.0010度/米。  
◆ 在EuRoC MAV数据集上所有序列误差降低约50%（如V2_03从1.58%降至0.79%）。  
◆ 保持ORB-SLAM3实时性能的同时，通过深度学习特征与学习式回环的融合实现了精度突破。</td></tr>
<tr><td>2025-06-12</td><td>LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System</td><td>[2506.10567](http://arxiv.org/pdf/2506.10567)</td><td>◆ 提出LRSLAM模型，采用低秩张量分解方法（Six-axis和CP分解）优化稠密视觉SLAM系统，显著提升计算效率和内存利用率。  
◆ 通过低秩表示有符号距离场（SDF），解决了传统神经隐式表示的高计算成本和内存占用问题，适合大规模场景。  
◆ 相比现有方法（如ESLAM的平面张量分解），进一步降低了内存增长压力，同时保持高精度重建与定位能力。  
◆ 在多种室内RGB-D数据集上验证，LRSLAM在参数效率、处理速度和准确性方面均优于当前最优方法。  
◆ 实现了更快的收敛速度和更高的系统鲁棒性，为自动驾驶、移动机器人等实时应用提供可行解决方案。  
◆ 代码将开源，促进相关领域研究发展。</td></tr>
<tr><td>2025-06-11</td><td>VAULT: A Mobile Mapping System for ROS 2-based Autonomous Robots</td><td>[2506.09583](http://arxiv.org/pdf/2506.09583)</td><td>◆ 提出VAULT原型系统，基于ROS 2框架，专为户外自主机器人设计，解决复杂环境下的实时定位与建图难题。  
◆ 创新性融合多传感器数据（GNSS、VIO、IMU）与扩展卡尔曼滤波（EKF），生成高可靠性3D里程计，提升户外定位鲁棒性。  
◆ 结合视觉SLAM（VSLAM）技术，构建精细3D点云地图，弥补传统2D LiDAR在户外场景的局限性。  
◆ 实现室内外环境通用性，通过多模态传感器协同，适应农业、林业等无结构化户外场景需求。  
◆ 提供开源ROS 2解决方案，为自主机器人社区提供可扩展、模块化的移动测绘系统（MMS）参考框架。</td></tr>
<tr><td>2025-06-10</td><td>UFM: A Simple Path towards Unified Dense Correspondence with Flow</td><td>[2506.09278](http://arxiv.org/pdf/2506.09278)</td><td>◆ 提出统一流与匹配模型（UFM），首次实现宽基线场景和光流估计的统一训练，突破传统分而治之的局限。  
◆ 采用简单通用的Transformer架构直接回归(u,v)流，避免传统 coarse-to-fine 代价体积的复杂性，训练更高效且对大位移更精准。  
◆ 在光流任务上精度超越当前最优方法（Unimatch）28%，在宽基线匹配任务上误差降低62%且速度提升6.7倍（对比RoMa）。  
◆ 首次证明统一训练模型可同时在光流和宽基线匹配两个领域超越专用方法，为通用稠密对应开辟新路径。  
◆ 通过共可见像素的统一数据训练，为多模态、长距离和实时对应任务提供新思路。</td></tr>
<tr><td>2025-06-10</td><td>Princeton365: A Diverse Dataset with Accurate Camera Pose</td><td>[2506.09035](http://arxiv.org/pdf/2506.09035)</td><td>◆ 提出了Princeton365数据集，包含365个多样化视频，提供高精度的相机位姿，填补了当前SLAM基准在精度和数据多样性之间的空白。  
◆ 设计了一种新颖的地面真值采集框架，结合校准板和360度相机，实现了室内、室外和物体扫描视频的多模态同步采集（单目/立体RGB视频和IMU）。  
◆ 提出了一种基于光流的场景尺度感知SLAM评估指标，克服了传统指标（如ATE）无法跨场景比较的局限性，便于分析算法失败模式。  
◆ 构建了具有挑战性的新视角合成（NVS）基准，涵盖当前基准未涉及的场景（如非朗伯表面和360度相机轨迹）。  
◆ 公开了完整的数据集、代码和提交平台（https://princeton365.cs.princeton.edu），推动SLAM和NVS领域的标准化研究。</td></tr>
<tr><td>2025-06-10</td><td>Planar Collisionless Shock Simulations with Semi-Implicit Particle-in-Cell Model FLEKS</td><td>[2506.08384](http://arxiv.org/pdf/2506.08384)</td><td>◆ 验证了半隐式粒子网格代码FLEKS在无碰撞激波模拟中的适用性，特别针对全球磁层建模相关参数范围。  
◆ 开发了精细化算法，使FLEKS能够在电子惯性长度量级的网格分辨率下精确模拟激波结构。  
◆ 成功捕捉了激波关键特征，包括激波结构（脚部、陡坡、过冲和欠冲）、上下游波动（快磁声波、哨声波、阿尔芬离子回旋波和镜像模）以及非麦克斯韦粒子分布。  
◆ 揭示了二维模拟对准确重现准垂直激波下游波动物理和准平行激波复杂动力学（如表面波纹、激波子、SLAMS和喷流）的必要性。  
◆ 通过参数研究阐明了质量比和网格分辨率对激波物理的影响，为半隐式PIC代码的物理和数值参数选择提供了重要指导。  
◆ 为将动力学激波过程整合到MHD-AEPIC模型的大尺度空间等离子体模拟中奠定了基础。</td></tr>
<tr><td>2025-06-09</td><td>ZeroVO: Visual Odometry with Minimal Assumptions</td><td>[2506.08005](http://arxiv.org/pdf/2506.08005)</td><td>ZeroVO是一种无需预训练即可泛化至不同相机和环境的视觉里程计算法，其核心贡献与创新点如下：

◆ 提出无需标定的几何感知网络结构，能有效处理深度估计和相机参数中的噪声，摆脱传统方法对固定标定配置的依赖。

◆ 引入基于语言的先验知识，通过语义信息增强特征提取的鲁棒性，显著提升模型在未知领域的泛化能力。

◆ 开发半监督训练框架，利用未标注数据迭代适应新场景，进一步强化模型在真实复杂场景中的适应能力。

◆ 在KITTI、nuScenes和Argoverse 2等标准数据集及GTA合成数据上验证性能，相对现有方法提升超过30%。

◆ 无需微调或相机标定的特性，使得该技术具备大规模实际部署的潜力，极大扩展了视觉里程计的应用范围。</td></tr>
<tr><td>2025-06-08</td><td>Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs</td><td>[2506.07164](http://arxiv.org/pdf/2506.07164)</td><td>这篇论文的核心贡献是通过优化低端嵌入式GPU上的Oriented FAST特征检测，显著提升了视觉SLAM系统的实时处理能力。具体创新点如下：

◆ 提出了一种二进制级编码策略，快速确定FAST特征点候选点，大幅减少了计算复杂度。  
◆ 设计了一种可分离的Harris角点检测策略，结合底层GPU硬件指令优化，提高了计算效率。  
◆ 在Jetson TX2嵌入式GPU上实现了平均7.3倍的速度提升，远超现有OpenCV的GPU加速方案。  
◆ 通过优化FAST特征点检测和Harris角点检测这两个最耗时的步骤，解决了移动平台实时处理的瓶颈问题。  
◆ 为资源受限环境下的实时SLAM应用提供了高效解决方案，具有广泛的移动和嵌入式应用潜力。</td></tr>
<tr><td>2025-06-08</td><td>UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment</td><td>[2506.07013](http://arxiv.org/pdf/2506.07013)</td><td>◆ 提出UNO框架，实现跨平台、跨环境的统一自监督单目视觉里程计，无需针对特定场景或设备进行调优。  
◆ 采用混合专家策略（Mixture-of-Experts），通过多个专用解码器分别处理不同类别的运动模式，提升泛化能力。  
◆ 设计可微分的Gumbel-Softmax模块，动态构建帧间关联图并选择最优解码器，同时剔除错误估计。  
◆ 结合预训练的尺度无关深度先验与轻量级捆绑调整（bundling adjustment），后端统一优化几何一致性。  
◆ 在KITTI（自动驾驶）、EuRoC-MAV（无人机）和TUM-RGBD（手持设备）三大数据集上验证，性能达到SOTA。</td></tr>
<tr><td>2025-06-06</td><td>GS4: Generalizable Sparse Splatting Semantic SLAM</td><td>[2506.06517](http://arxiv.org/pdf/2506.06517)</td><td>◆ 提出了首个基于可泛化高斯泼溅（GS）的语义SLAM算法，通过学习网络实现跨场景的3D地图构建，摆脱传统方法依赖单场景优化的限制。  
◆ 采用RGB-D图像识别主干网络，直接从降采样和反向投影的图像位置预测高斯参数，实现高效增量式地图更新。  
◆ 创新性地将3D语义分割集成到GS框架中，通过共享主干网络统一3D建图与识别任务，提升语义理解能力。  
◆ 提出仅需1次迭代的全局定位后优化策略，有效解决定位漂移和漂浮物问题，显著提升系统鲁棒性。  
◆ 在ScanNet数据集上实现SOTA性能，所用高斯数量比同类方法少一个数量级，并在NYUv2和TUM RGB-D上展示零样本泛化能力。</td></tr>
<tr><td>2025-06-06</td><td>Enhancing Situational Awareness in Underwater Robotics with Multi-modal Spatial Perception</td><td>[2506.06476](http://arxiv.org/pdf/2506.06476)</td><td>◆ 提出多模态感知融合框架，整合摄像头、IMU和声学设备数据，解决水下视觉SLAM因光线衰减和低对比度导致的失效问题。  
◆ 突破传统单目/双目视觉限制，支持多摄像头配置，提升系统在复杂水下环境中的可扩展性。  
◆ 结合几何方法与学习技术，引入语义分析增强场景理解，实现更鲁棒的状态估计和3D重建。  
◆ 通过真实海域实验验证（特隆赫姆峡湾），首次展示多模态系统在恶劣水下条件下的实时可靠性能。  
◆ 系统分析传感器标定等工程挑战，指出基于学习方法的局限性，为未来大规模水下作业研究指明方向。</td></tr>
<tr><td>2025-06-06</td><td>Dy3DGS-SLAM: Monocular 3D Gaussian Splatti...</td><td>[2506.05965](http://arxiv.org/pdf/2506.05965)</td><td>◆ 提出了首个基于单目RGB输入的动态场景3D高斯泼溅SLAM系统Dy3DGS-SLAM。  
◆ 通过融合光流掩码和深度掩码的概率模型生成动态掩码，仅需单次网络迭代即可优化跟踪尺度和几何渲染。...</td></tr>
<tr><td>2025-06-06</td><td>Analysis of points outcome in ATP Grand Slam Tenni...</td><td>[2506.05866](http://arxiv.org/pdf/2506.05866)</td><td>◆ 该论文创新地利用大数据和机器学习方法（如逻辑回归、随机森林等）预测网球大满贯赛事中每一分的胜负，并结合球员排名、历史数据等因素分析影响得分的关键战略因素。  
◆ 研究基于2016-2020...</td></tr>
<tr><td>2025-06-05</td><td>On-the-fly Reconstruction for Large-Scale Novel Vi...</td><td>[2506.05558](http://arxiv.org/pdf/2506.05558)</td><td>◆提出实时重建方法，在拍摄后立即生成相机位姿和训练好的3D高斯泼溅模型，解决了传统方法耗时过长的问题。  
◆结合快速初始位姿估计和直接采样高斯基元位置/形状的技术，显著加速联合优化过程。  
...</td></tr>
<tr><td>**2025-06-05**</td><td>**Deep Learning Reforms Image Matching: A Survey and Outlook**</td><td>[2506.04619](http://arxiv.org/abs/2506.04619)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-06-04**</td><td>**cuVSLAM: CUDA accelerated visual odometry**</td><td>[2506.04359](http://arxiv.org/abs/2506.04359)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-06-04**</td><td>**Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset**</td><td>[2506.04224](http://arxiv.org/abs/2506.04224)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-06-03**</td><td>**LEG-SLAM: Real-Time Language-Enhanced Gaussian Splatting for SLAM**</td><td>[2506.03073](http://arxiv.org/abs/2506.03073)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-06-03**</td><td>**Online Performance Assessment of Multi-Source-Localization for Autonomous Driving Systems Using Subjective Logic**</td><td>[2506.02932](http://arxiv.org/abs/2506.02932)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-06-03**</td><td>**VTGaussian-SLAM: RGBD SLAM for Large Scale Scenes with Splatting View-Tied 3D Gaussians**</td><td>[2506.02741](http://arxiv.org/abs/2506.02741)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-06-03**</td><td>**GeneA-SLAM2: Dynamic SLAM with AutoEncoder-Preprocessed Genetic Keypoints Resampling and Depth Variance-Guided Dynamic Region Removal**</td><td>[2506.02736](http://arxiv.org/abs/2506.02736)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-06-03**</td><td>**Olfactory Inertial Odometry: Methodology for Effective Robot Navigation by Scent**</td><td>[2506.02373](http://arxiv.org/abs/2506.02373)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-06-01**</td><td>**Globally Consistent RGB-D SLAM with 2D Gaussian Splatting**</td><td>[2506.00970](http://arxiv.org/abs/2506.00970)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-30**</td><td>**Black-box Adversarial Attacks on CNN-based SLAM Algorithms**</td><td>[2505.24654](http://arxiv.org/abs/2505.24654)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**Semantic Exploration and Dense Mapping of Complex Environments using Ground Robots Equipped with LiDAR and Panoramic Camera**</td><td>[2505.22880](http://arxiv.org/abs/2505.22880)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians**</td><td>[2505.22859](http://arxiv.org/abs/2505.22859)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**UP-SLAM: Adaptively Structured Gaussian SLAM with Uncertainty Prediction in Dynamic Environments**</td><td>[2505.22335](http://arxiv.org/abs/2505.22335)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-27**</td><td>**HS-SLAM: A Fast and Hybrid Strategy-Based SLAM Approach for Low-Speed Autonomous Driving**</td><td>[2505.20906](http://arxiv.org/abs/2505.20906)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-27**</td><td>**ProBA: Probabilistic Bundle Adjustment with the Bhattacharyya Coefficient**</td><td>[2505.20858](http://arxiv.org/abs/2505.20858)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-26**</td><td>**ADD-SLAM: Adaptive Dynamic Dense SLAM with Gaussian Splatting**</td><td>[2505.19420](http://arxiv.org/abs/2505.19420)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-25**</td><td>**VPGS-SLAM: Voxel-based Progressive 3D Gaussian SLAM in Large-Scale Scenes**</td><td>[2505.18992](http://arxiv.org/abs/2505.18992)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-23**</td><td>**CU-Multi: A Dataset for Multi-Robot Data Association**</td><td>[2505.17576](http://arxiv.org/abs/2505.17576)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-22**</td><td>**TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition**</td><td>[2505.16447](http://arxiv.org/abs/2505.16447)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-20**</td><td>**A Methodological Framework for Measuring Spatial Labeling Similarity**</td><td>[2505.14128](http://arxiv.org/abs/2505.14128)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-22**</td><td>**Place Recognition: A Comprehensive Review, Current Challenges and Future Directions**</td><td>[2505.14068](http://arxiv.org/abs/2505.14068)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-19**</td><td>**eStonefish-scenes: A synthetically generated dataset for underwater event-based optical flow prediction tasks**</td><td>[2505.13309](http://arxiv.org/abs/2505.13309)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-23**</td><td>**VGGT-SLAM: Dense RGB SLAM Optimized on the SL(4) Manifold**</td><td>[2505.12549](http://arxiv.org/abs/2505.12549)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-18**</td><td>**Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey**</td><td>[2505.12384](http://arxiv.org/abs/2505.12384)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-18**</td><td>**Structureless VIO**</td><td>[2505.12337](http://arxiv.org/abs/2505.12337)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-16**</td><td>**EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video**</td><td>[2505.11709](http://arxiv.org/abs/2505.11709)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-16**</td><td>**Improved Bag-of-Words Image Retrieval with Geometric Constraints for Ground Texture Localization**</td><td>[2505.11620](http://arxiv.org/abs/2505.11620)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-16**</td><td>**Robust 2D lidar-based SLAM in arboreal environments without IMU/GNSS**</td><td>[2505.10847](http://arxiv.org/abs/2505.10847)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-15**</td><td>**TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation**</td><td>[2505.10696](http://arxiv.org/abs/2505.10696)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-15**</td><td>**A hybrid SLAM-Payne framework for atmospheric parameter and abundance determination of early-type Stars from LAMOST DR9 low-resolution Spectra**</td><td>[2505.10310](http://arxiv.org/abs/2505.10310)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-15**</td><td>**Large-Scale Gaussian Splatting SLAM**</td><td>[2505.09915](http://arxiv.org/abs/2505.09915)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-13**</td><td>**Automated Meta Prompt Engineering for Alignment with the Theory of Mind**</td><td>[2505.09024](http://arxiv.org/abs/2505.09024)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-13**</td><td>**MDF: Multi-Modal Data Fusion with CNN-Based Object Detection for Enhanced Indoor Localization Using LiDAR-SLAM**</td><td>[2505.08388](http://arxiv.org/abs/2505.08388)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-13**</td><td>**SKiD-SLAM: Robust, Lightweight, and Distributed Multi-Robot LiDAR SLAM in Resource-Constrained Field Environments**</td><td>[2505.08230](http://arxiv.org/abs/2505.08230)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-12**</td><td>**RDD: Robust Feature Detector and Descriptor using Deformable Transformer**</td><td>[2505.08013](http://arxiv.org/abs/2505.08013)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-12**</td><td>**Ranking-aware Continual Learning for LiDAR Place Recognition**</td><td>[2505.07198](http://arxiv.org/abs/2505.07198)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-07**</td><td>**Scalable Aerial GNSS Localization for Marine Robots**</td><td>[2505.04095](http://arxiv.org/abs/2505.04095)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-06**</td><td>**Thermal-LiDAR Fusion for Robust Tunnel Localization in GNSS-Denied and Low-Visibility Conditions**</td><td>[2505.03565](http://arxiv.org/abs/2505.03565)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-06**</td><td>**AquaticVision: Benchmarking Visual SLAM in Underwater Environment with Events and Frames**</td><td>[2505.03448](http://arxiv.org/abs/2505.03448)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-06**</td><td>**LiftFeat: 3D Geometry-Aware Local Feature Matching**</td><td>[2505.03422](http://arxiv.org/abs/2505.03422)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-05**</td><td>**LiDAR-Inertial SLAM-Based Navigation and Safety-Oriented AI-Driven Control System for Skid-Steer Robots**</td><td>[2505.02598](http://arxiv.org/abs/2505.02598)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-04**</td><td>**Robust Localization, Mapping, and Navigation for Quadruped Robots**</td><td>[2505.02272](http://arxiv.org/abs/2505.02272)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-04**</td><td>**SafeNav: Safe Path Navigation using Landmark Based Localization in a GPS-denied Environment**</td><td>[2505.01956](http://arxiv.org/abs/2505.01956)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-03**</td><td>**GauS-SLAM: Dense RGB-D SLAM with Gaussian Surfels**</td><td>[2505.01934](http://arxiv.org/abs/2505.01934)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-02**</td><td>**Tightly Coupled Range Inertial Odometry and Mapping with Exact Point Cloud Downsampling**</td><td>[2505.01017](http://arxiv.org/abs/2505.01017)</td><td>摘要生成中...</td></tr>
</tbody>
</table>
</div>

<h2 id='sfm'>SFM</h2>

<div class="table-container">
<table>
<thead><tr><th>日期</th><th>标题</th><th>论文与代码</th><th>摘要</th></tr></thead>
<tbody>
<tr><td>2025-09-02</td><td>Doctoral Thesis: Geometric Deep Learning For Camera Pose Prediction, Registration, Depth Estimation, and 3D Reconstruction</td><td>[2509.01873](http://arxiv.org/pdf/2509.01873)</td><td>该论文的核心贡献是开发了结合几何先验与深度学习的几何深度学习方法，以解决三维视觉中的关键任务。  
◆ 针对相机位姿估计、点云配准、深度预测及三维重建等任务，提出了定制化的几何深度学习模型。  
◆ 通过引入深度信息、表面法线和等变性约束等几何先验，增强了模型的表示准确性与鲁棒性。  
◆ 克服了传统方法（如SfM和SLAM）在非结构化环境中特征模糊和几何细节缺失的局限性。  
◆ 在文化遗产保护和VR/AR等实际应用中验证了方法的有效性，推动了三维映射与场景重建技术的发展。</td></tr>
<tr><td>2025-08-25</td><td>SAIL-Recon: Large SfM by Augmenting Scene Regression with Localization</td><td>[2508.17972](http://arxiv.org/pdf/2508.17972)</td><td>SAIL-Recon提出了一种用于大规模运动恢复结构（SfM）的前馈Transformer方法，有效解决了现有场景回归方法难以处理大量输入图像的问题。

◆ 核心创新在于将视觉定位能力融入场景回归网络，通过结合两种范式的优势来提升处理大规模场景的能力。
◆ 方法首先从锚图像子集计算出一个神经场景表示，然后基于此表示对回归网络进行微调，以重建所有输入图像。
◆ 该方法不仅能够高效扩展到大规模场景，还在相机姿态估计和新视图合成任务上取得了最先进的性能。
◆ 在多个权威数据集（如TUM-RGBD、CO3Dv2和Tanks &amp; Temples）上的综合实验验证了其有效性和优越性。</td></tr>
<tr><td>2025-08-25</td><td>HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images</td><td>[2508.16465](http://arxiv.org/pdf/2508.16465)</td><td>该论文提出了一种名为HOSt3R的、无需关键点检测的手-物三维重建方法。其核心贡献在于摆脱了现有方法对关键点检测技术的依赖，从而提升了在复杂场景下的鲁棒性和泛化能力。
◆ 提出了一种无需关键点检测器（keypoint-free）的鲁棒方法，直接从单目运动视频中估计手和物体的三维变换。
◆ 解决了现有基于SfM和手部关键点优化的方法在物体几何多样、纹理弱以及手物严重遮挡情况下的失效问题。
◆ 将所提的变换估计方法与一个多视图重建流程集成，实现了精确的手-物三维形状恢复。
◆ 该方法不受约束，不依赖预先扫描的物体模板或相机内参，具有更强的通用性和非侵入式应用潜力。
◆ 在SHOWMe基准测试中达到了最先进的性能，并在HO3D数据集上验证了其对未见物体类别的泛化能力。</td></tr>
<tr><td>2025-08-22</td><td>NeuralMeshing: Complete Object Mesh Extraction from Casual Captures</td><td>[2508.16026](http://arxiv.org/pdf/2508.16026)</td><td>该论文提出了NeuralMeshing系统，用于从日常拍摄的多段视频中自动重建物体的完整网格模型。其核心创新如下：
◆ 仅需通过普通视频而非专业扫描设备即可实现完整物体建模，大幅降低硬件门槛。
◆ 提出基于多视频融合的完整重建方案，无需依赖后处理的孔洞填充技术。
◆ 采用最少人工干预的标注方式（仅需在每段视频中指定一个已知点），支持通过标定板或AR标记实现自动化。
◆ 结合运动恢复结构（SfM）技术实现自动帧定位与三维重建。
◆ 开源系统代码，促进相关研究和应用发展。</td></tr>
<tr><td>2025-08-21</td><td>Enhancing Novel View Synthesis from extremely sparse views with SfM-free 3D Gaussian Splatting Framework</td><td>[2508.15457](http://arxiv.org/pdf/2508.15457)</td><td>该论文针对3D高斯泼溅（3DGS）在极端稀疏视角（如仅2个训练视图）下因运动恢复结构（SfM）初始化失败导致的渲染质量下降问题，提出了一种无需SfM的新型框架。其核心创新点包括：
◆ 提出密集立体模块替代SfM，通过渐进式相机姿态估计和全局稠密点云重建实现初始化。
◆ 设计连贯视图插值模块，通过插值相机姿态并生成视角一致的内容作为额外监督信号，缓解稀疏输入的信息稀缺问题。
◆ 引入多尺度拉普拉斯一致性正则化和自适应空间感知多尺度几何正则化，显著提升几何结构和渲染内容的质量。
实验表明，该方法在极端稀疏条件下PSNR指标提升2.75dB，合成图像畸变小且高频细节丰富，显著优于现有技术。</td></tr>
<tr><td>2025-08-20</td><td>GeMS: Efficient Gaussian Splatting for Extreme Motion Blur</td><td>[2508.14682](http://arxiv.org/pdf/2508.14682)</td><td>GeMS是首个直接从极端运动模糊图像中进行3D高斯溅射（3DGS）重建的框架，无需依赖任何清晰图像。其核心创新点包括：
◆ 提出VGGSfM，一种基于深度学习的运动恢复结构（SfM）方法，直接从模糊输入中估计相机位姿并生成点云。
◆ 引入3DGS-MCMC方法，将高斯分布视为概率分布样本进行初始化，取代了依赖启发式 densification 和 pruning 的传统策略。
◆ 联合优化相机轨迹与高斯参数，实现更稳定的三维场景重建。
◆ 进一步提出GeMS-E变体，集成事件相机数据，通过事件双积分去模糊（EDI）生成更清晰图像以优化初始估计。
该框架在合成与真实数据集上实现了最先进的性能，解决了严重模糊下3DGS重建的根本性挑战。</td></tr>
<tr><td>2025-08-19</td><td>Smooth Flow Matching</td><td>[2508.13831](http://arxiv.org/pdf/2508.13831)</td><td>本文提出Smooth Flow Matching（SFM）框架，用于解决函数型数据的生成建模问题。其核心贡献与创新点包括：
◆ 专为函数型数据设计，突破传统方法对高斯性或低秩假设的限制，构建半参数Copula流生成无限维非高斯函数数据。
◆ 计算效率高且能处理不规则采样观测，直接保证生成函数的平滑性，克服了现有深度生成模型在函数数据场景中的适用性局限。
◆ 通过模拟实验验证了SFM在合成数据质量和计算效率方面的优势，并在MIMIC-IV电子健康记录数据上成功生成了高质量临床轨迹替代数据。
◆ 为隐私敏感场景下的统计分析提供了实用灵活的解决方案，显著提升了电子健康记录等函数型数据在临床应用中的效用价值。</td></tr>
<tr><td>2025-08-17</td><td>HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization</td><td>[2508.12292](http://arxiv.org/pdf/2508.12292)</td><td>◆ 提出HuBERT-VIC模型，通过方差-不变性-协方差正则化（VICReg）提升语音基础模型在噪声环境下的鲁棒性。  
◆ 首次将VICReg目标应用于语音领域，调整噪声语音表征的统计特性，增强模型对多样化声学特征的捕捉能力。  
◆ 通过联合优化方差、不变性和协方差约束，有效提升模型在不同噪声类型中的泛化性能。  
◆ 在HuBERT模型上验证有效性，相比基线模型，LibriSpeech测试集上相对性能提升23.3%（clean）和13.2%（other）。  
◆ 为解决语音基础模型因依赖干净数据训练导致的噪声场景性能下降问题提供了新思路。</td></tr>
<tr><td>2025-08-17</td><td>What do Speech Foundation Models Learn? Analysis and Applications</td><td>[2508.12255](http://arxiv.org/pdf/2508.12255)</td><td>◆ 提出轻量级分析框架，结合统计工具和无训练任务，系统研究语音基础模型（SFMs）各层编码的声学和语言学知识。  
◆ 首次对多种SFMs和统计工具进行横向对比研究，揭示模型内部知识表示与下游任务性能的关联性。  
◆ 针对口语理解（SLU）领域数据匮乏问题，创新性地贡献了口语命名实体识别（NER）和定位（NEL）任务，扩充SLU评测基准。  
◆ 验证端到端SFM模型在SLU任务上的优越性，其性能超越传统级联式（语音识别+文本模型）方法。  
◆ 全面评估不同SFMs及适配策略对SLU任务的影响，为模型选择提供实证依据。  
◆ 通过工具链和数据集的双重创新，推动社区对SFMs的机理理解与实用化开发。</td></tr>
<tr><td>2025-08-10</td><td>GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction</td><td>[2508.07355](http://arxiv.org/pdf/2508.07355)</td><td>◆ 提出GS4Buildings方法，利用语义3D建筑模型作为先验，增强高斯泼溅（GS）在大规模复杂城市场景中的重建能力，解决传统方法因遮挡导致的不完整问题。  
◆ 直接基于低细节层次（LoD2）语义建筑模型初始化高斯分布，替代传统运动恢复结构（SfM）流程，简化重建流程并提升鲁棒性。  
◆ 通过建筑几何生成先验深度和法线图，并将其融入优化过程，显著提升表面一致性和结构准确性。  
◆ 引入可选建筑聚焦模式，仅重建建筑区域，减少71.8%的高斯基元数量，实现更高效紧凑的表示。  
◆ 在城市场景数据集上验证，重建完整度提升20.5%，几何精度提高32.8%，为智慧城市和数字孪生等应用提供新思路。</td></tr>
<tr><td>2025-08-09</td><td>Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View</td><td>[2508.06968](http://arxiv.org/pdf/2508.06968)</td><td>◆首次在真实超180度鱼眼图像上评估两种鱼眼兼容的3D高斯泼溅方法（Fisheye-GS和3DGUT），填补了极端畸变场景下的技术空白。  
◆通过室内外200度鱼眼相机实测，系统分析不同视场角（200/160/120度）下两种方法的性能平衡：Fisheye-GS在160度表现最佳，而3DGUT在全200度下仍保持稳定高质量。  
◆提出基于UniK3D预测的深度初始化策略，仅需2-3张鱼眼图即可生成稠密点云，克服传统SfM在强畸变场景失效的问题。  
◆验证UniK3D在未训练真实鱼眼数据的情况下，对雾霾、眩光、天空等复杂场景仍能实现与SfM相当的3D重建质量。  
◆研究成果证实了鱼眼3DGS方法在稀疏高畸变图像中进行广角3D重建的实用价值，为实际应用提供重要参考。</td></tr>
<tr><td>2025-08-07</td><td>EndoMatcher: Generalizable Endoscopic Image Matcher via Multi-Domain Pre-training for Robot-Assisted Surgery</td><td>[2508.05205](http://arxiv.org/pdf/2508.05205)</td><td>◆提出EndoMatcher，一种基于多领域预训练的内窥镜图像通用匹配器，通过大规模跨域数据解决内窥镜图像匹配泛化性难题。  
◆首创双分支视觉Transformer架构，结合多尺度特征提取与双重交互模块，显著提升弱纹理、大视角变化等复杂内窥镜场景的匹配鲁棒性。  
◆构建首个多领域内窥镜匹配数据集Endo-Mix6，包含6个领域约120万真实/合成图像对，通过运动恢复结构和模拟变换生成标注，解决数据稀缺与领域多样性不足问题。  
◆设计渐进式多目标训练策略，有效应对跨域数据规模差异、分布偏移和误差不平衡问题，实现不同领域的均衡学习与表征优化。  
◆在零样本设置下实现跨器官和成像条件的泛化能力，在三个基准数据集上以140%-201%的匹配内点提升率和9.4%的方向预测准确率超越现有最优方法。</td></tr>
<tr><td>2025-08-07</td><td>Refining Gaussian Splatting: A Volumetric Densification Approach</td><td>[2508.05187](http://arxiv.org/pdf/2508.05187)</td><td>◆ 提出基于惯性体积的新型密度控制方法，利用高斯函数的惯性体积指导3D高斯分布的精细化过程，克服原始3DGS密度策略的缺陷。  
◆ 首次系统研究了传统SfM与深度图像匹配(DIM)两种点云初始化方法对3DGS重建质量的影响，为初始化选择提供依据。  
◆ 在Mip-NeRF 360数据集上的实验表明，该方法显著提升了3DGS的重建质量，在不同场景中均表现出优越性能。  
◆ 改进了自适应密度控制(ADC)流程，通过更智能的密集化和修剪机制优化点基元管理，实现更高质量的新视角合成。  
◆ 提出的体积感知策略为3D高斯分布的形状和空间分布优化提供了新思路，增强了场景表示的几何准确性。</td></tr>
<tr><td>2025-08-06</td><td>Bursting at the seams: the star-forming main sequence and its scatter at z=3-9 using NIRCam photometry from JADES</td><td>[2508.04410](http://arxiv.org/pdf/2508.04410)</td><td>◆ 首次利用JADES巡天的NIRCam测光数据系统研究了红移z=3-9范围内恒星形成主序(SFMS)及其弥散，样本恒星质量完备性下限达log(M⋆/M⊙)≈8.1。  
◆ 发现10Myr时间尺度下的SFMS演化符合sSFR∝(1+z)^2.30的关系，与暗物质晕质量吸积率的理论预测高度吻合。  
◆ 揭示了SFMS归一化随恒星形成率(SFR)平均时间尺度变化的复杂规律，反映了爆发性恒星形成与上升型恒星形成历史的综合效应。  
◆ 首次定量分析SFMS弥散随SFR平均时间尺度的演变：从10Myr的0.4-0.5dex降至100Myr的0.2dex，表明短期波动主导弥散，但长期变化也存在。  
◆ 发现低质量星系中爆发性恒星形成历史更显著，并指出需要引入初始质量函数偏重、恒星形成效率提升或爆发性增强等机制来解释z&gt;10观测到的UV亮星系过量现象。  
◆ 强调在拟合SFMS时（特别是对爆发性恒星形成历史的星系），准确确定恒星质量完备性限的重要性。</td></tr>
<tr><td>2025-08-06</td><td>PIS3R: Very Large Parallax Image Stitching via Deep 3D Reconstruction</td><td>[2508.04236](http://arxiv.org/pdf/2508.04236)</td><td>◆ 提出PIS3R方法，首次通过深度3D重建解决大视差图像拼接难题，突破传统方法在显著视差下的性能瓶颈。  
◆ 采用视觉几何驱动的Transformer网络，从大视差图像中联合估计相机内外参数并完成稠密3D场景重建，实现几何精确的初始对齐。  
◆ 创新性地将重建的3D点云重投影到参考视图，实现像素级精准配准，保留所有像素在3D摄影测量中的几何完整性。  
◆ 设计点云条件扩散模型，针对初始拼接可能存在的空洞或噪声进行精细化修复，生成无缝高质量结果。  
◆ 实验证明该方法在大视差场景下显著优于现有方法，且输出结果可直接支持SfM等下游3D视觉任务，具有实用价值。</td></tr>
<tr><td>2025-08-03</td><td>CVD-SfM: A Cross-View Deep Front-end Structure-from-Motion System for Sparse Localization in Multi-Altitude Scenes</td><td>[2508.01936](http://arxiv.org/pdf/2508.01936)</td><td>◆ 提出了一种新颖的多高度相机位姿估计系统CVD-SfM，专门针对稀疏图像输入下不同高度场景的鲁棒精准定位问题。  
◆ 创新性地将跨视角Transformer、深度特征与运动恢复结构(SfM)技术融合到统一框架中，有效应对复杂环境条件和视角变化。  
◆ 为解决该领域数据稀缺问题，专门收集并发布了两个新的多高度相机位姿估计数据集，为后续研究提供基准平台。  
◆ 通过大量对比实验验证，该系统在多高度稀疏位姿估计任务中展现出优于现有方案的精度和鲁棒性。  
◆ 所提框架特别适合无人机导航、搜救行动、自动化检测等实际机器人应用场景，具有重要实用价值。</td></tr>
<tr><td>2025-08-01</td><td>Counting topological interface modes using simplicial characteristic classes</td><td>[2508.01063](http://arxiv.org/pdf/2508.01063)</td><td>◆ 提出了一种基于谱流-单极子对应关系的计算方法，用于预测厄米系统中拓扑界面模（TIMs）的数量。  
◆ 通过计算围绕外尔点的相空间球上局部极化向量复线丛的陈数，确定TIMs数量，创新性地将拓扑不变量与物理现象直接关联。  
◆ 采用离散向量丛的单纯第一陈类构造方法计算陈数，该方法具有规范不变性、无需导数运算、结构保持性强且抗噪声干扰的特点。  
◆ 算法在赤道流体波和拓扑朗缪尔回旋波的案例中成功复现了预期的TIMs数量，验证了其有效性。  
◆ 探索了该算法在实验测量中的应用潜力，通过合成示例展示了如何利用体波极化数据预测TIMs数量，为实验研究提供了新工具。</td></tr>
<tr><td>2025-08-01</td><td>3D Reconstruction via Incremental Structure From Motion</td><td>[2508.01019](http://arxiv.org/pdf/2508.01019)</td><td>这篇论文的核心贡献和创新点如下：

◆ 提出了一种增量式运动恢复结构（SfM）的详细实现方法，相比全局SfM技术更具灵活性。  
◆ 通过逐步加入新视图的方式，能够在稀疏或部分重叠的数据集中恢复场景结构和相机运动。  
◆ 重点研究了几何估计的一致性，并通过光束法平差（bundle adjustment）实现迭代优化，提升了重建精度。  
◆ 在真实数据集上验证了方法的有效性，通过重投影误差和相机轨迹一致性评估了重建质量。  
◆ 证明了增量式SfM在视觉结构化环境中是一种可靠的稀疏3D重建方法，适用于实际应用场景。</td></tr>
<tr><td>2025-07-27</td><td>RESCUE: Crowd Evacuation Simulation via Controlling SDM-United Characters</td><td>[2507.20117](http://arxiv.org/pdf/2507.20117)</td><td>这篇论文的核心贡献是提出了一种实时3D人群疏散模拟框架RESCUE，通过模拟人类感知-决策-运动（SDM）流程来提升疏散仿真的真实性和动态适应性。  

◆ 提出基于SDM流程的仿真框架，首次将3D自适应社会力模型（SFM）决策机制与个性化步态控制运动模块结合，实现更符合人类行为逻辑的疏散模拟。  
◆ 引入动态群体感知机制，支持多智能体并行运动，能适应不同地形和场景需求，突破了传统模型对复杂环境适应性的限制。  
◆ 开发个性化步态控制模块，通过考虑个体体型差异和地形影响，首次实现疏散过程中个体运动特征的差异化模拟。  
◆ 创新提出部件级受力可视化技术，为疏散分析提供直观的力学交互数据支持，辅助安全策略优化。  
◆ 实验证明该框架支持动态路径规划和实时行为调整，在崎岖地形中仍能生成视觉可信、符合现实的疏散动画。  
◆ 开源代码并验证了方法在真实性和实用性上的优势，为公共安全领域提供了新的仿真分析工具。</td></tr>
<tr><td>2025-07-22</td><td>Sparse-View 3D Reconstruction: Recent Advances and Open Challenges</td><td>[2507.16406](http://arxiv.org/pdf/2507.16406)</td><td>◆ 该论文首次将稀疏视角3D重建领域的几何方法、神经隐式模型（如NeRF）和生成式方法（如扩散模型）纳入统一框架进行系统分析。  
◆ 重点对比了不同方法在几何正则化、显式形状建模和生成推理方面的创新，揭示了它们在解决稀疏视角下浮游伪影和位姿模糊问题上的独特优势。  
◆ 提出当前方法在标准基准测试中面临的核心权衡：重建精度、计算效率和泛化能力之间的相互制约关系。  
◆ 区别于以往综述，特别强调了视觉基础模型（VFMs）和3D高斯泼溅等新兴技术在稀疏重建中的迁移应用潜力。  
◆ 明确指出该领域尚未解决的两大挑战：跨域泛化能力和无位姿约束的重建，并首次提出发展&quot;3D原生生成先验&quot;的未来方向。  
◆ 通过整合实时重建需求与无约束条件设定，为稀疏视角3D重建的工业落地提供了新的技术路线图。</td></tr>
<tr><td>2025-07-21</td><td>Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing</td><td>[2507.15683](http://arxiv.org/pdf/2507.15683)</td><td>◆ 提出Hi^2-GSLoc框架，首次将3D高斯溅射（3DGS）引入遥感视觉重定位任务，利用其紧凑的几何与外观表征能力解决传统方法精度与效率的矛盾。  
◆ 设计双层次稀疏到稠密、粗到精的定位范式：稀疏阶段通过渲染感知采样和地标引导检测器获取鲁棒初始位姿，稠密阶段通过多级栅格化匹配迭代优化位姿。  
◆ 开发分区高斯训练、GPU并行匹配和动态内存管理策略，突破大尺度遥感场景的计算瓶颈，实现高效处理高海拔变化和跨域数据。  
◆ 创新性提出高斯基元一致性渲染感知采样方法，结合可靠性验证机制，显著提升特征匹配的稳定性和位姿估计的准确性。  
◆ 在仿真数据、公开数据集和真实飞行实验中验证了方法的优越性，兼具高定位精度（竞争性指标）、召回率和计算效率，为实际遥感应用提供可靠解决方案。</td></tr>
<tr><td>2025-07-21</td><td>Few-Shot Object Detection via Spatial-Channel State Space Model</td><td>[2507.15308](http://arxiv.org/pdf/2507.15308)</td><td>◆ 提出空间-通道状态空间建模（SCSM）模块，通过联合建模空间和通道关系，解决小样本目标检测中特征提取不准确的问题。  
◆ 设计空间特征建模（SFM）模块，平衡空间关系和通道关系的学习，提升特征表示的有效性。  
◆ 创新性地将Mamba模型引入通道序列建模，提出通道状态建模（CSM）模块，利用通道间相关性动态调整通道权重。  
◆ 通过SCSM模块，模型能够自动强化有效通道特征并修正无效通道特征，从而提升小样本条件下的检测性能。  
◆ 在VOC和COCO数据集上的实验表明，该方法显著优于现有技术，实现了最先进的性能。</td></tr>
<tr><td>2025-07-20</td><td>An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks</td><td>[2507.14798](http://arxiv.org/pdf/2507.14798)</td><td>◆ 首次对DUSt3R/MASt3R/VGGT三种基于Transformer的3D重建模型在航摄影像块上进行系统性评估，填补了该领域的研究空白。  
◆ 证明这些模型在极稀疏影像（少于10张、分辨率低至518像素）下仍能生成完整稠密点云，相比传统COLMAP方法完整性提升高达50%。  
◆ 发现VGGT模型具有显著计算效率和可扩展性优势，同时提供更可靠的相机位姿估计能力。  
◆ 揭示了这些模型在高分辨率影像和大规模数据集上的局限性，表现为位姿估计可靠性随影像数量增加而下降。  
◆ 提出Transformer模型虽无法完全替代传统SfM/MVS流程，但在低分辨率、稀疏影像等挑战性场景中可作为有效补充方案。  
◆ 为航测领域提供了基于深度学习的3D重建新思路，特别适用于影像重叠率极低或纹理缺失区域的快速重建需求。</td></tr>
<tr><td>2025-07-17</td><td>Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation</td><td>[2507.13486](http://arxiv.org/pdf/2507.13486)</td><td>这篇论文的核心贡献和创新点如下：

◆ 提出了一个完整的误差传播框架，用于量化航空和无人机摄影测量中从SfM到MVS两阶段的全流程不确定性，填补了MVS阶段不确定性评估的研究空白。

◆ 针对MVS阶段非可微、多模态的特性，创新性地提出基于可靠多视角点（n≥6）的自校准方法，通过匹配代价等关键特征回归视差不确定性。

◆ 该方法直接从MVS过程中提取自包含的可靠3D点，具有自监督特性，无需外部数据即可实现不确定性建模。

◆ 提出的误差协方差矩阵建模方法严格遵循摄影测量误差传播路径，能适应不同场景的鲁棒性验证需求。

◆ 通过公开数据集验证表明，该方法在保证高边界覆盖率的同时避免了不确定性高估问题，性能优于现有方法。

◆ 首次实现了摄影测量点云逐点精度凭证的标准化输出，为场景依赖的摄影测量精度评估提供了可认证的量化工具。</td></tr>
<tr><td>2025-07-16</td><td>Enhancing In-Domain and Out-Domain EmoFake Detection via Cooperative Multilingual Speech Foundation Models</td><td>[2507.12595](http://arxiv.org/pdf/2507.12595)</td><td>◆ 提出多语言语音基础模型（SFMs）在情感伪造检测（EFD）中的有效性假设，认为其跨语言预训练能更好捕捉音高、音调和强度的细微变化。  
◆ 通过全面对比实验验证了多语言SFMs在同语言（域内）和跨语言（域外）场景下的优越性能。  
◆ 创新性地提出THAMA融合方法，结合Tucker分解和Hadamard乘积，实现基础模型的高效互补融合。  
◆ THAMA与多语言SFMs协同合作，在域内和域外评测中均达到最优性能，超越单一模型、基线融合方法和先前SOTA方法。  
◆ 首次系统探索了多语言SFMs在EFD任务中的潜力，为跨语言情感伪造检测提供了新思路。</td></tr>
<tr><td>2025-07-16</td><td>BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images</td><td>[2507.12095](http://arxiv.org/pdf/2507.12095)</td><td>这篇论文的核心贡献是通过稀疏视角输入实现高精度的3D车辆重建，解决了现有方法依赖密集视角的局限性。  

◆提出基于深度图和鲁棒位姿估计架构的新方法，能够从稀疏输入合成新视角并增强训练数据。  
◆改进高斯泼溅技术，引入选择性光度损失函数，仅对高置信度像素进行计算，提升重建质量。  
◆采用DUSt3R架构替代传统运动恢复结构（SfM）流程，显著提高了相机位姿估计的准确性。  
◆发布了一个包含合成和真实公共交通工具车辆的新数据集，支持方法的全面评估。  
实验结果表明，该方法在多个基准测试中达到最先进性能，尤其在输入条件受限时仍能实现高质量重建。</td></tr>
<tr><td>2025-07-23</td><td>Spatial Frequency Modulation for Semantic Segmentation</td><td>[2507.11893](http://arxiv.org/pdf/2507.11893)</td><td>◆ 提出空间频率调制（SFM）方法，通过在下采样前将高频特征调制到低频，上采样时再解调回来，有效解决语义分割中高频信息因下采样导致的混叠失真问题。  
◆ 设计自适应重采样（ARS）模块，通过密集采样高频区域来缩放信号，利用频率缩放特性降低高频成分的频率，实现高效调制。  
◆ 提出多尺度自适应上采样（MSAU）模块，通过非均匀上采样解调特征并恢复高频信息，同时利用多尺度密集与稀疏采样区域的交互增强分割精度。  
◆ 模块设计轻量且通用，可无缝集成到CNN和Transformer等多种架构中，扩展性强。  
◆ 通过特征可视化验证了该方法能有效缓解混叠并保留细节，进一步在图像分类、对抗鲁棒性、实例分割和全景分割等任务中验证了其广泛适用性。</td></tr>
<tr><td>2025-07-20</td><td>Supporting SENCOTEN Language Documentation Efforts with Automatic Speech Recognition</td><td>[2507.10827](http://arxiv.org/pdf/2507.10827)</td><td>这篇论文的核心贡献是通过自动语音识别（ASR）技术支持濒危语言SENĆOTEN的文档化工作，具体创新点如下：

◆ 提出了一种ASR驱动的文档化流程，结合文本转语音（TTS）系统增强有限的语言数据，解决了数据不足的问题。  
◆ 利用跨语言迁移学习技术，借助语音基础模型（SFMs）提升ASR在低资源语言上的性能。  
◆ 引入n-gram语言模型，通过浅层融合或n-best恢复技术，最大化利用现有词汇数据。  
◆ 在SENĆOTEN数据集上实现了19.34%的词错误率（WER）和5.09%的字符错误率（CER），经过过滤后分别提升至14.32%和3.45%，展示了方法的有效性。  
◆ 特别针对SENĆOTEN的多合成结构和重音驱动的音位变换等语言特点，优化了ASR系统的适应性。  
◆ 为濒危语言的数字化保护和教学资源创建提供了可行的技术方案。</td></tr>
<tr><td>2025-07-11</td><td>Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT</td><td>[2507.08448](http://arxiv.org/pdf/2507.08448)</td><td>◆ 提出了前馈式3D重建新范式，以DUSt3R为代表，通过单一前向传播直接从无约束图像中联合推断相机位姿和稠密几何结构，颠覆了传统迭代优化流程。  
◆ 采用基于Transformer的对应关系建模技术，实现了跨图像的高效特征匹配，显著提升了纹理缺失等挑战性场景的鲁棒性。  
◆ 设计了联合位姿与几何回归机制，将传统多阶段流程（如SfM+MVS）整合为端到端网络，大幅简化了工作流程并降低计算成本。  
◆ 系统分析了从双视图到多视图的扩展策略，为不同应用场景提供了灵活的技术路径。  
◆ 通过与传统方法（如SfM）和早期学习型方法（如MVSNet）的对比，阐明了该范式在效率、泛化性和易用性方面的突破性优势。  
◆ 探讨了动态场景处理、模型精度与可扩展性等未来挑战，为该领域的进一步发展指明了方向。</td></tr>
<tr><td>2025-07-04</td><td>MGSfM: Multi-Camera Geometry Driven Global Structure-from-Motion</td><td>[2507.03306](http://arxiv.org/pdf/2507.03306)</td><td>◆ 提出了一种专为多相机系统设计的全局运动平均框架，通过解耦旋转平均和混合平移平均模块提升传统全局SfM的鲁棒性问题。  
◆ 采用分层策略的旋转平均方法：先估计刚性相机单元内的相对旋转，再计算全局刚性单元旋转，优化多相机系统的旋转估计精度。  
◆ 创新性融合相机间约束和相机-点约束的平移平均模块，通过凸距离目标函数初始化相机位姿和3D点，并采用无偏非双线性角度目标函数进行细化。  
◆ 在保持与增量式SfM相当精度的前提下，显著提升计算效率，实验证明其在大规模数据集上优于现有全局SfM方法。  
◆ 框架充分利用多相机系统的固有相对位姿约束，为自动驾驶和机器人环境感知提供了更鲁棒的实时SfM解决方案。  
◆ 开源代码便于学术和工业界应用验证，推动多相机SfM技术的实际部署。</td></tr>
<tr><td>2025-06-30</td><td>Towards Initialization-free Calibrated Bundle Adjustment</td><td>[2506.23808](http://arxiv.org/pdf/2506.23808)</td><td>◆ 提出了一种无需初始化的标定束调整方法，能够在初始重建阶段直接利用相机标定信息，生成接近度量精度的重建结果（仅差一个相似变换）。  
◆ 创新性地引入具有标定信息的成对相对旋转估计，这些旋转估计仅对相似变换保持不变，从而推动解保持真实场景的度量特征。  
◆ 将旋转平均技术整合到伪物体空间误差（pOSE）框架中，实现了标定信息与初始化无关的SfM（运动恢复结构）流程。  
◆ 实验证明该方法能够可靠优化目标函数，即使从随机初始解出发也能高概率收敛到全局最优，获得精确的接近度量重建。  
◆ 相比现有基于pOSE的方法（仅能获得射影变换解且需要更多数据），新方法显著提升了重建精度和效率。</td></tr>
<tr><td>2025-06-30</td><td>AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention</td><td>[2506.23611](http://arxiv.org/pdf/2506.23611)</td><td>◆ 提出AttentionGS框架，首次实现无需高质量初始点云的3D高斯泼溅重建，突破传统3DGS对SfM点云的强依赖。  
◆ 创新性引入几何注意力机制，在训练初期快速恢复场景全局结构，解决随机初始化导致的收敛难题。  
◆ 设计渐进式纹理注意力模块，在训练后期精细化局部细节，显著提升纹理缺失场景的渲染质量。  
◆ 开发不透明度加权梯度策略，优化高斯分布致密化过程，实现更精准的表面重建。  
◆ 在标准数据集上全面超越现有方法，尤其在低纹理/受限视角场景中表现突出，验证了方案的鲁棒性。  
◆ 为实际应用中复杂场景的3D重建提供新思路，扩展了3DGS技术的适用边界。</td></tr>
<tr><td>2025-06-27</td><td>Single-Scanline Relative Pose Estimation for Rolling Shutter Cameras</td><td>[2506.22069](http://arxiv.org/pdf/2506.22069)</td><td>◆ 提出了一种基于单扫描线投影交点的新方法，用于估计滚动快门相机间的相对位姿，无需显式建模相机运动。  
◆ 创新性地实现了单视图内扫描线的相对位姿估计，扩展了滚动快门相机的应用场景。  
◆ 该方法作为滚动快门运动恢复结构（SfM）的基础模块，支持独立计算每条扫描线的位姿，且无需运动模型假设。  
◆ 在已知内参和无镜头畸变的条件下，分类了通用和特定场景（如平行线和已知重力方向）的最小求解器。  
◆ 针对平行线场景，开发了带/不带重力先验的最小求解器，通过将其与1D相机的2D结构估计问题关联实现创新求解。  
◆ 在Fastec数据集上的实验验证了该方法用于滚动快门SfM初始化的可行性，展现了进一步开发的潜力。</td></tr>
<tr><td>2025-06-24</td><td>ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes</td><td>[2506.21629](http://arxiv.org/pdf/2506.21629)</td><td>◆ 提出了一种无需SfM预处理的方法ICP-3DGS，将迭代最近点（ICP）与基于优化的位姿细化相结合，解决了大范围无边界场景中相机位姿估计的难题。  
◆ 创新性地将ICP引入3D高斯泼溅（3DGS）框架，实现了在大幅度相机运动下的高精度位姿估计，突破了传统神经渲染对SfM先验的依赖。  
◆ 设计了基于体素的场景致密化策略，有效指导大规模场景的重建过程，提升了场景覆盖率和几何细节的完整性。  
◆ 在室内外多种尺度场景的实验中，ICP-3DGS在相机位姿估计和新视角合成任务上均优于现有方法，证明了其鲁棒性和泛化能力。  
◆ 开源了完整代码，为后续研究提供了可复现的基础，推动了无预计算位姿的神经渲染技术的发展。</td></tr>
<tr><td>2025-07-08</td><td>Wild refitting for black box prediction</td><td>[2506.21460](http://arxiv.org/pdf/2506.21460)</td><td>◆ 提出了一种名为&quot;wild refitting&quot;的高效计算流程，仅需单次数据集和预测方法的黑箱访问，通过残差计算、对称化和缩放三个步骤，为惩罚非参数估计提供实例级均方预测误差的高概率上界。  
◆ 创新性地采用Rademacher残差对称化技术（类似wild bootstrap变体），通过预定义缩放因子ρ调整残差，构建以当前估计为中心的修正预测问题。  
◆ 在允许噪声异质性的较温和条件下，理论证明了该方法性能：当wild噪声尺度ρ选择适当时，wild refit能确保预测误差上界的有效性。  
◆ 为实际应用提供关键设计指导，包括残差构建方法、wild子问题中噪声缩放量的选择依据，以及黑箱程序局部稳定性的分析框架。  
◆ 展示了方法在多个领域的适用性，如基于结构化矩阵惩罚的非刚性运动恢复、深度神经网络先验的即插即用图像修复，以及核方法的随机草图技术。</td></tr>
<tr><td>2025-06-24</td><td>Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications</td><td>[2506.19491](http://arxiv.org/pdf/2506.19491)</td><td>◆ 提出了一种将神经三维重建（N3DR）技术与小型无人机系统结合的新方法，用于精细三维数字重建静态小物体。  
◆ 设计并实现了一套基于N3DR的流程，整合了Instant-ngp、Nerfacto和Splatfacto等先进模型，显著提升了重建质量。  
◆ 通过多无人机协同采集图像，解决了小型无人机在动态飞行和功耗限制下的自主性与任务能力问题。  
◆ 采用多种图像和点云指标评估模型性能，并与传统运动恢复结构（SfM）算法对比，验证了N3DR的优越性。  
◆ 实验证明该方案能支持高精度三维建模和异常检测，拓展了小型无人机在受限环境中的应用潜力。  
◆ 整体研究展示了N3DR技术在提升微型无人机系统能力方面的广阔前景。</td></tr>
<tr><td>2025-06-23</td><td>ViDAR: Video Diffusion-Aware 4D Reconstruction From Monocular Inputs</td><td>[2506.18792](http://arxiv.org/pdf/2506.18792)</td><td>◆ 提出ViDAR框架，首次将个性化扩散模型引入单目视频的4D重建任务，通过生成伪多视角监督信号解决单目输入的结构-运动歧义问题。  
◆ 创新性地利用场景特定特征进行条件扩散，在保持外观细节的同时有效缓解单目模糊性导致的伪影问题。  
◆ 设计扩散感知损失函数，专门处理扩散生成视图的时空不一致性，提升合成视图与真实几何的对齐精度。  
◆ 提出相机位姿优化策略，动态调整合成视角与底层场景几何的匹配关系，增强动态区域的几何一致性。  
◆ 在极端视角变化的DyCheck基准测试中全面超越现有方法，尤其在运动丰富区域重建质量上取得显著提升。  
◆ 发布新评测基准，首次针对场景中高动态部分的重建性能进行系统化比较，推动领域评估标准发展。</td></tr>
<tr><td>2025-06-23</td><td>Room temperature spin injection into commercial VCSELs at non-resonant wavelengths</td><td>[2506.18376](http://arxiv.org/pdf/2506.18376)</td><td>◆ 首次在室温下实现了对商用垂直腔面发射激光器（VCSEL）的非共振波长自旋注入，突破了传统共振波长限制。  
◆ 通过794 nm和810 nm光泵浦实验，观察到20%和5%的最大圆偏振度差异，揭示了波长对自旋注入效率的影响机制。  
◆ 结合量子阱光学取向研究，证实长波长激发会导致自旋注入效率降低，为器件优化提供理论依据。  
◆ 扩展自旋翻转模型（SFM），首次纳入实际激发条件，使理论模型能准确复现实验观测趋势。  
◆ 该成果为自旋激光器的低阈值、高速调制和全光数据处理等应用提供了新的实现路径。</td></tr>
<tr><td>2025-06-11</td><td>OWSM-Biasing: Contextualizing Open Whisper-Style Speech Models for Automatic Speech Recognition with Dynamic Vocabulary</td><td>[2506.09448](http://arxiv.org/pdf/2506.09448)</td><td>◆ 提出了一种将上下文偏置（CB）方法与预训练的开放Whisper风格语音模型（OWSM v3.1）结合的新方法，无需微调预训练参数。  
◆ 通过利用预训练语音基础模型（SFMs）的嵌入知识，即使在小数据集上也能有效提升罕见词和未登录词的识别准确率。  
◆ 该方法在保持SFMs原有优势的同时，显著降低了偏置词错误率（B-WER），在LibriSpeech测试集上提升11.6个百分点。  
◆ 整体词错误率（WER）改善0.9个百分点，同时实时因子（RTF）减少7.5%，兼顾性能与效率。  
◆ 实验证明，该方法优于从头训练的CB方法，凸显了预训练模型知识迁移的重要性。</td></tr>
<tr><td>2025-06-06</td><td>SurGSplat: Progressive Geometry-Constrained Gaussian Splatting for Surgical Scene Reconstruction</td><td>[2506.05935](http://arxiv.org/pdf/2506.05935)</td><td>◆提出SurGSplat新范式，通过渐进式几何约束优化3D高斯泼溅(3DGS)技术，解决内窥镜场景稀疏特征和光照不均导致的传统SfM方法重建失败问题。  
◆首创将几何约束融入3DGS优化过程，实现血管等关键解剖结构的高精度重建，显著提升手术场景的视觉清晰度。  
◆开发渐进式优化框架，逐步细化重建细节，在保持实时性的同时突破现有方法在复杂手术环境中的性能瓶颈。  
◆实验证明该方法在新型视角合成(NVS)和位姿估计精度上均超越现有技术，为术中导航提供高保真重建解决方案。  
◆通过专属几何约束机制有效克服内窥镜图像特征稀疏的固有挑战，为微创手术提供更可靠的3D场景理解支持。  
◆开源项目网站提供完整技术细节和可视化结果，推动手术导航领域的可重复研究。</td></tr>
<tr><td>2025-06-05</td><td>On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images</td><td>[2506.05558](http://arxiv.org/pdf/2506.05558)</td><td>◆ 提出实时重建方法，能够在图像采集完成后立即生成相机位姿和训练好的3D高斯泼溅模型，显著缩短传统方法所需的分钟到小时级计算时间。  
◆ 针对大场景和宽基线图像序列，设计了快速初始位姿估计方案，结合学习特征和GPU友好的小型束调整，提升处理效率。  
◆ 创新性地采用高斯图元位置与形状的直接采样方法，通过增量式生成图元加速训练过程，实现位姿与高斯图元的快速联合优化。  
◆ 提出可扩展的辐射场构建技术，通过渐进式聚类将3DGS图元存储在锚点中并从GPU卸载，有效管理大规模场景的内存需求。  
◆ 引入动态图元合并机制，根据视点需求自适应调整3DGS规模，保持渲染质量的同时优化计算资源使用。  
◆ 实验验证该方法能实时处理多种采集场景和不同规模的数据集，在速度、图像质量或两者兼备方面优于仅针对特定场景的现有方法。</td></tr>
<tr><td>2025-06-05</td><td>SupeRANSAC: One RANSAC to Rule Them All</td><td>[2506.04803](http://arxiv.org/pdf/2506.04803)<br><a href=''>[代码]</a></td><td>◆ SupeRANSAC提出了一种统一的RANSAC框架，解决了传统RANSAC在不同视觉任务中性能不稳定的问题。  
◆ 通过系统分析RANSAC在特定视觉任务（如单应性矩阵、基础矩阵、位姿估计等）中的有效技术，优化了整体流程。  
◆ 相比现有最佳方法，SupeRANSAC在基础矩阵估计任务中平均提升了6个AUC点，表现出更高的准确性。  
◆ 该框架克服了现有库（如OpenCV和PoseLib）在不同任务中表现不一致的缺陷，实现了跨任务的稳定高性能。  
◆ 论文提供了详细的实现细节和任务特定优化，为鲁棒估计领域提供了可复现的高效解决方案。  
◆ 开源代码便于社区验证和应用，已在多个数据集和问题上展示了显著的性能提升。</td></tr>
<tr><td>2025-06-04</td><td>Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation</td><td>[2506.04225](http://arxiv.org/pdf/2506.04225)</td><td>◆ Voyager提出了一种新颖的视频扩散框架，能够从单张图像生成用户自定义相机路径下的3D点云序列，实现端到端的世界一致场景生成，无需依赖传统3D重建流程。  
◆ 该框架首次整合了RGB与深度视频的联合生成，通过现有世界观测条件确保全局一致性，解决了长序列生成中的累积误差问题。  
◆ 创新性地采用带点云剔除的世界缓存机制和自回归推理方法，支持上下文感知的迭代场景扩展，实现超长距离（&gt;100米）的3D场景探索。  
◆ 开发了可扩展的数据引擎，通过自动化相机位姿估计和深度预测，构建大规模无人工标注的训练数据集，显著降低数据获取成本。  
◆ 在视觉质量和几何精度上超越现有方法，支持虚拟现实、游戏开发等需要动态3D场景构建的应用场景。  
◆ 整体架构摒弃了多阶段处理流程，首次实现单模型直接输出几何一致的可探索3D场景，为生成式3D建模开辟新方向。</td></tr>
<tr><td>2025-06-04</td><td>Accelerating SfM-based Pose Estimation with Dominating Set</td><td>[2506.03667](http://arxiv.org/pdf/2506.03667)</td><td>◆ 提出基于支配集的预处理技术，显著加速基于SfM的位姿估计过程，适用于AR/VR和机器人等实时应用场景。  
◆ 首次将图论中的支配集概念引入SfM模型优化，在不显著损失精度前提下实现计算效率提升。  
◆ 在OnePose数据集上验证了方法的普适性，兼容多种SfM位姿估计技术，展现广泛适用性。  
◆ 实现1.5-14.48倍的加速效果，同时将参考图像数量和点云规模分别缩减17-23倍和2.27-4倍。  
◆ 通过平衡速度与精度，为实时3D位姿估计提供了高效解决方案，突破现有技术瓶颈。</td></tr>
<tr><td>2025-06-03</td><td>Nearby dwarf galaxies with extreme star formation rates: a window into dwarf-galaxy evolution in the early Universe</td><td>[2506.03265](http://arxiv.org/pdf/2506.03265)</td><td>◆ 研究发现附近低光度矮星系（质量10^7-10^8太阳质量）存在极端恒星形成率（0.1-3太阳质量/年），可作为早期宇宙（z~5.5）矮星系的类比样本。  
◆ 通过对比正常矮星系样本，发现极端恒星形成率并非由星系结构紧凑性或特殊环境（如靠近节点/纤维结构）驱动。  
◆ 揭示具有极端恒星形成率的矮星系中相互作用星系和早型形态比例显著升高（分别增加约5.6倍和9倍），表明星系相互作用是关键触发机制。  
◆ 指出当前基于中低红移数据的主序星形成率演化模型会低估早期宇宙（z~5.5）矮星系的恒星形成率。  
◆ 提出早期宇宙矮星系通过更高气体丰度与频繁相互作用的共同作用，驱动其恒星质量快速累积的新演化图景。</td></tr>
<tr><td>2025-06-02</td><td>Fast and Robust Rotation Averaging with Anisotropic Coordinate Descent</td><td>[2506.01940](http://arxiv.org/pdf/2506.01940)</td><td>◆ 提出了一种快速且鲁棒的各向异性旋转平均方法，通过分析块坐标下降法家族，简化了原有和弦距离优化的复杂形式。  
◆ 首次将各向异性扩展应用于块坐标下降法，开发出一个通用的快速求解器，显著提升了计算效率。  
◆ 将该求解器集成到大规模鲁棒旋转平均流程中，解决了传统方法在问题规模增大时计算效率低下的问题。  
◆ 通过实验验证，该方法在公开的结构运动数据集上达到了最先进的性能表现。  
◆ 克服了传统局部方法对初始化的敏感性，避免了最小生成树方法中常见的漂移累积和局部极小值陷阱问题。  
◆ 在全局最优性、鲁棒性和效率之间取得了良好平衡，为各向异性旋转平均提供了实用解决方案。</td></tr>
<tr><td>2025-06-03</td><td>Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC</td><td>[2505.24200](http://arxiv.org/pdf/2505.24200)</td><td>◆ 提出多种微调策略（冻结上游训练、部分微调、低秩适应）优化多语言语音基础模型（SFM）在ML-SUPERB 2.0上的表现。  
◆ 采用数据增强技术缓解少样本场景下的性能下降问题，提升模型在资源受限条件下的鲁棒性。  
◆ 创新性地引入语言识别（LID）感知的CTC损失函数作为正则化手段，联合优化LID和ASR任务。  
◆ 在ML-SUPERB 2.0基准上实现显著提升：LID准确率相对提高14%，ASR字错误率（CER）相对降低30%。  
◆ 综合方法在Interspeech 2025 ML-SUPERB 2.0挑战赛中斩获第二名，验证了策略的有效性。</td></tr>
<tr><td>2025-05-29</td><td>Rooms from Motion: Un-posed Indoor 3D Object Detection as Localization and Mapping</td><td>[2505.23756](http://arxiv.org/pdf/2505.23756)</td><td>◆ 提出Rooms from Motion (RfM)方法，首次实现无需先验相机位姿的室内3D物体检测，通过物体中心化框架同时完成定位与建图。  
◆ 创新性地用图像衍生的3D定向包围盒替代传统基于2D关键点的匹配器，从而估计相机位姿并生成全局语义3D物体地图。  
◆ 在已有相机位姿时，通过全局3D包围盒优化显著提升地图质量，优于依赖点云或多视图的过参数化方法。  
◆ 实现稀疏定位与参数化建图，其计算复杂度仅与场景中物体数量成正比，效率更高。  
◆ 在CA-1M和ScanNet++数据集上，RfM的定位性能与地图质量均超越基于点云和密集体素的领先方法。  
◆ 扩展Cubify Anything至全场景，建立通用的物体中心化表征，为场景理解提供新范式。</td></tr>
<tr><td>2025-05-30</td><td>FAMA: The First Large-Scale Open-Sc...</td><td>[2505.22759](http://arxiv.org/pdf/2505.22759)<br><a href=''>[代码]</a></td><td>◆FAMA是首个面向英语和意大利语的大规模开源语音基础模型，填补了语音领域开放科学的空白。  
◆创新性地使用15万+小时开源语音数据训练，并发布了包含1.6万小时清洗和伪标注数据的新数据集。 ...</td></tr>
<tr><td>**2025-05-28**</td><td>**UAVPairs: A Challenging Benchmark for Match Pair Retrieval of Large-scale UAV Images**</td><td>[2505.22098](http://arxiv.org/abs/2505.22098)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**Fast Feature Matching of UAV Images via Matrix Band Reduction-based GPU Data Schedule**</td><td>[2505.22089](http://arxiv.org/abs/2505.22089)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-30**</td><td>**Towards Robust Assessment of Pathological Voices via Combined Low-Level Descriptors and Foundation Model Representations**</td><td>[2505.21356](http://arxiv.org/abs/2505.21356)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-27**</td><td>**Intern-GS: Vision Model Guided Sparse-View 3D Gaussian Splatting**</td><td>[2505.20729](http://arxiv.org/abs/2505.20729)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-26**</td><td>**Robust fine-tuning of speech recognition models via model merging: application to disordered speech**</td><td>[2505.20477](http://arxiv.org/abs/2505.20477)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-29**</td><td>**Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud**</td><td>[2505.19854](http://arxiv.org/abs/2505.19854)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-25**</td><td>**Improving Novel view synthesis of 360$^\circ$ Scenes in Extremely Sparse Views by Jointly Training Hemisphere Sampled Synthetic Images**</td><td>[2505.19264](http://arxiv.org/abs/2505.19264)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-24**</td><td>**Token-Level Logits Matter: A Closer Look at Speech Foundation Models for Ambiguous Emotion Recognition**</td><td>[2505.18484](http://arxiv.org/abs/2505.18484)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-22**</td><td>**Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga)**</td><td>[2505.16882](http://arxiv.org/abs/2505.16882)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-21**</td><td>**A Taxonomy of Structure from Motion Methods**</td><td>[2505.15814](http://arxiv.org/abs/2505.15814)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-18**</td><td>**Shallow Flow Matching for Coarse-to-Fine Text-to-Speech Synthesis**</td><td>[2505.12226](http://arxiv.org/abs/2505.12226)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-15**</td><td>**Mapping Semantic Segmentation to Point Clouds Using Structure from Motion for Forest Analysis**</td><td>[2505.10751](http://arxiv.org/abs/2505.10751)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-13**</td><td>**Unveiling the Best Practices for Applying Speech Foundation Models to Speech Intelligibility Prediction for Hearing-Impaired People**</td><td>[2505.08215](http://arxiv.org/abs/2505.08215)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-12**</td><td>**RDD: Robust Feature Detector and Descriptor using Deformable Transformer**</td><td>[2505.08013](http://arxiv.org/abs/2505.08013)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-12**</td><td>**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**</td><td>[2505.07373](http://arxiv.org/abs/2505.07373)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-11**</td><td>**Symmetry in Fundamental Parameters of Galaxies on the Star-forming Main Sequence**</td><td>[2505.06868](http://arxiv.org/abs/2505.06868)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-10**</td><td>**TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility**</td><td>[2505.06743](http://arxiv.org/abs/2505.06743)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-08**</td><td>**DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion**</td><td>[2505.05473](http://arxiv.org/abs/2505.05473)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-20**</td><td>**FastMap: Revisiting Dense and Scalable Structure from Motion**</td><td>[2505.04612](http://arxiv.org/abs/2505.04612)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-15**</td><td>**Estimating the Diameter at Breast Height of Trees in a Forest With a Single 360 Camera**</td><td>[2505.03093](http://arxiv.org/abs/2505.03093)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-03**</td><td>**AquaGS: Fast Underwater Scene Reconstruction with SfM-Free Gaussian Splatting**</td><td>[2505.01799](http://arxiv.org/abs/2505.01799)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-03**</td><td>**PosePilot: Steering Camera Pose for Generative World Models with Self-supervised Depth**</td><td>[2505.01729](http://arxiv.org/abs/2505.01729)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-01**</td><td>**Are Minimal Radial Distortion Solvers Really Necessary for Relative Pose Estimation?**</td><td>[2505.00866](http://arxiv.org/abs/2505.00866)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
</tbody>
</table>
</div>

<h2 id='visual-localization'>Visual Localization</h2>

<div class="table-container">
<table>
<thead><tr><th>日期</th><th>标题</th><th>论文与代码</th><th>摘要</th></tr></thead>
<tbody>
<tr><td>2025-09-04</td><td>Global-to-Local or Local-to-Global? Enhancing Image Retrieval with Efficient Local Search and Effective Global Re-ranking</td><td>[2509.04351](http://arxiv.org/pdf/2509.04351)</td><td>该论文提出了与主流相反的“局部到全局”图像检索新范式，取代了传统的“全局到局部”方法。  
◆ 利用新兴的高效局部特征搜索技术，首先进行大规模精细的局部匹配，以找到全局特征容易遗漏的局部相似图像。  
◆ 创新性地引入了一种基于局部检索相似性的全局特征即时重排序方法，在重排序阶段才动态生成全局特征。  
◆ 采用多维缩放技术，将局部特征检索获得的相似性关系嵌入到全局特征表示中，使全局特征能够尊重局部匹配的结果。  
这种结合使得重排序过程既保持了高计算效率，又显著提升了检索精度。  
实验表明，该方法在Revisited Oxford和Paris数据集上取得了新的最先进性能。</td></tr>
<tr><td>2025-09-04</td><td>DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval</td><td>[2509.04193](http://arxiv.org/pdf/2509.04193)</td><td>该论文提出了一种基于扩散模型的无监督跨域图像检索方法DUDE，其核心贡献在于通过特征解耦解决跨域检索中对象特征与域风格纠缠的难题。  
◆ 利用文本到图像生成模型实现对象特征与域特定风格的解耦，增强语义表示的纯净性。  
◆ 提出渐进式跨域互近邻对齐机制，通过域内到域间的逐步对齐提升特征匹配可靠性。  
◆ 在三个基准数据集（涵盖13个域）上取得最先进性能，验证了方法的泛化能力。  
该方法无需标注即可实现跨域精准检索，为无监督域适应领域提供了新思路。</td></tr>
<tr><td>2025-09-02</td><td>Scale, Don&#x27;t Fine-tune: Guiding Multimodal LLMs for Efficient Visual Place Recognition at Test-Time</td><td>[2509.02129](http://arxiv.org/pdf/2509.02129)</td><td>该论文提出了一种用于视觉地点识别（VPR）的零样本新框架，核心贡献在于无需微调即可实现高效且强大的跨域识别。其创新点包括：
◆ 提出测试时缩放（TTS）框架，利用多模态大模型（MLLM）的视觉-语言对齐能力，通过基于引导的方法直接进行相似性评分，避免了传统微调的高计算开销。
◆ 采用结构化提示生成长度可控的JSON输出，消除了传统方法中复杂的多阶段处理流程，简化了流程。
◆ 引入不确定性感知自一致性（UASC）机制，使模型能在测试时进行实时自适应，无需额外训练成本，提升了实时性。
◆ 实现了卓越的跨域泛化能力，在多种环境中显著提升性能，同时计算效率提升了高达210倍。
实验结果表明，该方法在保持高性能的同时，极大提升了效率与适应性。</td></tr>
<tr><td>2025-09-02</td><td>Ensemble-Based Event Camera Place Recognition Under Varying Illumination</td><td>[2509.01968](http://arxiv.org/pdf/2509.01968)</td><td>本文提出了一种集成式事件相机地点识别方法，显著提升了在剧烈光照变化下的环境鲁棒性。  
◆ 采用多事件重建、多特征提取与多时序分辨率的集成融合策略，突破了以往仅融合时序信息的局限。  
◆ 在跨日-夜光照变化场景下实现了Recall@1指标57%的相对提升，表现出极强的光照鲁棒性。  
◆ 在长达8公里的实际驾驶数据集上验证了有效性，未进行降采样，保留了真实事件密度变化。  
◆ 提出了对序列匹配框架的改进，有效提升了长序列下的识别性能。  
◆ 系统分析了事件表征、重建方法和特征提取等关键设计选项的影响，为后续研究提供了重要参考。</td></tr>
<tr><td>2025-09-01</td><td>M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision</td><td>[2509.01360](http://arxiv.org/pdf/2509.01360)</td><td>M3Ret论文的核心贡献是提出了一种统一的自监督视觉编码器，成功解决了多模态医学图像检索的碎片化问题。其创新点包括：
◆构建了大规模混合模态医学数据集，包含86万余样本，涵盖2D、3D及视频数据
◆首次在不使用任何模态定制化设计的前提下，实现了统一的多模态视觉编码器
◆融合生成式(MAE)与对比式(SimDINO)自监督学习范式，学习可迁移的视觉表示
◆在零样本检索任务上全面超越DINOv3和BMC-CLIP等强基线模型
◆展现出强大的跨模态对齐能力，无需配对数据即可实现跨模态检索
◆首次证明纯视觉自监督学习可泛化至未见模态（如未训练的MRI数据），为医学基础模型发展提供了新方向</td></tr>
<tr><td>2025-09-01</td><td>ReCap: Event-Aware Image Captioning with Article Retrieval and Semantic Gaussian Normalization</td><td>[2509.01259](http://arxiv.org/pdf/2509.01259)</td><td>该论文提出了ReCap系统，旨在解决传统图像描述生成无法捕捉事件级语义的问题，通过整合相关文章中的上下文信息来生成叙事丰富且事实准确的描述。  
◆ 设计了一个两阶段文章检索系统，结合DINOv2全局特征相似度初选和局部块互近邻相似度重排序，提升事件相关文章的检索精度。  
◆ 开发了上下文提取框架，综合文章摘要、通用描述和源数据信息，为生成描述提供多维度语义支持。  
◆ 引入了基于大语言模型的描述生成机制，并采用语义高斯归一化技术，增强生成文本的流畅性和相关性。  
在EVENTA 2025挑战赛中，ReCap在OpenEvents V1数据集上取得0.54666的综合评分，排名第二，验证了其有效性和实用性。  
该系统为新闻存档等高要求领域提供了视觉感知与真实世界知识融合的解决方案。</td></tr>
<tr><td>2025-09-03</td><td>Multimodal Iterative RAG for Knowledge Visual Question Answering</td><td>[2509.00798](http://arxiv.org/pdf/2509.00798)</td><td>该论文提出了MI-RAG，一个多模态迭代检索增强生成框架，用于解决知识密集型视觉问答任务。其核心创新点在于：

◆ 采用迭代式检索-推理框架，通过多轮迭代逐步完善外部知识的获取与理解，克服了传统单次检索知识不足的局限。

◆ 利用累积的推理记录动态生成多查询，驱动对包含视觉和文本信息的异构知识库进行联合搜索。

◆ 实现了跨模态的知识融合与推理更新，将新检索到的知识合成到推理记录中，进行渐进式的精化理解。

实验证明，该方法在多个挑战性基准上显著提高了检索召回率和答案准确率，为知识密集型视觉问答提供了一个可扩展的组合推理方案。</td></tr>
<tr><td>2025-08-31</td><td>Multi-Level CLS Token Fusion for Contrastive Learning in Endoscopy Image Classification</td><td>[2509.00752](http://arxiv.org/pdf/2509.00752)</td><td>本文提出了一种面向内窥镜图像分析的统一视觉-语言框架，其核心贡献在于通过多模态对比学习实现三类临床任务的高效协同处理。  
◆ 采用CLIP ViT-B/16主干网络并引入低秩自适应（LoRA）技术，实现有限医疗数据下的高效微调。  
◆ 提出多级CLS令牌聚合机制，增强视觉特征的多样性和表征能力。  
◆ 设计球面特征插值方法，优化跨模态语义对齐效果。  
◆ 创新性地引入类别特定的自然语言提示，将诊断文本上下文与视觉特征通过对比学习和监督分类联合训练目标进行融合。  
该框架在多项任务中达到S性能（分类准确率95%，检索Recall@1超0.92），并通过消融实验验证了各模块的有效性，为低资源医疗场景提供了鲁棒的多模态理解方案。</td></tr>
<tr><td>2025-08-31</td><td>EVENT-Retriever: Event-Aware Multimodal Image Retrieval for Realistic Captions</td><td>[2509.00751](http://arxiv.org/pdf/2509.00751)</td><td>该论文提出了一个面向复杂事件描述的多模态图像检索系统EVENT-Retriever，其核心创新在于通过多阶段框架解决传统方法对隐含事件语义和长文本描述的检索瓶颈。  
◆ 结合密集文档检索、事件感知语言模型重排序和高效图像收集的多阶段检索架构  
◆ 利用Qwen3系列模型实现文章搜索、上下文对齐和精准图像评分的分层处理  
◆ 引入基于标题的语义匹配与排序感知选择机制增强事件关联性  
◆ 采用 Reciprocal Rank Fusion 融合多配置输出提升系统鲁棒性  
该系统在EVENTA 2025挑战赛Track 2私有测试集上获得第一名，证明了语言推理与多模态检索结合对复杂现实图像理解的有效性。</td></tr>
<tr><td>2025-08-29</td><td>Category-level Text-to-Image Retrieval Improved: Bridging the Domain Gap with Diffusion Models and Vision Encoders</td><td>[2509.00177](http://arxiv.org/pdf/2509.00177)</td><td>该论文针对类别级文本-图像检索任务，提出了一种解决模态差异的创新方法。其核心贡献在于通过融合生成模型与视觉编码器，显著提升了跨模态检索性能。

◆ 提出两阶段检索框架：首先生成模型将文本查询转换为视觉查询，再用视觉模型计算图像间相似度。
◆ 利用扩散模型生成高质量图像，将文本模态转化为视觉模态，有效缩小文本与图像在表示空间中的差距。
◆ 设计聚合网络整合多个生成图像的向量表示，形成单一且鲁棒的查询表征。
◆ 创新性地融合文本和生成图像双模态的相似度评分，进一步提升检索精度。
该方法综合运用了视觉语言模型、扩散生成模型和视觉编码器的最新进展，在多个评估中显著优于仅依赖文本查询的检索方法。</td></tr>
<tr><td>2025-08-29</td><td>HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones</td><td>[2508.21539](http://arxiv.org/pdf/2508.21539)</td><td>该论文针对自然语言引导无人机任务中的复杂视觉-语言理解挑战，提出了HCCM分层跨粒度对比与匹配学习框架。其核心创新如下：
◆ 提出区域-全局图像文本对比学习（RG-ITC），无需精确场景划分即可捕获从局部到全局的分层语义对齐；
◆ 设计区域-全局图像文本匹配（RG-ITM），通过评估全局跨模态表征中的局部语义一致性来增强组合推理能力；
◆ 引入动量对比与蒸馏机制（MCD），有效缓解无人机文本描述不完整或模糊带来的对齐不稳定问题；
◆ 在GeoText-1652和ERA数据集上实现检索精度突破，显著优于现有方法并展现强大零样本泛化能力。</td></tr>
<tr><td>2025-08-27</td><td>Disentangling Latent Embeddings with Sparse Linear Concept Subspaces (SLiCS)</td><td>[2508.20322](http://arxiv.org/pdf/2508.20322)</td><td>该论文提出了一种名为SLiCS的方法，用于解耦视觉-语言共嵌入空间中的语义信息。其核心贡献是通过稀疏线性概念子空间实现嵌入向量的结构化分解。  
◆ 提出一种监督式字典学习框架，将嵌入向量分解为多个概念特定的成分，每个成分由字典中一组稀疏非负的原子向量线性组合而成。  
◆ 设计了一种新颖的交替优化算法，保证收敛性，并能学习具有分组结构的字典，其组活动与多标签信息匹配。  
◆ 利用文本共嵌入特性，实现无监督字典学习：通过概念标签的文本嵌入进行零样本分类，自动生成实例级多标签。  
◆ 能够为每个概念子空间找到语义明确的文本描述，增强可解释性。  
该方法在概念过滤图像检索和条件生成任务中表现出更高精度，适用于CLIP、TiTok和DINOv2等多种嵌入空间。</td></tr>
<tr><td>2025-08-27</td><td>Low-exposure, high-quality multimodal speckle X-ray imaging via an intrinsic gradient-flow approach</td><td>[2508.20209](http://arxiv.org/pdf/2508.20209)</td><td>该论文提出了一种基于梯度流方法的新型多模态散斑X射线成像技术。其核心创新在于开发了梯度流MIST算法，显著提升了成像性能和数据效率。  
◆ 首次将梯度流方法引入散斑成像领域，通过求解福克-普朗克方程同步获取衰减、相移和暗场三种互补成像模式  
◆ 大幅减少成像所需数据量，降低实验中对曝光量和采样数量的要求  
◆ 在保持X射线福克-普朗克方程完整通用性的前提下，突破传统算法的局限性  
◆ 显著提升暗场图像质量，能有效显示低于空间分辨率的亚像素结构信息  
◆ 通过澳大利亚同步辐射实验验证了该方法在相位衬度和暗场成像中的应用潜力，特别适用于需要简化实验流程的场景。</td></tr>
<tr><td>2025-08-27</td><td>Grounding Multimodal Large Language Models with Quantitative Skin Attributes: A Retrieval Study</td><td>[2508.20188](http://arxiv.org/pdf/2508.20188)</td><td>该论文探索了如何利用定量皮肤属性提升多模态大语言模型在皮肤疾病诊断中的可解释性。  
◆ 创新性地将多模态大语言模型（MLLMs）与定量皮肤属性（如病灶面积）相结合，以增强诊断推理的可解释性。  
◆ 提出通过微调MLLMs，使其能够从皮肤图像中预测这些定量属性值，从而实现模型嵌入空间与临床属性的对齐。  
◆ 采用基于内容的图像检索方法，在SLICE-3D数据集上验证了嵌入空间与属性之间的关联性。  
◆ 为模型诊断结果提供了可量化的视觉依据，使模型输出更具可信度和交互性。  
这一研究为构建更透明、可解释的医疗人工智能系统提供了新的思路和方法基础。</td></tr>
<tr><td>2025-08-27</td><td>Addressing Deepfake Issue in Selfie banking through camera based authentication</td><td>[2508.19714](http://arxiv.org/pdf/2508.19714)</td><td>该论文的核心贡献是提出了一种利用相机成像特征来防御自拍银行中深度伪造攻击的新型认证方法。

◆ 创新性地将原本用于图像溯源（如图片相机定位）的取证识别系统，应用于深度伪造检测领域，实现了技术应用的跨界迁移。
◆ 该方法专注于利用相机本身的硬件缺陷（如镜头光学特性、传感器噪声模式）作为生物特征之外的辅助认证因素，因为深度伪造技术难以完美复制这些物理层面的细微特征。
◆ 通过分析图像中嵌入的相机固有“指纹”来区分真实拍摄的照片与AI生成的伪造图像，为现有的面部识别生物系统增加了一个强大的安全层。
◆ 为解决自拍银行等金融场景下面临的日益严峻的深度伪造威胁，提供了一种实用且可能更可靠的解决方案。</td></tr>
<tr><td>2025-08-26</td><td>Can we make NeRF-based visual localization privacy-preserving?</td><td>[2508.18971](http://arxiv.org/pdf/2508.18971)</td><td>该论文针对基于NeRF的视觉定位方法存在的隐私泄露风险提出了解决方案。  
◆ 首先设计了一种新的评估协议，用于系统检验NeRF表示中的隐私保护性，发现即使移除颜色预测头，其几何表示仍会存储敏感细节。  
◆ 提出一种自监督学习框架，将RGB图像转换为分割标签作为训练监督，避免直接使用原始图像数据。  
◆ 构建了ppNeSF（隐私保护神经分割场），以分割标签替代RGB进行训练，确保场景表示既粗糙无法还原细节，又保留足够的判别性用于定位。  
◆ 在保护隐私的同时，该方法实现了先进的视觉定位精度，平衡了隐私与实用性。  
◆ 整体工作首次系统揭示了NeRF的隐私漏洞，并提供了可替代的隐私保护范式。</td></tr>
<tr><td>2025-08-26</td><td>Event-Enriched Image Analysis Grand Challenge at ACM Multimedia 2025</td><td>[2508.18904](http://arxiv.org/pdf/2508.18904)</td><td>该论文的核心贡献是推出了首个专注于事件级多模态理解的大规模基准挑战EVENTA，以解决传统方法在图像分析中忽视上下文和语义深度的问题。

◆ 首创大规模事件级多模态理解基准，突破传统图像描述与检索的表层识别局限。
◆ 通过整合上下文、时序和语义信息，构建“人物、时间、地点、事件、原因”五维事件理解框架。
◆ 基于OpenEvents V1数据集设计双赛道：事件增强图像检索与描述，以及事件驱动图像检索。
◆ 建立包含45支国际团队参与的公平评估体系，通过公开和私有测试阶段确保结果可复现性。
◆ 为叙事驱动多媒体AI奠定基础，推动新闻、媒体分析、文化存档等领域的上下文感知应用发展。</td></tr>
<tr><td>2025-08-25</td><td>GSVisLoc: Generalizable Visual Localization for Gaussian Splatting Scene Representations</td><td>[2508.18242](http://arxiv.org/pdf/2508.18242)</td><td>GSVisLoc提出了一种专为3D高斯泼溅（3DGS）场景表示设计的通用视觉定位方法。  
◆ 首次实现了无需任何修改或重训练，直接利用原始3DGS模型进行视觉定位。  
◆ 通过下采样和编码3D高斯来提取场景特征，并与查询图像特征进行鲁棒匹配。  
◆ 采用由粗到精的三阶段流程：粗匹配、精细匹配和姿态优化，确保高精度位姿估计。  
◆ 在室内外标准基准测试中表现出竞争力，显著优于现有基于3DGS的基线方法。  
◆ 展现出强大的泛化能力，无需额外训练即可直接应用于全新场景。</td></tr>
<tr><td>2025-08-25</td><td>SAIL-Recon: Large SfM by Augmenting Scene Regression with Localization</td><td>[2508.17972](http://arxiv.org/pdf/2508.17972)</td><td>SAIL-Recon提出了一种用于大规模运动恢复结构（SfM）的前馈Transformer模型，旨在解决现有场景回归方法难以处理大量输入图像的问题。

◆ 核心创新是将视觉定位能力融入场景回归网络，通过引入锚点图像子集来构建神经场景表示。
◆ 该方法首先从锚点图像计算出一个紧凑的神经场景表示，作为全局场景先验。
◆ 回归网络随后以该神经表示为条件进行微调，从而能够高效地重建所有输入图像的相机位姿和3D结构。
◆ 该方法在保持场景回归方法应对极端视角变化优势的同时，成功将其扩展至大规模场景。
实验表明，该方法在TUM-RGBD、CO3Dv2和Tanks &amp; Temples等多个基准测试中，在相机位姿估计和新视角合成任务上均达到了最先进的性能。</td></tr>
<tr><td>2025-08-24</td><td>Data Leakage in Visual Datasets</td><td>[2508.17416](http://arxiv.org/pdf/2508.17416)</td><td>该论文的核心贡献是系统性地分析了视觉数据集中的数据泄漏问题及其对模型评估可靠性的影响。  
◆首次对视觉数据泄漏进行了多维度分类，依据模态、覆盖范围和程度划分泄漏类型。  
◆采用图像检索技术实证检验了多个主流数据集，发现所有被分析数据集均存在不同形式的泄漏。  
◆证明了各类泄漏（从严重到轻微）均会损害下游任务中模型评估的公正性。  
◆揭示了互联网数据源与公开基准并存导致的泄漏必然性，呼吁学界关注数据构建规范。  
研究结果对视觉领域基准构建和模型评估实践具有重要警示意义。</td></tr>
<tr><td>2025-08-22</td><td>Sparse and Dense Retrievers Learn Better Together: Joint Sparse-Dense Optimization for Text-Image Retrieval</td><td>[2508.16707](http://arxiv.org/pdf/2508.16707)</td><td>本文提出了一种联合稀疏-密集检索优化框架，用于提升多模态文本-图像检索性能。  
◆ 通过自知识蒸馏实现稀疏与密集表示的双向协同学习，突破以往单向蒸馏或独立训练的限制。  
◆ 提出融合相似度分数（稀疏与密集得分的加权和）作为共享教师信号，同步优化两种表示。  
◆ 仅微调密集编码器最后一层和稀疏投影头，无需全模型重训练，高效兼容现有视觉-语言预训练模型。  
实验表明，该框架使稀疏检索器性能显著优于现有稀疏基线，甚至达到或超越密集模型效果，同时保持稀疏模型的高效与可解释性优势。</td></tr>
<tr><td>2025-08-21</td><td>DesignCLIP: Multimodal Learning with CLIP for Design Patent Understanding</td><td>[2508.15297](http://arxiv.org/pdf/2508.15297)</td><td>该论文提出了DesignCLIP，一个基于CLIP的多模态框架，用于提升设计专利的理解与分析。其核心贡献与创新点包括：
◆ 构建了首个针对美国设计专利的大规模数据集，为多模态研究提供了基础。
◆ 提出类感知分类与对比学习策略，有效适应专利数据的抽象和结构性特点。
◆ 利用生成式详细标注和专利图像的多视角学习，增强了图像与文本的语义对齐。
◆ 验证了框架在专利分类和检索任务上的优越性，显著超越现有基线及SOTA模型。
◆ 探索了多模态专利检索的应用潜力，为设计创新提供更多样化的灵感来源。</td></tr>
<tr><td>2025-08-19</td><td>UniECS: Unified Multimodal E-Commerce Search Framework with Gated Cross-modal Fusion</td><td>[2508.13843](http://arxiv.org/pdf/2508.13843)</td><td>◆ 提出了UniECS统一多模态电商搜索框架，能灵活处理图像、文本及其任意组合的检索场景，突破了传统方法局限于固定模态配对的限制。  
◆ 设计了新型门控多模态编码器，采用自适应融合机制，有效整合不同模态表征并处理模态缺失问题。  
◆ 开发了综合训练策略，结合跨模态对齐损失、局部对齐损失、模态内对比损失和自适应损失加权，优化模型学习效果。  
◆ 构建了M-BEER基准数据集，包含5万商品对，为多模态电商检索提供全面评估标准。  
◆ 在多个基准测试中显著优于现有模型（如文本搜图任务R@10提升28%），参数量仅0.2B，效率远超更大规模模型。  
◆ 成功部署于快手电商搜索平台，点击率提升2.74%、收入增长8.33%，验证了实际应用价值。</td></tr>
<tr><td>2025-08-19</td><td>ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments</td><td>[2508.13488](http://arxiv.org/pdf/2508.13488)</td><td>该论文提出了一种在重复环境中进行鲁棒回环闭合验证的方法ROVER，其核心创新在于利用历史轨迹作为先验约束来提升验证可靠性。  
◆ 首次将机器人的时空运动轨迹作为先验知识引入回环验证过程，突破了传统方法仅依赖外观特征的局限性。  
◆ 提出通过位姿图优化生成候选回环对应的轨迹，并设计评分机制评估该轨迹与无回环先验轨迹的一致性。  
◆ 在存在高度相似结构的重复环境中能有效拒绝错误回环，显著降低SLAM系统的误检风险。  
实验证明，该方法在公开数据集和真实场景中均表现出优越性能，并可无缝集成至现有先进SLAM系统中。</td></tr>
<tr><td>2025-08-17</td><td>CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval</td><td>[2508.12290](http://arxiv.org/pdf/2508.12290)</td><td>◆ 提出CLAIR方法，利用CLIP生成的噪声伪标签进行弱监督零样本跨域图像检索（WSZS-CDIR），替代传统无监督方法。  
◆ 通过CLIP文本与图像特征的相似度计算置信分数，有效优化噪声伪标签的质量。  
◆ 设计类感知潜在空间编码机制，结合实例间和簇间对比损失，提升特征区分度。  
◆ 提出跨域对比损失减少域差异，并创新性地通过闭式解学习跨域映射函数，仅用CLIP文本嵌入实现特征对齐。  
◆ 引入可学习提示词增强零样本泛化能力，支持新类别检索。  
◆ 在TUBerlin、Sketchy等数据集上验证了CLAIR的优越性，性能超越现有最优方法。</td></tr>
<tr><td>2025-08-15</td><td>Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering</td><td>[2508.11272](http://arxiv.org/pdf/2508.11272)</td><td>◆ 提出了一种名为PMTFR的框架，结合金字塔匹配模型与无训练精炼机制，显著提升了监督式组合图像检索（CIR）的性能。  
◆ 设计了简单高效的金字塔修补模块（Pyramid Patcher），通过多粒度视觉信息理解增强模型对参考图像和修改指令的联合解析能力。  
◆ 首次将表示工程（Representation Engineering）引入CIR任务，利用思维链（CoT）数据提取表征并注入多模态大模型，无需额外训练排序模型即可优化检索结果。  
◆ 创新性地在监督式CIR中实现无训练精炼范式，摆脱传统方法对显式文本推理或复杂提示设计的依赖，仅通过表征注入即可提升分数。  
◆ 在主流CIR基准测试中超越现有最优方法，验证了框架的有效性，同时保持模型轻量化与可扩展性。</td></tr>
<tr><td>2025-08-12</td><td>Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications</td><td>[2508.10933](http://arxiv.org/pdf/2508.10933)</td><td>◆ 将相机位姿自编码器（PAE）从绝对位姿回归（APR）扩展到相对位姿回归（RPR），提出了一种新的基于PAE的RPR方法。  
◆ 设计了一种无需额外存储图像或位姿数据的重定位方案，通过PAE-based RPR对APR预测结果进行优化，显著提升了定位精度。  
◆ 在同等架构下，验证了PAE-based RPR相比传统图像基RPR模型的有效性，证明了其性能优势。  
◆ 在室内场景基准测试中，展示了该方法对APR定位精度的显著提升，尤其在数据有限的情况下表现突出。  
◆ 仅需30%的训练数据即可达到竞争性性能，大幅降低了零售场景部署中的数据收集负担，提升了数据效率。  
◆ 开源了代码与预训练模型，为后续研究与应用提供了便利。</td></tr>
<tr><td>2025-08-12</td><td>FineState-Bench: A Comprehensive Benchmark for Fine-Grained State Control in GUI Agents</td><td>[2508.09241](http://arxiv.org/pdf/2508.09241)</td><td>◆ 提出了首个细粒度GUI代理控制评估标准FineState-Bench，填补了现有基准仅关注粗粒度任务完成的空白  
◆ 构建了跨平台（桌面/网页/移动端）的2257项任务测试集，包含四个组件模块和四阶段评估指标  
◆ 创新开发了即插即用的视觉诊断助手VDA，首次实现感知与定位能力的量化解耦分析  
◆ 通过实验揭示当前最先进模型在细粒度交互中仅达32.8%准确率，验证了基准的有效性  
◆ 首次证实视觉定位能力是当前GUI代理的主要瓶颈（理想视觉可使Gemini模型成功率提升14.9%）  
◆ 完整开源评估框架与数据集，为GUI代理研究提供标准化测试环境与诊断工具</td></tr>
<tr><td>2025-08-13</td><td>SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling</td><td>[2508.09105](http://arxiv.org/pdf/2508.09105)</td><td>◆ 提出首个面向半黑盒检索控制环境的来源感知成员审计框架(SMA)，实现生成内容细粒度来源追踪（预训练/外部检索/用户输入），解决传统成员推理方法在RAG系统中失效的问题。  
◆ 设计基于零阶优化的归因估计机制，通过大规模扰动采样和岭回归建模，在半黑盒约束下鲁棒近似输入令牌对输出的真实影响。  
◆ 首创跨模态归因技术，利用多模态大模型将图像输入投影为文本描述，实现文本模态的令牌级归因，首次支持MRAG系统中图像检索痕迹的成员推理。  
◆ 将成员推理的研究焦点从&quot;数据是否被记忆&quot;转向&quot;内容来源何处&quot;，为复杂生成系统的数据溯源审计提供新范式。  
◆ 突破现有方法在检索与多模态融合场景下的局限性，通过控制检索过程实现可验证的隐私泄露责任认定。</td></tr>
<tr><td>2025-08-12</td><td>A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition</td><td>[2508.08917](http://arxiv.org/pdf/2508.08917)</td><td>◆提出基于伪全局融合范式的跨视角网络，通过多模态分支协同学习统一语义空间特征，解决传统方法忽略特征空间内在结构的问题。  
◆创新性地引入伪全局信息引导机制，有效协调不同模态分支的特征表达，增强复杂环境下的场景识别能力。  
◆提出流形适应与成对方差-局部性学习度量方法，构建对称正定(SPD)矩阵计算马氏距离，取代传统欧氏距离度量。  
◆通过几何化建模准确刻画特征空间内数据本质分布，捕捉复杂的类间依赖关系，显著提升时变场景下的识别鲁棒性。  
◆实验证明该方法在复杂环境条件下具有竞争优势，尤其在GPS拒止环境中的定位和闭环检测任务表现突出。  
◆整体框架突破了欧式空间线性假设的局限性，为激光雷达地点识别任务提供了新的非线性特征学习范式。</td></tr>
<tr><td>2025-07-31</td><td>Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace</td><td>[2508.05661](http://arxiv.org/pdf/2508.05661)</td><td>◆ 提出了一种基于零样本检索的可扩展视觉搜索系统，适用于C2C电商平台，解决了非结构化商品列表的搜索难题。  
◆ 首次在Mercari平台中对比了多种视觉语言模型的零样本检索性能，发现多语言SigLIP模型表现最优，nDCG@5指标比原有微调基线提升13.3%。  
◆ 设计了实时推理与后台索引相结合的工作流，并通过降维优化统一嵌入管道，实现了高效部署。  
◆ 通过线上A/B测试验证了实际效果，实验组用户通过图像搜索的成交率提升高达40.9%，显著提升了用户参与度和转化率。  
◆ 证明了零样本模型可作为生产环境的强基线方案，既能快速部署，又保留了未来微调的灵活性，大幅降低开发成本。</td></tr>
<tr><td>2025-08-06</td><td>ACM Multimedia Grand Challenge on ENT Endoscopy Analysis</td><td>[2508.04801](http://arxiv.org/pdf/2508.04801)</td><td>◆ 提出了ENTRep挑战赛，首次将耳鼻喉内窥镜分析的细粒度解剖分类与跨模态检索（图像到图像、文本到图像）结合，填补了该领域公共基准的空白。  
◆ 构建了首个支持双语（越南语和英语）临床描述的专业数据集，包含专家标注的解剖区域、正常/异常状态及双语言叙事文本，增强了数据多样性。  
◆ 设计了三个标准化评测任务（分类、图像检索、文本检索），并建立服务器端评分机制，确保评估的公平性与可复现性。  
◆ 引入公开和私有测试集的双轨评估策略，兼顾模型泛化能力与临床实际需求。  
◆ 通过分析优胜团队方案，揭示了多模态融合和跨语言对齐在医疗影像分析中的关键作用，为后续研究提供方向。</td></tr>
<tr><td>2025-08-06</td><td>Advanced Multi-Architecture Deep Learning Framework for BIRADS-Based Mammographic Image Retrieval: Comprehensive Performance Analysis with Super-Ensemble Optimization</td><td>[2508.04790](http://arxiv.org/pdf/2508.04790)</td><td>◆ 提出首个针对BIRADS五分类乳腺图像检索的综合深度学习框架，解决了现有医学图像检索中样本不足、数据划分不当和统计验证不足的方法学局限。  
◆ 系统比较了DenseNet121、ResNet50和VGG16架构，结合差异化微调、度量学习和超集成优化等先进训练策略，其中差异化微调使DenseNet121和ResNet50的precision@10提升19.6%。  
◆ 采用严格分层数据划分（50%/20%/30%训练/验证/测试）和1000次bootstrap置信区间验证，测试集包含602例查询，确保结果临床可靠性。  
◆ 创新性提出超集成优化方法，整合互补架构实现36.33%的precision@10（95% CI: 34.78%-37.88%），比基线提升24.93%，每查询返回3.6个相关病例。  
◆ 通过统计验证显示不同优化策略间存在显著差异（p&lt;0.001，Cohen&#x27;s d&gt;0.8），同时保持2.8毫秒的实时检索效率，远超文献中5类医学检索20-25%的性能预期。  
◆ 建立临床部署的循证架构选择指南，为诊断支持和质量控制应用提供新性能基准。</td></tr>
<tr><td>2025-08-06</td><td>Metric Learning in an RKHS</td><td>[2508.04476](http://arxiv.org/pdf/2508.04476)</td><td>◆ 提出了一个在再生核希尔伯特空间（RKHS）中进行度量学习的通用框架，突破了以往仅限于欧几里得空间（ℝᵈ）的理论局限。  
◆ 首次为基于核方法和神经网络的非线性度量学习提供了理论保证，填补了该领域缺乏理论支撑的空白。  
◆ 推导了新的泛化误差界和样本复杂度上界，为实际应用中所需的数据量提供了理论指导。  
◆ 通过仿真实验和真实数据集验证了框架的有效性，代码已开源以促进后续研究。  
◆ 将三元组比较（如“h更接近i还是j？”）的弱监督信号与RKHS结合，扩展了度量学习在图像检索、推荐系统等场景的应用潜力。</td></tr>
<tr><td>2025-08-06</td><td>Composed Object Retrieval: Object-level Retrieval via Composed Expressions</td><td>[2508.04424](http://arxiv.org/pdf/2508.04424)</td><td>◆ 提出全新任务Composed Object Retrieval (COR)，突破现有图像级组合检索局限，实现基于参考对象+文本描述的对象级精确检索与分割。  
◆ 揭示COR任务的核心挑战：需在复杂场景中精准定位符合组合语义的任意对象，同时排除语义相似但无关的干扰对象。  
◆ 构建首个大规模COR基准数据集COR127K，包含408个类别、12.7万组检索三元组，覆盖多样化语义变换场景。  
◆ 设计统一端到端模型CORE，创新性整合参考区域编码、自适应视觉-文本交互和区域级对比学习三大关键技术。  
◆ 实验证明CORE在基类和新类上均显著优于现有模型，为细粒度多模态检索研究开辟新方向。  
◆ 首次实现从&quot;图像级匹配&quot;到&quot;对象级定位&quot;的跨越，推动多模态系统对用户意图的精细化理解。</td></tr>
<tr><td>2025-08-06</td><td>RiemanLine: Riemannian Manifold Representation of 3D Lines for Factor Graph Optimization</td><td>[2508.04335](http://arxiv.org/pdf/2508.04335)</td><td>◆ 提出RiemanLine，一种基于黎曼流形的3D直线统一最小表示法，可同时处理独立直线和平行线组，解决了人造环境中普遍存在的结构规律性问题。  
◆ 创新性地将直线地标解耦为全局和局部组件：在单位球面S²上优化的共享消失方向，以及在正交子空间上约束的缩放法向量，实现了结构规律的紧凑编码。  
◆ 对于n条平行线，将参数空间从4n（正交形式）减少到2n+2，无需显式约束即可自然嵌入平行性，显著降低了参数维度。  
◆ 将该参数化方法集成到因子图框架中，实现了全局方向对齐和局部重投影优化的统一基于流形的束调整。  
◆ 在ICL-NUIM、TartanAir和合成基准测试上的大量实验表明，该方法在姿态估计和直线重建方面显著提高了准确性，同时改善了收敛稳定性。</td></tr>
<tr><td>2025-08-05</td><td>Prototype-Enhanced Confidence Modeling for Cross-Modal Medical Image-Report Retrieval</td><td>[2508.03494](http://arxiv.org/pdf/2508.03494)</td><td>◆ 提出Prototype-Enhanced Confidence Modeling (PECM)框架，通过多级原型建模解决医学跨模态检索中语义模糊性问题。  
◆ 首次在医学图像-报告检索中引入双流置信度估计机制，结合原型相似度分布自适应调整高不确定性数据的影响权重。  
◆ 设计多模态原型学习模块，分别捕捉图像和文本的层次化语义特征，显著提升跨模态对齐的鲁棒性。  
◆ 开发自适应加权策略，动态平衡不同置信度样本在检索排序中的贡献，改善临床复杂场景下的结果可靠性。  
◆ 在完全监督和零样本检索任务上实现最高10.17%的性能提升，在多个放射学数据集上刷新当前最优水平。  
◆ 首次系统验证原型增强方法对医学数据固有歧义性的处理能力，为临床跨模态检索提供新范式。</td></tr>
<tr><td>2025-08-04</td><td>Protego: User-Centric Pose-Invariant Privacy Protection Against Face Recognition-Induced Digital Footprint Exposure</td><td>[2508.02034](http://arxiv.org/pdf/2508.02034)</td><td>◆提出Protego，一种用户中心化的隐私保护方法，通过3D面部签名生成姿态不变的2D表示，动态变形为自然3D面具，适配用户任意姿态表情的图像，在分享前进行保护。  
◆创新性地增强FR模型敏感性，使受保护图像无法相互匹配，突破现有方法仅防御外部查询的局限。  
◆实验证明在多种黑盒FR模型下显著降低检索准确率，性能至少优于现有方法2倍。  
◆首次实现视频场景下的视觉连贯性保护，满足动态内容对一致性和自然外观的高要求。  
◆为对抗FR技术滥用（如大规模监控与非自愿身份追踪）提供实用化解决方案，填补用户主动防护的技术空白。  
◆通过3D到2D的封装与动态适配机制，兼顾强隐私保护与视觉自然度，解决传统方法易被检测或影响用户体验的痛点。</td></tr>
<tr><td>2025-07-31</td><td>DRACo-SLAM2: Distributed Robust Acoustic Communication-efficient SLAM for Imaging Sonar EquippedUnderwater Robot Teams with Object Graph Matching</td><td>[2507.23629](http://arxiv.org/pdf/2507.23629)</td><td>◆ 提出DRACo-SLAM2框架，改进原有系统，专为配备多波束成像声纳的水下机器人团队设计，实现分布式SLAM。  
◆ 创新性地将声纳地图表示为对象图，通过对象图匹配实现高效跨机器人闭环检测，无需依赖先验几何信息。  
◆ 针对水下扫描匹配特点，提出增量式群组一致测量集最大化（GCM）方法，改进原有PCM算法，有效处理相邻跨机器人闭环共享相似配准误差的场景。  
◆ 通过模拟和真实数据集进行广泛对比分析，验证了所提方法的优越性和实用性。  
◆ 框架在通信效率和鲁棒性方面表现突出，特别适合水下机器人团队协作建图与定位需求。</td></tr>
<tr><td>2025-07-31</td><td>Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization</td><td>[2507.23569](http://arxiv.org/pdf/2507.23569)</td><td>◆ 提出高斯泼溅特征场（GSFFs），将显式几何模型（3DGS）与隐式特征场结合，用于视觉定位任务。  
◆ 利用3DGS的密集几何信息和可微分光栅化算法，学习基于3D空间的鲁棒特征表示。  
◆ 通过对比学习框架，将3D尺度感知特征场与2D特征编码器对齐到同一嵌入空间，提升特征一致性。  
◆ 引入3D结构感知的聚类方法，正则化表征学习并生成可用于隐私保护的场景分割结果。  
◆ 提出基于特征图或分割图对齐的位姿优化方法，支持隐私保护和非隐私保护两种定位流程。  
◆ 在多个真实数据集上验证了方法的先进性，实现了当前最优的定位性能。</td></tr>
<tr><td>2025-07-25</td><td>A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents</td><td>[2507.22938](http://arxiv.org/pdf/2507.22938)</td><td>◆ 提出基于图结构的创新方法，将流程图转化为图表示，解决了传统文本检索增强生成(RAG)系统难以处理图像问答的痛点。  
◆ 首次将视觉大语言模型(VLM)生成的流程图图表示与文本嵌入管道结合，实现电信领域多模态问答的端到端解决方案。  
◆ 开发了完整的处理流程，包括技术文档处理、图像类型分类、图表示构建等关键步骤，形成可落地的系统架构。  
◆ 实验证明微调后的VLM生成的图表示与真实值编辑距离更小，验证了该方法对流程图表示的鲁棒性。  
◆ 创新性地在推理阶段无需使用VLM，仅需文本嵌入模型即可实现高效检索，显著降低部署成本。  
◆ 在电信产品文档构建的QA数据集上验证了方法的有效性，特别是电信领域适配的文本嵌入模型表现优异。</td></tr>
<tr><td>2025-07-30</td><td>Modality-Aware Feature Matching: A Comprehensive Review of Single- and Cross-Modality Techniques</td><td>[2507.22791](http://arxiv.org/pdf/2507.22791)</td><td>◆ 全面综述了单模态与跨模态特征匹配技术，涵盖RGB图像、深度图像、3D点云、LiDAR扫描、医学图像及视觉-语言交互等多种模态，填补了该领域系统性总结的空白。  
◆ 对比分析了传统手工方法（如Harris角点、SIFT和ORB描述符）与深度学习方法（如SuperPoint和LoFTR）的优劣，指出后者在跨模态鲁棒性和适应性上的显著提升。  
◆ 重点介绍了模态感知技术进展，包括针对深度图像的几何与深度专用描述符、3D点云的稀疏与稠密学习方法、LiDAR扫描的注意力增强神经网络，以及医学图像匹配的MIND描述符等创新方案。  
◆ 深入探讨跨模态应用场景，如医学图像配准和视觉-语言任务，揭示了特征匹配技术在处理多样化数据交互中的关键作用与发展趋势。  
◆ 系统总结了当前挑战与未来方向，为跨模态特征匹配的研究提供了清晰的路线图，推动该领域向更复杂、更实用的场景拓展。</td></tr>
<tr><td>2025-07-29</td><td>Adversarial Reconstruction Feedback for Robust Fine-grained Generalization</td><td>[2507.21742](http://arxiv.org/pdf/2507.21742)</td><td>◆ 提出AdvRF框架，通过对抗性重建反馈机制学习与类别无关的差异表征，解决现有细粒度图像检索方法对预定义类别的语义依赖问题。  
◆ 将细粒度图像检索重新定义为视觉差异重建任务，结合检索模型的类别感知差异定位与重建模型的类别无关特征学习，实现双向优化。  
◆ 通过重建模型揭示检索模型忽略的残差异，迫使检索模型提升定位精度，同时检索模型的优化信号指导重建模型改进重建能力。  
◆ 采用知识蒸馏将重建模型生成的类别无关差异表征迁移到检索模型，实现高效部署。  
◆ 在广泛使用的细粒度和粗粒度数据集上验证了AdvRF的优越性能，定量和定性评估均显示其显著提升泛化能力。</td></tr>
<tr><td>2025-07-28</td><td>Exploring text-to-image generation for historical document image retrieval</td><td>[2507.20934](http://arxiv.org/pdf/2507.20934)</td><td>◆ 提出T2I-QBE新方法，首次将文本生成图像（T2I）技术应用于文档图像检索（DIR）领域，填补了基于属性检索（ABDIR）与基于示例检索（QBE）之间的技术鸿沟。  
◆ 利用生成式AI（Leonardo.Ai）将文本提示（包含文档类型描述和ABDIR风格属性列表）转化为查询图像，无需用户提供真实查询样本，解决了QBE依赖现有样本的局限性。  
◆ 针对历史文档的视觉多样性和独特性设计检索方案，通过CNN提取生成图像与数据集中文档的特征进行相似度匹配，验证了生成图像作为查询的有效性。  
◆ 在HisIR19历史文档数据集上的实验证明，该方法能够成功检索相关文档，为无样本场景下的文档检索提供了可行解决方案。  
◆ 首次探索了T2I生成技术与传统QBE范式的结合，为DIR领域开辟了基于生成模型的新研究方向。</td></tr>
<tr><td>2025-07-28</td><td>PixelNav: Towards Model-based Vision-Only Navigation with Topological Graphs</td><td>[2507.20892](http://arxiv.org/pdf/2507.20892)</td><td>◆ 提出了一种结合深度学习与经典模型规划算法的混合视觉导航方法，突破了纯端到端数据驱动模型的局限性。  
◆ 采用分层系统架构，整合了模型预测控制、可通行性估计、视觉地点识别和位姿估计等多项前沿技术。  
◆ 创新性地使用拓扑图作为环境表征，显著提升了系统的可扩展性和环境适应能力。  
◆ 相比端到端方案，该系统具有更高的可解释性，解决了黑箱模型在机器人应用中的关键瓶颈。  
◆ 通过大量真实场景实验验证了方法的有效性，为视觉导航提供了新的技术路径。  
◆ 在减少训练数据依赖的同时，保持了数据驱动方法的灵活性和适应性优势。</td></tr>
<tr><td>2025-07-28</td><td>ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided Captioning</td><td>[2507.20564](http://arxiv.org/pdf/2507.20564)</td><td>◆ 提出ZSE-Cap系统，在EVENTA竞赛中无需微调即获得第四名，展示了零样本学习的强大能力。  
◆ 创新性地集成CLIP、SigLIP和DINOv2三种模型的相似度分数，提升图像检索性能。  
◆ 通过精心设计的提示词引导Gemma 3模型，实现文章高层事件与图像视觉内容的关联生成描述。  
◆ 结合基础模型的集成和提示技术，在私有测试集上取得0.42002的高分，验证了方法的有效性。  
◆ 提供开源代码，促进零样本图像检索与描述生成领域的进一步研究。</td></tr>
<tr><td>2025-07-28</td><td>Uni-Mapper: Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments</td><td>[2507.20538](http://arxiv.org/pdf/2507.20538)</td><td>◆ Uni-Mapper提出首个动态感知的多模态LiDAR地图统一框架，解决复杂动态环境中多传感器地图融合的难题。  
◆ 采用基于体素自由空间哈希的粗到细动态物体剔除方法，通过时序占用不一致性检测并移除动态对象，提升场景一致性。  
◆ 创新设计动态感知的闭环检测模块，结合保留的静态局部特征生成全局描述符，增强动态环境下的地点识别鲁棒性。  
◆ 提出集中式锚节点策略优化位姿图，有效解决地图合并时的会话内漂移误差和跨地图闭环问题。  
◆ 框架支持异构LiDAR（如机械式与固态雷达）的跨模态匹配，在公开数据集上显著优于现有方法。  
◆ 实现端到端的多地图对齐流程，包含动态处理、闭环检测与多阶段位姿图优化，适用于多机器人协作场景。</td></tr>
<tr><td>2025-07-24</td><td>DSFormer: A Dual-Scale Cross-Learning Transformer for Visual Place Recognition</td><td>[2507.18444](http://arxiv.org/pdf/2507.18444)</td><td>◆ 提出DSFormer双尺度交叉学习Transformer模块，通过双向信息传递整合CNN最后两层的双尺度特征，同时捕捉语义丰富性和空间细节。  
◆ 设计自注意力机制处理单尺度内的长程依赖关系，并引入共享交叉注意力实现跨尺度学习，增强特征表示能力。  
◆ 创新性地提出多视角块聚类策略，重构SF-XL训练数据集的分区方式，优化数据组织以提升对视角变化的鲁棒性。  
◆ 结合上述技术，生成适应环境变化的鲁棒全局嵌入表征，相比先前分区方法减少约30%训练数据需求。  
◆ 仅使用512维全局描述符即实现全局检索，在多数基准数据集上超越DELG、Patch-NetVLAD等先进方法，达到SOTA性能。  
◆ 显著提升计算效率，为视觉地点识别任务提供高效解决方案。</td></tr>
<tr><td>2025-07-23</td><td>VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization</td><td>[2507.17455](http://arxiv.org/pdf/2507.17455)</td><td>◆ 提出了一种新型混合地理定位框架，结合了视觉语言模型（VLM）和检索式视觉地点识别（VPR）方法的优势。  
◆ 利用VLM生成地理先验信息，有效缩小检索搜索空间，解决了传统检索方法在可扩展性和感知混淆上的不足。  
◆ 设计了重排序机制，结合特征相似度和初始坐标邻近性，筛选地理合理性最高的匹配结果。  
◆ 在多个地理定位基准测试中表现优异，尤其在街道级（提升4.51%）和城市级（提升13.52%）定位精度上显著超越现有方法。  
◆ 通过VLM与VPR的结合，实现了可扩展、鲁棒且高精度的行星级地理定位系统，解决了单一方法存在的幻觉和可解释性问题。</td></tr>
<tr><td>2025-07-23</td><td>Content-based 3D Image Retrieval and a ColBERT-inspired Re-ranking for Tumor Flagging and Staging</td><td>[2507.17412](http://arxiv.org/pdf/2507.17412)</td><td>◆ 提出了一种不依赖预分割数据和器官特异性数据集的CBIR框架，适用于临床中大型非结构化图像归档系统（如PACS）。  
◆ 创新性地引入C-MIR方法，将ColBERT的上下文感知延迟交互机制适配于3D医学影像重排序，实现高效上下文感知检索。  
◆ 在四种肿瘤部位上进行了全面评估，结合三种特征提取器和三种数据库配置，验证了方法的普适性。  
◆ 研究发现C-MIR能自动定位感兴趣区域，无需数据预分割，显著降低了传统方法依赖昂贵数据增强的计算成本。  
◆ 实验证明C-MIR在肿瘤标记（尤其结肠和肺癌）中性能显著提升（p&lt;0.05），并在肿瘤分期任务中展现出潜在应用价值。  
◆ 该研究为先进检索技术在医疗实践中的落地提供了新思路，有望优化临床诊断流程。</td></tr>
<tr><td>2025-07-20</td><td>LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM</td><td>[2507.15109](http://arxiv.org/pdf/2507.15109)</td><td>◆ 提出LoopNet，一种基于多任务学习的少样本学习方法，专门针对大规模SLAM中的闭环检测问题，兼顾精度与实时性需求。  
◆ 采用改进的ResNet架构，支持动态视觉数据集的在线重训练，并针对嵌入式设备进行优化，适应实际部署场景。  
◆ 创新性结合少样本学习策略，使模型能够快速适应新环境，同时输出查询索引和预测质量评估，增强系统可靠性。  
◆ 利用DISK描述符替代传统手工特征或常规深度学习方法，显著提升光照、视角等变化条件下的闭环检测性能。  
◆ 开源了新型闭环检测基准数据集LoopDB，填补现有数据在动态场景和嵌入式硬件评估方面的不足。  
◆ 整体方案在精度和计算效率上均优于现有方法，代码与数据集均已公开，推动SLAM领域研究可复现性。</td></tr>
<tr><td>2025-07-20</td><td>Visual Place Recognition for Large-Scale UAV Applications</td><td>[2507.15089](http://arxiv.org/pdf/2507.15089)</td><td>◆ 提出了LASED大规模无人机视觉定位数据集，包含约100万张图片，覆盖爱沙尼亚17万个独特地点，具有广泛的地理和时间多样性，显著提升了模型在航空场景中的训练效果。  
◆ 数据集采用结构化设计，确保地点分离清晰，解决了现有数据集规模小、多样性不足导致的模型泛化能力差的问题。  
◆ 提出使用可转向卷积神经网络（steerable CNNs）处理无人机图像中的旋转模糊问题，利用其旋转等变性生成方向不变的特征表示。  
◆ 实验证明，基于LASED训练的模型召回率显著高于小规模数据集训练的模型，凸显了地理覆盖和时间多样性的重要性。  
◆ 可转向CNN在旋转模糊问题上表现优异，平均召回率比最佳非可转向网络提高12%，有效提升了航空视觉定位的鲁棒性。  
◆ 结合大规模结构化数据集和旋转等变网络，该方法显著增强了航空视觉定位模型的泛化能力和鲁棒性。</td></tr>
<tr><td>2025-07-20</td><td>U-MARVEL: Unveiling Key Factors for Universal Multimodal Retrieval via Embedding Learning with MLLMs</td><td>[2507.14902](http://arxiv.org/pdf/2507.14902)</td><td>◆ 首次系统分析了基于MLLMs的通用多模态检索（UMR）中影响嵌入学习性能的关键因素，揭示了常被忽视的训练细节对模型性能的重要影响。  
◆ 提出了一种通用的MLLM嵌入学习框架U-MARVEL，通过渐进式过渡、困难负样本挖掘和重排序蒸馏等策略优化嵌入生成和训练过程。  
◆ 在监督学习场景下，U-MARVEL在M-BEIR基准测试中大幅超越现有最优方法，展示了显著的性能优势。  
◆ 框架在零样本场景下表现优异，在组合图像检索、文本-视频检索等任务中展现出强大的泛化能力。  
◆ 研究为多模态检索领域提供了可复现的代码实现和系统化的训练方案，推动了该领域的可解释性和可扩展性发展。</td></tr>
<tr><td>2025-07-19</td><td>OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition</td><td>[2507.14477](http://arxiv.org/pdf/2507.14477)</td><td>◆ OptiCorNet提出首个端到端可训练的序列建模框架，将空间特征提取与时序差分统一到单一模块中，突破了传统单帧嵌入方法的局限。  
◆ 创新设计可微分时序差分算子（DSD），通过固定权重差分核捕捉方向性序列差异，结合LSTM精修模块，有效建模短时空间上下文和长程时序关联。  
◆ 引入残差投影机制增强描述符判别力，生成的紧凑序列描述符对视角变化和外观差异具有显著鲁棒性。  
◆ 采用四元组损失函数同步优化批次内正样本对齐与多负样本分离，显著提升跨场景类间可分性。  
◆ 首次实现时序聚合的端到端联合学习，相比后处理方法直接优化序列级嵌入，在季节和视角变化场景下取得突破性性能提升。  
◆ 轻量级1D卷积编码器设计确保计算效率，在多个公开基准测试中全面超越现有最优方法。</td></tr>
<tr><td>2025-07-16</td><td>Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired</td><td>[2507.14215](http://arxiv.org/pdf/2507.14215)</td><td>◆ 开发了JerryNet，一种定制CNN架构，可实时精确定位9个方向的声源，方向识别准确率达91.1%，优于基线模型。  
◆ 基于CLAP模型进行微调，实现纯音频分类，在自定义数据集和AudioSet上分别达到98.5%和95%的准确率。  
◆ 提出多模态融合模型，结合音频、视觉和文本数据精确定位图像中的声源，采用Yolov9目标检测和音频-视觉定位模块，cIoU达0.892，AUC为0.658。  
◆ 设计了硬件系统，包括四麦克风矩形阵列和眼镜式摄像头，通过腕带显示方向等关键信息，提升聋哑人群的实时交互体验。  
◆ 填补了当前研究中针对弱势群体的技术空白，为新一代无障碍设备开发奠定基础。  
◆ 在自定义数据集上全面验证系统性能，各项指标均超越同类模型，展现出实际应用潜力。</td></tr>
<tr><td>2025-07-17</td><td>FAR-Net: Multi-Stage Fusion Network with Enhanced Semantic Alignment and Adaptive Reconciliation for Composed Image Retrieval</td><td>[2507.12823](http://arxiv.org/pdf/2507.12823)</td><td>◆ 提出FAR-Net多阶段融合框架，结合早期和晚期融合优势，解决现有方法在视觉-文本模态融合中的局限性。  
◆ 设计增强语义对齐模块（ESAM），通过跨注意力机制实现细粒度语义关联，弥补晚期融合对局部对齐的不足。  
◆ 引入自适应协调模块（ARM），利用不确定性嵌入的早期融合增强模型鲁棒性，平衡文本显式描述与视觉上下文。  
◆ 创新性地整合ESAM与ARM，形成互补机制，同时捕捉全局语义和局部细节，提升组合图像检索精度。  
◆ 在CIRR和FashionIQ数据集上显著超越现有方法，Recall@1最高提升2.4%，验证了框架的有效性和可扩展性。</td></tr>
<tr><td>2025-07-17</td><td>MCoT-RE: Multi-Faceted Chain-of-Thought and Re-Ranking for Training-Free Zero-Shot Composed Image Retrieval</td><td>[2507.12819](http://arxiv.org/pdf/2507.12819)</td><td>◆ 提出MCoT-RE框架，首次在零样本训练自由的组合图像检索任务中引入多角度思维链（Chain-of-Thought）技术，解决现有方法模态交互不足的问题。  
◆ 通过双路径生成策略，分别生成侧重文本修改的 caption 和融合视觉上下文的 caption，平衡显式修改与隐式视觉线索的利用。  
◆ 设计两阶段检索流程：首阶段用修改导向 caption 粗筛候选图像，第二阶段结合双 caption 和参考图像进行多粒度重排序，提升精度。  
◆ 创新性地将思维链扩展至多模态场景，指导 MLLM 同时处理文本指令与视觉上下文，避免信息丢失。  
◆ 在主流数据集上实现显著提升，FashionIQ 的 Recall@10 提高 6.24%，CIRR 的 Recall@1 提升 8.58%，达到零样本方法最优性能。  
◆ 整个框架无需额外训练，仅依赖预训练模型，保持高效低成本优势的同时突破现有技术瓶颈。</td></tr>
<tr><td>2025-07-16</td><td>QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval</td><td>[2507.12416](http://arxiv.org/pdf/2507.12416)</td><td>◆ 提出QuRe方法，通过硬负样本采样解决组合图像检索（CIR）中假阴性问题，优化奖励模型目标以提升检索相关性。  
◆ 设计新颖的硬负样本采样策略，选择目标图像后相关性分数两次陡降之间的图像，有效过滤假阴性样本。  
◆ 创建HP-FashionIQ数据集，首次在CIR任务中明确捕获用户偏好，超越传统仅关注目标图像检索的评估方式。  
◆ 实验证明QuRe在FashionIQ和CIRR数据集上达到最优性能，并在HP-FashionIQ上展现出与人类偏好最强的对齐性。  
◆ 开源代码促进后续研究，为CIR领域提供可复现的基准方法和用户满意度导向的评估框架。</td></tr>
<tr><td>2025-07-16</td><td>CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning</td><td>[2507.11834](http://arxiv.org/pdf/2507.11834)</td><td>◆ 提出CorrMoE框架，首次针对跨场景和跨域对应点修剪任务设计，解决了现有方法在视觉域不一致和场景结构多样时的性能瓶颈。  
◆ 创新性地引入去风格化双分支结构，通过隐式和显式图特征的风格混合，有效减少域特异性表征的负面影响，提升跨域鲁棒性。  
◆ 设计双融合专家混合模块（Bi-Fusion MoE），结合线性复杂度注意力机制和动态专家路由，自适应整合多视角特征以应对场景多样性。  
◆ 在特征融合中实现计算效率优化，通过线性注意力降低传统Transformer的二次复杂度，同时保持多专家模型的动态适应性。  
◆ 在多个基准数据集上验证了方法的优越性，显著超越现有SOTA方法，尤其在跨域和跨场景任务中展现强泛化能力。  
◆ 开源代码与预训练模型，为后续研究提供可复现的基础。</td></tr>
<tr><td>2025-07-09</td><td>Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning</td><td>[2507.10571](http://arxiv.org/pdf/2507.10571)</td><td>◆ 提出了一种新型模块化Agentic AI视觉分类框架，将通用多模态智能体与非视觉推理协调器、RAG模块相结合，实现感知与元推理的分离。  
◆ 创新性地引入信任感知协调机制，通过置信度校准指标（ECE/OCR/CCC）动态调节对多智能体的信任度，在零样本场景下准确率提升77.94%。  
◆ 开发了基于CLIP图像检索和重评估循环的信任校准方法，利用视觉相似案例修正智能体的过度自信，增强预测可解释性。  
◆ 在苹果叶病害诊断任务中验证三种配置：零样本置信协调、微调智能体优化、以及RAG增强的信任校准协调，最高达85.63%准确率。  
◆ 发现GPT-4o具有更优校准性，而Qwen-2.5-VL存在过度自信现象，为多智能体行为分析提供实证依据。  
◆ 开源全部模型、提示词、软件代码及实验结果，为可信多智能体系统建立可复现基准，适用于生物诊断等高风险领域。</td></tr>
<tr><td>2025-07-14</td><td>GT-Loc: Unifying When and Where in Images Through a Joint Embedding Space</td><td>[2507.10473](http://arxiv.org/pdf/2507.10473)</td><td>◆ GT-Loc首次提出联合学习图像拍摄时间和地理位置的统一嵌入空间，通过多编码器（图像、时间、地点）在共享特征空间中对齐三者表征，解决传统方法中时间预测依赖地理信息的局限性。  
◆ 创新性地采用环形时序度量学习目标，将时间差异建模为环面（toroidal）上的软目标，替代传统对比学习的硬正负样本，更贴合时间周期性的本质。  
◆ 实验证明联合优化显著优于现有时间预测方法，即使对比那些在推理阶段使用真实地理位置作为输入的方法，仍展现出更高精度。  
◆ 在标准地理定位任务中达到竞争性性能，同时统一嵌入空间支持组合检索（如&quot;夏季黄昏的巴黎&quot;）和文本引导的图像检索，扩展了应用场景。  
◆ 提出新基准验证方法有效性，揭示了时间与地理线索的深层关联，为跨模态检索研究提供新方向。</td></tr>
<tr><td>2025-07-14</td><td>Text-to-Remote-Sensing-Image Retrieval beyond RGB Sources</td><td>[2507.10403](http://arxiv.org/pdf/2507.10403)</td><td>◆ 提出CrisisLandMark数据集，包含64.7万张Sentinel-1 SAR和Sentinel-2多光谱图像，并配对了结构化文本标注，覆盖土地覆盖、土地利用和危机事件，数据来源权威。  
◆ 开发CLOSP框架，通过文本作为桥梁，将未配对的光学和SAR图像对齐到统一的嵌入空间，实现跨模态检索。  
◆ CLOSP在检索性能上取得突破，nDGC指标比现有模型提升54%，显著提高了检索效果。  
◆ 提出统一训练策略，通过光学图像的丰富语义知识间接辅助SAR图像解译，克服SAR图像解译的固有困难。  
◆ 扩展GeoCLOSP模型，整合地理坐标信息，在通用语义任务和地理位置相关的危机事件检索之间取得平衡，成为特定领域的专家。  
◆ 强调多传感器数据和地理上下文整合的重要性，为遥感档案的全面利用提供了新思路。</td></tr>
<tr><td>2025-07-14</td><td>Kaleidoscopic Background Attack: Disrupting Pose Estimation with Multi-Fold Radial Symmetry Textures</td><td>[2507.10265](http://arxiv.org/pdf/2507.10265)</td><td>◆提出了一种新颖的对抗攻击方法——万花筒背景攻击（KBA），通过多重复制对称纹理构造圆形背景图案，有效干扰相机位姿估计模型。  
◆首次利用自然纹理片段构建具有多重复制对称性的圆盘结构，这种设计在不同视角下保持高度相似性，显著提升了攻击的跨视角一致性。  
◆创新性地提出了投影方向一致性损失函数，通过优化万花筒纹理片段的空间分布，进一步增强了攻击效果。  
◆实验证明该方法能有效攻击多种主流相机位姿估计模型，揭示了稀疏输入场景下背景纹理对位姿估计的关键影响。  
◆为对抗攻击领域提供了新思路，将几何对称性与自然纹理相结合，实现了无需复杂对抗样本生成的高效攻击。</td></tr>
<tr><td>2025-07-11</td><td>RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features</td><td>[2507.08546](http://arxiv.org/pdf/2507.08546)</td><td>◆ 提出RadiomicsRetrieval框架，首次将手工设计的放射组学特征与深度学习嵌入结合，实现肿瘤级别的3D医学图像检索，突破现有2D方法的局限。  
◆ 采用可提示分割模型（如SAM）生成肿瘤特异性图像嵌入，并通过对比学习与放射组学特征对齐，增强特征表达能力。  
◆ 引入解剖位置嵌入（APE），为检索系统提供全局解剖上下文，支持基于位置的灵活查询。  
◆ 框架仅需最小用户交互（如单点标注），显著降低分割开销，适应多样临床场景。  
◆ 支持混合查询模式（图像嵌入或选定放射组学属性），提升诊断、治疗规划及医学研究的实用性。  
◆ 在肺部CT和脑部MRI公开数据集验证中，放射组学特征显著提高检索特异性，APE对基于位置的搜索至关重要。</td></tr>
<tr><td>2025-07-11</td><td>LiDAR, GNSS and IMU Sensor Alignment through Dynamic Time Warping to Construct 3D City Maps</td><td>[2507.08420](http://arxiv.org/pdf/2507.08420)</td><td>◆ 提出了一种融合LiDAR、GNSS和IMU数据的统一框架，通过动态时间规整（DTW）进行速度对齐，解决城市规模3D建图时的累积漂移问题。  
◆ 采用扩展卡尔曼滤波优化GNSS和IMU信号，结合基于正态分布变换（NDT）的局部建图与位姿图优化，提升局部精度。  
◆ 引入GNSS约束锚点和重叠段精细配准技术，显著改善全局一致性，将平均全局对齐误差从3.32米降低至1.24米（提升61.4%）。  
◆ 发布了一个大规模多模态数据集，包含21条城市环线的12.8万帧128线LiDAR数据、同步RTK-GNSS轨迹及MEMS-IMU测量值，填补研究空白。  
◆ 提出基于道路中心线和交叉口的几何一致性评估指标，量化全局与局部精度，为后续研究建立新基准。  
◆ 所构建的高精度地图支持智慧城市规划、基础设施监测等应用，同时公开代码与数据集推动领域发展。</td></tr>
<tr><td>2025-07-11</td><td>Deep Hashing with Semantic Hash Centers for Image Retrieval</td><td>[2507.08404](http://arxiv.org/pdf/2507.08404)</td><td>◆ 提出语义哈希中心概念，通过数据依赖的相似性计算捕捉类别间的语义关系，取代传统数据无关的哈希中心生成方法。  
◆ 设计三阶段框架SHC：先训练分类网络识别语义相似性，再优化生成保留语义结构的哈希中心，最后训练深度哈希网络生成二进制码。  
◆ 开发新型优化算法，在保持语义相关性的同时强制最小中心间距，避免哈希码过度相似的问题。  
◆ 首次将类别语义关系建模为汉明空间的距离约束，使相似类别的哈希中心距离更近，不相似类别更远。  
◆ 在多个公开数据集上验证显著提升检索性能，MAP@100/1000/ALL指标平均提升7.26%/7.62%/11.71%，超越现有最佳方法。  
◆ 提出的数据依赖相似性计算方法能自适应不同数据分布，增强模型泛化能力。</td></tr>
<tr><td>2025-07-08</td><td>Unveiling Effective In-Context Configurations for Image Captioning: An External &amp; Internal Analysis</td><td>[2507.08021](http://arxiv.org/pdf/2507.08021)</td><td>◆ 首次对多模态上下文学习（ICL）在图像描述任务中的演示配置进行系统性外部研究，探索了示例数量、图像检索和描述分配三个维度的策略。  
◆ 通过内部注意力机制分析，揭示了典型大型多模态模型（LMM）的注意力特征，并开发了基于注意力的量化指标以评估模型行为。  
◆ 结合外部实验与内部机制分析的双重视角，提供了理解多模态ICL的新方法，揭示了示例配置如何通过注意力机制影响模型表现。  
◆ 提出注意力驱动的模型加速与压缩实验，验证了基于注意力分析的模型优化可行性。  
◆ 对比了相同架构与预训练策略的LMM性能差异，从预训练数据特征角度解释了模型表现差异的原因。  
◆ 开发了结合外部评估与内部指标的新方法论，可扩展至其他大模型研究领域。</td></tr>
<tr><td>2025-07-10</td><td>SCREP: Scene Coordinate Regression and Evidential Learning-based Perception-Aware Trajectory Generation</td><td>[2507.07467](http://arxiv.org/pdf/2507.07467)</td><td>◆ 提出了一种结合场景坐标回归（SCR）和证据学习的新型感知感知轨迹生成框架SCREP，用于GPS拒止环境下的自主飞行。  
◆ 通过证据学习方法优化SCR位姿估计器，能够预测像素不确定性并引导相机朝向可靠性高的场景坐标区域。  
◆ 采用滚动时域轨迹优化器，实时调整飞行轨迹以最大化定位精度，同时结合固定滞后平滑器融合低频SCR数据与高频IMU数据。  
◆ 在仿真实验中，相比固定偏航和前视基线方法，该框架将平移（旋转）平均误差降低了54%/15%（40%/31%）。  
◆ 通过硬件在环实验验证了框架的实时性和可行性，实现了感知-控制闭环的高效运行。</td></tr>
<tr><td>2025-07-10</td><td>VP-SelDoA: Visual-prompted Selective DoA Estimation of Target Sound via Semantic-Spatial Matching</td><td>[2507.07384](http://arxiv.org/pdf/2507.07384)</td><td>◆ 提出跨实例音频-视觉定位（CI-AVL）新任务，利用同类声音事件的不同实例图像定位目标声源，减少对配对数据的依赖并提升泛化能力。  
◆ 设计VP-SelDoA框架，通过语义级模态融合和Frequency-Temporal ConMamba架构生成目标选择性掩码，实现多声源场景下的目标声源隔离。  
◆ 提出语义-空间匹配机制，结合交叉注意力和自注意力对齐异构的语义与空间特征，解决传统方法中视觉语义与声学空间特征错位问题。  
◆ 构建大规模数据集VGG-SSL，包含296类声音事件的13,981条空间音频片段，为CI-AVL研究提供数据支持。  
◆ 实验表明，该方法在平均绝对误差（MAE）和准确率（ACC）上均优于现有音频-视觉定位方法，分别达到12.04和78.23%。</td></tr>
<tr><td>2025-07-08</td><td>FACap: A Large-scale Fashion Dataset for Fine-grained Composed Image Retrieval</td><td>[2507.07135](http://arxiv.org/pdf/2507.07135)</td><td>◆ 提出了FACap数据集，这是一个大规模自动构建的时尚领域组合图像检索数据集，解决了现有数据集缺乏专业细粒度标注的问题。  
◆ 设计了两阶段自动标注流程，结合视觉语言模型和大语言模型生成高质量修改文本，降低了人工标注成本。  
◆ 提出了FashionBLIP-2模型，通过在FACap上微调通用BLIP-2模型，并引入轻量级适配器和多头查询-候选匹配机制，提升了时尚细粒度信息的处理能力。  
◆ 在Fashion IQ基准和增强版enhFashionIQ数据集上验证了模型效果，实验表明该方法显著提升了时尚领域组合检索性能，尤其在细粒度文本修改场景。  
◆ 为电商等实际应用场景提供了高效的时尚图像检索解决方案，展示了自动构建领域专用数据集与模型适配相结合的有效性。</td></tr>
<tr><td>2025-07-09</td><td>Evaluating Attribute Confusion in Fashion Text-to-Image Generation</td><td>[2507.07079](http://arxiv.org/pdf/2507.07079)</td><td>◆ 针对时尚领域文本生成图像（T2I）任务中现有评估方法难以捕捉细粒度属性关联的问题，提出了一种基于视觉定位和视觉问答（VQA）的新型评估框架。  
◆ 通过单实体定位策略，在视觉和文本模态上同步分析属性混淆现象（如属性正确生成但归属错误实体），解决了传统方法对复杂组合语义评估的局限性。  
◆ 设计了局部化人工评估协议，并创新性地提出自动指标L-VQAScore，结合视觉定位与VQA技术，同时检测属性正确反映（reflection）和错误泄漏（leakage）情况。  
◆ 构建了包含挑战性组合对齐场景的新数据集，验证了L-VQAScore在细粒度实体-属性关联评估上的优越性，其与人类判断的相关性超越现有最优方法。  
◆ 该工作为时尚领域T2I模型提供了可扩展的客观评估方案，显著减少对主观评价的依赖，推动生成模型在复杂语义场景下的精准优化。</td></tr>
<tr><td>2025-07-09</td><td>MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval</td><td>[2507.06654](http://arxiv.org/pdf/2507.06654)</td><td>◆ 提出新任务CDR-CA（复合属性上下文多样性优化），针对文本到图像检索中不同应用场景对多样性需求的差异，实现多属性多样性按需调整。  
◆ 提出多源行列式点过程（MS-DPPs），将传统DPP扩展为多源形式，通过流形表示构建统一相似性矩阵，支持多属性联合优化。  
◆ 引入切线归一化（Tangent Normalization）技术，有效融合不同上下文信息，动态适应多样化应用场景的需求。  
◆ 实验验证了MS-DPPs在多样性优化任务中的优越性能，尤其在复合属性控制方面显著优于传统方法。  
◆ 公开代码促进后续研究，为文本到图像检索的实用化多样性优化提供新基线。</td></tr>
<tr><td>2025-07-08</td><td>Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval</td><td>[2507.05970](http://arxiv.org/pdf/2507.05970)</td><td>◆ 提出了一种可扩展的自动三元组生成流程，解决了传统CIR方法依赖人工标注数据导致的扩展性和零样本能力受限问题。  
◆ 构建了首个全合成数据集CIRHS，利用大语言模型生成多样化提示词，并通过文本到图像生成模型控制生成具有相同元素的图像对，经筛选重组形成高质量训练数据。  
◆ 创新性地提出混合上下文对齐框架（CoAlign），实现了全局对齐与局部推理的协同优化，能够学习更鲁棒且信息丰富的表征。  
◆ 首次验证了在全合成数据集上训练CIR模型的可行性，CoAlign在三个常用基准测试中展现出卓越的零样本性能。  
◆ 在监督训练场景下，该方法超越所有现有先进CIR模型，证明了检索框架的有效性。  
◆ 开源代码和CIRHS数据集将促进CIR领域的进一步研究。</td></tr>
<tr><td>2025-07-08</td><td>OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval</td><td>[2507.05631](http://arxiv.org/pdf/2507.05631)</td><td>◆ 提出基于分割的焦点映射特征提取器，通过主导区域分割和双重焦点映射模块，有效区分图像中的关键区域与噪声，提升查询特征质量。  
◆ 设计文本引导的焦点修正模块，利用修改文本的语义信息自适应调整参考图像的视觉焦点，解决传统方法中文本优先级被忽视的问题。  
◆ 首次在组合图像检索（CIR）中引入视觉主导区域分割技术，减少噪声干扰对多模态特征融合的负面影响。  
◆ 通过双焦点映射机制同步优化视觉与文本特征提取，增强模型对用户复杂修改意图的理解能力。  
◆ 构建完整网络OFFSET，在四个基准数据集上验证其优越性，为CIR领域提供新的解决方案。  
◆ 公开代码与数据，促进后续研究发展。</td></tr>
<tr><td>2025-07-07</td><td>Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model</td><td>[2507.05513](http://arxiv.org/pdf/2507.05513)</td><td>◆ 提出llama-nemoretriever-colembed模型，实现文本-图像跨模态检索的顶尖性能，在ViDoRe V1/V2基准上NDCG@5分别达到91.0和63.5，刷新榜单记录。  
◆ 基于NVIDIA Eagle2视觉语言模型进行架构改造，将因果注意力替换为双向注意力机制，增强多模态特征交互能力。  
◆ 创新性地引入ColBERT风格的延迟交互机制，在共享嵌入空间中实现细粒度跨模态检索，显著提升匹配精度。  
◆ 设计两阶段训练策略，先预训练再微调，有效增强模型检索能力。  
◆ 全面分析模型在存储效率与检索精度之间的权衡关系，为实际应用提供优化依据。  
◆ 发布1B和3B两种参数量变体，其中3B版本成为当前性能最优的跨模态检索模型。</td></tr>
<tr><td>2025-07-07</td><td>An analysis of vision-language models for fabric retrieval</td><td>[2507.04735](http://arxiv.org/pdf/2507.04735)</td><td>◆ 提出了一种自动化标注流程，利用多模态大语言模型（MLLMs）生成两种文本描述（自由自然语言和结构化属性描述），解决了织物领域公开数据集的缺失问题。  
◆ 首次系统评估了三种视觉语言模型（CLIP、LAION-CLIP和Meta Perception Encoder）在零样本织物图像检索任务中的性能。  
◆ 发现结构化属性描述能显著提升检索精度，尤其在视觉复杂的织物类别中，揭示了文本描述形式对跨模态检索的关键影响。  
◆ 验证了Meta Perception Encoder凭借更强的特征对齐能力，在织物检索任务中优于其他模型，为工业应用提供了模型选择依据。  
◆ 指出零样本检索在细粒度织物领域的局限性，强调领域自适应方法的必要性，为后续研究指明方向。  
◆ 结合技术性文本描述与先进视觉语言模型的策略，为制造业等专业领域的跨模态检索优化提供了实践指导。</td></tr>
<tr><td>2025-07-08</td><td>What&#x27;s Making That Sound Right Now? Video-centric Audio-Visual Localization</td><td>[2507.04667](http://arxiv.org/pdf/2507.04667)</td><td>◆ 提出AVATAR基准测试，首次引入视频中心化视角，解决现有音频-视觉定位（AVL）研究仅关注静态图像的问题。  
◆ 设计四种复杂场景（单声源、混合声源、多实体、屏幕外声源），突破传统方法假设声源可见且单一的局限性。  
◆ 开发TAVLO模型，首创高分辨率时序建模机制，有效捕捉声音与视觉对象的动态关联。  
◆ 实证发现传统方法因依赖全局音频特征和逐帧映射，难以追踪时序变化，而TAVLO通过时序建模实现精准对齐。  
◆ 建立视频中心化AVL新标准，首次系统论证时序动态对音频-视觉定位的关键影响。</td></tr>
<tr><td>2025-07-07</td><td>Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR</td><td>[2507.04662](http://arxiv.org/pdf/2507.04662)</td><td>◆ 提出利用毫米波5G NR系统进行主动感知，实现类似激光雷达的点云生成，克服了传统被动SLAM技术依赖镜面反射假设的局限。  
◆ 采用二进制搜索方法从每个波束方向的功率延迟剖面中提取点云，提高了环境感知的精度和细节。  
◆ 通过多目标点校准硬件延迟，确保点云数据的准确性，为后续定位和建图提供可靠输入。  
◆ 利用点云配准算法从连续轨迹视角估计终端位姿变化，实现动态环境下的高精度定位。  
◆ 结合闭环检测与位姿图优化技术，进一步优化感知结果，完成精确的终端定位和无线电地图重建。  
◆ 通过仿真和实验验证了系统的有效性，为5G NR在SLAM领域的应用提供了实践依据。</td></tr>
<tr><td>2025-07-06</td><td>U-ViLAR: Uncertainty-Aware Visual Localization for Autonomous Driving via Differentiable Association and Registration</td><td>[2507.04503](http://arxiv.org/pdf/2507.04503)</td><td>◆ 提出U-ViLAR框架，首次将感知不确定性和定位不确定性同时纳入视觉定位系统，提升自动驾驶在复杂城市环境中的鲁棒性。  
◆ 创新性地将视觉特征映射到鸟瞰图（BEV）空间，增强与高精地图的空间一致性，解决视角差异问题。  
◆ 设计感知不确定性引导的特征关联模块（Perceptual Uncertainty-guided Association），有效降低感知误差对匹配的影响。  
◆ 开发定位不确定性引导的配准模块（Localization Uncertainty-guided Registration），通过量化定位置信度优化位姿估计精度。  
◆ 实现关联（大范围粗定位）与配准（精细定位）的协同优化，在保持大场景覆盖能力的同时提升厘米级定位准确性。  
◆ 通过大规模自动驾驶车队实测验证，在GNSS失效、动态障碍物等复杂场景下保持稳定性能，综合精度超越现有方法。</td></tr>
<tr><td>2025-07-04</td><td>Query-Based Adaptive Aggregation for Multi-Dataset Joint Training Toward Universal Visual Place Recognition</td><td>[2507.03831](http://arxiv.org/pdf/2507.03831)</td><td>◆提出基于查询的自适应聚合（QAA）方法，通过可学习的查询向量作为参考码本，有效提升多数据集联合训练中的信息容量，避免传统特征聚合层的信息饱和问题。  
◆创新性地引入跨查询相似度（CS）计算机制，利用查询级图像特征与参考码本的相似性生成鲁棒描述符，显著提升模型泛化能力。  
◆首次实现多数据集联合训练的通用视觉位置识别（VPR）模型，在保持单数据集峰值性能的同时，实现跨数据集的平衡泛化表现。  
◆通过可视化分析揭示学习到的查询向量具有跨数据集的多样化注意力模式，为多源数据融合提供可解释性依据。  
◆在计算效率和参数量控制方面表现优异，未显著增加模型复杂度的情况下实现性能突破。  
◆开源代码并辅以详尽的消融实验，验证了QAA机制的可扩展性和核心组件有效性。</td></tr>
<tr><td>2025-07-01</td><td>LoD-Loc v2: Aerial Visual Localization over Low Level-of-Detail City Models using Explicit Silhouette Alignment</td><td>[2507.00659](http://arxiv.org/pdf/2507.00659)</td><td>◆ 提出LoD-Loc v2方法，首次实现基于低细节层次（LoD1）城市模型的无人机空中视觉定位，突破以往依赖高细节模型（LoD2/LoD3）的限制。  
◆ 采用粗到精的双阶段策略：通过显式轮廓对齐构建姿态代价体积筛选粗姿态，再结合粒子滤波与多光束跟踪进行精细优化。  
◆ 创新性设计姿态代价体积，通过均匀采样姿态假设并量化投影轮廓与预测轮廓的对齐度，实现高效概率分布建模。  
◆ 提出多光束跟踪的粒子滤波方法，显著扩大收敛域容错范围，可适应更大初始姿态误差。  
◆ 发布首个覆盖10.7平方公里的LoD1城市模型数据集，包含真实RGB查询图像与姿态真值，推动该领域研究。  
实验表明该方法在高/低LoD模型下均实现最优精度，甚至超越基于纹理模型的方法，为全球城市定位提供新范式。</td></tr>
<tr><td>2025-06-28</td><td>Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data</td><td>[2506.22939](http://arxiv.org/pdf/2506.22939)</td><td>这篇论文的核心贡献和创新点如下：  

◆ 提出了一种名为“Cuttlefish Optimized Bidirectional Recurrent Neural Network (CO-BRNN)”的新型深度学习方法，用于遥感数据的场景分类。  
◆ 通过结合双向循环神经网络和优化算法（Cuttlefish优化），显著提升了模型在复杂遥感数据中的特征提取能力。  
◆ 在实验中，CO-BRNN的准确率达到97%，优于现有的多种方法（如MLP-CNN、CNN-LSTM、LSTM-CRF等），展现了其优越性能。  
◆ 解决了传统深度学习方法对大规模、高噪声数据的依赖问题，提高了模型在有限数据条件下的鲁棒性。  
◆ 强调了物理验证在卫星数据应用中的重要性，确保模型结果的可靠性和实用性。  
◆ 为遥感场景分类提供了新的技术思路，可应用于灾害控制、生态监测、城市规划等多个领域。</td></tr>
<tr><td>2025-06-28</td><td>Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval</td><td>[2506.22864](http://arxiv.org/pdf/2506.22864)</td><td>◆ 提出Mask-aware TIR（MaTIR）新任务，首次将文本到图像检索（TIR）与指代表达分割（RES）统一，要求同时实现高效图像搜索和精确目标分割。  
◆ 设计两阶段框架：第一阶段利用SAM 2和Alpha-CLIP离线生成对象掩码和区域级嵌入，实现可扩展的分割感知检索；第二阶段通过多模态大语言模型（MLLM）重新排序并生成目标框，与掩码匹配提升精度。  
◆ 创新性结合分割模型（SAM 2）与跨模态检索技术（Alpha-CLIP），在离线阶段预计算掩码和嵌入，显著降低在线检索计算成本。  
◆ 引入MLLM进行结果重排和定位优化，利用其多模态理解能力提升检索准确率与分割质量。  
◆ 在COCO和D$^3$数据集上验证，检索精度和分割效果均显著优于现有方法，为跨模态任务提供新范式。</td></tr>
<tr><td>2025-06-27</td><td>MatChA: Cross-Algorithm Matching with Feature Augmentation</td><td>[2506.22336](http://arxiv.org/pdf/2506.22336)</td><td>◆ 提出了首个解决跨特征检测器视觉定位问题的方法MatChA，突破了现有方法必须使用相同检测器的限制。  
◆ 创新性地通过特征描述符增强技术提升跨检测器特征匹配性能，解决了关键点重复率低和描述符区分度不足的难题。  
◆ 设计了将特征转换到潜在空间的方案，有效实现了不同算法生成描述符的兼容匹配。  
◆ 在多个基准测试中验证了该方法显著提升了跨特征场景下的图像匹配和视觉定位精度。  
◆ 突破了传统方案依赖共同关键点的假设，更贴合实际应用中不同设备使用不同特征提取算法的复杂场景。</td></tr>
<tr><td>2025-06-26</td><td>OracleFusion: Assisting the Decipherment of Oracle Bone Script with Structurally Constrained Semantic Typography</td><td>[2506.21101](http://arxiv.org/pdf/2506.21101)</td><td>◆ 提出OracleFusion两阶段框架，首次将语义排版技术应用于甲骨文破译，通过结构约束生成语义增强的矢量字体。  
◆ 第一阶段采用多模态大语言模型（MLLM）结合空间感知推理（SAR），实现对甲骨文字形的结构分析与关键部件视觉定位。  
◆ 第二阶段创新性引入甲骨文结构向量融合（OSVF）技术，通过字形结构约束和字形保持约束，确保生成结果的结构完整性与语义准确性。  
◆ 在视觉呈现上突破传统方法，生成兼具美学质量与可读性的字形表达，为专家破译提供直观辅助。  
◆ 实验证明OracleFusion在语义相关性、视觉吸引力和字形保持方面均优于现有基线模型，显著提升破译效率。  
◆ 框架可对未解读甲骨文字符提供专家级见解，成为推动甲骨文研究的实用工具。</td></tr>
<tr><td>2025-06-25</td><td>Visualizing intercalation effects in 2D materials using AFM based techniques</td><td>[2506.20467](http://arxiv.org/pdf/2506.20467)</td><td>◆ 提出了一种基于原子力显微镜（AFM）的非侵入性方法，用于可视化二维材料（如MoS2/石墨烯/Ir(111)）中硫插层引起的局部结构和电子性质变化，避免了传统超高真空技术的耗时、高成本和空间限制问题。  
◆ 通过AFM形貌成像直接观察到插层导致的结构变化，并结合相位成像与力学测量，首次发现插层区域杨氏模量和粘附力的降低。  
◆ 利用开尔文探针力显微镜（KPFM）揭示了插层区域的表面电势和功函数变化，为插层效应提供了明确的电子学特征证据。  
◆ 创新性地采用光诱导力显微镜（PiFM）检测插层区域的光学响应增强，拓展了AFM技术在光学性质表征中的应用。  
◆ 综合多种AFM技术实现了插层效应的多维度映射（结构、力学、电子、光学），为二维材料性能调控提供了新工具和理论依据。  
◆ 证明了AFM技术在二维材料插层研究中的高效性和普适性，为未来材料设计和器件开发提供了低成本、高分辨率的表征方案。</td></tr>
<tr><td>2025-06-25</td><td>On the Burstiness of Faces in Set</td><td>[2506.20312](http://arxiv.org/pdf/2506.20312)</td><td>◆ 首次揭示了集合人脸识别(SFR)中普遍存在的&quot;突发性&quot;现象，即特定属性人脸在集合中高频出现，导致模型泛化能力下降和评估干扰。  
◆ 提出三种突发性人脸检测策略：基于Quickshift++的聚类方法、特征自相似性分析和广义最大池化(GMP)技术，有效识别集合中的高频人脸。  
◆ 在训练阶段通过调整采样比例抑制突发性影响，在评估阶段增强低频人脸的贡献度，显著提升模型在无约束场景下的表现。  
◆ 创新性提出质量感知GMP方法，使模型能够感知人脸质量并对低质量图像保持鲁棒性，解决了原始GMP的局限性。  
◆ 通过大量实验验证了突发性现象的广泛存在，证明抑制突发性能显著提升现有SFR基准测试的识别性能，为集合人脸识别提供了新思路。</td></tr>
<tr><td>2025-06-24</td><td>jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval</td><td>[2506.18902](http://arxiv.org/pdf/2506.18902)</td><td>◆ 提出jina-embeddings-v4模型，这是一个38亿参数的多模态嵌入模型，统一了文本和图像的表示。  
◆ 采用新颖的架构，支持单向量和多向量嵌入，并采用后期交互风格。  
◆ 引入任务特定的低秩适应（LoRA）适配器，优化了多种检索场景的性能，包括基于查询的信息检索、跨模态语义相似性和编程代码搜索。  
◆ 在单模态和跨模态检索任务中实现了最先进的性能，尤其在处理视觉丰富内容（如表格、图表、图表和混合媒体格式）方面表现突出。  
◆ 提出Jina-VDR基准，专门用于评估视觉丰富图像检索能力，填补了该领域的空白。</td></tr>
<tr><td>2025-06-26</td><td>Referring Expression Instance Retrieval and A Strong End-to-End Baseline</td><td>[2506.18246](http://arxiv.org/pdf/2506.18246)</td><td>◆ 提出新任务REIR（Referring Expression Instance Retrieval），填补了传统文本-图像检索（TIR）精度不足和指代表达理解（REC）扩展性差的空白，支持跨大规模图库的实例级检索与定位。  
◆ 构建首个大规模基准数据集REIRCOCO，通过视觉-语言模型生成细粒度指代表达，基于MSCOCO和RefCOCO实例增强数据多样性。  
◆ 提出端到端基线方法CLARE，采用双流架构设计，结合目标检测与REC预训练，实现跨模态特征对齐。  
◆ 创新性引入Mix of Relation Experts（MORE）模块，显式建模实例间关系，提升复杂场景下的检索精度。  
◆ 通过对比学习框架CLIA（Contrastive Language-Instance Alignment）优化语言-实例对齐，使模型在REIR、TIR和REC任务上均达到SOTA性能。  
◆ 验证了CLARE的强泛化能力，首次实现单一模型同时支持实例检索、粗粒度检索和细粒度定位三类任务。</td></tr>
<tr><td>2025-06-20</td><td>Class Agnostic Instance-level Descriptor for Visual Instance Search</td><td>[2506.16745](http://arxiv.org/pdf/2506.16745)</td><td>◆提出了一种基于自监督ViT的类无关实例级描述符，解决了视觉实例搜索中缺乏有效实例级特征表示的问题。  
◆通过层次化分解特征集，将实例区域发现建模为检测紧凑特征子集的过程，生成多层次的语义特征子集。  
◆构建的特征层次结构中，非叶节点和叶节点对应图像中不同语义尺度的实例区域，有效处理了物体嵌入和遮挡问题。  
◆生成的节点特征构成图像的全面实例表示，适用于已知和未知物体类别，具有强泛化能力。  
◆在三个实例搜索基准测试中表现显著优于现有方法，验证了其优越性。</td></tr>
<tr><td>2025-06-19</td><td>MambaHash: Visual State Space Deep Hashing Model for Large-Scale Image Retrieval</td><td>[2506.16353](http://arxiv.org/pdf/2506.16353)<br><a href=''>[代码]</a></td><td>◆ 首次将视觉状态空间模型（Mamba）引入大规模图像哈希检索任务，探索其在该领域的适用性和优势。  
◆ 提出分阶段的主干网络架构，通过分组Mamba操作实现多方向扫描，有效建模局部和全局信息。  
◆ 设计通道交互注意力模块，增强跨通道信息交流，提升特征表达能力。  
◆ 开发自适应特征增强模块，增加特征多样性并强化模型的视觉表示能力。  
◆ 在CIFAR-10、NUS-WIDE和IMAGENET等主流数据集上验证了方法的优越性，相比现有深度哈希方法具有更高效率和检索性能。  
◆ 开源代码促进后续研究，为线性复杂度模型在图像检索中的应用提供新思路。</td></tr>
<tr><td>2025-06-19</td><td>Fine-grained Image Retrieval via Dual-Vision Adaptation</td><td>[2506.16273](http://arxiv.org/pdf/2506.16273)</td><td>◆提出双视觉适应（DVA）方法，通过样本和特征协同适配解决细粒度图像检索（FGIR）中预训练模型易过拟合的问题，保留预训练知识的同时提升泛化能力。  
◆设计对象感知适配（Object-Perceptual Adaptation），通过修改输入样本引导冻结的预训练模型聚焦对类别预测关键的物体及局部特征。  
◆提出上下文内适配（In-Context Adaptation），仅引入少量可调参数进行特征适配，使调整后的特征更贴近预训练任务，避免修改原始预训练参数。  
◆结合知识蒸馏机制提出判别感知迁移（Discrimination Perception Transfer），将对象感知适配中的判别知识高效迁移至图像编码器，平衡检索效率与性能。  
◆实验表明DVA在3个分布内和3个分布外细粒度数据集上表现优异，且可学习参数量显著少于现有方法。</td></tr>
<tr><td>2025-06-19</td><td>Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation</td><td>[2506.15988](http://arxiv.org/pdf/2506.15988)<br><a href=''>[代码]</a></td><td>◆ 首次系统分析了四种常见对抗攻击和四种VPR专用攻击对视觉地点识别（VPR）定位性能的影响，揭示了现有系统的脆弱性。  
◆ 提出了一种闭环系统框架，将VPR、对抗攻击检测器（AAD）和主动导航决策相结合，并通过实验验证其性能优势。  
◆ 设计了新颖的实验范式，证明即使AAD的检测准确率有限（如真阳性率75%、假阳性率25%），也能显著降低平均沿轨定位误差约50%。  
◆ 首次研究了快速梯度符号法（FGSM）对抗攻击在VPR中的有效性，填补了该领域的研究空白。  
◆ 提出了多项关键评估指标（如沿轨误差、受攻击时间比例、不安全状态时间比例等），为系统设计提供了量化依据。  
◆ 强调了AAD在实际机器人导航系统中的必要性，为构建可信赖的导航系统提供了重要参考。</td></tr>
<tr><td>2025-06-18</td><td>Semantic and Feature Guided Uncertainty Quantification of Visual Localization for Autonomous Vehicles</td><td>[2506.15851](http://arxiv.org/pdf/2506.15851)</td><td>◆ 提出了一种结合图像特征和语义信息的轻量级传感器误差模型，用于预测视觉定位中的二维误差分布。  
◆ 通过条件化不确定性估计，隐含地捕捉了未标注的关键环境因素（如城市/高速、动态/静态场景、季节变化）。  
◆ 采用高斯混合模型（GMM）替代传统高斯分布，更准确地描述恶劣天气和光照条件下的测量误差特性。  
◆ 在Ithaca365多天气/光照数据集上验证了框架的准确性，涵盖晴天、夜间和雪天等复杂场景。  
◆ 提出独特的传感器门控方法，结合贝叶斯定位滤波器评估传感器与神经网络的联合不确定性量化性能。  
◆ 为自动驾驶安全关键系统提供了可解释的上下文相关不确定性量化工具。</td></tr>
<tr><td>2025-06-18</td><td>ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections</td><td>[2506.15180](http://arxiv.org/pdf/2506.15180)</td><td>◆ 提出ReSeDis任务，首次将大规模图像检索与像素级定位结合，要求模型根据文本描述在图像库中检索目标并精确定位其位置（边界框或分割掩码）。  
◆ 构建首个针对该任务的基准数据集，确保每个描述唯一对应分散在大规模多样化图像库中的目标实例，避免误匹配问题。  
◆ 设计联合评估指标，同时衡量检索召回率与定位精度，解决现有技术只能单独评估某一方面的局限。  
◆ 提供基于冻结视觉语言模型的零样本基线方法，揭示该任务未来研究的巨大提升空间。  
◆ 为构建下一代鲁棒、可扩展的多模态搜索系统提供真实端到端测试平台，弥补现有技术（视觉定位假设目标必然存在，文本检索缺乏细粒度定位）的不足。</td></tr>
<tr><td>2025-06-17</td><td>HARMONY: A Scalable Distributed Vector Database for High-Throughput Approximate Nearest Neighbor Search</td><td>[2506.14707](http://arxiv.org/pdf/2506.14707)</td><td>◆ 提出Harmony分布式向量数据库，解决单机处理高维向量时的内存和效率瓶颈。  
◆ 创新性地采用多粒度分区策略，结合基于维度和基于向量的分区方法，实现计算负载均衡。  
◆ 通过优化分区策略有效降低节点间通信开销，提升系统整体吞吐量。  
◆ 引入基于距离计算单调性的早期停止剪枝机制，大幅减少计算和通信开销。  
◆ 在真实数据集上的实验表明，Harmony在四节点配置下平均吞吐量达到现有方案的4.63倍。  
◆ 针对倾斜工作负载，性能比传统分布式方案提升58%，展现出优异的负载适应能力。</td></tr>
<tr><td>2025-06-17</td><td>TACS-Graphs: Traversability-Aware Consistent Scene Graphs for Ground Robot Indoor Localization and Mapping</td><td>[2506.14178](http://arxiv.org/pdf/2506.14178)</td><td>◆ 提出TACS-Graphs框架，首次将地面机器人可通行性（traversability）与房间分割相结合，解决传统3D场景图中房间层分割不一致问题。  
◆ 通过可通行性约束重新定义房间边界，克服体素方法仅依赖几何邻近性导致的欠分割（开放空间误判）和过分割（复杂环境碎片化）缺陷。  
◆ 构建拓扑与语义更一致的场景图，在结构复杂室内环境中实现更准确的房间层语义分割。  
◆ 开发基于一致性场景图的闭环检测方法（CoSG-LCD），利用增强的分割一致性提升闭环检测效率，进而提高位姿估计精度。  
◆ 实验验证该方法在场景图一致性和位姿图优化性能上优于现有先进技术，为机器人定位与建图提供更可靠的环境表征。</td></tr>
<tr><td>2025-06-16</td><td>A Semantically-Aware Relevance Measure for Content-Based Medical Image Retrieval Evaluation</td><td>[2506.13509](http://arxiv.org/pdf/2506.13509)</td><td>◆ 提出了一种基于知识图谱的语义感知相关性度量方法，用于解决医学图像检索（CBIR）的性能评估难题。  
◆ 创新性地利用医学文本（如放射学报告或文献描述）中隐含的医学概念，避免了传统评估方法对人工标注数据的依赖。  
◆ 通过知识图谱量化医学概念间的语义距离，克服了现有方法将医学概念视为独立标签的局限性，能够捕捉概念间的细微关联。  
◆ 设计了基于近似匹配的相关性评分机制，通过计算两组医学概念的相似性间接衡量医学图像的相似度。  
◆ 在公开数据集上验证了所提方法的有效性和可行性，为医学CBIR评估提供了更符合临床语义的新标准。</td></tr>
<tr><td>2025-06-19</td><td>Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval</td><td>[2506.13496](http://arxiv.org/pdf/2506.13496)</td><td>◆提出分层多正例对比学习损失函数，首次利用Locarno国际分类体系（LIC）的层级关系指导专利图像检索。  
◆通过层级分类树动态分配多组正样本对，根据专利图像在LIC中的层级距离赋予不同相似度权重。  
◆突破传统对比学习仅使用单一样本对的限制，能同时学习跨层级的细粒度语义关联。  
◆在DeepPatent2数据集上验证了方法的普适性，可适配多种视觉和多模态预训练模型。  
◆特别优化了小参数量模型的检索性能，在计算资源受限环境下具有显著部署优势。  
◆实验表明该方法能有效捕捉专利图像的技术细节和复杂语义，提升跨类别检索准确率。</td></tr>
<tr><td>2025-06-16</td><td>EmbodiedPlace: Learning Mixture-of-Features with Embodied Constraints for Visual Place Recognition</td><td>[2506.13133](http://arxiv.org/pdf/2506.13133)</td><td>◆ 提出了一种新颖的简单重排序方法，通过混合特征（MoF）方法在具身约束下优化全局特征，提升视觉地点识别（VPR）性能。  
◆ 首次系统分析了具身约束在VPR中的实际可行性，并根据现有数据集将其分类为GPS标签、时序戳、局部特征匹配和自相似矩阵等类型。  
◆ 设计了一种基于学习的MoF权重计算策略，采用多度量损失函数，有效融合多种特征信息。  
◆ 在公开数据集上实现了性能提升，仅需25 KB额外参数和每帧10微秒处理时间，显著优于现有方法。  
◆ 在Pitts-30k测试集上，基于DINOv2的基线性能提升0.9%，计算开销极低，适合实际机器人应用。</td></tr>
<tr><td>2025-06-16</td><td>SuperPlace: The Renaissance of Classical Feature Aggregation for Visual Place Recognition in the Era of Foundation Models</td><td>[2506.13073](http://arxiv.org/pdf/2506.13073)</td><td>◆ 提出SuperPlace框架，重新利用经典特征聚合方法（如GeM和NetVLAD），在基础模型时代优化视觉地点识别（VPR）性能。  
◆ 开发监督标签对齐方法，实现跨多个VPR数据集的统一训练框架，提升模型泛化能力。  
◆ 提出G²M特征聚合方法，通过双GeM结构学习特征图的主成分并校准输出，仅需十分之一特征维度即可达到优异效果。  
◆ 设计NetVLAD-Linear（NVL）的二次微调策略（FT²），先在高维空间学习特征向量，再通过单线性层压缩，显著提升性能。  
◆ 实验证明SuperPlace的优越性，G²M在低维度下表现突出，NVL-FT²在MSLS排行榜上排名第一。</td></tr>
<tr><td>2025-06-14</td><td>Feature Complementation Architecture for Visual Place Recognition</td><td>[2506.12401](http://arxiv.org/pdf/2506.12401)</td><td>◆ 提出局部-全局特征互补网络（LGCN），通过并行CNN-ViT混合架构解决视觉地点识别（VPR）中局部细节与全局上下文难以兼顾的问题。  
◆ 设计动态特征融合模块（DFM），通过联合建模空间和通道依赖关系实现自适应特征融合，提升特征表达的鲁棒性。  
◆ 在冻结的ViT主干中引入轻量级频域-空间融合适配器，以可控参数量实现任务特定适配，增强ViT分支对VPR任务的适应能力。  
◆ 实验证明LGCN在多个VPR基准数据集上均优于现有方法，定位精度和鲁棒性显著提升。  
◆ 整体架构兼顾计算效率与性能，为复杂环境下的机器人定位提供了新思路。</td></tr>
<tr><td>2025-06-11</td><td>Towards a general-purpose foundation model for fMRI analysis</td><td>[2506.11167](http://arxiv.org/pdf/2506.11167)</td><td>◆ 提出NeuroSTORM，首个面向fMRI分析的通用基础模型，直接从4D fMRI数据学习，解决传统方法因复杂预处理和任务专用模型导致的复现性和迁移性不足问题。  
◆ 采用Mamba架构和移位扫描策略，高效处理完整4D fMRI体积，突破传统时空建模效率瓶颈。  
◆ 设计空间-时间联合优化的预训练方法，结合任务特定提示微调（prompt tuning），显著提升跨任务迁移能力。  
◆ 基于超大规模数据集预训练（28.65百万帧fMRI，50,000+受试者，跨多中心及5-100岁年龄范围），建立迄今最全面的脑功能表征库。  
◆ 在五项任务（年龄/性别预测、表型预测、疾病诊断、fMRI-图像检索、任务态分类）中全面超越现有方法，并在美、韩、澳临床数据验证中展现卓越诊断性能。  
◆ 开源标准化模型框架，为fMRI临床研究提供可复现、可迁移的基础工具，推动脑疾病诊断的跨中心应用。</td></tr>
<tr><td>2025-06-11</td><td>Improving Personalized Search with Regularized Low-Rank Parameter Updates</td><td>[2506.10182](http://arxiv.org/pdf/2506.10182)<br><a href=''>[代码]</a></td><td>◆ 提出一种正则化低秩参数更新方法，仅需微调语言编码器最后一层的少量参数，即可有效适应个性化视觉-语言检索任务，避免传统文本反转方法的不足。  
◆ 发现参数相加策略能有效整合多个已学习个性化概念的参数，提升模型对多概念组合的识别能力。  
◆ 引入基于视觉语言模型生成描述的图像检索评估指标，量化微调后模型对通用知识的保留程度。  
◆ 在DeepFashion2和ConCon-Chi两个基准测试中实现最先进性能，个性化检索准确率较之前方法提升4%-22%。  
◆ 通过双编码器模型内部表征的针对性适配，解决了少样本场景下个性化概念与通用知识融合的难题。  
◆ 实验证明低秩参数更新在保留通用知识的同时，显著提升对&quot;我的狗Fido&quot;等个性化概念的跨上下文识别能力。</td></tr>
<tr><td>2025-06-10</td><td>Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment</td><td>[2506.10030](http://arxiv.org/pdf/2506.10030)</td><td>◆ 提出了首个针对多模态RAG系统中图像知识版权保护的水印框架AQUA，填补了该领域的空白。  
◆ 设计了两种互补的水印嵌入方法：基于首字母缩写的触发器和空间关系线索，确保水印信号在图像到文本的间接传播中保持有效。  
◆ 实现了水印的高效性、强鲁棒性和不可感知性，能够在不同模型和数据集上稳定工作。  
◆ 解决了现有RAG水印技术仅关注文本知识而忽略图像保护的局限性，扩展了版权保护范围。  
◆ 通过实验验证了AQUA在跨模态场景下的可靠性，支持对贡献数据的精准版权追踪。  
◆ 为RAG-as-a-Service环境中的多模态知识共享提供了实用的版权安全保障方案。</td></tr>
<tr><td>2025-06-11</td><td>Hierarchical Image Matching for UAV Absolute Visual Localization via Semantic and Structural Constraints</td><td>[2506.09748](http://arxiv.org/pdf/2506.09748)</td><td>◆ 提出了一种分层跨源图像匹配方法，结合语义感知和结构约束的粗匹配模块与轻量级细粒度匹配模块，显著提升了无人机绝对视觉定位的精度。  
◆ 在粗匹配模块中，利用视觉基础模型提取的语义特征，在语义和结构约束下建立区域级对应关系，有效克服了跨源差异和时变因素带来的挑战。  
◆ 设计了轻量级细粒度匹配模块，通过提取精细特征建立像素级对应关系，进一步提升了定位的准确性。  
◆ 构建了不依赖相对定位技术的无人机绝对视觉定位流程，通过图像检索模块与分层匹配模块的结合，实现了完全基于视觉的全局定位。  
◆ 在公开基准数据集和新提出的CS-UAV数据集上验证了方法的优越性，展示了其在多种挑战性条件下的高精度和鲁棒性。</td></tr>
<tr><td>2025-06-10</td><td>Robust Visual Localization via Semantic-Guided Multi-Scale Transformer</td><td>[2506.08526](http://arxiv.org/pdf/2506.08526)</td><td>◆ 提出了一种结合多尺度特征学习与语义场景理解的视觉定位框架，通过层次化Transformer和跨尺度注意力机制融合几何细节与上下文信息，在保持空间精度的同时适应环境变化。  
◆ 创新性地引入神经场景表征提供的语义监督信号，指导网络学习视角不变特征，有效编码持久结构信息并抑制动态环境干扰。  
◆ 设计了多尺度Transformer架构，利用跨层级注意力机制整合不同尺度的视觉线索，显著提升了复杂场景下的定位鲁棒性。  
◆ 在TartanAir数据集上的实验表明，该方法在动态物体、光照变化和遮挡等挑战性场景中优于现有位姿回归方法。  
◆ 首次验证了语义引导与多尺度处理的协同策略对现实动态环境中视觉定位的有效性，为鲁棒定位提供了新思路。</td></tr>
<tr><td>2025-06-08</td><td>Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs</td><td>[2506.07045](http://arxiv.org/pdf/2506.07045)</td><td>◆ 提出了一种基于多模态大语言模型（MLLMs）的可解释AI生成图像检测方法，通过结合视觉定位和文本推理能力，不仅检测准确率高，还能提供人类可理解的解释。  
◆ 构建了一个包含边界框标注和描述性文本的数据集，突出AI生成图像的合成伪影，为模型提供视觉-文本对齐的推理基础。  
◆ 设计了多阶段优化策略，逐步平衡检测准确性、视觉定位能力和文本解释连贯性，解决了现有MLLMs在检测任务中的幻觉问题。  
◆ 通过微调MLLMs，使其能够同时定位图像中的视觉缺陷并生成合理的解释，显著提升了检测的可靠性和可解释性。  
◆ 实验表明，该方法在检测AI生成图像和定位视觉瑕疵方面均优于基线方法，为可解释的伪造检测提供了新思路。</td></tr>
<tr><td>2025-06-07</td><td>Zero Shot Composed Image Retrieval</td><td>[2506.06602](http://arxiv.org/pdf/2506.06602)</td><td>◆ 提出了一种基于BLIP-2的轻量级Q-Former模型，通过融合视觉和文本特征到单一嵌入，显著提升了零样本组合图像检索（Zero-shot CIR）的性能。  
◆ 在FashionIQ基准测试中，将Recall@10指标从原先的20-25%大幅提升至45.6%（衬衫）、40.1%（裙子）和50.4%（T恤），平均Recall@50达到67.6%。  
◆ 探索了Retrieval-DPO方法，尝试通过直接偏好优化（DPO）损失微调CLIP文本编码器，但发现其效果远低于基线（仅0.02% Recall@10）。  
◆ 分析了Retrieval-DPO失败的四大原因：缺乏图像-文本联合融合、目标函数与Top-K指标不匹配、负样本质量低，以及视觉和Transformer层冻结。  
◆ 研究表明，有效的基于偏好的CIR需要真正的多模态融合、与排名相关的目标函数，以及精心筛选的负样本。</td></tr>
<tr><td>2025-06-06</td><td>GenIR: Generative Visual Feedback for Mental Image Retrieval</td><td>[2506.06220](http://arxiv.org/pdf/2506.06220)</td><td>◆ 提出Mental Image Retrieval (MIR)任务，研究用户通过多轮交互从模糊心理图像中检索目标图像的真实场景，填补了现有文本-图像检索研究的空白。  
◆ 设计GenIR方法，首次利用扩散模型生成可视化反馈，将AI系统对用户意图的理解转化为直观的合成图像，克服传统抽象语言反馈的模糊性问题。  
◆ 构建自动化流水线生成高质量多轮MIR数据集，为后续研究提供基准支持。  
◆ 实验证明GenIR在多轮交互检索中显著优于现有方法，验证了生成式视觉反馈的有效性。  
◆ 开创性地将生成模型与交互式检索结合，为心理图像检索领域奠定新范式，推动人机协同搜索系统的发展。</td></tr>
<tr><td>2025-06-06</td><td>Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning</td><td>[2506.06205](http://arxiv.org/pdf/2506.06205)</td><td>◆提出Astra双模型架构（Astra-Global和Astra-Local），通过分层多模态学习实现通用移动机器人导航，突破传统模块化系统的局限性。  
◆Astra-Global首次将多模态大语言模型（LLM）与混合拓扑-语义图结合，显著提升视觉地点识别和全局定位能力，优于传统方法。  
◆Astra-Local采用自监督训练的4D时空编码器生成鲁棒特征，支持局部路径规划和里程计估计等多任务学习。  
◆创新性提出基于流匹配和掩码ESDF损失的规划头，有效降低碰撞风险，生成更安全的局部轨迹。  
◆里程计头通过Transformer编码器融合多传感器数据，实现高精度相对位姿预测。  
◆在真实室内场景的移动机器人上验证，端到端任务成功率显著提升，展现强泛化能力。</td></tr>
<tr><td>2025-06-05</td><td>HypeVPR: Exploring Hyperbolic Space for Perspective to Equirectangular Visual Place Recognition</td><td>[2506.04764](http://arxiv.org/pdf/2506.04764)</td><td>◆ 提出HypeVPR框架，首次将双曲空间嵌入引入透视到环视（P2E）视觉位置识别任务，利用双曲空间更适合表示层次结构的特性。  
◆ 设计分层特征聚合机制，在双曲空间中组织局部到全局的特征表示，有效捕捉全景图像的固有层次关系。  
◆ 开发高效的粗到精搜索策略，显著提升匹配速度（最高达5倍）同时保持高精度，解决跨图像类型的鲁棒匹配问题。  
◆ 通过双曲空间的距离保持特性，优化特征空间中的距离度量，增强不同视角下描述符的区分能力。  
◆ 在多个基准数据集上验证了方法的优越性，性能超越现有最优方法，同时大幅降低检索时间。  
◆ 开源代码和模型，推动相关领域研究。</td></tr>
<tr><td>2025-06-05</td><td>Deep Learning Reforms Image Matching: A Survey and Outlook</td><td>[2506.04619](http://arxiv.org/pdf/2506.04619)</td><td>这篇论文系统综述了深度学习如何逐步革新传统图像匹配流程，并提出了分类框架。  
◆创新点一：首次从&quot;逐步替代传统模块&quot;和&quot;端到端合并多步骤&quot;两个维度，对深度学习方法进行系统分类（包括可学习检测-...</td></tr>
<tr><td>2025-06-02</td><td>Entity Image and Mixed-Modal Image Retrieval Datas...</td><td>[2506.02291](http://arxiv.org/pdf/2506.02291)</td><td>◆提出首个结合视觉与文本信息的混合模态图像检索基准MMIR，包含单实体图像和多实体图像两种复杂查询类型。  
◆发布Entity Image和MMIR两个高质量数据集，通过众包标注验证数据质量，...</td></tr>
<tr><td>2025-06-01</td><td>Quantization-based Bounds on the Wasserstein Metri...</td><td>[2506.00976](http://arxiv.org/pdf/2506.00976)</td><td>◆提出了一种基于量化网格的高效Wasserstein距离近似方法，通过粗网格上的Kantorovich问题精确求解结合升尺度校正步骤，在保持2%误差内实现10-100倍加速。◆创新性地在原始空间...</td></tr>
<tr><td>2025-05-30</td><td>SORCE: Small Object Retrieval in Com...</td><td>[2505.24441](http://arxiv.org/pdf/2505.24441)<br><a href=''>[代码]</a></td><td>◆提出新任务SORCE（复杂环境中的小物体检索），专注于通过文本查询检索复杂图像中的不显眼小物体。  
◆构建新基准SORCE-1K，包含复杂环境图像和描述小物体的文本查询，揭示现有T2IR方法...</td></tr>
<tr><td>**2025-05-29**</td><td>**Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch**</td><td>[2505.23763](http://arxiv.org/abs/2505.23763)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians**</td><td>[2505.22859](http://arxiv.org/abs/2505.22859)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**UAVPairs: A Challenging Benchmark for Match Pair Retrieval of Large-scale UAV Images**</td><td>[2505.22098](http://arxiv.org/abs/2505.22098)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**Fast Feature Matching of UAV Images via Matrix Band Reduction-based GPU Data Schedule**</td><td>[2505.22089](http://arxiv.org/abs/2505.22089)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-27**</td><td>**Visual Loop Closure Detection Through Deep Graph Consensus**</td><td>[2505.21754](http://arxiv.org/abs/2505.21754)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-27**</td><td>**QuARI: Query Adaptive Retrieval Improvement**</td><td>[2505.21647](http://arxiv.org/abs/2505.21647)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-27**</td><td>**ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval**</td><td>[2505.20764](http://arxiv.org/abs/2505.20764)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-26**</td><td>**Visualized Text-to-Image Retrieval**</td><td>[2505.20291](http://arxiv.org/abs/2505.20291)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-26**</td><td>**Multimodal Reasoning Agent for Zero-Shot Composed Image Retrieval**</td><td>[2505.19952](http://arxiv.org/abs/2505.19952)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-26**</td><td>**Can Visual Encoder Learn to See Arrows?**</td><td>[2505.19944](http://arxiv.org/abs/2505.19944)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-22**</td><td>**TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition**</td><td>[2505.16447](http://arxiv.org/abs/2505.16447)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-21**</td><td>**Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval**</td><td>[2505.15877](http://arxiv.org/abs/2505.15877)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-21**</td><td>**SCENIR: Visual Semantic Clarity through Unsupervised Scene Graph Retrieval**</td><td>[2505.15867](http://arxiv.org/abs/2505.15867)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-20**</td><td>**Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models**</td><td>[2505.13828](http://arxiv.org/abs/2505.13828)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-18**</td><td>**MMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset and Benchmark**</td><td>[2505.12254](http://arxiv.org/abs/2505.12254)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-16**</td><td>**Improved Bag-of-Words Image Retrieval with Geometric Constraints for Ground Texture Localization**</td><td>[2505.11620](http://arxiv.org/abs/2505.11620)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-16**</td><td>**Redundancy-Aware Pretraining of Vision-Language Foundation Models in Remote Sensing**</td><td>[2505.11121](http://arxiv.org/abs/2505.11121)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-04**</td><td>**OBD-Finder: Explainable Coarse-to-Fine Text-Centric Oracle Bone Duplicates Discovery**</td><td>[2505.03836](http://arxiv.org/abs/2505.03836)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-06**</td><td>**Thermal-LiDAR Fusion for Robust Tunnel Localization in GNSS-Denied and Low-Visibility Conditions**</td><td>[2505.03565](http://arxiv.org/abs/2505.03565)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-06**</td><td>**LiftFeat: 3D Geometry-Aware Local Feature Matching**</td><td>[2505.03422](http://arxiv.org/abs/2505.03422)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-06**</td><td>**Seeing the Abstract: Translating the Abstract Language for Vision Language Models**</td><td>[2505.03242](http://arxiv.org/abs/2505.03242)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-13**</td><td>**SafeNav: Safe Path Navigation using Landmark Based Localization in a GPS-denied Environment**</td><td>[2505.01956](http://arxiv.org/abs/2505.01956)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-02**</td><td>**NeuroLoc: Encoding Navigation Cells for 6-DOF Camera Localization**</td><td>[2505.01113](http://arxiv.org/abs/2505.01113)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-01**</td><td>**GSFeatLoc: Visual Localization Using Feature Correspondence on 3D Gaussian Splatting**</td><td>[2504.20379](http://arxiv.org/abs/2504.20379)</td><td>摘要生成中...</td></tr>
</tbody>
</table>
</div>

<h2 id='keypoint-detection'>Keypoint Detection</h2>

<div class="table-container">
<table>
<thead><tr><th>日期</th><th>标题</th><th>论文与代码</th><th>摘要</th></tr></thead>
<tbody>
<tr><td>2025-08-28</td><td>Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation</td><td>[2508.20830](http://arxiv.org/pdf/2508.20830)</td><td>本文提出了一种利用视觉语言模型（VLM）进行手术工具二维关键点检测的新方法。  
◆ 创新性地采用预训练视觉语言模型（VLM），并通过低秩自适应（LoRA）技术进行微调，有效缓解了在小型医疗数据集上容易过拟合的问题。  
◆ 设计了一套精心构建的提示模板，构建指令微调数据集，实现了视觉特征与语义关键点描述之间的对齐。  
◆ 仅需两个训练周期即可显著超越传统CNN或Transformer基线模型，显示出在低资源场景下的高效性能。  
◆ 该方法为后续三维手术器械及手部姿态估计奠定了基础，拓展了VLM在医疗视觉任务中的应用潜力。</td></tr>
<tr><td>2025-08-25</td><td>DroneKey: Drone 3D Pose Estimation in Image Sequences using Gated Key-representation and Pose-adaptive Learning</td><td>[2508.17746](http://arxiv.org/pdf/2508.17746)</td><td>该论文提出了一种名为DroneKey的新型框架，用于从图像序列中精确估计无人机的三维位姿。其核心贡献在于解决了无人机关键点检测中因螺旋桨视觉相似性高和姿态多样性大而导致的难题。  
◆ 提出了一种结合二维关键点检测器和三维位姿估计器的专用框架，针对无人机特性进行优化。  
◆ 在关键点检测阶段，创新性地从每个Transformer编码器层提取两种关键表示（中间表示和紧凑表示），并通过门控求和进行最优融合。  
◆ 引入了姿态自适应的马氏距离损失函数，有效提升了极端姿态下关键点预测的稳定性和准确性。  
◆ 构建并公开了新的无人机二维关键点及三维位姿数据集，为后续研究提供基础。  
实验结果表明，该方法在关键点检测中达到了99.68%的AP（OKS指标），三维位姿估计误差极低（角度MAE为10.62度，位置RMSE为0.221米），同时实现了44 FPS的实时处理速度。</td></tr>
<tr><td>2025-08-25</td><td>HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images</td><td>[2508.16465](http://arxiv.org/pdf/2508.16465)</td><td>该论文提出了名为HOSt3R的无需关键点检测的手-物体三维重建方法。其核心贡献在于摆脱了传统方法对关键点检测的依赖，显著提升了在复杂场景下的鲁棒性和泛化能力。
◆ 提出了一种无需关键点检测器的、直接从单目运动视频估计手-物体三维变换的鲁棒方法。
◆ 摆脱了对预扫描物体模板或已知相机内参的依赖，实现了更通用和无约束的应用。
◆ 将所提出的变换估计方法与多视图重建流程相结合，实现了精确的手-物体三维形状恢复。
◆ 在SHOWMe基准测试中，在手-物体三维变换和形状估计任务上达到了最先进的性能。
◆ 在HO3D数据集上验证了其对未见过的物体类别具有良好的泛化能力。</td></tr>
<tr><td>2025-08-21</td><td>Mag-Match: Magnetic Vector Field Features for Map Matching and Registration</td><td>[2508.15300](http://arxiv.org/pdf/2508.15300)</td><td>Mag-Match提出了一种利用三维磁场矢量特征进行地图匹配与注册的新方法。  
◆ 创新性地利用磁力计数据提取高阶导数特征，这些特征对视觉或激光传感器失效的烟雾、粉尘等恶劣环境具有鲁棒性。  
◆ 所提出的磁场特征描述子具有全局旋转不变性，无需依赖重力方向对齐，显著提升了不同地图或不同机器人数据之间的配准灵活性。  
◆ 采用物理信息高斯过程进行概率推理，能够从离散点云数据中高效、递归地推断整个地图的磁场及其高阶导数，实现了对磁场场的连续建模。  
◆ 在仿真和真实实验中验证了方法有效性，实现了地图-地图、机器人-地图和机器人-机器人之间的精确变换，性能优于基于SIFT的传统方法。</td></tr>
<tr><td>2025-08-17</td><td>Splat Feature Solver</td><td>[2508.12216](http://arxiv.org/pdf/2508.12216)</td><td>◆ 提出了一种统一且与核函数及特征无关的特征提升问题稀疏线性逆问题公式化方法，可通过闭式解高效求解。  
◆ 在凸损失函数下提供了全局最优误差的可证明上界，确保高质量的特征提升结果。  
◆ 引入两种互补的正则化策略（Tikhonov Guidance和Post-Lifting Aggregation）以解决多视角观测中的不一致性和噪声问题，提升语义保真度。  
◆ Tikhonov Guidance通过软对角优势确保数值稳定性，Post-Lifting Aggregation通过特征聚类过滤噪声输入。  
◆ 在开放词汇3D分割基准测试中达到最先进性能，显著优于基于训练、分组和启发式的前沿基线方法，且特征提升仅需数分钟完成。</td></tr>
<tr><td>2025-08-13</td><td>Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram</td><td>[2508.10942](http://arxiv.org/pdf/2508.10942)</td><td>◆ 提出了一种新型特征描述符——方向直方图形状（shape of orientation histogram），用于描述Artcode的通用拓扑结构。  
◆ 将Artcode识别问题重新定义为Artcode提案检测任务，将拓扑相似但几何和语义不同的对象归为同一类别。  
◆ 构建了专门的数据集并进行全面实验，验证了所提特征向量在表示拓扑结构方面的可行性。  
◆ 开发了基于该特征向量的Artcode检测系统，实验结果表明其检测效果显著。  
◆ 首次尝试开发基于特征的拓扑对象检测系统，为Artcode等拓扑对象的识别提供了新思路。  
◆ 该研究为虚实交互开辟了新机会，并展示了拓扑对象检测的潜在应用前景。</td></tr>
<tr><td>2025-08-13</td><td>Stable Diffusion Models are Secretly Good at Visual In-Context Learning</td><td>[2508.09949](http://arxiv.org/pdf/2508.09949)</td><td>◆ 揭示了现成Stable Diffusion模型具备视觉上下文学习潜力，无需专门训练即可适应多种视觉任务。  
◆ 提出原位注意力重计算机制，通过改造自注意力层显式融合查询与示例提示的上下文关系。  
◆ 首次实现单一预训练扩散模型在六大视觉任务（如前景分割、目标检测等）的零样本迁移，突破现有方法需定制化训练的局限。  
◆ 在Pascal-5i数据集上，前景分割任务mIoU指标分别超越Visual Prompting和IMProv方法8.9%和3.2%。  
◆ 通过集成多提示样本提升任务推理能力，证明模型能有效利用上下文示例提升性能。  
◆ 为视觉上下文学习提供轻量化新范式，仅需修改注意力机制且保持模型权重冻结，显著提升通用性。</td></tr>
<tr><td>2025-08-16</td><td>AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation</td><td>[2508.07112](http://arxiv.org/pdf/2508.07112)</td><td>◆ 提出AugLift方法，通过简单但有效的输入增强策略，显著提升了基于2D关键点提升的3D人体姿态估计模型的泛化能力，无需额外数据或传感器。  
◆ 创新性地在标准2D关键点坐标(x,y)基础上，稀疏地增加了关键点检测置信度c和对应深度估计d两个信号，利用预训练模型计算这些信号，继承了它们的强泛化能力。  
◆ 方法具有模块化特性，可以轻松集成到现有的各种提升架构中，无需修改模型结构。  
◆ 在四个数据集上的大量实验表明，AugLift将未见数据集的跨数据集性能平均提升10.1%，同时将分布内性能提升4.0%。  
◆ 分析表明，这些稀疏的关键点对齐线索提供了鲁棒的帧级上下文信息，为提升任何基于提升的姿态估计模型的泛化性能提供了实用方案。  
◆ 所有代码将公开，便于研究社区使用和复现。</td></tr>
<tr><td>2025-08-07</td><td>Head Anchor Enhanced Detection and Association for Crowded Pedestrian Tracking</td><td>[2508.05514](http://arxiv.org/pdf/2508.05514)</td><td>◆ 提出融合目标检测器回归分支和分类分支特征的双重特征增强策略，将空间位置信息直接嵌入特征表示，提升外观建模的鲁棒性。  
◆ 创新性引入头部关键点检测模块，利用头部不易被遮挡的特性，有效缓解密集场景中全身特征丢失导致的跟踪失效问题。  
◆ 设计迭代式卡尔曼滤波运动模型，突破传统线性匀速假设，结合3D场景先验知识实现复杂遮挡下的轨迹补全。  
◆ 首次将检测任务的多维度特征（分类/回归/关键点）与改进运动模型联合优化，形成外观-运动协同增强的跟踪框架。  
◆ 针对严重遮挡场景，通过头部定位与全身检测的异构特征互补，显著提升密集人群的轨迹连续性和ID保持能力。  
◆ 所提方法在保持实时性的前提下，对重叠率超过70%的极端遮挡情况展现出优于传统Re-ID方案的跟踪稳定性。</td></tr>
<tr><td>2025-07-31</td><td>Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection</td><td>[2507.23461](http://arxiv.org/pdf/2507.23461)</td><td>◆ 首次在联邦学习中提出并系统研究了&quot;分辨率漂移&quot;问题，揭示了分辨率差异作为非独立同分布数据的新维度对关键点检测任务的重要影响。  
◆ 提出分辨率自适应联邦学习（RAF）方法，通过基于热图的多分辨率知识蒸馏机制，在高分辨率教师模型和低分辨率学生模型间传递知识，有效增强模型对分辨率变化的鲁棒性。  
◆ 创新性地采用高低分辨率双向蒸馏策略，既避免了低分辨率客户端过拟合，又保留了高分辨率空间细节特征，突破了传统联邦学习在非分类任务中的性能瓶颈。  
◆ 通过理论分析和大量实验验证，证明RAF不仅能显著缓解分辨率漂移（最高提升23.6%准确率），还能无缝集成到现有联邦学习框架中，具有强实用性。  
◆ 通过t-SNE可视化分析，首次揭示了分类任务与高分辨率表征任务在特征分布上的本质差异，为RAF方法扩展到其他需要保持空间细节的任务（如医疗影像分析）提供了理论基础。  
◆ 开辟了联邦学习在人体姿态估计等非分类任务中的新研究方向，为解决跨设备视觉任务中的分辨率异构性问题提供了标准化解决方案。</td></tr>
<tr><td>2025-07-25</td><td>Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching</td><td>[2507.19118](http://arxiv.org/pdf/2507.19118)</td><td>◆提出跨时空融合注意力机制(CSTF)，通过独立检测参考图像和查询图像中的尺度不变关键点来增强特征表示，解决多模态遥感图像间几何和辐射差异大的问题。  
◆创新性地构建对应关系图，同时利用多个图像区域的信息，有效捕捉跨模态相似性，克服传统全连接层特征提取的局限性。  
◆将相似性匹配重新定义为分类任务，结合SoftMax和全卷积网络(FCN)层，在保持局部特征敏感性的同时整合全局上下文信息。  
◆在HRSC2016和DOTA基准数据集上实现目标检测任务的最优性能，平均mAP分别达到90.99%和90.86%，显著超越现有模型。  
◆保持12.5 FPS的推理速度，证明该方法在提升精度的同时具备实际应用的高效性。  
◆验证了改进的跨模态特征匹配能直接提升遥感目标检测等下游任务性能，为多模态遥感分析提供新思路。</td></tr>
<tr><td>2025-07-24</td><td>A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration</td><td>[2507.18551](http://arxiv.org/pdf/2507.18551)</td><td>◆提出了一种新型3D跨模态关键点描述符，专门用于解决MRI与实时超声(iUS)之间的配准难题，克服了两种模态在外观、分辨率和视野上的显著差异。  
◆采用患者特异性的合成匹配方法，从术前MRI生成合成iUS体积，通过监督对比学习训练共享描述符空间，增强了跨模态匹配能力。  
◆设计了基于概率的关键点检测策略，能够识别解剖学显著且模态一致的位置，提高了关键点的可靠性和一致性。  
◆在训练阶段引入课程式三元组损失和动态难负样本挖掘，使描述符对iUS伪影（如斑点噪声和有限覆盖）具有鲁棒性，同时保持旋转不变性。  
◆在推理阶段，通过稀疏匹配实现刚性配准，无需人工初始化，且在ReMIND数据集上验证了其优越性，平均匹配精度达69.8%，配准误差低至2.39 mm。  
◆相比现有方法，该框架具有可解释性，对iUS视野变化表现出强鲁棒性，代码已开源，便于进一步研究和应用。</td></tr>
<tr><td>2025-07-23</td><td>CartoonAlive: Towards Expressive Live2D Modeling from Single Portraits</td><td>[2507.17327](http://arxiv.org/pdf/2507.17327)</td><td>◆ 提出CartoonAlive方法，首次实现从单张肖像照片快速生成高质量Live2D卡通模型，耗时不足30秒。  
◆ 创新地将3D人脸建模中的形状基概念引入2D领域，构建适用于Live2D的面部混合形状系统。  
◆ 通过面部关键点检测自动推断混合形状权重，无需人工干预即可实现高精度表情驱动。  
◆ 采用分层分割技术模拟3D运动效果，在保持2D卡通风格的同时实现类似3D的实时动态操控。  
◆ 相比传统3D建模方案大幅降低制作成本，相比2D视频方案显著提升交互灵活性。  
◆ 为数字内容创作提供高效可扩展的解决方案，拓展了虚拟角色动画的应用场景。</td></tr>
<tr><td>2025-07-21</td><td>Toward a Real-Time Framework for Accurate Monocular 3D Human Pose Estimation with Geometric Priors</td><td>[2507.16850](http://arxiv.org/pdf/2507.16850)</td><td>◆ 提出了一种实时单目3D人体姿态估计框架，结合2D关键点检测与几何感知的2D到3D提升技术，显著提升了在无约束环境下的性能。  
◆ 显式利用相机内参和个性化解剖学先验知识，通过自校准和生物力学约束的反向运动学增强模型精度。  
◆ 创新性地从动作捕捉和合成数据集中生成大规模合理的2D-3D训练对，解决了标注数据不足的问题。  
◆ 框架无需专用硬件即可实现快速、个性化的高精度3D姿态估计，具有强部署适应性。  
◆ 融合数据驱动学习与模型先验知识，在提升准确性的同时增强了模型的可解释性和边缘设备部署能力。</td></tr>
<tr><td>2025-07-17</td><td>DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model</td><td>[2507.13145](http://arxiv.org/pdf/2507.13145)</td><td>◆ 提出DINO-VO系统，首次将视觉基础模型DINOv2的鲁棒语义特征应用于单目视觉里程计（VO），解决了传统学习型VO在泛化性和鲁棒性上的不足。  
◆ 针对DINOv2特征粒度粗糙的问题，设计了专用显著关键点检测器，有效提升稀疏特征匹配的精度。  
◆ 结合DINOv2的语义特征与细粒度几何特征，生成兼具鲁棒性和局部化能力的混合特征表示。  
◆ 采用基于Transformer的匹配器和可微分位姿估计层，通过端到端学习优化特征匹配与运动估计。  
◆ 在TartanAir、KITTI等数据集上超越传统帧间VO方法（如SuperPoint），并在室外驾驶场景中与视觉SLAM系统性能相当，同时保持72 FPS实时性。  
◆ 系统内存占用低于1GB，展现了高效部署潜力，为视觉基础模型在实时定位任务中的应用提供新范式。</td></tr>
<tr><td>2025-07-15</td><td>KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model</td><td>[2507.11102](http://arxiv.org/pdf/2507.11102)</td><td>◆ 提出KptLLM++，首个专用于通用关键点理解的多模态大语言模型，通过用户指令整合多样化输入模态，填补了MLLMs在细粒度语义捕捉上的空白。  
◆ 创新性地采用&quot;先识别后检测&quot;范式，通过结构化思维链推理机制，先解析关键点语义再精确定位，提升复杂场景下的理解能力。  
◆ 构建超50万样本的大规模训练数据集，覆盖多样物体、关键点类别、图像风格及遮挡场景，显著增强模型泛化性。  
◆ 实现跨场景关键点检测的统一框架，建立高效人机协作接口，支持细粒度图像分析、物体检索和行为识别等应用。  
◆ 在多个关键点检测基准测试中达到SOTA性能，验证了其作为统一细粒度图像理解解决方案的潜力。  
◆ 为AI理解结构化像素级语义信息提供新思路，对推动人机交互变革具有重要启示意义。</td></tr>
<tr><td>2025-07-15</td><td>GKNet: Graph-based Keypoints Network for Monocular Pose Estimation of Non-cooperative Spacecraft</td><td>[2507.11077](http://arxiv.org/pdf/2507.11077)</td><td>◆ 提出基于图结构的关键点网络GKNet，利用关键点间的几何约束关系提升非合作航天器单目姿态估计的精度。  
◆ 针对航天器结构对称性和局部遮挡问题，通过图网络建模关键点拓扑关系，增强检测鲁棒性。  
◆ 构建中等规模航天器关键点检测数据集SKD，包含3种航天器目标、9万张仿真图像及高精度标注，填补领域数据空白。  
◆ 实验证明GKNet在关键点检测精度上显著优于现有先进方法，尤其适用于复杂空间场景。  
◆ 开源代码和数据集促进后续研究，为在轨服务任务（如卫星维护、太空碎片清理）提供可靠技术支撑。</td></tr>
<tr><td>2025-07-14</td><td>FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching</td><td>[2507.10770](http://arxiv.org/pdf/2507.10770)</td><td>◆提出FPC-Net，通过特征金字塔和基于一致性的隐式匹配实现无描述符的关键点检测，重新改进了SuperPoint方法。  
◆创新性地在关键点检测阶段直接建立关联性，省去了传统方法中描述符的计算、存储、传输和匹配步骤。  
◆尽管匹配精度略低于传统方法，但完全消除了描述符需求，大幅降低了定位系统的内存占用。  
◆通过特征金字塔和一致性匹配机制，实现了高效且轻量化的关键点检测与匹配流程。  
◆在实验中对比了传统手工方法和现代学习方法，验证了该方法的有效性和实用性。  
◆为几何计算机视觉任务提供了一种更简洁、更高效的解决方案，尤其适合资源受限的应用场景。</td></tr>
<tr><td>2025-07-27</td><td>Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection</td><td>[2507.07994](http://arxiv.org/pdf/2507.07994)</td><td>◆ 提出首个基于草图的小样本关键点检测框架，利用人类手绘草图作为无源数据替代方案，解决传统方法在查询数据分布不一致时的困境。  
◆ 设计跨模态嵌入学习机制，有效桥接草图与真实图像之间的模态差异，实现草图到关键点的精准映射。  
◆ 引入网格化定位器（grid-based locator）增强空间感知能力，结合原型网络优化关键点定位精度。  
◆ 创新性采用原型域适应技术（prototypical domain adaptation），自适应消除用户手绘风格的个体差异，提升模型泛化性。  
◆ 通过大量实验验证框架在跨类别、跨关键点任务中的小样本快速收敛能力，扩展了关键点检测的应用边界。</td></tr>
<tr><td>2025-07-09</td><td>Reading a Ruler in the Wild</td><td>[2507.07077](http://arxiv.org/pdf/2507.07077)</td><td>◆ 提出RulerNet深度学习框架，将标尺读数重新定义为统一的关键点检测问题，通过几何级数参数表示标尺刻度，实现透视变换下的鲁棒性测量。  
◆ 采用抗畸变标注和训练策略直接定位厘米刻度，摆脱传统方法对手工阈值或固定流程的依赖，显著提升对不同标尺类型和成像条件的泛化能力。  
◆ 开发可扩展的合成数据生成流程，结合图形化标尺生成与ControlNet技术添加逼真背景，有效缓解数据稀缺问题并增强训练多样性。  
◆ 提出轻量级DeepGP网络，直接从噪声标记回归几何级数参数，替代传统迭代优化方法，实现移动或边缘设备上的实时尺度估计。  
◆ 实验证明RulerNet在复杂真实场景中能提供高精度、一致且高效的尺度估计，为生物医学、法医等领域的自动化测量提供通用解决方案。</td></tr>
<tr><td>2025-07-09</td><td>MK-Pose: Category-Level Object Pose Estimation via Multimodal-Based Keypoint Learning</td><td>[2507.06662](http://arxiv.org/pdf/2507.06662)</td><td>◆ 提出MK-Pose框架，首次融合RGB图像、点云数据和类别级文本描述，通过多模态输入提升类别级物体姿态估计的鲁棒性。  
◆ 设计自监督关键点检测模块，结合注意力机制生成查询、软热图匹配和图关系建模，有效解决遮挡和跨实例泛化问题。  
◆ 创新性引入图增强特征融合模块，整合局部几何信息与全局上下文，增强对复杂场景的建模能力。  
◆ 在CAMERA25和REAL275数据集上验证性能，无需形状先验即超越现有最优方法（IoU和平均精度指标）。  
◆ 额外测试跨数据集能力（HouseCat6D），证明模型具备强泛化性，适用于实际工业场景。  
◆ 开源代码并提供完整实现，推动领域研究与应用落地。</td></tr>
<tr><td>2025-06-27</td><td>MatChA: Cross-Algorithm Matching with Feature Augmentation</td><td>[2506.22336](http://arxiv.org/pdf/2506.22336)</td><td>◆ 提出了首个解决跨特征检测器场景下视觉定位问题的方法MatChA，突破了现有方法必须使用相同检测器的限制。  
◆ 通过特征描述符增强技术提升跨检测器特征匹配性能，解决了关键点重复率低和描述符区分度不足的难题。  
◆ 创新性地将增强后的特征转换到潜在空间，实现了不同算法生成描述符的有效匹配。  
◆ 在多个基准测试中验证了该方法显著提升了跨特征场景下的图像匹配和视觉定位精度。  
◆ 突破了传统方案依赖共同关键点的假设，更贴合实际应用中不同设备使用不同特征提取算法的复杂场景。</td></tr>
<tr><td>2025-06-27</td><td>SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images</td><td>[2506.21945](http://arxiv.org/pdf/2506.21945)</td><td>◆ 提出堆叠式深度残差网络（SDRNet），通过双编码器-解码器结构同时捕获长程语义并保留空间细节，解决高分辨率遥感图像分割中空间信息丢失问题。  
◆ 在编码器与解码器之间引入膨胀残差块（DRB），增强全局依赖关系建模能力，有效应对地物类别差异和遮挡导致的特征提取挑战。  
◆ 通过多上下文特征学习机制，覆盖不同尺寸地物目标，缓解因物体尺寸变化导致的细分不准问题。  
◆ 结合全局与局部上下文信息，显著提升对细小地物和复杂边界的识别精度，克服传统深度网络下采样导致的边界模糊缺陷。  
◆ 在ISPRS Vaihingen和Potsdam数据集上验证了模型优越性，性能超越现有深度卷积网络，为高精度地物分类提供新解决方案。</td></tr>
<tr><td>2025-05-29</td><td>TimePoint: Accelerated Time Series Alignment via Self-Supervised Keypoint and Descriptor Learning</td><td>[2505.23475](http://arxiv.org/pdf/2505.23475)<br><a href=''>[代码]</a></td><td>◆提出TimePoint方法，通过自监督学习从合成数据中提取关键点和描述符，显著加速动态时间规整（DTW）的对齐过程，同时提高对齐精度。  
◆创新性地将2D关键点检测思想适配到1D信号，设计高效的一维微分同胚模型生成逼真训练数据，有效模拟非线性时间扭曲。  
◆采用全卷积和小波卷积架构提取信息丰富的稀疏表示，使DTW在稀疏数据上运行时获得数量级加速，且精度通常优于原始信号上的标准DTW。  
◆仅使用合成数据训练即可在真实时间序列上展现强泛化能力，结合真实数据微调后性能进一步提升。  
◆通过大量实验验证，TimePoint在速度和精度上均优于标准DTW，为大规模时间序列分析提供可扩展解决方案。</td></tr>
<tr><td>2025-05-24</td><td>Why Not Replace? Sustaining Long-Term Visual Localization via Handcrafted-Learned Feature Collaboration on CPU</td><td>[2505.18652](http://arxiv.org/pdf/2505.18652)<br><a href=''>[代码]</a></td><td>◆ 提出手工-学习特征协作机制：首次系统论证手工特征（适合连续跟踪）与学习特征（擅长宽基线匹配）的功能互补性，打破传统&quot;替代&quot;思维，建立协同框架。  
◆ 设计CPU友好的分层定位架构：实时层采用手工特征进行相对位姿估计，异步层选择性调用学习特征进行绝对定位，实现仅需CPU的长期稳定运行。  
◆ 创新关键帧优化策略：通过动态筛选机制平衡学习特征的计算开销与定位精度，使系统在光照变化下保持47%的平均误差降低。  
◆ 实现全时段环境适应性：通过特征协作有效应对工业场景中的季节更替、昼夜光照变化等挑战，定位一致性显著提升。  
◆ 提供完整开源实现：公开代码包含特征互补性分析、计算延迟剖析到系统级验证的全套实验数据，推动工业应用落地。  
◆ 建立三阶段验证体系：从特征特性对比、CPU平台算力剖析到真实光照变化测试，形成严谨的技术验证链路。</td></tr>
<tr><td>2025-05-18</td><td>SEPT: Standard-Definition Map Enhanced Scene Perception and Topology Reasoning for Autonomous Driving</td><td>[2505.12246](http://arxiv.org/pdf/2505.12246)</td><td>◆ 提出SEPT框架，利用标准定义地图（SD地图）作为先验知识，增强自动驾驶场景感知与拓扑推理能力，减少对高精地图的依赖。  
◆ 设计混合特征融合策略，结合SD地图与鸟瞰图（BEV）特征，同时处理栅格化和矢量化表示，解决两者空间对齐问题。  
◆ 创新性引入基于SD地图的辅助任务——交叉路口感知关键点检测，提升长距离和遮挡场景下的理解性能。  
◆ 通过实验验证，在OpenLane-V2数据集上显著超越现有方法，证明SD地图先验的有效性。  
◆ 整体框架兼顾感知与推理，为无高精地图自动驾驶系统提供更鲁棒的在线环境理解方案。</td></tr>
<tr><td>2025-05-17</td><td>Keypoints as Dynamic Centroids for Unified Human Pose and Segmentation</td><td>[2505.12130](http://arxiv.org/pdf/2505.12130)</td><td>◆ 提出Keypoints as Dynamic Centroid (KDC)方法，通过动态质心表示统一解决人体姿态估计和实例分割任务，克服传统方法在关节重叠或快速运动时的局限性。  
◆ 采用自底向上范式生成关键点热图，并引入KeyCentroids（基于关键点磁盘）提升关键点检测精度和置信度得分。  
◆ 利用高置信度关键点作为嵌入空间中的动态质心（MaskCentroids），实现快速运动下像素到人体实例的高效聚类。  
◆ 在CrowdPose、OCHuman和COCO等基准测试中验证了KDC的优越性，尤其在复杂场景下的准确性和实时性能表现突出。  
◆ 通过动态质心机制有效处理实例级分割中的遮挡和姿态快速变化问题，增强了模型的泛化能力。</td></tr>
<tr><td>2025-05-16</td><td>Deepfake Forensic Analysis: Source Dataset Attribution and Legal Implications of Synthetic Media Manipulation</td><td>[2505.11110](http://arxiv.org/pdf/2505.11110)</td><td>◆提出了一种新型的GAN生成图像溯源框架，通过可解释特征分析准确识别训练数据集（如CelebA或FFHQ）。  
◆创新性地融合频域变换（傅里叶/DCT）、色彩分布度量和局部特征描述符（SIFT），提取合成图像中的 discriminative 统计特征。  
◆监督分类器（随机森林、SVM、XGBoost）在二元分类（真实vs合成）和多类数据集溯源任务中达到98-99%准确率，覆盖多种主流GAN架构（如StyleGAN系列）。  
◆实验证明频域特征（DCT/FFT）对捕捉数据集特异性伪影（如上采样模式、频谱异常）具有显著优势，色彩直方图则能揭示GAN训练的隐式正则化策略。  
◆首次系统探讨了合成媒体数据集溯源的法律应用场景，包括版权侵权、隐私数据滥用（如GDPR合规）及加州AB 602法案等监管应对方案。  
◆该框架为生成模型的问责制治理提供了技术支撑，可应用于数字取证、内容审核和知识产权诉讼等实际领域。</td></tr>
<tr><td>2025-06-19</td><td>RDD: Robust Feature Detector and Descriptor using Deformable Transformer</td><td>[2505.08013](http://arxiv.org/pdf/2505.08013)</td><td>◆ 提出RDD（Robust Deformable Detector），一种基于可变形Transformer的新型关键点检测与描述方法，通过可变形自注意力机制捕获全局上下文和几何不变性。  
◆ 利用可变形注意力机制聚焦关键位置，显著降低搜索空间复杂度并有效建模几何变换，解决了传统方法难以学习长程视觉关系的问题。  
◆ 结合标准MegaDepth数据集与自建的Air-to-Ground（空对地）数据集进行训练，增强模型在跨视角和跨尺度场景下的鲁棒性。  
◆ 在稀疏匹配任务中性能超越现有最优方法，并具备半稠密匹配能力，扩展了应用场景。  
◆ 引入两个新基准测试：一个针对大视角与尺度变化，另一个为空对地场景，填补了跨高度3D重建评估的空白。</td></tr>
<tr><td>2025-05-12</td><td>Enabling Privacy-Aware AI-Based Ergonomic Analysis</td><td>[2505.07306](http://arxiv.org/pdf/2505.07306)</td><td>◆ 提出了一种隐私感知的AI工效学分析框架，通过对抗训练开发轻量级神经网络，在视频数据中模糊隐私信息，仅保留人体姿态估计所需关键特征。  
◆ 采用数据混淆技术确保与标准姿态估计算法兼容，在保护隐私的同时维持高精度分析能力，解决了传统摄像头系统的隐私泄露问题。  
◆ 创新性地将混淆后的数据传输至中央服务器处理，结合多视角融合技术重建3D关键点，实现远程高精度工效学评估。  
◆ 整合REBA（快速全身评估）方法对3D姿态进行工效学风险量化，形成从数据采集到风险评估的完整闭环系统。  
◆ 在工业场景中首次实现隐私保护与工效学监测的平衡，为制造业提供兼顾安全性与合规性的解决方案。  
◆ 系统设计轻量化且可扩展，适用于资源受限的工业环境，具有实际部署的可行性优势。</td></tr>
<tr><td>2025-05-09</td><td>My Emotion on your face: The use of Facial Keypoint Detection to preserve Emotions in Latent Space Editing</td><td>[2505.06436](http://arxiv.org/pdf/2505.06436)</td><td>◆ 提出了一种结合面部关键点检测模型的新损失函数（HFLD损失），用于解决StyleGAN/2潜在空间编辑中的表情纠缠问题。  
◆ 通过在现有模型损失函数中增加HFLD损失，有效限制了编辑过程中对面部表情的干扰，实验显示情绪变化减少高达49%。  
◆ 首次将面部关键点检测技术与GAN潜在空间编辑结合，定量和定性验证了该方法在保持表情一致性上的优越性。  
◆ 相比现有方法，显著提升了生成图像在固定表情下变换外貌特征的能力，为手势和表情研究提供了可靠的数据增强手段。  
◆ 通过对比实验证明，该方法在保持面部表情的同时编辑其他属性（如性别、年龄）的效果优于当前最先进模型。  
◆ 为面部生成任务提供了一种可解释的技术路径，通过关键点约束直接解决特征解耦问题，而非依赖隐式学习。</td></tr>
<tr><td>2025-05-05</td><td>Unsupervised training of keypoint-agnostic descriptors for flexible retinal image registration</td><td>[2505.02787](http://arxiv.org/pdf/2505.02787)</td><td>◆提出首个不依赖关键点检测的无监督描述符学习方法，突破视网膜图像配准领域对标注数据的依赖。  
◆创新性地实现描述符网络与关键点检测器的解耦，使模型能适配任意检测器，提升临床应用灵活性。  
◆在标准视网膜配准数据集上进行了全面验证，证明无监督方法性能媲美有监督方法。  
◆设计并测试了多种新型关键点检测器，验证了方法对不同检测器的强鲁棒性。  
◆为医学领域无监督学习应用提供了重要范例，解决了医学图像标注稀缺的核心痛点。  
◆通过端到端无监督训练框架，显著降低了视网膜图像配准的技术门槛和实现成本。</td></tr>
<tr><td>2025-05-05</td><td>Unsupervised Deep Learning-based Keypoint Localization Estimating Descriptor Matching Performance</td><td>[2505.02779](http://arxiv.org/pdf/2505.02779)</td><td>◆提出首个完全无监督的视网膜图像配准流程，无需任何标注数据，解决了医学领域标注稀缺的难题。  
◆创新性地颠覆传统思路，通过描述子性能反推关键点检测（描述子驱动检测器），而非传统的关键点驱动描述子学习。  
◆开发了无需关键点检测或标签的描述子学习方法，可直接为视网膜图像任意位置生成高质量描述符。  
◆设计了新型无标签关键点检测网络，能够直接从输入图像预测描述子匹配性能来定位关键点。  
◆在四个独立数据集上验证表明，无监督描述子超越有监督SOTA方法，无监督检测器显著优于现有无监督检测方法。  
◆整个配准流程性能媲美主流有监督方法，且无需标注数据的特性使其可直接迁移到其他领域和模态。</td></tr>
<tr><td>**2025-05-04**</td><td>**Focus What Matters: Matchability-Based Reweighting for Local Feature Matching**</td><td>[2505.02161](http://arxiv.org/abs/2505.02161)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-04**</td><td>**Enhancing Lidar Point Cloud Sampling via Colorization and Super-Resolution of Lidar Imagery**</td><td>[2505.02049](http://arxiv.org/abs/2505.02049)</td><td>摘要生成中...</td></tr>
</tbody>
</table>
</div>

<h2 id='image-matching'>Image Matching</h2>

<div class="table-container">
<table>
<thead><tr><th>日期</th><th>标题</th><th>论文与代码</th><th>摘要</th></tr></thead>
<tbody>
<tr><td>2025-09-04</td><td>Dual-Scale Volume Priors with Wasserstein-Based Consistency for Semi-Supervised Medical Image Segmentation</td><td>[2509.04273](http://arxiv.org/pdf/2509.04273)</td><td>本文提出了一种用于半监督医学图像分割的新框架，其核心贡献在于将变分模型中的先验知识与深度学习网络有效结合。  
◆ 创新性地引入了双尺度体积先验，即在图像尺度和数据集尺度上分别利用强显式先验和弱隐式先验来约束分割网络。  
◆ 设计了一个回归网络来估计未标注图像的目标区域体积，并通过图像尺度的Wasserstein距离损失，强制分割结果与回归预测的类别比例一致。  
◆ 提出了一个数据集尺度的Wasserstein距离损失函数，使得未标注数据集预测的体积分布与已标注数据集的分布相似，从而利用数据集层面的统计信息。  
◆ 将Threshold Dynamics空间正则化方法融入分割网络主干，增强了特征提取的几何约束能力。  
实验在多个公开数据集上验证了该方法的优越性，显著提升了半监督分割性能。</td></tr>
<tr><td>2025-08-27</td><td>POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection</td><td>[2508.19742](http://arxiv.org/pdf/2508.19742)</td><td>该论文提出了一个名为POEv2的通用且鲁棒的线检测框架，其核心贡献是统一了通用线段检测和结构化线段检测两大任务。  
◆ 提出了一个灵活的框架，能够同时胜任通用线检测和结构化线检测，解决了以往两类检测器因设计目标不同而无法互相替代的问题。  
◆ 作为Pixel Orientation Estimation (POE)方法的改进版，新框架能从边缘强度图中检测线段，并可兼容任何边缘检测器。  
◆ 通过结合高效的边缘检测器，该方法在三个公开数据集上实现了最先进的性能，证明了其有效性和优越性。  
◆ 该框架兼具鲁棒性和灵活性，为不同应用场景下的线检测需求提供了一个统一的解决方案。</td></tr>
<tr><td>2025-08-14</td><td>Revisiting Cross-View Localization from Image Matching</td><td>[2508.10716](http://arxiv.org/pdf/2508.10716)</td><td>◆ 提出基于跨视角图像匹配的新框架，将定位问题转化为匹配问题，突破传统直接位姿回归或BEV特征对齐的局限。  
◆ 引入Surface Model精确建模地面视角可见区域，实现更准确的鸟瞰图投影，解决几何不一致问题。  
◆ 设计SimRefiner模块通过局部-全局残差校正优化相似度矩阵，无需RANSAC后处理即可获得精细匹配。  
◆ 构建首个像素级标注的跨视角匹配基准CVFM（含32,509对图像），填补领域数据空白。  
◆ 在极端视角差异下实现定位精度和匹配质量双重提升，实验验证其显著优于现有方法。  
核心贡献在于通过建模、匹配、数据三方面的创新，首次系统解决了跨视角图像严格对应难题，推动GNSS拒止环境下的高精度定位发展。</td></tr>
<tr><td>2025-08-14</td><td>A Sub-Pixel Multimodal Optical Remote Sensing Images Matching Method</td><td>[2508.10294](http://arxiv.org/pdf/2508.10294)</td><td>◆ 提出了一种基于相位一致性加权最小绝对偏差（PCWLAD）的亚像素模板匹配方法，显著提高了多模态光学图像的匹配精度。  
◆ 采用两阶段匹配策略：先通过结构相似性指数（SSIM）进行粗匹配，再利用WLAD进行精细匹配，兼顾效率与精度。  
◆ 在粗匹配阶段保留原始结构细节（无噪声滤波），通过SSIM增强对非线性辐射差异的鲁棒性。  
◆ 在精细匹配阶段引入辐射和几何变换模型，结合互结构滤波抑制噪声对结构一致性的影响，提升跨模态匹配稳定性。  
◆ 在可见光-红外（Landsat、无人机）和可见光-近红外（近景）三类数据集上验证，平均匹配精度达0.4像素，优于现有8种先进方法。  
◆ 公开了软件和数据集，促进多模态遥感图像匹配研究的发展。</td></tr>
<tr><td>2025-08-13</td><td>Episodic Memory Representation for Long-form Video Understanding</td><td>[2508.09486](http://arxiv.org/pdf/2508.09486)</td><td>◆ 提出Video-EM框架，解决现有Video-LLMs因上下文窗口限制难以处理长视频的问题，无需额外训练即可实现高效视频理解。  
◆ 突破传统关键帧检索方法的静态图像匹配局限，通过模拟人类情景记忆机制，将关键帧建模为时序化情景事件，保留时空动态关系。  
◆ 创新性地结合思维链（CoT）技术，利用大语言模型迭代筛选信息量最大化的最小情景记忆子集，避免冗余帧干扰。  
◆ 首次在关键帧表示中同时捕捉空间关联与时间动态性，精准还原视频叙事逻辑，提升场景转换和上下文连续性的理解能力。  
◆ 在四大主流评测基准（Video-MME等）上验证有效性，性能显著优于基线4-9%，且使用更少帧数，兼顾效率与准确性。</td></tr>
<tr><td>2025-08-11</td><td>VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models</td><td>[2508.08521](http://arxiv.org/pdf/2508.08521)</td><td>◆提出VISOR方法，仅通过优化视觉输入即可实现精准的行为控制，无需修改模型内部参数或文本指令。  
◆首创&quot;通用引导图像&quot;概念，通过视觉刺激诱导目标激活模式，在保持隐蔽性的同时实现双向行为调控。  
◆在LLaVA-1.5-7B模型上验证了三大关键对齐任务（拒绝、谄媚、生存本能），单张150KB图像即可达到与激活向量相当的调控效果。  
◆相比系统提示词（3-4%改变）和激活向量（微弱负向调控），VISOR实现高达25%的行为偏移，同时保持99.9%的MMLU基准性能。  
◆揭示了视觉通道的新型安全威胁：攻击者仅通过图像即可绕过文本防御机制，实现复杂行为操控。  
◆为多模态模型控制提供了无需运行时开销、兼容API服务的解决方案，同时警示了视觉引导攻击的防御紧迫性。</td></tr>
<tr><td>2025-08-11</td><td>Semi-supervised Multiscale Matching for SAR-Optical Image</td><td>[2508.07812](http://arxiv.org/pdf/2508.07812)</td><td>◆提出半监督多尺度匹配框架S2M2-SAR，利用少量标注数据和大量无标注SAR-光学图像对进行训练，解决标注成本高的问题。  
◆通过结合深层和浅层匹配结果生成伪标签相似性热图，为无标注数据提供监督信号，提升模型泛化能力。  
◆设计跨模态特征增强模块，采用无监督的跨模态互独立性损失，分离模态共享和模态特定特征，增强特征解耦能力。  
◆无需人工标注即可优化跨模态特征表示，降低对标注数据的依赖，提升模型实用性。  
◆实验表明，S2M2-SAR性能优于现有半监督方法，并与全监督SOTA方法相当，验证了其高效性和应用潜力。</td></tr>
<tr><td>2025-08-07</td><td>Refining Gaussian Splatting: A Volumetric Densification Approach</td><td>[2508.05187](http://arxiv.org/pdf/2508.05187)</td><td>◆ 提出基于惯性体积的新型密度控制方法，利用高斯函数的惯性体积指导3D高斯分布的精细化过程，克服了原始3DGS密度策略的缺陷。  
◆ 创新性地研究了传统SfM与深度图像匹配(DIM)两种点云初始化方法对重建质量的影响，为初始化选择提供了新见解。  
◆ 通过自适应密度控制(ADC)自动化实现了高斯基元的动态增删，显著提升了点基元管理效率。  
◆ 在Mip-NeRF 360数据集上的实验表明，该方法在重建质量上全面超越原始3DGS，且在不同场景中均表现优异。  
◆ 将体积信息与密度控制相结合，为3D高斯泼溅技术的几何优化开辟了新思路。</td></tr>
<tr><td>2025-08-09</td><td>SGAD: Semantic and Geometric-aware Descriptor for Local Feature Matching</td><td>[2508.02278](http://arxiv.org/pdf/2508.02278)</td><td>◆ 提出SGAD网络，通过生成高区分度的区域描述符，直接实现区域匹配，避免传统低效的像素级比较和复杂图优化，显著提升匹配精度和效率。  
◆ 设计新颖的监督策略，将区域匹配任务分解为分类和排序子任务，进一步提升匹配性能。  
◆ 引入层次包容冗余过滤器（HCRF），通过分析包容图消除重叠区域，优化匹配结果。  
◆ 在效率上实现重大突破，相比MESA方法运行时减少60倍（0.82秒 vs 60.23秒），同时保持更高精度。  
◆ 在多个基准测试中验证有效性：SGAD+LoFTR在室外姿态估计中比DKM更快（0.82秒 vs 1.51秒）且更准确（65.98 vs 61.11）；SGAD+ROMA在室内姿态估计中AUC@5°提升7.39%，达到新SOTA。</td></tr>
<tr><td>2025-07-31</td><td>VMatcher: State-Space Semi-Dense Local Feature Matching</td><td>[2507.23371](http://arxiv.org/pdf/2507.23371)</td><td>◆ 提出VMatcher，一种结合Mamba和Transformer的混合网络，用于图像对的半稠密特征匹配。  
◆ 首次将选择性状态空间模型（SSM）引入特征匹配任务，利用Mamba的线性计算复杂度显著降低传统Transformer的二次方计算开销。  
◆ 设计多层级混合架构，同时保留Transformer注意力机制的优势和Mamba高效长序列处理能力，兼顾性能与效率。  
◆ 在保持或超越当前最优方法精度的前提下，大幅提升计算效率，适合实时性要求高的应用场景。  
◆ 开源代码并提供多种配置方案，为后续研究提供灵活可扩展的基准框架。</td></tr>
<tr><td>2025-07-30</td><td>Modality-Aware Feature Matching: A Comprehensive Review of Single- and Cross-Modality Techniques</td><td>[2507.22791](http://arxiv.org/pdf/2507.22791)</td><td>◆ 全面综述了单模态与跨模态特征匹配技术，涵盖RGB图像、深度图像、3D点云、LiDAR扫描、医学图像及视觉-语言交互等多种模态，填补了该领域系统性总结的空白。  
◆ 对比分析了传统手工方法（如Harris角点、SIFT和ORB描述子）与深度学习方法（如SuperPoint和LoFTR）的优劣，指出后者在跨模态鲁棒性和适应性上的显著提升。  
◆ 重点介绍了模态感知的创新技术，例如针对深度图像的几何与深度专用描述子、针对3D点云的稀疏与稠密学习方法，以及LiDAR扫描中基于注意力增强的神经网络。  
◆ 强调了跨模态应用的突破，如医学图像配准中的MIND描述子和视觉-语言任务中的交互匹配技术，展示了特征匹配在多样化数据交互中的扩展潜力。  
◆ 系统总结了当前挑战与未来方向，为跨模态特征匹配的研究提供了清晰的路线图，推动该领域向更复杂场景发展。</td></tr>
<tr><td>2025-07-25</td><td>Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching</td><td>[2507.19118](http://arxiv.org/pdf/2507.19118)</td><td>◆提出跨时空融合注意力机制(CSTF)，通过独立检测参考图和查询图中的尺度不变关键点来增强特征表示，解决多模态遥感图像间几何和辐射差异大的问题。  
◆创新性地构建对应图，同时利用多图像区域信息，提升跨模态特征匹配能力。  
◆将相似性匹配重新定义为分类任务，结合SoftMax和全卷积网络(FCN)层，兼顾局部特征敏感性和全局上下文信息。  
◆在HRSC2016和DOTA基准数据集上实现目标检测任务的最优性能，平均mAP分别达到90.99%和90.86%。  
◆保持12.5 FPS的推理速度，验证了算法的高效性和实用性。  
◆首次证明改进的跨模态特征匹配能直接提升遥感下游任务（如目标检测）的性能。</td></tr>
<tr><td>2025-07-24</td><td>A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration</td><td>[2507.18551](http://arxiv.org/pdf/2507.18551)</td><td>◆提出了一种新型3D跨模态关键点描述符，用于解决MRI与实时超声(iUS)之间的配准难题，克服了模态间外观、分辨率和视野差异大的问题。  
◆采用患者特异性的&quot;合成匹配&quot;方法，从术前MRI生成合成iUS体积，实现了有监督对比学习的共享描述符空间训练。  
◆开发了概率关键点检测策略，能够识别解剖学显著且模态一致的特征位置，提高了匹配的准确性。  
◆在训练阶段使用基于课程的三元组损失函数和动态难负样本挖掘技术，使描述符具有抗iUS伪影(如斑点噪声)和旋转不变性的特点。  
◆整个框架具有可解释性，无需人工初始化，对iUS视野变化表现出强鲁棒性，在ReMIND数据集上达到69.8%的平均匹配精度和2.39mm的配准误差。  
◆相比现有方法，该方案首次实现了从关键点匹配到刚性配准的完整流程，在临床实际应用中更具实用价值。</td></tr>
<tr><td>2025-07-22</td><td>A Single-step Accurate Fingerprint Registration Method Based on Local Feature Matching</td><td>[2507.16201](http://arxiv.org/pdf/2507.16201)</td><td>◆ 提出了一种端到端的单步指纹配准算法，直接通过预测两幅指纹图像之间的半密集匹配点对应关系来实现对齐，避免了传统两步法的复杂性。  
◆ 解决了低质量指纹图像因特征点数量不足导致的初始配准失败问题，提高了配准的鲁棒性和成功率。  
◆ 创新性地结合全局-局部注意力机制，实现了两幅指纹图像之间的端到端像素级对齐，提升了配准精度。  
◆ 实验证明该方法仅需单步配准即可达到最先进的匹配性能，同时还能与密集配准算法结合以进一步提升性能。  
◆ 为指纹识别中的图像失真问题提供了一种高效且可靠的解决方案，具有实际应用价值。</td></tr>
<tr><td>2025-07-09</td><td>Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching</td><td>[2507.06744](http://arxiv.org/pdf/2507.06744)</td><td>◆ 提出局部-全局双粒度身份关联机制，通过批内跨模态显式关联强化身份约束，提升模型对细微差异的捕捉能力。  
◆ 构建以视觉模态为锚点的动态跨模态关联网络，引入基于置信度的动态调整机制，有效增强弱关联样本的识别能力。  
◆ 设计信息不对称样本对构建方法，结合一致性学习解决困难样本挖掘问题，提升模型鲁棒性。  
◆ 首次在弱监督文本-行人图像匹配任务中实现复杂一对多身份关系的建模，突破性能瓶颈。  
◆ 实验证明该方法显著提升跨模态匹配准确率，为实际应用提供高效解决方案。</td></tr>
<tr><td>2025-07-05</td><td>From Query to Explanation: Uni-RAG for Multi-Modal Retrieval-Augmented Learning in STEM</td><td>[2507.03868](http://arxiv.org/pdf/2507.03868)</td><td>◆ 提出Uni-Retrieval模块，通过提取查询风格原型并动态匹配Prompt Bank中的标记，解决现有检索系统无法处理教育场景多样性和模糊性的问题。  
◆ 引入Prompt Bank，结合MoE-LoRA模块编码领域知识，支持测试时适应未见查询类型，增强检索灵活性。  
◆ 将Uni-Retrieval与轻量级指令调优语言模型结合，构建完整的Uni-RAG流程，实现从检索到自然语言生成的教育内容输出。  
◆ 采用风格条件查询机制，生成符合学习目标的可读解释、反馈或教学内容，提升个性化教学效果。  
◆ 在SER等多模态基准测试中，Uni-RAG在检索精度和生成质量上均优于基线系统，同时保持低计算成本。  
◆ 为STEM教育提供可扩展的智能解决方案，弥合检索与生成的鸿沟，支持高效、可解释的学习辅助。</td></tr>
<tr><td>2025-07-02</td><td>What does really matter in image goal navigation?</td><td>[2507.01667](http://arxiv.org/pdf/2507.01667)</td><td>◆ 研究了端到端强化学习在图像目标导航任务中的有效性，挑战了传统依赖专用图像匹配或预训练视觉模块的方法。  
◆ 通过大规模实验分析了多种架构设计（如延迟融合、通道堆叠、空间到深度投影和交叉注意力）对导航性能的影响。  
◆ 揭示了仿真环境设置对现有方法性能的影响，指出仿真中存在的捷径问题，同时证明部分能力可迁移到更真实场景。  
◆ 首次发现导航性能与相对位姿估计能力之间存在相关性，表明后者是导航任务中自然涌现的重要子技能。  
◆ 为仅通过导航奖励信号训练相对位姿估计器提供了可能性，对具身AI及其他领域具有潜在影响。  
◆ 通过系统实验验证了端到端训练智能体的潜力，同时指出了仿真与现实场景间的性能差距问题。</td></tr>
<tr><td>2025-06-30</td><td>Efficient and Accurate Image Provenance Analysis: A Scalable Pipeline for Large-scale Images</td><td>[2506.23707](http://arxiv.org/pdf/2506.23707)</td><td>这篇论文的核心贡献是提出了一种高效且准确的图像溯源分析管道，解决了现有方法在精度和可扩展性上的两大瓶颈。  

◆ 创新性地引入修改关系追踪技术，显著提升了图像变体的过滤效果，能够全面发现与查询图像视觉相似度低的变体，解决了传统方法因低相似度而遗漏严重修改图像的问题。  

◆ 通过结合局部特征匹配和压缩伪影捕捉技术，增强了方法对多样化修改的鲁棒性，能够更准确地分析图像间的关联性和修改方向。  

◆ 提出了一种优化的相似度计算策略，并在构建有向溯源图时消除了冗余的成对分析，将时间复杂度从二次降低到线性，实现了大规模场景下的高效处理。  

◆ 实验证明，该方法在精度上比现有技术提升了16.7%-56.1%，并在1000万规模图像上平均响应时间仅3秒，远优于现有方法的12分钟，展现了卓越的可扩展性。  

◆ 最终生成的溯源图能够精确刻画图像的演化历史，为数字治理提供了可靠的取证工具。</td></tr>
<tr><td>2025-06-29</td><td>Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization</td><td>[2506.23077](http://arxiv.org/pdf/2506.23077)</td><td>◆ 提出了Distance-Aware Cross-View Geo-Localization (DACVGL)新问题，强调模型需综合捕捉目标周围上下文信息并降低定位误差成本。  
◆ 构建首个多视角图像与精确距离标注的基准数据集DA-Campus，涵盖三种空间分辨率，支持系统性研究。  
◆ 将DACVGL问题形式化为跨域分层检索任务，揭示传统度量学习无法解决建筑间复杂空间关系的问题。  
◆ 提出动态对比学习框架DyCL，通过分层空间间隔逐步对齐特征表示，解决跨视角层次化检索难题。  
◆ 实验证明DyCL与现有多尺度度量学习方法高度互补，显著提升分层检索性能和跨视角地理定位精度。  
◆ 公开代码和基准数据集，推动后续研究。</td></tr>
<tr><td>2025-06-27</td><td>MatChA: Cross-Algorithm Matching with Feature Augmentation</td><td>[2506.22336](http://arxiv.org/pdf/2506.22336)</td><td>◆ 首次提出跨特征检测器的特征匹配方法，解决了不同设备使用不同稀疏特征提取算法时视觉定位失效的问题。  
◆ 通过特征描述符增强技术提升跨检测器场景下的特征匹配性能，突破了现有方法依赖相同关键点的限制。  
◆ 引入特征转换到潜在空间的策略，有效应对关键点低重复性和描述符区分度不足的挑战。  
◆ 实验证明该方法在跨特征场景下显著提升了图像匹配和视觉定位的准确率。  
◆ 在多个基准数据集上验证了方法的有效性，为实际应用中不同描述符混合使用的场景提供了可行解决方案。</td></tr>
<tr><td>2025-07-22</td><td>Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs</td><td>[2506.22139](http://arxiv.org/pdf/2506.22139)</td><td>◆提出Q-Frame方法，通过查询自适应的帧选择策略解决视频-大语言模型中关键时空信息丢失的问题，突破传统均匀采样的局限性。  
◆创新性地结合CLIP等文本-图像匹配网络，实现无需训练的即插即用式帧选择，利用Gumbel-Max技巧提升选择效率。  
◆引入多分辨率缩放机制，根据视频内容和查询需求动态调整帧的时空分辨率，优化计算资源分配。  
◆在保持计算负载不变的前提下，显著增加可处理的帧数，同时保留对任务至关重要的时空细节。  
◆在MLVU、LongVideoBench等基准测试中验证了方法的优越性，涵盖多种视频理解任务，性能超越现有技术。  
◆为视频-大模型的实际应用提供轻量化解决方案，平衡了计算效率与语义理解深度的矛盾。</td></tr>
<tr><td>2025-06-27</td><td>ZeroReg3D: A Zero-shot Registration Pipeline for 3D Consecutive Histopathology Image Reconstruction</td><td>[2506.21923](http://arxiv.org/pdf/2506.21923)</td><td>◆ 提出ZeroReg3D，首个针对连续组织病理切片3D重建的零样本配准框架，无需训练或微调即可直接应用。  
◆ 创新结合零样本深度学习关键点匹配与基于优化的仿射/非刚性配准技术，解决传统方法在精度与泛化性上的矛盾。  
◆ 首次系统解决组织变形、切片伪影、染色差异和光照不一致四大挑战，显著提升3D重建的解剖结构保真度。  
◆ 突破现有深度学习方法依赖大规模标注数据的限制，通过零样本策略实现跨数据集的高适应性。  
◆ 公开完整代码库，为病理学研究和临床诊断提供可直接部署的开源工具。</td></tr>
<tr><td>2025-06-25</td><td>Fast entropy-regularized SDP relaxations for permutation synchronization</td><td>[2506.20191](http://arxiv.org/pdf/2506.20191)</td><td>◆ 提出了一种快速随机算法，用于解决部分排列同步问题（PPS）的半定规划（SDP）松弛，显著提升了多图像匹配的效率。  
◆ 利用熵正则化技术解决了标准松弛中优化解非唯一性的问题，增强了算法的稳定性和可靠性。  
◆ 开发了一种随机求解器，其计算复杂度在观测到的对应关系数量上接近最优，大幅提升了计算效率。  
◆ 设计了多种舍入程序，能够从隐式表示的原问题解变量中恢复组合解，同时支持保持循环一致性而不影响计算效率。  
◆ 在合成和真实数据集上验证了算法的优越性，在速度和精度方面均达到了当前最优水平。  
◆ 展示了熵正则化SDP在PPS问题中的理论和实践优势，为传统低秩或谱技术提供了新的替代方案。</td></tr>
<tr><td>2025-06-18</td><td>ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections</td><td>[2506.15180](http://arxiv.org/pdf/2506.15180)</td><td>◆ 提出ReSeDis任务，首次将大规模图像检索与像素级定位统一，要求模型根据文本描述在图像库中同时判断对象是否存在并精确定位。  
◆ 构建首个针对该任务的基准数据集，确保每个描述唯一对应分散在大规模多样图像库中的对象实例，避免误匹配。  
◆ 设计联合评估指标，同时衡量检索召回率与定位精度，为端到端性能提供量化标准。  
◆ 提出基于冻结视觉语言模型的零样本基线方法，揭示该任务未来研究的巨大提升空间。  
◆ 为构建下一代鲁棒、可扩展的多模态搜索系统提供真实场景下的测试平台，弥补现有技术仅侧重检索或定位单一能力的缺陷。</td></tr>
<tr><td>2025-06-16</td><td>EmbodiedPlace: Learning Mixture-of-Features with Embodied Constraints for Visual Place Recognition</td><td>[2506.13133](http://arxiv.org/pdf/2506.13133)</td><td>◆ 提出了一种新颖的简单重排序方法，通过混合特征（MoF）方法在具身约束下优化全局特征，提升视觉地点识别（VPR）性能。  
◆ 首次系统分析了具身约束在VPR中的实际可行性，并根据现有数据集将其分类为GPS标签、时序戳、局部特征匹配和自相似矩阵等类型。  
◆ 设计了一种基于学习的MoF权重计算策略，采用多度量损失函数，有效融合多种特征信息。  
◆ 在公开数据集上实现了性能提升，仅需25 KB额外参数和每帧10微秒处理时间，计算开销极低。  
◆ 在Pitts-30k测试集上，基于DINOv2的基线性能提升0.9%，显著优于现有方法。</td></tr>
<tr><td>2025-06-12</td><td>RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration</td><td>[2506.10344](http://arxiv.org/pdf/2506.10344)</td><td>◆ 提出RealKeyMorph（RKM），首个无需固定分辨率重采样的医学图像配准方法，直接处理原始分辨率数据，避免插值伪影。  
◆ 创新性地将关键点输出为扫描仪真实世界坐标（而非体素坐标），通过利用扫描仪生成的仿射矩阵实现跨分辨率配准。  
◆ 扩展KeyMorph框架，在训练过程中融入真实世界坐标转换，使关键点提取与图像分辨率完全解耦。  
◆ 在腹部MRI正交2D堆栈和不同分辨率3D脑数据集上验证了方法的优越性，证明其对分辨率差异的鲁棒性。  
◆ 通过闭式关键点匹配计算变换参数，保持了KeyMorph原有的可解释性优势，同时突破分辨率限制。</td></tr>
<tr><td>2025-06-11</td><td>Hierarchical Image Matching for UAV Absolute Visual Localization via Semantic and Structural Constraints</td><td>[2506.09748](http://arxiv.org/pdf/2506.09748)</td><td>◆ 提出了一种分层跨源图像匹配方法，结合语义感知和结构约束的粗匹配模块与轻量级细粒度匹配模块，显著提升了无人机绝对视觉定位的精度。  
◆ 利用视觉基础模型提取语义特征，在语义和结构约束下建立区域级对应关系，有效解决了跨源差异和时变因素导致的匹配难题。  
◆ 设计了轻量级细粒度匹配模块，通过提取精细特征建立像素级对应关系，进一步提升了定位的准确性。  
◆ 构建了不依赖相对定位技术的无人机绝对视觉定位流程，通过图像检索模块与分层匹配模块的结合，实现了独立定位。  
◆ 在公开基准数据集和新提出的CS-UAV数据集上验证了方法的优越性，展示了其在多种挑战性条件下的高精度和鲁棒性。</td></tr>
<tr><td>2025-06-11</td><td>ScaleLSD: Scalable Deep Line Segment Detection Streamlined</td><td>[2506.09369](http://arxiv.org/pdf/2506.09369)<br><a href=''>[代码]</a></td><td>◆ 提出ScaleLSD，首个通过大规模自监督学习（超过1000万无标签图像）训练的领域无关鲁棒线检测模型，显著提升自然图像的线段检测能力。  
◆ 重新设计并简化了传统（深度与非深度）线段检测方法的核心架构，实现高效高性能的线段检测，检测数量远超经典非深度方法。  
◆ 在线段几何表征上更完整且准确，首次实现深度方法在所有测试场景（检测性能、单视图3D几何估计等）全面超越经典非深度LSD。  
◆ 通过零样本协议验证模型泛化性，在单视图3D重建、双视图线段匹配、多视图3D线段映射等任务中均表现优异。  
◆ 开源代码与模型，为图像线几何的广泛应用（如三维重建、匹配）提供更强通用性支持，强化线段几何在多任务中的实用性。</td></tr>
<tr><td>2025-05-21</td><td>Anti-interrupted sampling repeater jamming via linear canonical Wigner distribution lightweight LFM detection</td><td>[2506.06302](http://arxiv.org/pdf/2506.06302)</td><td>◆ 提出基于广义线性正则维格纳分布（GLWD）的抗干扰方法，通过合理设置参数获得高时频分辨率和能量集中性，显著提升信号分离能力和信噪比。  
◆ 改进现有移动线段检测（M-LSD）算法，提出移动长线段检测（M-LSD）算法，增强对目标线性调频信号的检测能力，降低对干扰信号的敏感性。  
◆ 利用GLWD与短时傅里叶变换（STFT）的映射关系构建时频滤波器，在STFT域进行滤波以高效抑制干扰。  
◆ 方法在低信噪比条件下仍能有效区分能量接近真实目标的干扰采样转发干扰（ISRJ），解决传统时频域方法在多分量信号场景中的时频混叠问题。  
◆ 仿真与实验验证了该方法对难区分干扰的有效抑制能力，兼具实时性和鲁棒性，适用于实际雷达抗干扰场景。</td></tr>
<tr><td>2025-06-05</td><td>Vanishing arcs for isolated plane curve singularities</td><td>[2506.04917](http://arxiv.org/pdf/2506.04917)</td><td>◆ 提出&quot;消失弧集&quot;新概念，作为传统消失循环的几何对应物，通过几何变分算子将嵌入弧与闭曲线联系起来。  
◆ 建立几何变分算子的拓扑框架，用几何弧和闭曲线替代同调循环，拓展了经典超曲面奇点理论的工具集。  
◆ 给出判定嵌入弧被几何变分算子映射为消失循环的充要条件，基于弧与几何单值化映像的交点数特征。  
◆ 证明对任意由A&#x27;Campo剖分产生的消失循环集，存在拓扑例外弧集使其变分映像与该消失循环集完全匹配。  
◆ 将几何单值化与交点数理论相结合，为平面曲线奇点的拓扑研究提供了新的几何化方法。</td></tr>
<tr><td>2025-06-05</td><td>Deep Learning Reforms Image Matching: A Survey and Outlook</td><td>[2506.04619](http://arxiv.org/pdf/2506.04619)</td><td>◆ 该论文首次从深度学习逐步改造传统图像匹配流程的视角，系统梳理了该领域的革命性进展，突破了传统综述按技术分类的框架。  
◆ 提出与经典流水线高度对齐的新型分类体系：一方面拆解各环节的可学习替代方案（如可学习检测-描述子、离群点过滤器），另一方面整合多环节的端到端模块（如中端稀疏匹配器、稠密匹配器）。  
◆ 深度剖析了可学习组件与端到端模块的设计哲学及优劣，首次明确揭示两类技术路线的互补性与适用边界。  
◆ 在相对位姿恢复、单应估计等核心任务上建立统一评测基准，定量比较了代表性方法的性能突破与现存缺陷。  
◆ 前瞻性指出自监督学习、跨模态匹配、动态场景适应等未来方向，为领域发展绘制了清晰的技术演进地图。  
◆ 通过揭示传统流程被深度学习&quot;解构-重构&quot;的完整路径，为计算机视觉基础问题研究提供了方法论层面的新范式。</td></tr>
<tr><td>2025-06-20</td><td>SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping</td><td>[2505.24305](http://arxiv.org/pdf/2505.24305)</td><td>◆提出SR3D框架，首次实现无需训练的基于单视角的透明与镜面物体3D重建与抓取，突破传统深度感知限制。  
◆利用外部视觉模型直接从RGB图像生成物体网格，结合深度图实现3D场景融合，避免复杂多视角采集系统。  
◆创新性提出视图匹配与关键点匹配双机制，联合2D语义与3D几何信息精准定位物体位姿与尺度。  
◆通过将重建物体逆向映射回原始深度缺失场景，生成高精度深度图，显著提升抓取检测效果。  
◆在仿真与真实场景中验证有效性，为透明/镜面物体抓取提供实用化解决方案，简化硬件依赖。</td></tr>
<tr><td>2025-06-05</td><td>Universal Domain Adaptation for Semantic Segmentation</td><td>[2505.22458](http://arxiv.org/pdf/2505.22458)</td><td>这篇论文提出了通用领域自适应语义分割（UniDA-SS）方法，解决了传统方法因忽略类别设置差异导致的性能下降问题。其核心贡献和创新点如下：

◆ 提出UniDA-SS框架，首次在语义分割任务中实现无需预知源域与目标域类别设置的通用领域自适应。  
◆ 设计Domain-Specific Prototype-based Distinction（DSPD）模块，通过将每类划分为两个域特定原型，增强跨域共有类别的特征区分能力。  
◆ 开发Target-based Image Matching（TIM）策略，基于目标域伪标签匹配最佳源域图像进行批量训练，有效提升共有类别的学习效果。  
◆ 构建新的UniDA-SS基准数据集，为后续研究提供标准化评估平台。  
◆ 实验证明UniMAP方法显著优于基线模型，代码已开源。</td></tr>
<tr><td>2025-05-23</td><td>To Glue or Not to Glue? Classical vs Learned Image Matching for Mobile Mapping Cameras to Textured Semantic 3D Building Models</td><td>[2505.17973](http://arxiv.org/pdf/2505.17973)<br><a href=''>[代码]</a></td><td>◆ 首次系统比较了传统手工特征匹配（如SIFT+RANSAC）与深度学习特征匹配方法在语义3D建筑模型相机定位任务中的性能差异。  
◆ 针对移动测绘相机与纹理化CityGML LoD2模型的匹配场景，提出定制化评估框架，填补了该领域的研究空白。  
◆ 结合标准数据集（HPatches、MegaDepth-1500）和自建数据集（含地面/无人机拍摄的立面纹理与对应影像），验证方法普适性。  
◆ 通过PnP算法量化绝对位姿估计精度，利用地理参考轨迹数据生成几何真值，建立客观评估基准。  
◆ 实验证明学习式特征匹配在挑战性场景（RANSAC内点数0-12、AUC 0-0.16）中显著优于传统方法，准确率和鲁棒性提升明显。  
◆ 公开代码库促进模型化视觉定位技术发展，为后续研究提供可复现基础。</td></tr>
<tr><td>2025-05-16</td><td>Multi-view dense image matching with similarity learning and geometry priors</td><td>[2505.11264](http://arxiv.org/pdf/2505.11264)</td><td>◆提出MV-DeepSimNets深度学习框架，首次将多视图相似性学习与极线几何先验结合，无需繁琐的多视图训练数据构建。  
◆创新性地引入在线几何先验，通过极线约束或单应性校正动态建模像素关系，生成几何感知的特征表示。  
◆采用平面扫描法将几何特征投影到候选深度假设空间，实现端到端的几何条件化特征适配，提升多视图重建精度。  
◆通过聚合学习到的相似性构建并正则化代价体，相比传统稠密匹配方法显著改善了表面重建质量。  
◆在泛化能力上表现突出，可同时适用于航空影像和卫星影像（不同地面采样距离），性能超越主流相似性学习网络和端到端回归模型。  
◆完整集成至MicMac开源软件，可直接兼容标准多分辨率影像匹配流程，具备工程实用价值。</td></tr>
<tr><td>2025-05-12</td><td>Boosting Global-Local Feature Matching via Anomaly...</td><td>[2505.07375](http://arxiv.org/pdf/2505.07375)<br><a href=''>[代码]</a></td><td>◆提出GLFM方法，通过全局-局部特征匹配解决多类别点云异常检测中的特征混淆问题。  
◆创新性地设计了三阶段框架：异常合成增强特征表示、建立抗混淆的全局-局部记忆库、基于特征距离的异常检测，显...</td></tr>
<tr><td>2025-05-04</td><td>OBD-Finder: Explainable Coarse-to-Fine Te...</td><td>[2505.03836](http://arxiv.org/pdf/2505.03836)<br><a href=''>[代码]</a></td><td>◆提出了一种渐进式甲骨文重复片发现框架，结合无监督低层关键点匹配与高层以文本为中心的内容匹配，实现语义感知和可解释的候选排序。◆在保持高召回率的同时，该方法在Top-5和Top-15检索结果中取...</td></tr>
<tr><td>2025-05-06</td><td>LiftFeat: 3D Geometry-Aware Local Feature Matching</td><td>[2505.03422](http://arxiv.org/pdf/2505.03422)<br><a href=''>[代码]</a></td><td>◆ 提出LiftFeat轻量网络，通过融合单目深度估计生成的伪表面法线特征与原始2D描述符，增强特征匹配在光照变化、弱纹理等极端场景下的鲁棒性。  
◆ 设计3D几何感知特征提升模块，利用表面法...</td></tr>
<tr><td>**2025-05-04**</td><td>**Focus What Matters: Matchability-Based Reweighting for Local Feature Matching**</td><td>[2505.02161](http://arxiv.org/abs/2505.02161)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-15**</td><td>**Mitigating Modality Bias in Multi-modal Entity Alignment from a Causal Perspective**</td><td>[2504.19458](http://arxiv.org/abs/2504.19458)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
</tbody>
</table>
</div>

<h2 id='nerf'>NeRF</h2>

<div class="table-container">
<table>
<thead><tr><th>日期</th><th>标题</th><th>论文与代码</th><th>摘要</th></tr></thead>
<tbody>
<tr><td>2025-09-03</td><td>GS-TG: 3D Gaussian Splatting Accelerator with Tile Grouping for Reducing Redundant Sorting while Preserving Rasterization Efficiency</td><td>[2509.00911](http://arxiv.org/pdf/2509.00911)</td><td>该论文提出了GS-TG，一种用于加速3D高斯泼溅渲染的硬件加速器，其核心贡献在于通过优化排序与光栅化过程来提升渲染速度。  
◆ 提出基于瓦片分组（Tile Grouping）的排序策略，将多个小瓦片组合成大组以共享排序操作，显著减少了冗余计算。  
◆ 引入位掩码（Bitmask）机制，为每个高斯图元标记其所属的有效小瓦片，使得光栅化阶段仍可按原始小瓦片高效执行，避免了不必要的像素计算。  
◆ 实现了排序阶段使用“大瓦片”逻辑以降低排序开销，而光栅化阶段保持“小瓦片”粒度以维持渲染效率，有效解决了传统方法中瓦片尺寸增大导致光栅化计算量上升的矛盾。  
◆ 该方法是无损的，无需重新训练或微调，并可与其他现有优化技术无缝集成。实验结果显示，GS-TG相比当前最先进的加速器平均实现了1.54倍的渲染速度提升。</td></tr>
<tr><td>2025-08-31</td><td>SWAGSplatting: Semantic-guided Water-scene Augmented Gaussian Splatting</td><td>[2509.00800](http://arxiv.org/pdf/2509.00800)</td><td>该论文提出了一种结合语义引导与3D高斯溅射的水下场景增强重建方法SWAGSplatting，核心解决了水下环境因光线扭曲、浑浊和低可见度导致的3D重建难题。其创新点包括：
◆ 引入多模态跨知识融合机制，将语言模型（CLIP）提取的语义特征嵌入每个高斯基元，实现语义与结构感知的联合优化。
◆ 设计专用的语义一致性损失函数，确保重建结果与高层场景理解保持一致，提升重建的语义准确性。
◆ 提出分阶段训练策略，结合由粗到细的学习与后期参数细化，显著增强训练稳定性和重建质量。
实验表明，该方法在SeaThru-NeRF和Submerged3D数据集上全面优于现有技术，PSNR指标平均提升最高达3.09 dB，为水下勘探和海洋感知应用提供了高效解决方案。</td></tr>
<tr><td>2025-08-28</td><td>Adam SLAM - the last mile of camera calibration with 3DGS</td><td>[2508.20526](http://arxiv.org/pdf/2508.20526)</td><td>该论文提出了一种利用3D高斯泼溅（3DGS）模型优化相机标定的新方法。  
◆ 创新性地通过新视图颜色损失的反向传播来精细调整相机参数，突破了传统标定方法的精度限制。  
◆ 将标定问题转化为可微分优化问题，实现了端到端的标定优化流程。  
◆ 在3DGS基准数据集上平均提升0.4 dB PSNR，显著提升了新视图合成质量。  
◆ 为高精度参考场景（如Mip-NeRF 360）的标定提供了以渲染质量为核心的新范式。  
该方法虽需较长调优时间，但对标定精度要求极高的场景具有重要应用价值。</td></tr>
<tr><td>2025-08-26</td><td>Can we make NeRF-based visual localization privacy-preserving?</td><td>[2508.18971](http://arxiv.org/pdf/2508.18971)</td><td>该论文针对基于NeRF的视觉定位方法存在的隐私泄露风险提出了解决方案。  
◆ 首先设计了一种新的评估协议，用于系统检验NeRF表示中的隐私安全性，发现即使移除颜色预测头，其几何表示仍会泄露敏感细节。  
◆ 创新性地提出ppNeRF（隐私保护神经分割场），将NeRF的传统光度监督替换为分割标签监督，避免直接学习原始图像纹理。  
◆ 通过自监督方式学习分割标签，确保标签既保留足够的几何判别性以支持精准定位，又充分模糊化细节以保护隐私。  
◆ 在保持高精度视觉定位能力的同时，显著提升了隐私保护水平，实现了隐私与性能的平衡。  
实验表明该方法在多个基准上达到了最先进的定位结果。</td></tr>
<tr><td>2025-08-25</td><td>Real-time 3D Visualization of Radiance Fields on Light Field Displays</td><td>[2508.18540](http://arxiv.org/pdf/2508.18540)</td><td>该论文提出了一种面向光场显示器的实时辐射场三维可视化统一框架。  
◆ 开发了基于单遍平面扫描策略的共享架构，高效支持多种辐射场表示（如NeRF、3D高斯泼溅和稀疏体素），无需针对不同场景重新训练。  
◆ 通过缓存非方向性共享组件，显著减少跨视角的冗余计算，实现了高达22倍的渲染加速。  
◆ 在45个视角下以512p分辨率达到200+ FPS的实时交互性能，并在Looking Glass显示器上验证了沉浸式三维交互应用。  
◆ 在提升渲染效率的同时保持了图像质量，解决了光场显示多视角渲染与辐射场计算密集型体积渲染之间的集成难题。</td></tr>
<tr><td>2025-08-28</td><td>Generating Human-AI Collaborative Design Sequence for 3D Assets via Differentiable Operation Graph</td><td>[2508.17645](http://arxiv.org/pdf/2508.17645)</td><td>该论文的核心贡献是提出了一种通过可微分操作图生成人机协作3D资产设计序列的方法，以弥合AI生成内容与人类参数化设计工作流之间的鸿沟。  
◆ 将传统建模操作（如拉伸、布尔运算）重新构建为可微分单元，支持通过梯度下降联合优化连续和离散参数。  
◆ 构建了带有门控机制的分层操作图，并通过端到端优化倒角距离实现与目标几何的高保真对齐。  
◆ 提出多阶段序列长度约束与领域规则惩罚机制，实现了无需真实序列标注的无监督紧凑序列学习。  
◆ 生成的序列具备高几何准确性、平滑网格结构、合理步骤组成和灵活编辑能力，完全兼容主流设计软件流程。  
该方法显著提升了AI生成内容在设计实践中的可用性和协作效率。</td></tr>
<tr><td>2025-08-23</td><td>Align 3D Representation and Text Embedding for 3D Content Personalization</td><td>[2508.16932](http://arxiv.org/pdf/2508.16932)</td><td>该论文提出了一种名为Invert3D的新型框架，旨在解决3D内容高效个性化这一关键挑战。其核心贡献与创新点如下：

◆ 提出了一个将3D表示与文本嵌入空间对齐的创新框架，弥合了2D视觉-语言模型与3D内容之间的鸿沟。
◆ 设计了一种以相机为条件的3D到文本逆向映射机制，能够将3D内容投影到与文本嵌入对齐的3D嵌入空间中。
◆ 实现了通过自然语言提示直接对3D内容进行操作和个性化定制，无需依赖基于知识蒸馏的繁琐重训练过程。
◆ 显著提升了3D内容个性化的效率，避免了现有方法计算成本高昂的再训练需求。
◆ 通过大量实验验证了该方法的有效性，为3D生成领域提供了更便捷的个性化解决方案。</td></tr>
<tr><td>2025-08-20</td><td>GOGS: High-Fidelity Geometry and Relighting for Glossy Objects via Gaussian Surfels</td><td>[2508.14563](http://arxiv.org/pdf/2508.14563)</td><td>GOGS提出了一种基于二维高斯面元的新型两阶段框架，旨在解决高光物体逆向渲染中的几何噪声和重光照不真实问题。其核心创新点包括：
◆ 采用基于物理渲染的分裂和近似法，并结合基础模型的几何先验，实现了鲁棒的表面重建，有效减少了多视图不一致导致的结构瑕疵。
◆ 利用蒙特卡洛重要性采样完整渲染方程进行材质分解，通过可微分的二维高斯光线追踪模拟间接光照，提升了光照计算的准确性。
◆ 引入基于球形mipmap的方向编码来细化高频镜面细节，能够有效捕捉各向异性高光，从而在复杂光照下生成逼真的重光照效果。
该框架在几何重建、材质分离和新光照重光照方面均实现了最先进的性能，显著超越了现有的逆向渲染方法。</td></tr>
<tr><td>2025-08-19</td><td>Is-NeRF: In-scattering Neural Radiance Field for Blurred Images</td><td>[2508.13808](http://arxiv.org/pdf/2508.13808)</td><td>Is-NeRF的核心贡献是提出了一种新颖的散射感知神经辐射场，用于从运动模糊图像中恢复清晰的三维场景。其创新点主要体现在以下四个方面：

◆ 提出了一个创新的内散射表示模型，统一了现实世界中六种常见的光线传播现象，从根本上改变了传统NeRF的直线体渲染方式。
◆ 建立了一个全新的、可适应复杂光路的散射感知体渲染管线，有效解决了传统方法因几何模糊导致的训练歧义问题。
◆ 引入了一种自适应学习策略，该策略能自主确定散射方向和采样间隔，从而捕捉到更精细的物体几何细节。
◆ 实现了对NeRF参数、散射参数和相机运动的联合优化，首次实现了仅从模糊图像中就能恢复出高保真场景表示和精确几何细节。</td></tr>
<tr><td>2025-08-17</td><td>PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism</td><td>[2508.13228](http://arxiv.org/pdf/2508.13228)</td><td>PreSem-Surf是一种基于神经辐射场（NeRF）的优化方法，旨在从RGB-D序列快速重建高质量场景表面。其核心贡献在于融合了颜色、深度和语义信息以全面提升重建性能。

◆ 提出了一种新颖的SG-MLP采样结构，结合PR-MLP（预条件多层感知机）进行体素预渲染，使模型能更早捕获场景信息并更好地区分噪声与局部细节。
◆ 采用了渐进式语义建模策略，通过逐步提取更精细的语义信息来增强场景理解，同时有效减少了模型训练所需时间。
实验结果表明，该方法在C-L1、F-score和IoU多项指标上达到最优，并在其他指标上保持竞争力，证明了其高效性和实用价值。</td></tr>
<tr><td>2025-08-16</td><td>RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis</td><td>[2508.12163](http://arxiv.org/pdf/2508.12163)</td><td>◆ 提出RealTalk框架，首次实现高情感准确度、强情感可控性和稳定身份保持的拟真说话头部合成。  
◆ 创新采用变分自编码器（VAE）从音频生成3D面部标志点，结合ResNet标志点变形模型（LDM）融合情感标签嵌入，精准控制表情。  
◆ 设计新型三平面注意力神经辐射场（NeRF），通过标志点和面部混合形状系数联合建模，显著提升合成图像的逼真度。  
◆ 引入情感标签嵌入机制，突破传统方法对情感表达控制的局限性，支持细粒度情感调节。  
◆ 通过大量实验验证，在情感准确性、可控性和身份保持等核心指标上全面超越现有技术，推动社交智能AI发展。</td></tr>
<tr><td>2025-08-22</td><td>A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation</td><td>[2508.09977](http://arxiv.org/pdf/2508.09977)</td><td>◆ 该论文首次系统综述了3D高斯泼溅（3DGS）技术在分割、编辑和生成等应用领域的最新进展，填补了该领域的调研空白。  
◆ 通过引入2D基础模型与NeRF方法的对比分析，揭示了3DGS在语义理解和几何控制方面的独特优势，突出了其显式紧凑表示的潜力。  
◆ 创新性地将3DGS应用划分为分割、编辑、生成等功能任务，并总结了各类任务的代表性方法、监督策略和学习范式，提炼出通用设计原则。  
◆ 提供了公开数据集和评估协议的详细总结，并对现有方法在公共基准上的表现进行了横向对比分析，为后续研究提供参考框架。  
◆ 建立了持续更新的开源资源库（GitHub），整合了相关论文、代码和工具，推动3DGS应用生态的协同发展。  
◆ 通过跨领域趋势分析，指出3DGS在实时渲染与语义操作结合方向的发展前景，为未来研究指明潜在突破点。</td></tr>
<tr><td>2025-08-13</td><td>Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision</td><td>[2508.09681](http://arxiv.org/pdf/2508.09681)</td><td>◆ 提出了一种基于可逆神经辐射场（InvNeRF）的新型测试时优化（TTO）框架，用于手术场景中的长期3D点跟踪，解决了现有方法在一致性运动或3D跟踪上的局限性。  
◆ 通过渲染监督像素对应关系，利用双向可变形-规范映射策略，有效处理定义的工作空间并优化光线密度，提升了跟踪精度。  
◆ 设计了多尺度HexPlanes结构，显著加速推理过程，同时提出高效像素采样和收敛准则算法，优化计算效率。  
◆ 在2D点跟踪任务中，平均精度比现有TTO方法提升近50%，并与非TTO方法竞争；在3D点跟踪中首次实现TTO框架，性能超越前馈方法。  
◆ 结合可变形NeRF重建优势，支持2D和3D跟踪一体化，并在STIR和SCARE数据集上验证了其有效性与运动学数据整合能力。</td></tr>
<tr><td>2025-08-12</td><td>MonoPartNeRF:Human Reconstruction from Monocular Video via Part-Based Neural Radiance Fields</td><td>[2508.08798](http://arxiv.org/pdf/2508.08798)</td><td>◆ 提出MonoPartNeRF框架，首次将基于分区的神经辐射场（NeRF）应用于单目视频人体重建，解决了复杂姿态下边界过渡不自然和遮挡区域重建不准的难题。  
◆ 设计双向变形模型，结合刚性与非刚性变换，建立观察空间与规范空间的可逆连续映射，通过参数化表面-时间空间（u, v, t）更精准捕捉非刚性运动。  
◆ 引入一致性损失函数，有效抑制变形导致的伪影和断裂问题，提升重建的几何连贯性。  
◆ 创新提出分区姿态嵌入机制，将全局姿态向量分解为局部关节嵌入，结合三轴方向的关键帧姿态检索与插值，实现精准的姿势感知特征采样。  
◆ 集成可学习的外观编码与注意力机制，动态建模纹理变化，显著提升复杂遮挡下的纹理保真度。实验在ZJU-MoCap和MonoCap数据集上验证了其在姿态适应性与遮挡恢复方面的优越性。</td></tr>
<tr><td>2025-08-11</td><td>SAGOnline: Segment Any Gaussians Online</td><td>[2508.08219](http://arxiv.org/pdf/2508.08219)</td><td>SAGOnline论文的核心贡献和创新点如下：

◆ 提出首个轻量级零样本框架SAGOnline，实现高斯场景的实时3D分割，解决了现有方法计算成本高、空间推理能力有限的问题。

◆ 采用解耦策略整合视频基础模型（如SAM2），通过合成视图间的2D掩码传播实现跨视角一致性分割。

◆ 开发GPU加速的3D掩码生成算法，通过高斯级实例标注为3D图元分配唯一ID，支持无损多目标跟踪与跨视角分割。

◆ 在NVOS（92.7% mIoU）和Spin-NeRF（95.2% mIoU）基准测试中达到SOTA性能，推理速度比现有方法快15-1500倍（27毫秒/帧）。

◆ 创新性将2D视频基础模型适配到3D领域，首次实现复杂场景中稳健的多目标分割与跟踪。

◆ 通过显式标注高斯图元，同时支持分割与跟踪功能，为AR/VR和机器人应用提供实时3D场景理解新方案。</td></tr>
<tr><td>2025-08-10</td><td>3D Gaussian Representations with Motion Trajectory Field for Dynamic Scene Reconstruction</td><td>[2508.07182](http://arxiv.org/pdf/2508.07182)</td><td>◆ 提出结合3D高斯泼溅与运动轨迹场的新方法，首次实现动态场景中复杂运动的精确建模与物理合理轨迹生成。  
◆ 通过动态物体与静态背景解耦技术，显著提升运动轨迹场的优化效率与场景表示紧凑性。  
◆ 创新采用时间不变运动系数和共享运动轨迹基，在捕捉复杂运动模式的同时大幅降低优化复杂度。  
◆ 实现单目视频中动态场景的高质量新视角合成与运动轨迹重建双突破，性能达到当前最优水平。  
◆ 所提方法为机器人等应用场景提供了首个能同时处理动态渲染与运动推理的统一框架。  
◆ 通过大量实验验证了方案在运动细节还原和物理合理性方面超越现有动态NeRF与3DGS方法的优势。</td></tr>
<tr><td>2025-08-08</td><td>CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition</td><td>[2508.06632](http://arxiv.org/pdf/2508.06632)</td><td>◆ 提出动态系数分解框架CoDe-NeRF，将复杂外观解耦为静态神经基底（编码材质属性）和动态系数（由视角/光照条件生成），突破传统NeRF对镜面反射建模的局限。  
◆ 设计系数网络（Coefficient Network）动态生成与视角/光照相关的系数，配合静态基底实现高效的光-物理解耦，避免逆向渲染的不稳定性。  
◆ 引入动态辐射积分器（Dynamic Radiance Integrator）自适应融合静态基底与动态系数，显著提升高光与镜面反射的锐利度和真实感。  
◆ 实验证明该方法在复杂反射场景中优于现有技术，能生成更清晰的镜面效果，且无需依赖物理逆向渲染的强假设。  
◆ 为神经场景表示中的复杂外观建模提供了灵活可扩展的新范式，通过解耦式设计增强了对动态光照条件的适应性。</td></tr>
<tr><td>2025-08-08</td><td>UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting</td><td>[2508.06169](http://arxiv.org/pdf/2508.06169)</td><td>这篇论文的核心贡献是通过改进3D高斯泼溅技术（3DGS）实现了高精度的水下三维重建，解决了传统方法因水下光线吸收、散射和浑浊度导致的几何与色彩失真问题。主要创新点包括：

◆ 提出可插拔的学习型水下成像模块，采用基于体素的回归方法模拟空间变化的衰减和背散射效应，提升颜色保真度。

◆ 设计了物理感知不确定性剪枝（PAUP）分支，通过不确定性评分自适应剔除噪声高斯点，显著减少浮游伪影（降低约65%）。

◆ 构建了端到端训练框架，同步优化高斯点参数与水下物理模型参数，实现几何与光传输的联合建模。

◆ 在渲染阶段生成两种输出：去除介质影响的纯净未衰减辐射图像（URI）和包含真实光传输效果的水下图像（UWI）。

实验表明，该方法在SeaThru-NeRF和UWBundle数据集上达到PSNR 27.604、SSIM 0.868、LPIPS 0.104的指标，性能优于现有技术。</td></tr>
<tr><td>2025-08-08</td><td>Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation</td><td>[2508.06136](http://arxiv.org/pdf/2508.06136)</td><td>◆ 提出首个基于显式3D眼球结构的视线重定向框架，突破传统神经辐射场（NeRF）隐式表示的局限。  
◆ 采用3D高斯泼溅（3DGS）技术精确建模眼球，通过显式旋转和平移控制视线方向，提升物理合理性。  
◆ 创新性设计自适应形变模块，模拟眼部周围肌肉的细微运动，增强生成图像的动态真实感。  
◆ 在ETH-XGaze数据集上验证，生成图像的光影、纹理质量显著优于现有方法，且视线估计精度更高。  
◆ 框架支持多样化新视线生成，为虚拟现实、人机交互等场景提供高保真眼部运动合成方案。</td></tr>
<tr><td>2025-08-07</td><td>MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses</td><td>[2508.05819](http://arxiv.org/pdf/2508.05819)</td><td>◆ 提出首个原生支持多缩放图像集的NeRF框架MZEN，解决了工业检测中高精度细节重建的难题。  
◆ 创新性地在针孔相机模型中引入可学习的缩放标量，动态调整焦距以适应不同缩放级别的图像。  
◆ 设计分层位姿优化策略：先通过广角图像建立全局坐标系，再通过缩放一致裁剪匹配方法将放大图像与最近广角图像对齐，最后联合优化。  
◆ 在合成TCAD模型、真实SEM微结构等8个场景中验证有效性，PSNR提升最高达28%，SSIM提升10%，LPIPS降低222%。  
◆ 突破传统NeRF在多缩放场景下的限制，首次实现全局精度与微米级细节的协同捕捉，推动NeRF在工业检测领域的实际应用。</td></tr>
<tr><td>2025-08-07</td><td>Refining Gaussian Splatting: A Volumetric Densification Approach</td><td>[2508.05187](http://arxiv.org/pdf/2508.05187)</td><td>◆ 提出基于惯性体积的新型密度控制方法，利用高斯函数的惯性体积指导3D高斯分布的精细化过程，改进原始3DGS的密度控制策略。  
◆ 系统研究了传统运动恢复结构(SfM)与深度图像匹配(DIM)两种点云初始化方法对重建质量的影响，为初始化选择提供依据。  
◆ 在Mip-NeRF 360数据集上的实验表明，该方法在重建质量上优于原始3DGS，在不同场景中均表现出色。  
◆ 解决了原始3DGS自适应密度控制(ADC)在点基元管理上的关键缺陷，提升了新视角合成的效果。  
◆ 通过更精细的密度控制策略，实现了对高斯分布更合理的分裂与剪枝操作，优化了场景表示。</td></tr>
<tr><td>2025-08-07</td><td>A Study of the Framework and Real-World Applications of Language Embedding for 3D Scene Understanding</td><td>[2508.05064](http://arxiv.org/pdf/2508.05064)</td><td>◆ 首次系统综述了语言嵌入与3D高斯泼溅（Gaussian Splatting）结合的跨领域研究，填补了该新兴交叉领域的空白。  
◆ 提出语言引导的3D场景理解新范式，通过大语言模型（LLMs）实现文本条件生成、编辑和语义理解，扩展了高斯泼溅的应用场景。  
◆ 详细分析了语言与3D高斯表征融合的理论基础和技术路径，包括嵌入策略、语义对齐方法及实时渲染优化方案。  
◆ 总结了实际应用中的关键挑战，如计算效率瓶颈、泛化性不足及语义标注数据稀缺，为后续研究指明方向。  
◆ 梳理了机器人、交互内容创作等领域的落地案例，验证了语言增强型3D建模的实用价值。</td></tr>
<tr><td>2025-08-07</td><td>Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research</td><td>[2508.04326](http://arxiv.org/pdf/2508.04326)</td><td>◆ 系统梳理了365篇辐射场（RF）相关文献，首次全面分析RF技术在XR领域的应用潜力与研究现状，填补了该领域的调研空白。  
◆ 提出三维分析框架：从XR应用愿景（i）、现有技术实现（ii）和研究缺口（iii）三个维度解构RF与XR的交叉研究，为后续研究提供结构化视角。  
◆ 筛选66篇核心论文进行深度分析，揭示RF在XR中的具体技术路径（如3DGS/NeRF的交互性优化），比传统综述更具技术颗粒度。  
◆ 将XR特异性研究问题（如实时渲染、用户交互）嵌入广义RF研究版图，明确XR社区的独特技术挑战与机遇。  
◆ 构建跨学科文献资源库，覆盖计算机视觉、图形学、人机交互等6大领域，助力研究者快速定位XR相关RF技术进展。  
◆ 通过量化分析指出RF在XR领域的研究稀疏性，推动学界关注这一潜力巨大的交叉方向。</td></tr>
<tr><td>2025-08-06</td><td>MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction</td><td>[2508.04297](http://arxiv.org/pdf/2508.04297)</td><td>◆ 提出MuGS方法，首次将多基线设置（包括稀疏视角下的小/大基线）统一整合到基于高斯泼溅的泛化性新视角合成框架中。  
◆ 创新性地融合多视角立体视觉（MVS）与单目深度估计（MDE）特征，增强跨场景的泛化重建能力。  
◆ 设计投影-采样机制的深度融合模块，通过精细概率体积构建指导特征图回归，提升几何精度。  
◆ 引入参考视图损失函数，显著优化几何一致性并加速训练收敛效率。  
◆ 采用3D高斯表征实现训练/推理加速，同时保持优于神经辐射场的渲染质量。  
◆ 在DTU简单物体到RealEstate10K复杂场景的跨数据集测试中达到SOTA，并在LLFF等数据集展现零样本迁移潜力。</td></tr>
<tr><td>2025-08-04</td><td>GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing</td><td>[2508.02831](http://arxiv.org/pdf/2508.02831)</td><td>◆ 提出GENIE混合模型，结合NeRF的高质量渲染与高斯泼溅(GS)的可编辑性，实现既逼真又可交互的3D场景表示。  
◆ 采用可训练特征嵌入替代传统球谐函数，通过每个高斯点附近的k近邻条件化NeRF网络，增强局部编辑能力。  
◆ 设计RT-GPS（光线追踪高斯邻近搜索）算法，基于改进的光线追踪管线快速定位最近高斯点，提升查询效率。  
◆ 引入多分辨率哈希网格初始化与更新高斯特征，支持动态场景的实时特征调整。  
◆ 实现实时局部感知编辑：高斯基元的位置或属性修改能即时影响渲染结果，保留NeRF的连续性优势。  
◆ 弥合隐式神经渲染与显式几何编辑的鸿沟，兼容物理模拟，为交互式创作提供新范式。</td></tr>
<tr><td>2025-08-04</td><td>ASDR: Exploiting Adaptive Sampling and Data Reuse for CIM-based Instant Neural Rendering</td><td>[2508.02304](http://arxiv.org/pdf/2508.02304)</td><td>◆ 提出ASDR算法-架构协同设计方法，首次将存内计算(CIM)技术应用于即时神经渲染领域，解决传统方案延迟高、能效差的问题。  
◆ 算法层面创新性地引入动态采样策略，通过实时感知像素渲染难度自适应调整采样点，显著减少内存访问和计算开销。  
◆ 提出颜色与密度体渲染解耦近似方法，通过分离MLP计算流程降低神经网络计算负荷，实现计算效率提升。  
◆ 架构层面设计新型ReRAM存算架构，创新性地开发数据映射与重用微架构，优化内存访问模式以匹配渲染特性。  
◆ 实验验证取得突破性性能：相比先进NeRF加速器和Xavier NX GPU分别实现9.55倍和69.75倍加速，仅损失0.1 PSNR画质。  
◆ 整体方案首次在CIM硬件上实现高质量实时神经渲染，为低功耗即时图形生成提供新范式。</td></tr>
<tr><td>2025-08-01</td><td>Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF</td><td>[2508.00967](http://arxiv.org/pdf/2508.00967)</td><td>◆提出了一种基于联邦学习和扩散模型的多无人机协同感知框架，解决了计算资源受限和低带宽通信下的实时3D场景重建难题。  
◆创新性地将扩散模型与NeRF结合，通过联邦学习实现多智能体联合场景合成，同时保护数据隐私并保持系统可扩展性。  
◆采用轻量级YOLOv12进行语义提取，配合局部NeRF更新策略，显著降低了计算和通信开销。  
◆设计了语义感知压缩协议，优化了无人机间的数据传输效率，提升了协同场景理解能力。  
◆重新设计了生成式扩散模型架构，使其更适合多视角联合场景重建任务，突破了传统方法的局限性。  
◆通过仿真和真实无人机测试验证了方案的可行性，为自主系统多智能体AI提供了突破性进展。</td></tr>
<tr><td>2025-07-31</td><td>NeRF Is a Valuable Assistant for 3D Gaussian Splatting</td><td>[2507.23374](http://arxiv.org/pdf/2507.23374)</td><td>◆ 提出NeRF-GS框架，首次联合优化神经辐射场（NeRF）与3D高斯泼溅（3DGS），实现两种技术的优势互补。  
◆ 利用NeRF的连续空间表征能力，有效解决3DGS对高斯初始化敏感、空间感知弱、高斯间关联性不足等固有缺陷。  
◆ 通过渐进式对齐3DGS与NeRF的空间特征，使两者能基于共享的3D空间信息在同一场景中协同优化。  
◆ 创新性地优化隐式特征与高斯位置的残差向量，弥合两种方法的理论差异，增强3DGS的个性化建模能力。  
◆ 在基准数据集上实现最先进性能，验证了NeRF与3DGS的互补性而非竞争关系，为混合表征方法提供新思路。  
◆ 为结合显式（3DGS）与隐式（NeRF）表示的3D场景高效建模开辟了新方向。</td></tr>
<tr><td>2025-07-30</td><td>Adaptive Time-step Training for Enhancing Spike-Based Neural Radiance Fields</td><td>[2507.23033](http://arxiv.org/pdf/2507.23033)</td><td>◆ 提出了一种基于脉冲神经网络的动态时间步训练策略（PATA），首次将SNN的节能特性与NeRF的高质量渲染能力相结合。  
◆ 通过预训练-自适应时间步调整机制，自动优化渲染质量与时间步长的平衡，解决了传统NeRF依赖密集采样导致的资源消耗问题。  
◆ 实现了场景自适应的动态推理，可根据不同场景的尺度和纹理复杂度灵活调整时间步，显著减少计算开销。  
◆ 在保持Instant-NGP架构优势的基础上，实验证明PATA能减少64%的推理时间步和61.55%的运行功耗，同时维持渲染精度。  
◆ 为边缘计算等资源受限场景提供了高效的神经渲染解决方案，扩展了NeRF技术的应用边界。</td></tr>
<tr><td>2025-07-28</td><td>DEM-NeRF: A Neuro-Symbolic Method for Scientific Discovery through Physics-Informed Simulation</td><td>[2507.21350](http://arxiv.org/pdf/2507.21350)</td><td>◆ 提出了一种新型神经符号框架DEM-NeRF，直接从稀疏多视角图像序列重建和模拟弹性物体，无需显式几何信息。  
◆ 创新性地将神经辐射场（NeRF）与物理信息神经网络（PINN）结合，同时利用图像监督和弹性力学偏微分方程的物理约束。  
◆ 通过能量约束的PINN架构处理复杂边界和初始条件，替代传统有限元或边界元方法，提升模拟精度。  
◆ 实现了时空变形物体的联合表征学习，弥合了纯数据驱动方法与传统数值模拟之间的鸿沟。  
◆ 增强了结果的可解释性，为科学发现提供兼具数据适应性与物理一致性的新工具。  
◆ 解决了高保真仿真计算成本高的问题，仅需稀疏观测数据即可完成物理规律建模。</td></tr>
<tr><td>2025-07-27</td><td>NeuroVoxel-LM: Language-Aligned 3D Perception via Dynamic Voxelization and Meta-Embedding</td><td>[2507.20110](http://arxiv.org/pdf/2507.20110)</td><td>◆ NeuroVoxel-LM提出了一种结合神经辐射场（NeRF）的动态体素化与轻量级元嵌入的新框架，解决了现有3D语言模型处理稀疏大规模点云时效率低和表示精度不足的问题。  
◆ 创新性地设计了动态分辨率多尺度体素化（DR-MSV）技术，根据几何和结构复杂度自适应调整体素粒度，在降低计算成本的同时保持重建保真度。  
◆ 提出了基于注意力加权和残差融合的轻量级元嵌入机制（TAP-LME），通过令牌级自适应池化增强语义表示能力，优于传统最大池化方法。  
◆ DR-MSV显著提升了点云特征提取的效率和精度，尤其适用于大范围复杂场景的快速处理。  
◆ TAP-LME机制能够从NeRF权重中捕获细粒度语义信息，为语言驱动的3D感知任务提供了更丰富的特征表示。  
◆ 实验结果表明，该框架在3D场景理解任务中实现了性能突破，为语言对齐的3D感知研究开辟了新方向。</td></tr>
<tr><td>2025-07-25</td><td>DINO-SLAM: DINO-informed RGB-D SLAM for Neural Implicit and Explicit Representations</td><td>[2507.19474](http://arxiv.org/pdf/2507.19474)</td><td>◆ 提出DINO-SLAM框架，通过DINO特征增强神经隐式（NeRF）和显式（3DGS）SLAM系统的场景表示能力。  
◆ 设计场景结构编码器（SSE），将原始DINO特征升级为增强版EDINO，有效捕捉场景层次结构和元素间关系。  
◆ 开发两种基于EDINO的SLAM范式，分别针对NeRF和3DGS实现端到端优化，提升系统鲁棒性。  
◆ 在Replica、ScanNet和TUM数据集上验证性能，超越现有最优方法，证明通用场景适应能力。  
◆ 首次将DINO语义先验与几何重建结合，为动态/弱纹理场景提供更全面的表示方案。</td></tr>
<tr><td>2025-07-25</td><td>Fast Learning of Non-Cooperative Spacecraft 3D Models through Primitive Initialization</td><td>[2507.19459](http://arxiv.org/pdf/2507.19459)</td><td>◆ 提出基于CNN的3D高斯泼溅（3DGS）初始化方法，仅需单目图像即可生成粗糙3D模型和目标姿态，解决了传统方法依赖多视角精确姿态的问题。  
◆ 开发支持噪声或隐式姿态估计的训练流程，突破NeRF/3DGS在太空场景中必须依赖精确姿态的限制。  
◆ 通过分析不同初始化变体，显著降低高精度3D模型的训练成本，所需训练迭代次数和输入图像数量减少至少一个数量级。  
◆ CNN模块集成多种姿态估计技术变体，为不同应用场景提供灵活性，并在噪声姿态条件下验证了有效性。  
◆ 实验证明即使使用不完美的姿态监督，该框架仍能学习高保真3D表示，为太空应用中的新视角合成技术铺平道路。</td></tr>
<tr><td>2025-07-25</td><td>NerT-CA: Efficient Dynamic Reconstruction from Sparse-view X-ray Coronary Angiography</td><td>[2507.19328](http://arxiv.org/pdf/2507.19328)</td><td>◆ NerT-CA提出了一种混合神经张量表示方法，结合神经场与张量场优势，显著提升稀疏视角X射线冠状动脉造影（CA）的动态4D重建效率。  
◆ 通过将CA场景分解为低秩静态成分（张量场）与动态稀疏成分（神经场），解决了传统方法依赖MLP导致训练耗时过长的问题。  
◆ 该方法在仅需3个造影视角下即可实现高质量重建，突破了稀疏视图重建的临床实用性瓶颈。  
◆ 创新性地利用低秩先验加速静态背景建模，同时保留神经场对血管动态细节的捕捉能力，兼顾速度与精度。  
◆ 在4D仿真数据集上定量与定性验证显示，其训练速度与重建精度均超越现有NeRF-based方法，为临床实时应用提供可能。</td></tr>
<tr><td>2025-07-24</td><td>SaLF: Sparse Local Fields for Multi-Sensor Rendering in Real-Time</td><td>[2507.18713](http://arxiv.org/pdf/2507.18713)</td><td>◆ 提出SaLF（稀疏局部场）新型体素表示方法，将场景表示为稀疏3D体素集合，每个体素包含局部隐式场，兼具栅格化和光线追踪能力。  
◆ 突破现有技术限制，首次实现同时支持非针孔相机和旋转激光雷达的高效渲染（相机50+ FPS，LiDAR 600+ FPS）。  
◆ 采用自适应剪枝与致密化策略，无需预处理即可动态优化大场景表示，显著提升可扩展性。  
◆ 解耦场景表示与渲染流程，支持多种传感器统一框架，克服了NeRF和3D高斯泼溅的互操作性缺陷。  
◆ 实现快速训练（&lt;30分钟）与实时渲染，在保持自动驾驶传感器仿真真实性的同时，效率远超传统NeRF方法。  
◆ 为多传感器自动驾驶测试提供首个兼顾高保真度与高效率的仿真方案，推动规模化虚拟测试发展。</td></tr>
<tr><td>2025-07-24</td><td>High-fidelity 3D Gaussian Inpainting: preserving multi-view consistency and photorealistic details</td><td>[2507.18023](http://arxiv.org/pdf/2507.18023)</td><td>◆ 提出首个基于3D高斯泼溅(3DGS)的高保真三维修复框架，通过稀疏修复视图重建完整三维场景  
◆ 设计自动掩膜优化流程，结合高斯场景过滤与反向投影技术，精准定位遮挡区域并实现逼真边界修复  
◆ 创新性开发区域级不确定性引导优化策略，通过多视角重要性评估缓解视角不一致问题  
◆ 实现细粒度优化机制，显著提升修复结果中高频细节的保真度与真实感  
◆ 在多样化数据集上的实验表明，本方法在视觉质量和多视角一致性方面均超越现有最优技术  
该工作解决了三维场景修复中视角不一致和细节失真的核心难题，为三维内容创作提供了新工具。</td></tr>
<tr><td>2025-07-23</td><td>Exploring Active Learning for Label-Efficient Training of Semantic Neural Radiance Field</td><td>[2507.17351](http://arxiv.org/pdf/2507.17351)</td><td>这篇论文的核心贡献和创新点如下：

◆ 提出将主动学习应用于语义神经辐射场（NeRF）的训练，以降低像素级标注的高成本。  
◆ 研究了语义NeRF主动学习中的关键设计选择，包括选择粒度和选择策略。  
◆ 创新性地提出了一种考虑3D几何约束的样本选择策略，提升了主动学习的效果。  
◆ 通过实验证明，该方法能显著减少语义NeRF训练的标注成本，相比随机采样可降低2倍以上。  
◆ 为语义场景理解的隐式神经表示提供了一种更高效的训练范式。  
◆ 首次系统探索了主动学习在3D语义神经表示领域的应用潜力。</td></tr>
<tr><td>2025-07-22</td><td>Sparse-View 3D Reconstruction: Recent Advances and Open Challenges</td><td>[2507.16406](http://arxiv.org/pdf/2507.16406)</td><td>◆ 该论文首次将稀疏视角3D重建领域的几何方法、神经隐式模型（如NeRF）和生成式方法（如扩散模型）纳入统一框架进行系统综述。  
◆ 深入分析了稀疏场景下几何正则化、显式形状建模和生成推理如何解决浮游伪影和位姿模糊等关键问题。  
◆ 对比了3D高斯泼溅等显式点云方法与神经隐式方法在精度、效率和泛化性方面的权衡关系。  
◆ 提出当前领域尚未解决的挑战，包括跨域泛化能力和无位姿约束的重建问题，为未来研究指明方向。  
◆ 特别强调视觉基础模型（VFMs）和3D原生生成先验在稀疏重建中的创新应用潜力。  
◆ 区别于以往综述，本文首次系统梳理了扩散模型与神经隐式方法的融合框架及其在稀疏数据下的优势。</td></tr>
<tr><td>2025-07-19</td><td>DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF</td><td>[2507.14596](http://arxiv.org/pdf/2507.14596)</td><td>◆ DiSCO-3D首次提出3D开放词汇子概念发现任务，结合场景内容和用户查询需求，实现更灵活的3D语义分割。  
◆ 该方法基于神经场表示，将无监督分割与弱开放词汇指导相结合，突破了传统方法仅适应单一任务或场景的限制。  
◆ 通过开放词汇查询，DiSCO-3D能够动态发现并分割子概念，适应多样化的用户需求。  
◆ 在开放词汇和无监督分割的边缘案例中，DiSCO-3D表现出最先进的性能，验证了其泛化能力。  
◆ 该方法为机器人、自动驾驶等应用提供了更高层次的场景理解能力，具有广泛的应用潜力。</td></tr>
<tr><td>2025-07-19</td><td>Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey</td><td>[2507.14501](http://arxiv.org/pdf/2507.14501)</td><td>◆ 系统梳理了基于前馈式深度学习的3D重建与视图合成技术，提出按表示架构（如点云、3D高斯泼溅、神经辐射场等）的分类体系。  
◆ 重点分析了无姿态重建、动态3D重建、3D感知图像/视频合成等关键任务，拓展了在数字人、SLAM等领域的应用场景。  
◆ 对比传统迭代优化方法，突显前馈方法在计算效率与泛化能力上的突破，推动AR/VR等实时应用落地。  
◆ 首次整合该领域常用数据集与评估协议，为不同下游任务提供标准化评测基准。  
◆ 指出动态场景建模、跨模态生成等开放挑战，为未来研究指明方向。</td></tr>
<tr><td>2025-07-18</td><td>TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views</td><td>[2507.13929](http://arxiv.org/pdf/2507.13929)</td><td>◆ TimeNeRF提出了一种通用神经渲染方法，能够在少量输入视图下渲染任意视角和任意时间点的新视图，解决了多视图采集成本高和场景重复优化效率低的问题。  
◆ 该方法首次探索了NeRF在时序3D场景建模中的潜力，填补了当前技术在该领域的空白，尤其适用于元宇宙中昼夜自然过渡的沉浸式体验需求。  
◆ 结合多视图立体视觉、神经辐射场和跨数据集解耦策略，构建了隐式内容辐射场，实现了场景表示和时间维度建模的统一框架。  
◆ 无需逐场景优化即可在少样本条件下生成新视图，显著提升了渲染效率，实验证明其能有效捕捉从黎明到黄昏的复杂自然场景变化。  
◆ 通过体渲染技术合成任意时间点的逼真新视图，在时间维度上实现了平滑过渡，为动态场景建模提供了新思路。</td></tr>
<tr><td>2025-07-18</td><td>EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation</td><td>[2507.13648](http://arxiv.org/pdf/2507.13648)</td><td>◆ 提出EPSilon框架，通过高效点采样策略显著提升基于混合表示（SMPL网格+NeRF）的3D虚拟人生成效率，兼顾生成质量与速度。  
◆ 创新性设计空射线剔除（ERO）方法，直接跳过空场景中的光线计算，减少无效采样点。  
◆ 提出空区间剔除（EIO）技术，进一步压缩光线采样区间，仅保留衣物或网格覆盖的有效区域。  
◆ 通过精细化采样策略，实现单阶段NeRF结构，无需传统分层采样，简化模型架构。  
◆ 实验表明，EPSilon仅需3.9%的采样点即可保持生成质量，推理速度提升约20倍，训练收敛加快4倍。</td></tr>
<tr><td>2025-07-16</td><td>DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi</td><td>[2507.12132](http://arxiv.org/pdf/2507.12132)</td><td>◆ 提出DoRF（多普勒辐射场）方法，首次将神经辐射场（NeRF）思想引入Wi-Fi传感领域，通过一维多普勒速度投影重建3D潜在运动表征。  
◆ 构建了统一的运动多普勒辐射场，提供活动全景视角，显著提升对环境变化的鲁棒性。  
◆ 利用Wi-Fi CSI提取的多普勒速度投影，克服了传统方法依赖环境特定特征的限制。  
◆ 所提3D潜在表征能有效捕捉人体活动时空特性，比现有2D方法更具判别力。  
◆ 实验证明该方法显著提高了跨环境、跨用户的泛化性能，推动Wi-Fi传感走向实用化。  
◆ 为无线感知开辟新思路，将计算机视觉中的体积渲染技术成功迁移至射频信号处理领域。</td></tr>
<tr><td>2025-07-16</td><td>HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing</td><td>[2507.11971](http://arxiv.org/pdf/2507.11971)</td><td>◆提出新型3D分层代理节点表示（HPR3D），通过物体表面及内部的稀疏层级树状代理节点网络统一表征形状与纹理，突破传统方法任务局限性的框架创新。  
◆每个代理节点采用轻量MLP隐式编码局部几何与纹理信息，结合邻近及父节点的高效神经插值解码机制，实现复杂性与保真度的动态平衡。  
◆层级结构天然支持语义对齐，用户可直接通过拖拽代理节点实现直观编辑，解决了NeRF结构模糊导致的操控难题。  
◆稀疏节点分布与分层查询机制显著降低数据复杂度（相比网格顶点密度和NeRF体素采样），同时保持亚毫米级重建精度。  
◆实验验证该表示在重建质量（PSNR提升2.1dB）、编辑效率（交互延迟&lt;10ms）和跨任务通用性（重建/生成/驱动）上的综合优势。</td></tr>
<tr><td>2025-07-14</td><td>VoxelRF: Voxelized Radiance Field for Fast Wireless Channel Modeling</td><td>[2507.09987](http://arxiv.org/pdf/2507.09987)</td><td>◆ 提出VoxelRF新型神经表示方法，通过体素化辐射场实现复杂环境中无线信道的快速建模，解决了传统方法在精度、效率和可扩展性上的平衡难题。  
◆ 用基于体素网格的三线性插值替代NeRF中昂贵的多层感知机（MLP），结合两个浅层MLP分别建模传播和发射端相关效应，显著降低计算成本。  
◆ 引入渐进式学习策略，逐步优化体素网格分辨率，加速训练过程并提升模型泛化能力。  
◆ 采用空区域跳过技术，避免对无信号区域的冗余计算，进一步提高推理效率。  
◆ 设计背景熵损失函数，增强模型对稀疏信号区域的建模能力，提升整体精度。  
实验表明，VoxelRF在有限训练数据下能以更低计算量达到竞争性精度，适用于实时和资源受限的无线通信场景。</td></tr>
<tr><td>2025-07-12</td><td>Stable Score Distillation</td><td>[2507.09168](http://arxiv.org/pdf/2507.09168)</td><td>◆ 提出稳定分数蒸馏（SSD）框架，通过将分类器锚定到源提示词，显著提升编辑过程的稳定性和对齐性。  
◆ 利用无分类器引导（CFG）方程实现跨提示词对齐，并通过引入恒定空文本分支稳定优化过程，避免冲突信号。  
◆ 设计提示词增强分支，专门强化风格转换等编辑任务的修改强度，提升编辑效果。  
◆ 在保持原始内容结构的同时，确保编辑轨迹与源提示词紧密对齐，实现局部精准编辑且不影响周围区域。  
◆ 在2D和3D编辑任务（如NeRF和文本驱动风格编辑）中达到最优效果，收敛更快且复杂度更低。</td></tr>
<tr><td>2025-07-11</td><td>From images to properties: a NeRF-driven framework for granular material parameter inversion</td><td>[2507.09005](http://arxiv.org/pdf/2507.09005)</td><td>◆ 提出了一种新颖的NeRF与MPM结合的框架，通过视觉观测反演颗粒材料参数，实现了从图像到物性参数的跨模态推理。  
◆ 利用NeRF从多视角初始图像重建高精度3D几何，克服了传统方法在复杂表面细节捕捉上的局限性，为MPM仿真提供准确初始条件。  
◆ 创新性地采用时序双固定相机图像作为观测数据，通过仿真渲染与真实图像的比对构建目标函数，实现纯视觉驱动的参数反演。  
◆ 引入贝叶斯优化高效搜索摩擦角参数，将反演误差控制在2度以内，验证了纯视觉反分析的可行性。  
◆ 该框架为无法直接测量物性的实际场景（如遥感、灾害评估）提供了非接触式材料表征新思路，具有重要应用价值。</td></tr>
<tr><td>2025-07-10</td><td>MUVOD: A Novel Multi-view Video Object Segmentation Dataset and A Benchmark for 3D Segmentation</td><td>[2507.07519](http://arxiv.org/pdf/2507.07519)</td><td>◆ 提出了MUVOD数据集，这是首个针对动态场景4D目标分割的大规模多视角视频数据集，填补了该领域数据集的空白。  
◆ 数据集包含17个真实场景，涵盖室内外多种活动，提供7830张RGB图像及对应的4D运动分割掩码，支持跨视角和跨帧的目标跟踪。  
◆ 数据集中包含459个实例，覆盖73个类别，为多视角视频分割方法提供了全面的基准测试平台。  
◆ 提出了新的评估指标和基线分割方法，为动态场景分割研究提供了标准化评估框架。  
◆ 基于MUVOD数据集构建了3D目标分割子集，包含50个不同场景下的标注对象，用于更全面地评估现有3D分割方法的性能。  
◆ 数据集来源多样，包含不同相机设备采集的视角（9-46个视角），增强了数据集的泛化性和实用性。</td></tr>
<tr><td>2025-07-14</td><td>BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields</td><td>[2507.06269](http://arxiv.org/pdf/2507.06269)</td><td>◆ 提出BayesSDF，首个针对神经隐式SDF模型的概率框架，解决3D几何不确定性量化问题，特别适用于科学模拟（如森林流体建模）。  
◆ 通过拉普拉斯近似和基于Hessian的局部表面稳定性度量，实现高效计算且几何感知的不确定性估计，克服传统方法计算效率低的问题。  
◆ 首次将几何一致性直接融入不确定性量化，生成与重建误差高度相关的校准化置信度地图，优于忽略几何的现有方法。  
◆ 证明SDF的连续可微几何特性比辐射场模型（如NeRF）更适合物理模拟，为下游任务（如机器人决策）提供可靠几何基础。  
◆ 在合成与真实数据集上验证了方法的优越性，其不确定性预测与重建缺陷高度吻合，校准性和几何一致性均超越现有技术。</td></tr>
<tr><td>2025-07-08</td><td>Reflections Unlock: Geometry-Aware Reflection Disentanglement in 3D Gaussian Splatting for Photorealistic Scenes Rendering</td><td>[2507.06103](http://arxiv.org/pdf/2507.06103)</td><td>◆ 提出Ref-Unlock框架，基于3D高斯泼溅（3DGS）实现几何感知的反射分离，首次在3DGS中显式解耦透射与反射成分，解决现有方法将反射误判为几何结构的问题。  
◆ 采用双分支表示结合高阶球谐函数，有效捕捉高频反射细节，同时通过反射移除模块提供伪无反射监督信号，实现更干净的反射分解。  
◆ 引入伪深度图与几何感知的双边平滑约束，增强3D几何一致性和分解稳定性，显著减少复杂场景下的表面伪影与模糊重建。  
◆ 支持基于视觉基础模型（VFMs）的灵活反射编辑功能，扩展了方法在实际应用中的可操作性。  
◆ 实验证明该方法大幅超越传统基于GS的反射处理方法，并与NeRF类模型性能相当，同时保持更高的计算效率。  
◆ 为含反射场景的光照真实渲染提供了高效且泛化性强的解决方案，代码已开源。</td></tr>
<tr><td>2025-07-08</td><td>DreamArt: Generating Interactable Articulated Objects from a Single Image</td><td>[2507.05763](http://arxiv.org/pdf/2507.05763)</td><td>◆ DreamArt首次提出从单张图像生成可交互的关节化3D物体的完整框架，填补了现有方法在部件分解和关节建模方面的空白。  
◆ 通过三阶段流程创新：结合图像生成3D、掩码提示的部件分割与修复，解决了单视角下部件形状不完整的问题。  
◆ 提出基于视频扩散模型的关节运动先验学习，利用部件遮罩和修复图像消除遮挡歧义，实现逼真关节运动生成。  
◆ 采用双四元数表示关节运动参数，配合全局纹理优化，确保多部件纹理一致性与高质量渲染效果。  
◆ 实验证明该方法能生成部件形状准确、外观逼真且关节运动合理的3D资产，为AR/VR和具身AI提供了可扩展的解决方案。</td></tr>
<tr><td>2025-07-06</td><td>A View-consistent Sampling Method for Regularized Training of Neural Radiance Fields</td><td>[2507.04408](http://arxiv.org/pdf/2507.04408)</td><td>◆ 提出基于视角一致分布的采样方法，替代传统固定深度值估计，用于NeRF的正则化训练。  
◆ 利用低层颜色特征和基础模型提取的高层特征，构建3D采样点在2D投影位置的视角一致性分布。  
◆ 通过从视角一致性分布中采样，实现对NeRF训练的隐式正则化，避免依赖误差较大的深度估计。  
◆ 结合深度推进损失（depth-pushing loss）与采样技术，共同消除训练中的失败模式。  
◆ 在公开数据集上的实验表明，该方法显著优于现有NeRF变体和深度正则化方法，尤其适用于户外无界场景。  
◆ 解决了传统深度估计方法需要昂贵3D监督和泛化性差的问题，提升了真实场景下的3D重建质量。</td></tr>
<tr><td>2025-07-02</td><td>Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation</td><td>[2507.01631](http://arxiv.org/pdf/2507.01631)</td><td>◆ 提出Snake-NeRF框架，首次实现单设备上大规模卫星影像的NeRF三维重建，突破传统方法受限于内存的小场景约束。  
◆ 设计外存（out-of-core）训练方法，无需同时加载所有图像和网络，显著降低硬件需求。  
◆ 创新性采用无重叠三维分块（3D tile）策略，将目标区域划分为独立训练的NeRF子模块。  
◆ 提出重叠裁剪图像技术，确保每个子模块训练时获取完整必要像素，避免边界信息缺失。  
◆ 开发2×2三维分块递进策略与分段采样器，有效消除分块边缘的三维重建误差。  
实验证明该方法在单GPU上实现线性时间复杂度，且不损失重建质量，为全球尺度地球观测提供新范式。</td></tr>
<tr><td>2025-07-01</td><td>Surgical Neural Radiance Fields from One Image</td><td>[2507.00969](http://arxiv.org/pdf/2507.00969)</td><td>◆ 提出了一种基于单张术中图像和术前MRI数据训练神经辐射场（NeRF）的新方法，解决了手术场景中多视角数据不足的限制。  
◆ 利用术前MRI数据预先定义相机视角和图像集，结合神经风格迁移技术（WTC2和STROTSS）将术中图像外观迁移至预构建数据集，避免过度风格化。  
◆ 实现了快速单图像NeRF训练，显著降低了术中数据采集的时间成本，提升了临床实用性。  
◆ 在四例神经外科手术案例中验证了方法的有效性，定量对比显示其合成结果与真实手术显微镜图像高度一致。  
◆ 重建结果与真实数据相比具有高结构相似性，证明了良好的重建质量和纹理保留能力。  
◆ 为手术场景中的实时3D重建和视角合成提供了可行方案，突破了传统多视角方法的局限性。</td></tr>
<tr><td>2025-07-01</td><td>PlantSegNeRF: A few-shot, cross-dataset method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching</td><td>[2507.00371](http://arxiv.org/pdf/2507.00371)</td><td>◆提出PlantSegNeRF方法，首次实现从多视角RGB图像序列直接生成高精度植物器官实例点云，突破传统点云分割技术的局限性。  
◆开发联合通道NeRF模型，同时渲染颜色、密度、语义和实例信息，构建包含多维度特征的隐式场景表示。  
◆设计创新的多视角实例匹配模块，通过2D实例分割结果跨视图关联同一器官的实例ID，解决复杂植物结构的对应难题。  
◆在语义分割任务中，关键指标（精确率、召回率等）平均提升16.1%-24.2%，显著优于现有最优方法。  
◆在实例分割任务中，四项核心指标（mPrec等）最高提升达38.2%，实现跨物种的高泛化性表现。  
◆为植物表型研究提供高通量三维数据生成方案，支持大规模植物模型开发。</td></tr>
<tr><td>2025-06-30</td><td>AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention</td><td>[2506.23611](http://arxiv.org/pdf/2506.23611)</td><td>◆ 提出AttentionGS框架，首次实现无需高质量初始点云的3D高斯泼溅重建，突破传统3DGS对SfM点云的强依赖。  
◆ 创新性引入两阶段注意力机制：几何注意力快速恢复场景全局结构，纹理注意力后期优化细粒度细节，实现从随机初始化直接重建。  
◆ 设计不透明度加权梯度策略，改进高斯分布致密化过程，显著提升表面重建质量。  
◆ 在纹理缺失和受限视角等极端场景下表现优异，相比现有方法重建质量提升显著。  
◆ 通过多基准数据集验证，为实际应用中更鲁棒的3D重建提供新思路，扩展了3DGS的应用边界。</td></tr>
<tr><td>2025-06-29</td><td>Dynamic View Synthesis from Small Camera Motion Videos</td><td>[2506.23153](http://arxiv.org/pdf/2506.23153)</td><td>这篇论文针对动态3D场景在小范围相机运动下的新视角合成问题提出了创新解决方案，核心贡献如下：

◆ 提出基于分布的深度正则化方法(DDR)，通过Gumbel-softmax从离散渲染权重分布中可微分采样，解决了传统深度损失仅计算期望误差的局限性。

◆ 引入物体边界前空间点体积密度趋近零的约束条件，确保场景几何结构的正确学习，有效改善了小相机运动下的几何表示问题。

◆ 开发了可视化工具，可直接在渲染权重层面观察场景几何表示，为方法原理提供了直观解释。

◆ 在训练过程中加入相机参数学习机制，增强了模型对相机参数的鲁棒性，解决了小运动下相机参数估计不准的问题。

论文通过大量实验证明，该方法在小范围相机运动输入下显著优于现有先进方法，为动态场景新视角合成提供了更实用的解决方案。</td></tr>
<tr><td>2025-06-27</td><td>UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields</td><td>[2506.21884](http://arxiv.org/pdf/2506.21884)</td><td>◆ 首次将光谱解混技术融入神经辐射场（NeRF），实现联合高光谱新视角合成与无监督材质分割，突破传统NeRF仅依赖RGB数据的局限。  
◆ 提出基于漫反射和镜面反射分量的光谱反射率建模方法，通过全局端元字典学习纯材质特征，结合逐点丰度分布实现材质精准表达。  
◆ 创新性地利用学习到的端元光谱特征进行无监督材质聚类，无需人工标注即可完成场景材质分割。  
◆ 支持通过修改端元字典实现场景材质编辑，为基于材质的灵活外观操控（如虚拟仿真、AR应用）提供新工具。  
◆ 实验证明该方法在高光谱重建和材质分割任务上显著优于现有技术，为机器人感知、虚拟现实等需精确材质建模的领域提供解决方案。</td></tr>
<tr><td>2025-06-24</td><td>ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes</td><td>[2506.21629](http://arxiv.org/pdf/2506.21629)</td><td>◆ 提出了一种无需SfM预处理的方法ICP-3DGS，通过结合迭代最近点（ICP）和基于优化的位姿细化，实现了大范围相机运动下的高精度位姿估计。  
◆ 引入基于体素的场景致密化策略，有效指导大规模无边界场景的3D高斯分布重建，解决了传统方法在户外场景中的扩展性问题。  
◆ 首次将ICP与3D高斯泼溅（3DGS）技术结合，在神经渲染框架中直接优化相机位姿，摆脱了对SfM先验数据的依赖。  
◆ 通过实验验证，该方法在室内外不同尺度场景中均优于现有技术，同时在相机位姿估计和新视角合成任务上表现更优。  
◆ 开源了完整代码，为后续研究提供了可复现的基础，推动了无约束场景神经渲染的实用化进程。</td></tr>
<tr><td>2025-06-26</td><td>PanSt3R: Multi-view Consistent Panoptic Segmentation</td><td>[2506.21348](http://arxiv.org/pdf/2506.21348)</td><td>◆ 提出PanSt3R方法，首次实现无需测试时优化的单次前向预测，直接联合输出3D几何和多视角全景分割结果，显著提升效率。  
◆ 基于MUSt3R框架改进，引入语义感知能力，将3D重建与多视角全景分割任务统一整合，克服传统方法依赖2D预分割的局限性。  
◆ 重新设计掩码后处理流程，提出更理论化的多视角分割融合策略，优化跨视角空间关系利用。  
◆ 结合3D高斯泼溅（3DGS）技术，提出简单有效的新视角生成方法，扩展模型应用场景。  
◆ 在多个基准测试中达到SOTA性能，速度比现有方法快数个数量级，兼具概念简洁性与计算高效性。</td></tr>
<tr><td>2025-06-25</td><td>Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects</td><td>[2506.20638](http://arxiv.org/pdf/2506.20638)</td><td>◆ 提出了一种联合优化方法，同时估计非合作空间物体的姿态（相机位姿）并利用神经辐射场（NeRF）进行3D重建，解决了传统方法在未知物体姿态下的重建难题。  
◆ 针对空间场景的特殊挑战（如单色图像、未知物体方向、有限视角、无漫反射光照等），改进了NeRF的适应性，使其在极端条件下仍能有效工作。  
◆ 实验证明，采用逐帧顺序训练图像的方式（而非批量训练）能显著提升3D重建的精度，为动态空间物体建模提供了新思路。  
◆ 通过优化均匀旋转参数估计相机姿态，并引入正则化约束相邻姿态的连续性，避免了位姿估计的突变问题。  
◆ 该方法为空间态势感知（SSA）任务提供了高精度的3D模型，可应用于主动碎片清除、在轨维护等实际场景。</td></tr>
<tr><td>2025-06-24</td><td>NeRF-based CBCT Reconstruction needs Normalization and Initialization</td><td>[2506.19742](http://arxiv.org/pdf/2506.19742)</td><td>◆ 提出归一化哈希编码器（Normalized Hash Encoder），解决NeRF-based CBCT重建中哈希编码器与神经网络的局部-全局训练不匹配问题，通过增强特征一致性提升训练稳定性。  
◆ 设计映射一致性初始化策略（MCI），利用预训练模型的全局映射特性初始化神经网络，减少早期训练波动，加速收敛并提高重建质量。  
◆ 首次系统分析了哈希编码器参数局部稀疏性与神经网络全局密集更新的矛盾，指出特征错位是导致训练不稳定的核心原因。  
◆ 方法仅需少量代码改动，即可在4个数据集、128例CT数据（涵盖7个解剖区域）上显著提升训练效率和重建性能。  
◆ 通过实验验证了归一化与初始化策略的协同作用，为NeRF-based医学影像重建提供了简单有效的优化范式。</td></tr>
<tr><td>2025-06-25</td><td>Self-Supervised Multimodal NeRF for Autonomous Driving</td><td>[2506.19615](http://arxiv.org/pdf/2506.19615)</td><td>◆ 提出自监督多模态NeRF框架NVSF，无需3D标注即可联合学习LiDAR和相机的时空隐式神经表示。  
◆ 针对自动驾驶场景设计，同时处理静态和动态环境，显著提升真实驾驶场景的适应性。  
◆ 引入启发式图像像素采样策略，优先选择信息丰富的像素，提升训练效率和收敛速度。  
◆ 创新采用双梯度掩码技术，有效保留LiDAR点的局部特征，增强点云数据重建精度。  
◆ 在KITTI-360数据集上验证，LiDAR和相机域性能均超越基线模型，展现多模态优势。  
◆ 开源代码推动相关研究，为自动驾驶领域提供可复用的新型神经渲染解决方案。</td></tr>
<tr><td>2025-06-24</td><td>HoliGS: Holistic Gaussian Splatting for Embodied View Synthesis</td><td>[2506.19291](http://arxiv.org/pdf/2506.19291)</td><td>◆ 提出HoliGS框架，首次将可变形高斯泼溅技术应用于长时序单目RGB视频的沉浸式视角合成任务，解决了传统4D高斯泼溅和动态NeRF在分钟级视频中训练开销过大的问题。  
◆ 创新性地采用分层变形策略，将场景分解为静态背景和动态物体，其中动态部分通过可逆神经流实现全局刚性变换、骨骼驱动形变和细微非刚性形变的统一建模。  
◆ 通过将高斯基元绑定到完整的前景规范形状（如第一人称或跟随视角），支持多演员交互和大视角变化的自由视点渲染，显著提升了复杂动态场景的重建鲁棒性。  
◆ 提出可逆高斯变形网络，在保持高保真重建质量的同时，相比现有单目可变形NeRF方法大幅降低训练和渲染时间，实现了实际场景中的高效部署。  
◆ 在挑战性数据集上的实验表明，该方法在重建质量和计算效率方面均优于当前最优技术，为沉浸式视角合成提供了可扩展的实用解决方案。</td></tr>
<tr><td>2025-06-23</td><td>MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation</td><td>[2506.18678](http://arxiv.org/pdf/2506.18678)</td><td>◆ 提出首个分布式多智能体协作神经SLAM框架MCN-SLAM，结合混合隐式神经场景表示，解决传统单智能体隐式SLAM在大场景和长序列中的局限性。  
◆ 创新设计三平面-网格联合场景表示方法，显著提升场景重建质量，优于现有NeRF-based方法。  
◆ 开发&quot;内部-跨智能体&quot;闭环检测机制，首次实现单智能体局部一致性与多智能体全局一致性的协同优化。  
◆ 提出在线蒸馏方法实现多子地图融合，突破通信带宽限制，确保全局地图一致性。  
◆ 发布首个真实世界密集SLAM数据集DES，涵盖单/多智能体场景，提供连续轨迹和高精度3D网格真值，填补领域空白。  
实验证明该方法在建图、定位和通信效率上均优于现有技术，代码与数据集将开源推动SLAM和3D重建领域发展。</td></tr>
<tr><td>2025-06-26</td><td>2D Triangle Splatting for Direct Differentiable Mesh Training</td><td>[2506.18575](http://arxiv.org/pdf/2506.18575)<br><a href=''>[代码]</a></td><td>◆ 提出2D三角形面片（2DTS）方法，替代传统3D高斯基元，实现更高效的直接可微分网格训练。  
◆ 结合离散网格结构与连续体积建模优势，形成类网格的表示形式，提升渲染质量和灵活性。  
◆ 引入紧凑性参数到三角形基元中，支持直接训练高真实感网格，简化传统网格重建流程。  
◆ 实验证明，即使未优化紧凑性参数，其基础版本也能超越当前最优高斯基元方法的渲染保真度。  
◆ 生成的网格在视觉质量上显著优于现有网格重建方法，尤其在复杂光照和阴影效果中表现突出。  
◆ 为可微分渲染领域提供新思路，平衡了渲染速度与高级渲染效果（如重光照）的兼容性。</td></tr>
<tr><td>2025-06-22</td><td>Limitations of NERF with pre-trained Vision Features for Few-Shot 3D Reconstruction</td><td>[2506.18208](http://arxiv.org/pdf/2506.18208)</td><td>◆ 首次系统评估了DINO预训练视觉特征在NeRF少样本3D重建中的表现，发现所有变体性能均低于原始NeRF基线（PSNR 12.9-13.0 vs 14.71）。  
◆ 揭示了反直觉结论：预训练视觉特征不仅无助于少样本重建，反而可能引入有害偏差，挑战了该领域普遍假设。  
◆ 提出三种潜在失效原因分析框架：特征-任务不匹配、有限数据过拟合问题以及特征融合技术瓶颈。  
◆ 通过对比实验验证了冻结特征、LoRA微调和多尺度融合等主流方法的局限性，为后续研究排除无效路径。  
◆ 指出少样本场景下应优先关注几何一致性而非复杂特征工程，为简化模型设计提供新方向。  
◆ 研究成果对基于预训练特征的3D重建方法提出重要警示，可能改变该领域技术路线选择。</td></tr>
<tr><td>2025-06-21</td><td>3D Gaussian Splatting for Fine-Detailed Surface Reconstruction in Large-Scale Scene</td><td>[2506.17636](http://arxiv.org/pdf/2506.17636)</td><td>◆ 提出从粗到精的渐进式重建策略，先快速构建粗糙模型，再通过自适应场景分割和子场景细化实现大规模场景的高效重建。  
◆ 创新性地结合解耦外观模型，有效捕捉户外环境中复杂的全局光照变化，提升动态外观的建模能力。  
◆ 设计瞬态掩模模型，自动过滤移动物体（如车辆、行人）的干扰，显著提高重建纯净度。  
◆ 扩展多视角约束并引入单视角正则化方法，针对性解决纹理缺失区域的几何优化难题。  
◆ 在无人机航拍数据集GauU-Scene V2上验证，首次实现全尺寸图像优化的大规模场景精细重建，性能超越现有NeRF和Gaussian类方法。  
（注：全文严格遵循5点创新性总结，未使用Markdown符号，字数控制在400字内）</td></tr>
<tr><td>2025-06-23</td><td>R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision</td><td>[2506.16262](http://arxiv.org/pdf/2506.16262)<br><a href=''>[代码]</a></td><td>◆ 提出“3D低层视觉（3D LLV）”新领域，将传统2D低层视觉任务（如超分、去模糊、天气退化修复等）扩展到3D空间，解决神经渲染在真实退化场景中的鲁棒性问题。  
◆ 首次系统化定义“退化感知渲染”问题，明确时空一致性和病态优化等核心挑战，为3D LLV研究建立理论框架。  
◆ 综述了将低层视觉技术与神经辐射场（NeRF）、3D高斯泼溅（3DGS）等神经渲染结合的创新方法，展示其在噪声、模糊、低分辨率等退化条件下的高保真3D重建能力。  
◆ 梳理了自动驾驶、AR/VR、机器人等关键应用场景，强调从退化输入中实现可靠3D感知的实用价值。  
◆ 汇总了代表性方法、数据集和评估协议，为未来3D LLV研究提供标准化参考，推动真实环境下鲁棒3D内容生成与场景重建的发展。</td></tr>
<tr><td>2025-06-24</td><td>RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories</td><td>[2506.15242](http://arxiv.org/pdf/2506.15242)</td><td>◆ 提出RA-NeRF方法，能够在复杂相机轨迹下实现高精度的相机位姿估计，解决了传统NeRF和3DGS依赖准确位姿先验的问题。  
◆ 采用增量式重建流程，结合光度一致性约束和光流驱动的位姿调节机制，提升了初始化和定位阶段的鲁棒性。  
◆ 引入隐式位姿滤波器，通过捕捉相机运动模式有效消除位姿估计中的噪声，增强复杂轨迹下的稳定性。  
◆ 在Tanks&amp;Temple和NeRFBuster等具有挑战性的数据集上验证了方法有效性，位姿估计和视觉质量均达到SOTA水平。  
◆ 整体框架无需外部约束，仅通过端到端优化即可同时优化场景重建与相机位姿，适用于SLAM等实际应用场景。</td></tr>
<tr><td>2025-06-17</td><td>Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction</td><td>[2506.14856](http://arxiv.org/pdf/2506.14856)</td><td>◆提出了一种基于轻量级前馈神经网络UPNet的新颖主动视角选择方法，直接预测候选视角的不确定性图，避免了传统方法需要计算每个视角不确定性的高计算成本。  
◆UPNet仅需单张输入图像即可预测所有候选视角的不确定性，通过学习自然物体视角与体素表示不确定性的映射关系，实现了高效的信息提取。  
◆通过聚合历史预测的不确定性图来抑制冗余视角，智能选择信息量最大的新视角，仅需一半视角即可达到与上限相当的3D重建精度。  
◆相比基线方法，计算效率显著提升，实现高达400倍的加速，并减少50%以上的CPU、RAM和GPU资源消耗。  
◆方法具有强大的泛化能力，无需额外训练即可适用于新物体类别的视角选择任务，展现了广泛的适用性。  
◆整体方案将神经渲染与高效视角选择相结合，为3D重建领域提供了高精度与低资源消耗的实用化解决方案。</td></tr>
<tr><td>2025-06-18</td><td>Rasterizing Wireless Radiance Field via Deformable 2D Gaussian Splatting</td><td>[2506.12787](http://arxiv.org/pdf/2506.12787)</td><td>◆ 提出SwiftWRF框架，首次将高斯泼溅（Gaussian Splatting）技术引入无线辐射场（WRF）建模，突破传统方法在精度和效率上的局限。  
◆ 采用可变形2D高斯泼溅方法，通过轻量级MLP建模高斯形变，有效捕捉收发端单侧移动导致的WRF动态变化。  
◆ 实现CUDA加速的光栅化渲染，频谱合成速度超过10万帧/秒，比现有最优方法快500倍，满足实时性需求。  
◆ 创新性地支持任意位置的WRF频谱合成，并在到达角（AoA）和信号强度（RSSI）预测任务中验证实用性。  
◆ 在真实和合成室内场景的实验中，显著提升信号重建质量，同时开源代码和数据集推动领域发展。</td></tr>
<tr><td>2025-06-17</td><td>Efficient multi-view training for 3D Gaussian Splatting</td><td>[2506.12727](http://arxiv.org/pdf/2506.12727)</td><td>这篇论文的核心贡献和创新点如下：

◆ 提出多视角训练方法，解决了3D高斯泼溅（3DGS）传统单视角训练导致的随机梯度方差过大问题，优化了训练效果。  
◆ 改进了光栅化流程，显著降低了多视角训练的计算开销，使其更高效可行。  
◆ 设计了3D距离感知的D-SSIM损失函数，更好地适应多视角场景，提升了渲染质量。  
◆ 提出多视角自适应密度控制机制，克服了传统单视角假设下高斯分布优化的局限性。  
◆ 实验证明，所提方法显著提升了3DGS及其变体的性能，突破了单视角训练的约束。  
◆ 为3DGS领域提供了更高效的训练框架，推动了其在逆向渲染中的应用。</td></tr>
<tr><td>2025-06-12</td><td>PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting</td><td>[2506.10335](http://arxiv.org/pdf/2506.10335)</td><td>◆ 提出PointGS框架，通过点注意力感知的稀疏视图合成方法，解决了3D高斯泼溅（3DGS）在输入视图不足时过拟合的问题。  
◆ 利用最新的立体基础模型估计精确相机姿态并重建密集点云，为高斯初始化提供高质量起点。  
◆ 设计多尺度2D外观特征采样与聚合机制，为每个3D高斯点编码颜色属性，增强稀疏输入下的特征表达能力。  
◆ 创新性地引入基于自注意力机制的点交互网络，使高斯点能与邻近点交互，提升点级外观表示能力。  
◆ 通过两个轻量级多层感知机（MLP）将增强特征解码为高斯参数，实现实时高质量渲染。  
◆ 在多个基准测试中显著优于基于NeRF的方法，并在少样本设置下达到与最先进3DGS方法竞争的性能。</td></tr>
<tr><td>2025-06-11</td><td>The Less You Depend, The More You Learn: Synthesizing Novel Views from Sparse, Unposed Images without Any 3D Knowledge</td><td>[2506.09885](http://arxiv.org/pdf/2506.09885)</td><td>◆ 提出了一种无需3D先验知识和相机位姿标注的通用化新视角合成框架，仅依赖稀疏无位姿的2D图像即可生成逼真新视图。  
◆ 通过系统性分析揭示了关键趋势：减少对3D知识的依赖能更高效利用数据规模，最终达到与依赖3D知识的方法相当的性能。  
◆ 创新性地消除了传统方法对显式3D表示（如NeRF、3DGS）和输入/目标视角位姿标注的双重依赖，实现完全数据驱动的隐式3D理解。  
◆ 实验证明该方法仅通过稀疏2D图像即可学习隐式3D一致性，生成质量媲美依赖位姿输入的方法，验证了数据为中心范式的可行性。  
◆ 为大规模数据时代的新视角合成提供了新思路，表明减少3D先验依赖与数据规模扩展之间存在正向关联性。</td></tr>
<tr><td>2025-06-10</td><td>A Probability-guided Sampler for Neural Implicit Surface Rendering</td><td>[2506.08619](http://arxiv.org/pdf/2506.08619)</td><td>◆ 提出基于概率密度函数的3D图像投影空间模型，实现针对感兴趣区域的射线采样优化，提升渲染精度。  
◆ 设计新型表面重建损失函数，充分利用3D投影空间模型，整合近表面和空白空间信息以增强性能。  
◆ 结合隐式表面表示，通过概率引导采样策略有效聚焦关键区域，减少冗余计算。  
◆ 将提出的采样策略与损失函数集成到现有神经隐式表面渲染器中，显著提升3D重建和图像渲染质量。  
◆ 特别针对场景中感兴趣区域（如物体表面）实现更精细的细节还原，克服传统均匀采样的局限性。  
◆ 通过联合优化采样与重建过程，在保证计算效率的同时获得更高保真度的渲染结果。</td></tr>
<tr><td>2025-06-09</td><td>Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes</td><td>[2506.07917](http://arxiv.org/pdf/2506.07917)<br><a href=''>[代码]</a></td><td>◆ 提出SpeeDe3DGS框架，显著加速动态3D高斯泼溅（3DGS/4DGS）的渲染速度，解决传统方法因逐帧神经网络推理导致的性能瓶颈。  
◆ 设计时序敏感度剪枝评分机制，自动识别并剔除对动态场景重建贡献低的冗余高斯元素，提升计算效率。  
◆ 引入退火平滑剪枝策略，增强在相机位姿不精确的真实场景中的剪枝鲁棒性，避免误删关键高斯元素。  
◆ 开发GroupFlow运动分析技术，通过轨迹相似性聚类高斯群组，以单组刚性变换替代逐高斯形变预测，大幅减少计算量。  
◆ 实验验证框架在NeRF-DS数据集上实现10.37倍渲染加速、7.71倍模型压缩和2.71倍训练提速，在D-NeRF和HyperNeRF数据集分别提升4.20倍和58.23倍性能。  
◆ 模块化设计兼容现有动态3DGS/4DGS框架，兼具高效性与通用性。</td></tr>
<tr><td>2025-06-20</td><td>Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency</td><td>[2506.07497](http://arxiv.org/pdf/2506.07497)</td><td>◆ 提出Genesis框架，首次实现多视角驾驶视频与LiDAR序列的联合生成，保证时空和跨模态一致性。  
◆ 采用两阶段架构：结合DiT视频扩散模型与3D-VAE编码，以及基于BEV的LiDAR生成器与NeRF渲染，实现高质量多模态输出。  
◆ 通过共享潜在空间直接耦合视觉与几何模态，确保生成内容在跨模态间的连贯演化。  
◆ 创新引入DataCrafter描述模块，利用视觉语言模型提供场景级和实例级语义监督，增强生成数据的结构化控制。  
◆ 在nuScenes基准测试中取得视频（FVD 16.95）和LiDAR（Chamfer 0.611）指标的SOTA性能，验证生成数据的语义保真度。  
◆ 生成数据可有效提升下游任务（如分割和3D检测）性能，证明其实际应用价值。</td></tr>
<tr><td>2025-06-07</td><td>SPC to 3D: Novel View Synthesis from Binary SPC via I2I translation</td><td>[2506.06890](http://arxiv.org/pdf/2506.06890)</td><td>◆ 提出首个从二进制单光子相机(SPC)数据生成高质量彩色新视角的两阶段框架，解决了传统3D合成方法无法处理的严重信息丢失问题。  
◆ 第一阶段采用Pix2PixHD等生成模型进行图像到图像转换，将二进制SPC输入转化为可信的RGB图像，有效恢复丢失的纹理和颜色信息。  
◆ 第二阶段结合神经辐射场(NeRF)或高斯泼溅(3DGS)等先进3D重建技术，从生成的RGB图像中合成新视角。  
◆ 通过大量定性和定量实验验证了所提框架(Pix2PixHD + Nerf/3DGS)的优越性，在感知质量和几何一致性上显著超越基线方法。  
◆ 该工作为单光子相机这类新兴成像技术的3D应用开辟了新途径，特别适用于极低光照或超高速成像场景。</td></tr>
<tr><td>2025-06-06</td><td>Splat and Replace: 3D Reconstruction with Repetitive Elements</td><td>[2506.06462](http://arxiv.org/pdf/2506.06462)</td><td>◆ 利用场景中的重复元素提升新视角合成质量，解决了传统NeRF和3DGS在训练视角不足时渲染效果差的问题。  
◆ 提出一种基于3D高斯泼溅（3DGS）的重复实例分割与配准方法，实现不同实例间的信息共享。  
◆ 通过几何优化和外观变化建模，同时提升场景的几何精度和视觉一致性。  
◆ 在合成与真实场景中验证了方法的有效性，显著改善了遮挡和低覆盖区域的渲染效果。  
◆ 首次将重复元素作为先验知识融入3D重建流程，为复杂场景重建提供了新思路。</td></tr>
<tr><td>2025-06-06</td><td>NeurNCD: Novel Class Discovery via Implicit Neural Representation</td><td>[2506.06412](http://arxiv.org/pdf/2506.06412)</td><td>◆ NeurNCD首次提出利用隐式神经表示（Embedding-NeRF模型）替代传统显式3D分割图，通过KL散度聚合语义嵌入和视觉嵌入空间的熵，解决离散化、空洞和噪声问题。  
◆ 结合特征查询、特征调制和聚类等关键组件，实现预训练语义分割网络与隐式神经表示之间的高效特征增强和信息交互。  
◆ 该框架在开放和封闭场景中均实现优越分割性能，无需依赖密集标注数据集进行监督训练或人工生成稀疏标签监督。  
◆ 在NYUv2和Replica数据集上的大量实验表明，NeurNCD显著优于现有最先进方法，验证了其有效性和泛化能力。  
◆ 提出了一种通用且数据高效的新类别发现框架，为开放世界场景中的实际应用提供了新思路。</td></tr>
<tr><td>2025-06-06</td><td>Dy3DGS-SLAM: Monocular 3D Gaussian Splatting SLAM for Dynamic Environments</td><td>[2506.05965](http://arxiv.org/pdf/2506.05965)</td><td>◆ 提出了Dy3DGS-SLAM，这是首个基于单目RGB输入的动态场景3D高斯泼溅SLAM方法，填补了动态环境下纯视觉SLAM的空白。  
◆ 通过概率模型融合光流掩码和深度掩码，生成动态融合掩码，仅需单次网络迭代即可约束跟踪尺度并优化几何渲染。  
◆ 设计了新颖的运动损失函数，基于动态融合掩码约束位姿估计网络，显著提升了动态物体干扰下的跟踪鲁棒性。  
◆ 在映射阶段，结合动态像素的渲染损失、颜色和深度信息，有效消除了动态物体带来的瞬态干扰和遮挡问题。  
◆ 实验证明该方法在动态环境中实现了最先进的跟踪与渲染性能，甚至优于部分RGB-D方法，展现了单目输入的潜力。</td></tr>
<tr><td>2025-06-06</td><td>ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation</td><td>[2506.05317](http://arxiv.org/pdf/2506.05317)</td><td>◆ 提出ProJo4D框架，通过渐进式联合优化策略解决稀疏多视角视频下的物理参数估计问题，克服传统方法因分阶段优化导致的误差累积问题。  
◆ 创新性地引入参数敏感性指导的优化顺序，逐步联合优化几何、外观、物理状态和材料属性，避免直接全参数优化带来的非凸和非可微难题。  
◆ 在PAC-NeRF和Spring-Gaus数据集上的实验表明，该方法在4D未来状态预测、未来状态的新视角渲染和材料参数估计方面均优于现有方法。  
◆ 首次实现稀疏多视角输入下的物理准确数字孪生构建，为机器人和XR应用提供更实用的解决方案。  
◆ 通过渐进式优化策略平衡计算效率与精度，为复杂物理场景的神经渲染与参数估计提供新思路。</td></tr>
<tr><td>2025-06-06</td><td>Unifying Appearance Codes and Bilateral Grids for ...</td><td>[2506.05280](http://arxiv.org/pdf/2506.05280)<br><a href=''>[代码]</a></td><td>◆提出多尺度双边网格新方法，统一了外观编码和双边网格的优势，解决了动态驾驶场景中光度不一致导致的几何失真问题。  
◆通过像素级颜色映射和分层约束优化，显著降低了光不一致产生的漂浮伪影，在四大自...</td></tr>
<tr><td>2025-06-05</td><td>Generating Synthetic Stereo Datasets using 3D Gaus...</td><td>[2506.04908](http://arxiv.org/pdf/2506.04908)</td><td>◆ 提出基于3D高斯泼溅（3DGS）的立体数据集生成流程，相比NeRF方法更高效。  
◆ 结合显式3D重建几何与FoundationStereo模型的深度估计进行专家知识迁移，生成高质量数据。...</td></tr>
<tr><td>**2025-05-30**</td><td>**Hi-Dyna Graph: Hierarchical Dynamic Scene Graph for Robotic Autonomy in Human-Centric Environments**</td><td>[2506.00083](http://arxiv.org/abs/2506.00083)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-29**</td><td>**PhysicsNeRF: Physics-Guided 3D Reconstruction from Sparse Views**</td><td>[2505.23481](http://arxiv.org/abs/2505.23481)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-29**</td><td>**LODGE: Level-of-Detail Large-Scale Gaussian Splatting with Efficient Rendering**</td><td>[2505.23158](http://arxiv.org/abs/2505.23158)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**Can NeRFs See without Cameras?**</td><td>[2505.22441](http://arxiv.org/abs/2505.22441)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**Learning Fine-Grained Geometry for Sparse-View Splatting via Cascade Depth Loss**</td><td>[2505.22279](http://arxiv.org/abs/2505.22279)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-28**</td><td>**Hyperspectral Gaussian Splatting**</td><td>[2505.21890](http://arxiv.org/abs/2505.21890)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-27**</td><td>**Structure from Collision**</td><td>[2505.21335](http://arxiv.org/abs/2505.21335)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-26**</td><td>**OB3D: A New Dataset for Benchmarking Omnidirectional 3D Reconstruction Using Blender**</td><td>[2505.20126](http://arxiv.org/abs/2505.20126)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-30**</td><td>**ErpGS: Equirectangular Image Rendering enhanced with 3D Gaussian Regularization**</td><td>[2505.19883](http://arxiv.org/abs/2505.19883)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-26**</td><td>**GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis**</td><td>[2505.19813](http://arxiv.org/abs/2505.19813)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-26**</td><td>**Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction**</td><td>[2505.19793](http://arxiv.org/abs/2505.19793)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-22**</td><td>**UAV See, UGV Do: Aerial Imagery and Virtual Teach Enabling Zero-Shot Ground Vehicle Repeat**</td><td>[2505.16912](http://arxiv.org/abs/2505.16912)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-19**</td><td>**IPENS:Interactive Unsupervised Framework for Rapid Plant Phenotyping Extraction via NeRF-SAM2 Fusion**</td><td>[2505.13633](http://arxiv.org/abs/2505.13633)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-19**</td><td>**3D Gaussian Adaptive Reconstruction for Fourier Light-Field Microscopy**</td><td>[2505.12875](http://arxiv.org/abs/2505.12875)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-18**</td><td>**Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey**</td><td>[2505.12384](http://arxiv.org/abs/2505.12384)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-16**</td><td>**MutualNeRF: Improve the Performance of NeRF under Limited Samples with Mutual Information Theory**</td><td>[2505.11386](http://arxiv.org/abs/2505.11386)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-16**</td><td>**EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes**</td><td>[2505.10787](http://arxiv.org/abs/2505.10787)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-15**</td><td>**Large-Scale Gaussian Splatting SLAM**</td><td>[2505.09915](http://arxiv.org/abs/2505.09915)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-14**</td><td>**Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians**</td><td>[2505.09413](http://arxiv.org/abs/2505.09413)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-14**</td><td>**FreeDriveRF: Monocular RGB Dynamic NeRF without Poses for Autonomous Driving via Point-Level Dynamic-Static Decoupling**</td><td>[2505.09406](http://arxiv.org/abs/2505.09406)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-12**</td><td>**TUGS: Physics-based Compact Representation of Underwater Scenes by Tensorized Gaussian**</td><td>[2505.08811](http://arxiv.org/abs/2505.08811)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-13**</td><td>**FOCI: Trajectory Optimization on Gaussian Splats**</td><td>[2505.08510](http://arxiv.org/abs/2505.08510)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-13**</td><td>**TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset**</td><td>[2505.07396](http://arxiv.org/abs/2505.07396)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-12**</td><td>**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**</td><td>[2505.07373](http://arxiv.org/abs/2505.07373)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-11**</td><td>**NeuGen: Amplifying the &#x27;Neural&#x27; in Neural Radiance Fields for Domain Generalization**</td><td>[2505.06894](http://arxiv.org/abs/2505.06894)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-10**</td><td>**3D Characterization of Smoke Plume Dispersion Using Multi-View Drone Swarm**</td><td>[2505.06638](http://arxiv.org/abs/2505.06638)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-10**</td><td>**FlexNeRFer: A Multi-Dataflow, Adaptive Sparsity-Aware Accelerator for On-Device NeRF Rendering**</td><td>[2505.06504](http://arxiv.org/abs/2505.06504)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-08**</td><td>**3D Scene Generation: A Survey**</td><td>[2505.05474](http://arxiv.org/abs/2505.05474)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-04**</td><td>**HandOcc: NeRF-based Hand Rendering with Occupancy Networks**</td><td>[2505.02079](http://arxiv.org/abs/2505.02079)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-04**</td><td>**Learning Heterogeneous Mixture of Scene Experts for Large-scale Neural Radiance Fields**</td><td>[2505.02005](http://arxiv.org/abs/2505.02005)<br><a href=''>[代码]</a></td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-03**</td><td>**AquaGS: Fast Underwater Scene Reconstruction with SfM-Free Gaussian Splatting**</td><td>[2505.01799](http://arxiv.org/abs/2505.01799)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-03**</td><td>**Unified Steganography via Implicit Neural Representation**</td><td>[2505.01749](http://arxiv.org/abs/2505.01749)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-01**</td><td>**Cues3D: Unleashing the Power of Sole NeRF for Consistent and Unique Instances in Open-Vocabulary 3D Panoptic Segmentation**</td><td>[2505.00378](http://arxiv.org/abs/2505.00378)</td><td>摘要生成中...</td></tr>
<tr><td>**2025-05-01**</td><td>**GSFeatLoc: Visual Localization Using Feature Correspondence on 3D Gaussian Splatting**</td><td>[2504.20379](http://arxiv.org/abs/2504.20379)</td><td>摘要生成中...</td></tr>
</tbody>
</table>
</div>

---
> 本列表自动生成 | [反馈问题](https://github.com/your-repo/issues)
> 更新于: 2025.09.06
