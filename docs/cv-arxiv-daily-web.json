{
  "SLAM": {
    "2505.01017": "|**2025-05-02**|**Tightly Coupled Range Inertial Odometry and Mapping with Exact Point Cloud Downsampling**|Kenji Koide et.al.|[2505.01017](http://arxiv.org/abs/2505.01017)|null|\n",
    "2505.04095": "|**2025-05-07**|**Scalable Aerial GNSS Localization for Marine Robots**|Shuo Wen et.al.|[2505.04095](http://arxiv.org/abs/2505.04095)|**[link](https://github.com/stevvwen/aerial_gnss)**|\n",
    "2505.03565": "|**2025-05-06**|**Thermal-LiDAR Fusion for Robust Tunnel Localization in GNSS-Denied and Low-Visibility Conditions**|Lukas Schichler et.al.|[2505.03565](http://arxiv.org/abs/2505.03565)|null|\n",
    "2505.03448": "|**2025-05-06**|**AquaticVision: Benchmarking Visual SLAM in Underwater Environment with Events and Frames**|Yifan Peng et.al.|[2505.03448](http://arxiv.org/abs/2505.03448)|null|\n",
    "2505.03422": "|**2025-05-06**|**LiftFeat: 3D Geometry-Aware Local Feature Matching**|Yepeng Liu et.al.|[2505.03422](http://arxiv.org/abs/2505.03422)|**[link](https://github.com/lyp-deeplearning/liftfeat)**|\n",
    "2505.02598": "|**2025-05-05**|**LiDAR-Inertial SLAM-Based Navigation and Safety-Oriented AI-Driven Control System for Skid-Steer Robots**|Mehdi Heydari Shahna et.al.|[2505.02598](http://arxiv.org/abs/2505.02598)|null|\n",
    "2505.02272": "|**2025-05-04**|**Robust Localization, Mapping, and Navigation for Quadruped Robots**|Dyuman Aditya et.al.|[2505.02272](http://arxiv.org/abs/2505.02272)|null|\n",
    "2505.01956": "|**2025-05-04**|**SafeNav: Safe Path Navigation using Landmark Based Localization in a GPS-denied Environment**|Ganesh Sapkota et.al.|[2505.01956](http://arxiv.org/abs/2505.01956)|null|\n",
    "2505.01934": "|**2025-05-03**|**GauS-SLAM: Dense RGB-D SLAM with Gaussian Surfels**|Yongxin Su et.al.|[2505.01934](http://arxiv.org/abs/2505.01934)|null|\n",
    "2505.09024": "|**2025-05-13**|**Automated Meta Prompt Engineering for Alignment with the Theory of Mind**|Aaron Baughman et.al.|[2505.09024](http://arxiv.org/abs/2505.09024)|null|\n",
    "2505.08388": "|**2025-05-13**|**MDF: Multi-Modal Data Fusion with CNN-Based Object Detection for Enhanced Indoor Localization Using LiDAR-SLAM**|Saqi Hussain Kalan et.al.|[2505.08388](http://arxiv.org/abs/2505.08388)|null|\n",
    "2505.08230": "|**2025-05-13**|**SKiD-SLAM: Robust, Lightweight, and Distributed Multi-Robot LiDAR SLAM in Resource-Constrained Field Environments**|Hogyun Kim et.al.|[2505.08230](http://arxiv.org/abs/2505.08230)|null|\n",
    "2505.08013": "|**2025-05-12**|**RDD: Robust Feature Detector and Descriptor using Deformable Transformer**|Gonglin Chen et.al.|[2505.08013](http://arxiv.org/abs/2505.08013)|null|\n",
    "2505.07198": "|**2025-05-12**|**Ranking-aware Continual Learning for LiDAR Place Recognition**|Xufei Wang et.al.|[2505.07198](http://arxiv.org/abs/2505.07198)|null|\n",
    "2505.13309": "|**2025-05-19**|**eStonefish-scenes: A synthetically generated dataset for underwater event-based optical flow prediction tasks**|Jad Mansour et.al.|[2505.13309](http://arxiv.org/abs/2505.13309)|null|\n",
    "2505.12549": "|**2025-05-23**|**VGGT-SLAM: Dense RGB SLAM Optimized on the SL(4) Manifold**|Dominic Maggio et.al.|[2505.12549](http://arxiv.org/abs/2505.12549)|null|\n",
    "2505.12384": "|**2025-05-18**|**Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey**|Calvin Galagain et.al.|[2505.12384](http://arxiv.org/abs/2505.12384)|null|\n",
    "2505.12337": "|**2025-05-18**|**Structureless VIO**|Junlin Song et.al.|[2505.12337](http://arxiv.org/abs/2505.12337)|null|\n",
    "2505.11709": "|**2025-05-16**|**EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video**|Ryan Hoque et.al.|[2505.11709](http://arxiv.org/abs/2505.11709)|null|\n",
    "2505.11620": "|**2025-05-16**|**Improved Bag-of-Words Image Retrieval with Geometric Constraints for Ground Texture Localization**|Aaron Wilhelm et.al.|[2505.11620](http://arxiv.org/abs/2505.11620)|null|\n",
    "2505.10847": "|**2025-05-16**|**Robust 2D lidar-based SLAM in arboreal environments without IMU/GNSS**|Paola Nazate-Burgos et.al.|[2505.10847](http://arxiv.org/abs/2505.10847)|null|\n",
    "2505.10696": "|**2025-05-15**|**TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation**|Manthan Patel et.al.|[2505.10696](http://arxiv.org/abs/2505.10696)|null|\n",
    "2505.10310": "|**2025-05-15**|**A hybrid SLAM-Payne framework for atmospheric parameter and abundance determination of early-type Stars from LAMOST DR9 low-resolution Spectra**|Weijia Sun et.al.|[2505.10310](http://arxiv.org/abs/2505.10310)|null|\n",
    "2505.09915": "|**2025-05-15**|**Large-Scale Gaussian Splatting SLAM**|Zhe Xin et.al.|[2505.09915](http://arxiv.org/abs/2505.09915)|null|\n",
    "2505.16447": "|**2025-05-22**|**TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition**|Oliver Grainge et.al.|[2505.16447](http://arxiv.org/abs/2505.16447)|null|\n",
    "2505.14128": "|**2025-05-20**|**A Methodological Framework for Measuring Spatial Labeling Similarity**|Yihang Du et.al.|[2505.14128](http://arxiv.org/abs/2505.14128)|**[link](https://github.com/yihdu/slam)**|\n",
    "2505.14068": "|**2025-05-22**|**Place Recognition: A Comprehensive Review, Current Challenges and Future Directions**|Zhenyu Li et.al.|[2505.14068](http://arxiv.org/abs/2505.14068)|**[link](https://github.com/cv4ra/sota-place-recognitioner)**|\n",
    "2505.22880": "|**2025-05-28**|**Semantic Exploration and Dense Mapping of Complex Environments using Ground Robots Equipped with LiDAR and Panoramic Camera**|Xiaoyang Zhan et.al.|[2505.22880](http://arxiv.org/abs/2505.22880)|null|\n",
    "2505.22859": "|**2025-05-28**|**4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians**|Hidenobu Matsuki et.al.|[2505.22859](http://arxiv.org/abs/2505.22859)|null|\n",
    "2505.22335": "|**2025-05-28**|**UP-SLAM: Adaptively Structured Gaussian SLAM with Uncertainty Prediction in Dynamic Environments**|Wancai Zheng et.al.|[2505.22335](http://arxiv.org/abs/2505.22335)|null|\n",
    "2505.20906": "|**2025-05-27**|**HS-SLAM: A Fast and Hybrid Strategy-Based SLAM Approach for Low-Speed Autonomous Driving**|Bingxiang Kang et.al.|[2505.20906](http://arxiv.org/abs/2505.20906)|null|\n",
    "2505.20858": "|**2025-05-27**|**ProBA: Probabilistic Bundle Adjustment with the Bhattacharyya Coefficient**|Jason Chui et.al.|[2505.20858](http://arxiv.org/abs/2505.20858)|null|\n",
    "2505.19420": "|**2025-05-26**|**ADD-SLAM: Adaptive Dynamic Dense SLAM with Gaussian Splatting**|Wenhua Wu et.al.|[2505.19420](http://arxiv.org/abs/2505.19420)|null|\n",
    "2505.18992": "|**2025-05-25**|**VPGS-SLAM: Voxel-based Progressive 3D Gaussian SLAM in Large-Scale Scenes**|Tianchen Deng et.al.|[2505.18992](http://arxiv.org/abs/2505.18992)|null|\n",
    "2505.17576": "|**2025-05-23**|**CU-Multi: A Dataset for Multi-Robot Data Association**|Doncey Albin et.al.|[2505.17576](http://arxiv.org/abs/2505.17576)|null|\n",
    "2506.04224": "|**2025-06-04**|**Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset**|Zirui Wang et.al.|[2506.04224](http://arxiv.org/abs/2506.04224)|null|\n",
    "2506.03073": "|**2025-06-03**|**LEG-SLAM: Real-Time Language-Enhanced Gaussian Splatting for SLAM**|Roman Titkov et.al.|[2506.03073](http://arxiv.org/abs/2506.03073)|null|\n",
    "2506.02932": "|**2025-06-03**|**Online Performance Assessment of Multi-Source-Localization for Autonomous Driving Systems Using Subjective Logic**|Stefan Orf et.al.|[2506.02932](http://arxiv.org/abs/2506.02932)|null|\n",
    "2506.02741": "|**2025-06-03**|**VTGaussian-SLAM: RGBD SLAM for Large Scale Scenes with Splatting View-Tied 3D Gaussians**|Pengchong Hu et.al.|[2506.02741](http://arxiv.org/abs/2506.02741)|null|\n",
    "2506.02736": "|**2025-06-03**|**GeneA-SLAM2: Dynamic SLAM with AutoEncoder-Preprocessed Genetic Keypoints Resampling and Depth Variance-Guided Dynamic Region Removal**|Shufan Qing et.al.|[2506.02736](http://arxiv.org/abs/2506.02736)|**[link](https://github.com/qingshufan/GeneA-SLAM2)**|\n",
    "2506.02373": "|**2025-06-03**|**Olfactory Inertial Odometry: Methodology for Effective Robot Navigation by Scent**|Kordel K. France et.al.|[2506.02373](http://arxiv.org/abs/2506.02373)|null|\n",
    "2506.00970": "|**2025-06-01**|**Globally Consistent RGB-D SLAM with 2D Gaussian Splatting**|Xingguang Zhong et.al.|[2506.00970](http://arxiv.org/abs/2506.00970)|null|\n",
    "2505.24654": "|**2025-05-30**|**Black-box Adversarial Attacks on CNN-based SLAM Algorithms**|Maria Rafaela Gkeka et.al.|[2505.24654](http://arxiv.org/abs/2505.24654)|null|\n",
    "2506.08005": "|2025-06-09|ZeroVO: Visual Odometry with Minimal Assumptions|Lei Lai\u7b49|[2506.08005](http://arxiv.org/pdf/2506.08005)|\u65e0|ZeroVO\u662f\u4e00\u79cd\u65e0\u9700\u9884\u8bad\u7ec3\u5373\u53ef\u6cdb\u5316\u81f3\u4e0d\u540c\u76f8\u673a\u548c\u73af\u5883\u7684\u89c6\u89c9\u91cc\u7a0b\u8ba1\u7b97\u6cd5\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u4e0e\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u65e0\u9700\u6807\u5b9a\u7684\u51e0\u4f55\u611f\u77e5\u7f51\u7edc\u7ed3\u6784\uff0c\u80fd\u6709\u6548\u5904\u7406\u6df1\u5ea6\u4f30\u8ba1\u548c\u76f8\u673a\u53c2\u6570\u4e2d\u7684\u566a\u58f0\uff0c\u6446\u8131\u4f20\u7edf\u65b9\u6cd5\u5bf9\u56fa\u5b9a\u6807\u5b9a\u914d\u7f6e\u7684\u4f9d\u8d56\u3002\n\n\u25c6 \u5f15\u5165\u57fa\u4e8e\u8bed\u8a00\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u901a\u8fc7\u8bed\u4e49\u4fe1\u606f\u589e\u5f3a\u7279\u5f81\u63d0\u53d6\u7684\u9c81\u68d2\u6027\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u672a\u77e5\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u3002\n\n\u25c6 \u5f00\u53d1\u534a\u76d1\u7763\u8bad\u7ec3\u6846\u67b6\uff0c\u5229\u7528\u672a\u6807\u6ce8\u6570\u636e\u8fed\u4ee3\u9002\u5e94\u65b0\u573a\u666f\uff0c\u8fdb\u4e00\u6b65\u5f3a\u5316\u6a21\u578b\u5728\u771f\u5b9e\u590d\u6742\u573a\u666f\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u3002\n\n\u25c6 \u5728KITTI\u3001nuScenes\u548cArgoverse 2\u7b49\u6807\u51c6\u6570\u636e\u96c6\u53caGTA\u5408\u6210\u6570\u636e\u4e0a\u9a8c\u8bc1\u6027\u80fd\uff0c\u76f8\u5bf9\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u8d85\u8fc730%\u3002\n\n\u25c6 \u65e0\u9700\u5fae\u8c03\u6216\u76f8\u673a\u6807\u5b9a\u7684\u7279\u6027\uff0c\u4f7f\u5f97\u8be5\u6280\u672f\u5177\u5907\u5927\u89c4\u6a21\u5b9e\u9645\u90e8\u7f72\u7684\u6f5c\u529b\uff0c\u6781\u5927\u6269\u5c55\u4e86\u89c6\u89c9\u91cc\u7a0b\u8ba1\u7684\u5e94\u7528\u8303\u56f4\u3002|\n",
    "2506.07164": "|2025-06-08|Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs|Qiong Chang\u7b49|[2506.07164](http://arxiv.org/pdf/2506.07164)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u901a\u8fc7\u4f18\u5316\u4f4e\u7aef\u5d4c\u5165\u5f0fGPU\u4e0a\u7684Oriented FAST\u7279\u5f81\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9SLAM\u7cfb\u7edf\u7684\u5b9e\u65f6\u5904\u7406\u80fd\u529b\u3002\u5177\u4f53\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u4e8c\u8fdb\u5236\u7ea7\u7f16\u7801\u7b56\u7565\uff0c\u5feb\u901f\u786e\u5b9aFAST\u7279\u5f81\u70b9\u5019\u9009\u70b9\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u53ef\u5206\u79bb\u7684Harris\u89d2\u70b9\u68c0\u6d4b\u7b56\u7565\uff0c\u7ed3\u5408\u5e95\u5c42GPU\u786c\u4ef6\u6307\u4ee4\u4f18\u5316\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u5728Jetson TX2\u5d4c\u5165\u5f0fGPU\u4e0a\u5b9e\u73b0\u4e86\u5e73\u57477.3\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u8fdc\u8d85\u73b0\u6709OpenCV\u7684GPU\u52a0\u901f\u65b9\u6848\u3002  \n\u25c6 \u901a\u8fc7\u4f18\u5316FAST\u7279\u5f81\u70b9\u68c0\u6d4b\u548cHarris\u89d2\u70b9\u68c0\u6d4b\u8fd9\u4e24\u4e2a\u6700\u8017\u65f6\u7684\u6b65\u9aa4\uff0c\u89e3\u51b3\u4e86\u79fb\u52a8\u5e73\u53f0\u5b9e\u65f6\u5904\u7406\u7684\u74f6\u9888\u95ee\u9898\u3002  \n\u25c6 \u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u5b9e\u65f6SLAM\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u79fb\u52a8\u548c\u5d4c\u5165\u5f0f\u5e94\u7528\u6f5c\u529b\u3002|\n",
    "2506.07013": "|2025-06-08|UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment|Wentao Zhao\u7b49|[2506.07013](http://arxiv.org/pdf/2506.07013)|\u65e0|\u25c6 \u63d0\u51faUNO\u6846\u67b6\uff0c\u5b9e\u73b0\u8de8\u5e73\u53f0\u3001\u8de8\u73af\u5883\u7684\u7edf\u4e00\u81ea\u76d1\u7763\u5355\u76ee\u89c6\u89c9\u91cc\u7a0b\u8ba1\uff0c\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u573a\u666f\u6216\u8bbe\u5907\u8fdb\u884c\u8c03\u4f18\u3002  \n\u25c6 \u91c7\u7528\u6df7\u5408\u4e13\u5bb6\u7b56\u7565\uff08Mixture-of-Experts\uff09\uff0c\u901a\u8fc7\u591a\u4e2a\u4e13\u7528\u89e3\u7801\u5668\u5206\u522b\u5904\u7406\u4e0d\u540c\u7c7b\u522b\u7684\u8fd0\u52a8\u6a21\u5f0f\uff0c\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u8bbe\u8ba1\u53ef\u5fae\u5206\u7684Gumbel-Softmax\u6a21\u5757\uff0c\u52a8\u6001\u6784\u5efa\u5e27\u95f4\u5173\u8054\u56fe\u5e76\u9009\u62e9\u6700\u4f18\u89e3\u7801\u5668\uff0c\u540c\u65f6\u5254\u9664\u9519\u8bef\u4f30\u8ba1\u3002  \n\u25c6 \u7ed3\u5408\u9884\u8bad\u7ec3\u7684\u5c3a\u5ea6\u65e0\u5173\u6df1\u5ea6\u5148\u9a8c\u4e0e\u8f7b\u91cf\u7ea7\u6346\u7ed1\u8c03\u6574\uff08bundling adjustment\uff09\uff0c\u540e\u7aef\u7edf\u4e00\u4f18\u5316\u51e0\u4f55\u4e00\u81f4\u6027\u3002  \n\u25c6 \u5728KITTI\uff08\u81ea\u52a8\u9a7e\u9a76\uff09\u3001EuRoC-MAV\uff08\u65e0\u4eba\u673a\uff09\u548cTUM-RGBD\uff08\u624b\u6301\u8bbe\u5907\uff09\u4e09\u5927\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u6027\u80fd\u8fbe\u5230SOTA\u3002|\n",
    "2506.06517": "|2025-06-06|GS4: Generalizable Sparse Splatting Semantic SLAM|Mingqi Jiang\u7b49|[2506.06517](http://arxiv.org/pdf/2506.06517)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u57fa\u4e8e\u53ef\u6cdb\u5316\u9ad8\u65af\u6cfc\u6e85\uff08GS\uff09\u7684\u8bed\u4e49SLAM\u7b97\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u7f51\u7edc\u5b9e\u73b0\u8de8\u573a\u666f\u76843D\u5730\u56fe\u6784\u5efa\uff0c\u6446\u8131\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5355\u573a\u666f\u4f18\u5316\u7684\u9650\u5236\u3002  \n\u25c6 \u91c7\u7528RGB-D\u56fe\u50cf\u8bc6\u522b\u4e3b\u5e72\u7f51\u7edc\uff0c\u76f4\u63a5\u4ece\u964d\u91c7\u6837\u548c\u53cd\u5411\u6295\u5f71\u7684\u56fe\u50cf\u4f4d\u7f6e\u9884\u6d4b\u9ad8\u65af\u53c2\u6570\uff0c\u5b9e\u73b0\u9ad8\u6548\u589e\u91cf\u5f0f\u5730\u56fe\u66f4\u65b0\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c063D\u8bed\u4e49\u5206\u5272\u96c6\u6210\u5230GS\u6846\u67b6\u4e2d\uff0c\u901a\u8fc7\u5171\u4eab\u4e3b\u5e72\u7f51\u7edc\u7edf\u4e003D\u5efa\u56fe\u4e0e\u8bc6\u522b\u4efb\u52a1\uff0c\u63d0\u5347\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u3002  \n\u25c6 \u63d0\u51fa\u4ec5\u97001\u6b21\u8fed\u4ee3\u7684\u5168\u5c40\u5b9a\u4f4d\u540e\u4f18\u5316\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u5b9a\u4f4d\u6f02\u79fb\u548c\u6f02\u6d6e\u7269\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5728ScanNet\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0SOTA\u6027\u80fd\uff0c\u6240\u7528\u9ad8\u65af\u6570\u91cf\u6bd4\u540c\u7c7b\u65b9\u6cd5\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u5e76\u5728NYUv2\u548cTUM RGB-D\u4e0a\u5c55\u793a\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002|\n",
    "2506.06476": "|2025-06-06|Enhancing Situational Awareness in Underwater Robotics with Multi-modal Spatial Perception|Pushyami Kaveti\u7b49|[2506.06476](http://arxiv.org/pdf/2506.06476)|\u65e0|\u25c6 \u63d0\u51fa\u591a\u6a21\u6001\u611f\u77e5\u878d\u5408\u6846\u67b6\uff0c\u6574\u5408\u6444\u50cf\u5934\u3001IMU\u548c\u58f0\u5b66\u8bbe\u5907\u6570\u636e\uff0c\u89e3\u51b3\u6c34\u4e0b\u89c6\u89c9SLAM\u56e0\u5149\u7ebf\u8870\u51cf\u548c\u4f4e\u5bf9\u6bd4\u5ea6\u5bfc\u81f4\u7684\u5931\u6548\u95ee\u9898\u3002  \n\u25c6 \u7a81\u7834\u4f20\u7edf\u5355\u76ee/\u53cc\u76ee\u89c6\u89c9\u9650\u5236\uff0c\u652f\u6301\u591a\u6444\u50cf\u5934\u914d\u7f6e\uff0c\u63d0\u5347\u7cfb\u7edf\u5728\u590d\u6742\u6c34\u4e0b\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3002  \n\u25c6 \u7ed3\u5408\u51e0\u4f55\u65b9\u6cd5\u4e0e\u5b66\u4e60\u6280\u672f\uff0c\u5f15\u5165\u8bed\u4e49\u5206\u6790\u589e\u5f3a\u573a\u666f\u7406\u89e3\uff0c\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u72b6\u6001\u4f30\u8ba1\u548c3D\u91cd\u5efa\u3002  \n\u25c6 \u901a\u8fc7\u771f\u5b9e\u6d77\u57df\u5b9e\u9a8c\u9a8c\u8bc1\uff08\u7279\u9686\u8d6b\u59c6\u5ce1\u6e7e\uff09\uff0c\u9996\u6b21\u5c55\u793a\u591a\u6a21\u6001\u7cfb\u7edf\u5728\u6076\u52a3\u6c34\u4e0b\u6761\u4ef6\u4e0b\u7684\u5b9e\u65f6\u53ef\u9760\u6027\u80fd\u3002  \n\u25c6 \u7cfb\u7edf\u5206\u6790\u4f20\u611f\u5668\u6807\u5b9a\u7b49\u5de5\u7a0b\u6311\u6218\uff0c\u6307\u51fa\u57fa\u4e8e\u5b66\u4e60\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u6c34\u4e0b\u4f5c\u4e1a\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002|\n",
    "2506.05965": "|2025-06-06|Dy3DGS-SLAM: Monocular 3D Gaussian Splatti...|Mingrui Li\u7b49|[2506.05965](http://arxiv.org/pdf/2506.05965)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u57fa\u4e8e\u5355\u76eeRGB\u8f93\u5165\u7684\u52a8\u6001\u573a\u666f3D\u9ad8\u65af\u6cfc\u6e85SLAM\u7cfb\u7edfDy3DGS-SLAM\u3002  \n\u25c6 \u901a\u8fc7\u878d\u5408\u5149\u6d41\u63a9\u7801\u548c\u6df1\u5ea6\u63a9\u7801\u7684\u6982\u7387\u6a21\u578b\u751f\u6210\u52a8\u6001\u63a9\u7801\uff0c\u4ec5\u9700\u5355\u6b21\u7f51\u7edc\u8fed\u4ee3\u5373\u53ef\u4f18\u5316\u8ddf\u8e2a\u5c3a\u5ea6\u548c\u51e0\u4f55\u6e32\u67d3\u3002...|\n",
    "2506.05866": "|2025-06-06|Analysis of points outcome in ATP Grand Slam Tenni...|Martin Illum\u7b49|[2506.05866](http://arxiv.org/pdf/2506.05866)|\u65e0|\u25c6 \u8be5\u8bba\u6587\u521b\u65b0\u5730\u5229\u7528\u5927\u6570\u636e\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08\u5982\u903b\u8f91\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u7b49\uff09\u9884\u6d4b\u7f51\u7403\u5927\u6ee1\u8d2f\u8d5b\u4e8b\u4e2d\u6bcf\u4e00\u5206\u7684\u80dc\u8d1f\uff0c\u5e76\u7ed3\u5408\u7403\u5458\u6392\u540d\u3001\u5386\u53f2\u6570\u636e\u7b49\u56e0\u7d20\u5206\u6790\u5f71\u54cd\u5f97\u5206\u7684\u5173\u952e\u6218\u7565\u56e0\u7d20\u3002  \n\u25c6 \u7814\u7a76\u57fa\u4e8e2016-2020...|\n",
    "2506.05558": "|2025-06-05|On-the-fly Reconstruction for Large-Scale Novel Vi...|Andreas Meuleman\u7b49|[2506.05558](http://arxiv.org/pdf/2506.05558)|\u65e0|\u25c6\u63d0\u51fa\u5b9e\u65f6\u91cd\u5efa\u65b9\u6cd5\uff0c\u5728\u62cd\u6444\u540e\u7acb\u5373\u751f\u6210\u76f8\u673a\u4f4d\u59ff\u548c\u8bad\u7ec3\u597d\u76843D\u9ad8\u65af\u6cfc\u6e85\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u8017\u65f6\u8fc7\u957f\u7684\u95ee\u9898\u3002  \n\u25c6\u7ed3\u5408\u5feb\u901f\u521d\u59cb\u4f4d\u59ff\u4f30\u8ba1\u548c\u76f4\u63a5\u91c7\u6837\u9ad8\u65af\u57fa\u5143\u4f4d\u7f6e/\u5f62\u72b6\u7684\u6280\u672f\uff0c\u663e\u8457\u52a0\u901f\u8054\u5408\u4f18\u5316\u8fc7\u7a0b\u3002  \n...|\n",
    "2506.04619": "|**2025-06-05**|**Deep Learning Reforms Image Matching: A Survey and Outlook**|Shihua Zhang et.al.|[2506.04619](http://arxiv.org/abs/2506.04619)|null|\n",
    "2506.04359": "|**2025-06-04**|**cuVSLAM: CUDA accelerated visual odometry**|Alexander Korovko et.al.|[2506.04359](http://arxiv.org/abs/2506.04359)|null|\n",
    "2506.09035": "|2025-06-10|Princeton365: A Diverse Dataset with Accurate Camera Pose|Karhan Kayan\u7b49|[2506.09035](http://arxiv.org/pdf/2506.09035)|\u65e0|\u25c6 \u63d0\u51fa\u4e86Princeton365\u6570\u636e\u96c6\uff0c\u5305\u542b365\u4e2a\u591a\u6837\u5316\u89c6\u9891\uff0c\u63d0\u4f9b\u9ad8\u7cbe\u5ea6\u7684\u76f8\u673a\u4f4d\u59ff\uff0c\u586b\u8865\u4e86\u5f53\u524dSLAM\u57fa\u51c6\u5728\u7cbe\u5ea6\u548c\u6570\u636e\u591a\u6837\u6027\u4e4b\u95f4\u7684\u7a7a\u767d\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5730\u9762\u771f\u503c\u91c7\u96c6\u6846\u67b6\uff0c\u7ed3\u5408\u6821\u51c6\u677f\u548c360\u5ea6\u76f8\u673a\uff0c\u5b9e\u73b0\u4e86\u5ba4\u5185\u3001\u5ba4\u5916\u548c\u7269\u4f53\u626b\u63cf\u89c6\u9891\u7684\u591a\u6a21\u6001\u540c\u6b65\u91c7\u96c6\uff08\u5355\u76ee/\u7acb\u4f53RGB\u89c6\u9891\u548cIMU\uff09\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5149\u6d41\u7684\u573a\u666f\u5c3a\u5ea6\u611f\u77e5SLAM\u8bc4\u4f30\u6307\u6807\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u6307\u6807\uff08\u5982ATE\uff09\u65e0\u6cd5\u8de8\u573a\u666f\u6bd4\u8f83\u7684\u5c40\u9650\u6027\uff0c\u4fbf\u4e8e\u5206\u6790\u7b97\u6cd5\u5931\u8d25\u6a21\u5f0f\u3002  \n\u25c6 \u6784\u5efa\u4e86\u5177\u6709\u6311\u6218\u6027\u7684\u65b0\u89c6\u89d2\u5408\u6210\uff08NVS\uff09\u57fa\u51c6\uff0c\u6db5\u76d6\u5f53\u524d\u57fa\u51c6\u672a\u6d89\u53ca\u7684\u573a\u666f\uff08\u5982\u975e\u6717\u4f2f\u8868\u9762\u548c360\u5ea6\u76f8\u673a\u8f68\u8ff9\uff09\u3002  \n\u25c6 \u516c\u5f00\u4e86\u5b8c\u6574\u7684\u6570\u636e\u96c6\u3001\u4ee3\u7801\u548c\u63d0\u4ea4\u5e73\u53f0\uff08https://princeton365.cs.princeton.edu\uff09\uff0c\u63a8\u52a8SLAM\u548cNVS\u9886\u57df\u7684\u6807\u51c6\u5316\u7814\u7a76\u3002|\n",
    "2506.08384": "|2025-06-10|Planar Collisionless Shock Simulations with Semi-Implicit Particle-in-Cell Model FLEKS|Hongyang Zhou\u7b49|[2506.08384](http://arxiv.org/pdf/2506.08384)|\u65e0|\u25c6 \u9a8c\u8bc1\u4e86\u534a\u9690\u5f0f\u7c92\u5b50\u7f51\u683c\u4ee3\u7801FLEKS\u5728\u65e0\u78b0\u649e\u6fc0\u6ce2\u6a21\u62df\u4e2d\u7684\u9002\u7528\u6027\uff0c\u7279\u522b\u9488\u5bf9\u5168\u7403\u78c1\u5c42\u5efa\u6a21\u76f8\u5173\u53c2\u6570\u8303\u56f4\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u7cbe\u7ec6\u5316\u7b97\u6cd5\uff0c\u4f7fFLEKS\u80fd\u591f\u5728\u7535\u5b50\u60ef\u6027\u957f\u5ea6\u91cf\u7ea7\u7684\u7f51\u683c\u5206\u8fa8\u7387\u4e0b\u7cbe\u786e\u6a21\u62df\u6fc0\u6ce2\u7ed3\u6784\u3002  \n\u25c6 \u6210\u529f\u6355\u6349\u4e86\u6fc0\u6ce2\u5173\u952e\u7279\u5f81\uff0c\u5305\u62ec\u6fc0\u6ce2\u7ed3\u6784\uff08\u811a\u90e8\u3001\u9661\u5761\u3001\u8fc7\u51b2\u548c\u6b20\u51b2\uff09\u3001\u4e0a\u4e0b\u6e38\u6ce2\u52a8\uff08\u5feb\u78c1\u58f0\u6ce2\u3001\u54e8\u58f0\u6ce2\u3001\u963f\u5c14\u82ac\u79bb\u5b50\u56de\u65cb\u6ce2\u548c\u955c\u50cf\u6a21\uff09\u4ee5\u53ca\u975e\u9ea6\u514b\u65af\u97e6\u7c92\u5b50\u5206\u5e03\u3002  \n\u25c6 \u63ed\u793a\u4e86\u4e8c\u7ef4\u6a21\u62df\u5bf9\u51c6\u786e\u91cd\u73b0\u51c6\u5782\u76f4\u6fc0\u6ce2\u4e0b\u6e38\u6ce2\u52a8\u7269\u7406\u548c\u51c6\u5e73\u884c\u6fc0\u6ce2\u590d\u6742\u52a8\u529b\u5b66\uff08\u5982\u8868\u9762\u6ce2\u7eb9\u3001\u6fc0\u6ce2\u5b50\u3001SLAMS\u548c\u55b7\u6d41\uff09\u7684\u5fc5\u8981\u6027\u3002  \n\u25c6 \u901a\u8fc7\u53c2\u6570\u7814\u7a76\u9610\u660e\u4e86\u8d28\u91cf\u6bd4\u548c\u7f51\u683c\u5206\u8fa8\u7387\u5bf9\u6fc0\u6ce2\u7269\u7406\u7684\u5f71\u54cd\uff0c\u4e3a\u534a\u9690\u5f0fPIC\u4ee3\u7801\u7684\u7269\u7406\u548c\u6570\u503c\u53c2\u6570\u9009\u62e9\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002  \n\u25c6 \u4e3a\u5c06\u52a8\u529b\u5b66\u6fc0\u6ce2\u8fc7\u7a0b\u6574\u5408\u5230MHD-AEPIC\u6a21\u578b\u7684\u5927\u5c3a\u5ea6\u7a7a\u95f4\u7b49\u79bb\u5b50\u4f53\u6a21\u62df\u4e2d\u5960\u5b9a\u4e86\u57fa\u7840\u3002|\n",
    "2506.09583": "|2025-06-11|VAULT: A Mobile Mapping System for ROS 2-based Autonomous Robots|Miguel \u00c1. Gonz\u00e1lez-Santamarta\u7b49|[2506.09583](http://arxiv.org/pdf/2506.09583)|\u65e0|\u25c6 \u63d0\u51faVAULT\u539f\u578b\u7cfb\u7edf\uff0c\u57fa\u4e8eROS 2\u6846\u67b6\uff0c\u4e13\u4e3a\u6237\u5916\u81ea\u4e3b\u673a\u5668\u4eba\u8bbe\u8ba1\uff0c\u89e3\u51b3\u590d\u6742\u73af\u5883\u4e0b\u7684\u5b9e\u65f6\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u96be\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u878d\u5408\u591a\u4f20\u611f\u5668\u6570\u636e\uff08GNSS\u3001VIO\u3001IMU\uff09\u4e0e\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\uff08EKF\uff09\uff0c\u751f\u6210\u9ad8\u53ef\u9760\u60273D\u91cc\u7a0b\u8ba1\uff0c\u63d0\u5347\u6237\u5916\u5b9a\u4f4d\u9c81\u68d2\u6027\u3002  \n\u25c6 \u7ed3\u5408\u89c6\u89c9SLAM\uff08VSLAM\uff09\u6280\u672f\uff0c\u6784\u5efa\u7cbe\u7ec63D\u70b9\u4e91\u5730\u56fe\uff0c\u5f25\u8865\u4f20\u7edf2D LiDAR\u5728\u6237\u5916\u573a\u666f\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u5b9e\u73b0\u5ba4\u5185\u5916\u73af\u5883\u901a\u7528\u6027\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u4f20\u611f\u5668\u534f\u540c\uff0c\u9002\u5e94\u519c\u4e1a\u3001\u6797\u4e1a\u7b49\u65e0\u7ed3\u6784\u5316\u6237\u5916\u573a\u666f\u9700\u6c42\u3002  \n\u25c6 \u63d0\u4f9b\u5f00\u6e90ROS 2\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u81ea\u4e3b\u673a\u5668\u4eba\u793e\u533a\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u6a21\u5757\u5316\u7684\u79fb\u52a8\u6d4b\u7ed8\u7cfb\u7edf\uff08MMS\uff09\u53c2\u8003\u6846\u67b6\u3002|\n",
    "2506.09278": "|2025-06-10|UFM: A Simple Path towards Unified Dense Correspondence with Flow|Yuchen Zhang\u7b49|[2506.09278](http://arxiv.org/pdf/2506.09278)|\u65e0|\u25c6 \u63d0\u51fa\u7edf\u4e00\u6d41\u4e0e\u5339\u914d\u6a21\u578b\uff08UFM\uff09\uff0c\u9996\u6b21\u5b9e\u73b0\u5bbd\u57fa\u7ebf\u573a\u666f\u548c\u5149\u6d41\u4f30\u8ba1\u7684\u7edf\u4e00\u8bad\u7ec3\uff0c\u7a81\u7834\u4f20\u7edf\u5206\u800c\u6cbb\u4e4b\u7684\u5c40\u9650\u3002  \n\u25c6 \u91c7\u7528\u7b80\u5355\u901a\u7528\u7684Transformer\u67b6\u6784\u76f4\u63a5\u56de\u5f52(u,v)\u6d41\uff0c\u907f\u514d\u4f20\u7edf coarse-to-fine \u4ee3\u4ef7\u4f53\u79ef\u7684\u590d\u6742\u6027\uff0c\u8bad\u7ec3\u66f4\u9ad8\u6548\u4e14\u5bf9\u5927\u4f4d\u79fb\u66f4\u7cbe\u51c6\u3002  \n\u25c6 \u5728\u5149\u6d41\u4efb\u52a1\u4e0a\u7cbe\u5ea6\u8d85\u8d8a\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\uff08Unimatch\uff0928%\uff0c\u5728\u5bbd\u57fa\u7ebf\u5339\u914d\u4efb\u52a1\u4e0a\u8bef\u5dee\u964d\u4f4e62%\u4e14\u901f\u5ea6\u63d0\u53476.7\u500d\uff08\u5bf9\u6bd4RoMa\uff09\u3002  \n\u25c6 \u9996\u6b21\u8bc1\u660e\u7edf\u4e00\u8bad\u7ec3\u6a21\u578b\u53ef\u540c\u65f6\u5728\u5149\u6d41\u548c\u5bbd\u57fa\u7ebf\u5339\u914d\u4e24\u4e2a\u9886\u57df\u8d85\u8d8a\u4e13\u7528\u65b9\u6cd5\uff0c\u4e3a\u901a\u7528\u7a20\u5bc6\u5bf9\u5e94\u5f00\u8f9f\u65b0\u8def\u5f84\u3002  \n\u25c6 \u901a\u8fc7\u5171\u53ef\u89c1\u50cf\u7d20\u7684\u7edf\u4e00\u6570\u636e\u8bad\u7ec3\uff0c\u4e3a\u591a\u6a21\u6001\u3001\u957f\u8ddd\u79bb\u548c\u5b9e\u65f6\u5bf9\u5e94\u4efb\u52a1\u63d0\u4f9b\u65b0\u601d\u8def\u3002|\n",
    "2506.10567": "|2025-06-12|LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System|Hongbeen Park\u7b49|[2506.10567](http://arxiv.org/pdf/2506.10567)|\u65e0|\u25c6 \u63d0\u51faLRSLAM\u6a21\u578b\uff0c\u91c7\u7528\u4f4e\u79e9\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\uff08Six-axis\u548cCP\u5206\u89e3\uff09\u4f18\u5316\u7a20\u5bc6\u89c6\u89c9SLAM\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u5185\u5b58\u5229\u7528\u7387\u3002  \n\u25c6 \u901a\u8fc7\u4f4e\u79e9\u8868\u793a\u6709\u7b26\u53f7\u8ddd\u79bb\u573a\uff08SDF\uff09\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u795e\u7ecf\u9690\u5f0f\u8868\u793a\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u5185\u5b58\u5360\u7528\u95ee\u9898\uff0c\u9002\u5408\u5927\u89c4\u6a21\u573a\u666f\u3002  \n\u25c6 \u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff08\u5982ESLAM\u7684\u5e73\u9762\u5f20\u91cf\u5206\u89e3\uff09\uff0c\u8fdb\u4e00\u6b65\u964d\u4f4e\u4e86\u5185\u5b58\u589e\u957f\u538b\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u91cd\u5efa\u4e0e\u5b9a\u4f4d\u80fd\u529b\u3002  \n\u25c6 \u5728\u591a\u79cd\u5ba4\u5185RGB-D\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cLRSLAM\u5728\u53c2\u6570\u6548\u7387\u3001\u5904\u7406\u901f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\u3002  \n\u25c6 \u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u9ad8\u7684\u7cfb\u7edf\u9c81\u68d2\u6027\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u3001\u79fb\u52a8\u673a\u5668\u4eba\u7b49\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u4ee3\u7801\u5c06\u5f00\u6e90\uff0c\u4fc3\u8fdb\u76f8\u5173\u9886\u57df\u7814\u7a76\u53d1\u5c55\u3002|\n",
    "2506.13664": "|2025-06-16|Slanted light-sheet array microscopy for large volume imaging at rates exceeding 100 Hz|Kai Long\u7b49|[2506.13664](http://arxiv.org/pdf/2506.13664)|\u65e0|\u25c6 \u5f00\u53d1\u4e86\u503e\u659c\u5149\u7247\u9635\u5217\u663e\u5fae\u955c\uff08SLAM\uff09\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc7100 Hz\u7684\u8d85\u5feb\u901f\u5927\u4f53\u79ef\u6210\u50cf\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u6210\u50cf\u901f\u5ea6\u9650\u5236\u3002  \n\u25c6 \u57fa\u4e8e\u6807\u51c6\u5bbd\u573a\u590d\u5408\u663e\u5fae\u955c\u8fdb\u884c\u7b80\u5355\u6539\u9020\uff0c\u4ec5\u9700\u5bf9\u7167\u660e\u5149\u8def\u8fdb\u884c\u6700\u5c0f\u5316\u4fee\u6539\uff0c\u4fbf\u4e8e\u96c6\u6210\u548c\u63a8\u5e7f\u3002  \n\u25c6 \u652f\u6301\u5927\u8303\u56f4\u591a\u7ef4\u5ea6\u9ad8\u5206\u8fa8\u7387\u6210\u50cf\uff08\u6a2a\u5411\u8d85\u8fc7500\u50cf\u7d20\uff0c\u6df1\u5ea6\u8d85\u8fc7200\u5c42\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u5149\u5b66\u5207\u7247\u548c\u5c40\u90e8\u5149\u5316\u5b66\u80fd\u529b\u3002  \n\u25c6 \u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\uff08\u6761\u4ef6\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\uff09\uff0c\u5b9e\u73b0\u4e86\u5404\u5411\u540c\u6027\u5206\u8fa8\u7387\u63d0\u5347\uff0c\u4f18\u5316\u4e86\u56fe\u50cf\u8d28\u91cf\u3002  \n\u25c6 \u517c\u5bb9\u5e38\u89c4\u751f\u7269\u6837\u672c\u5236\u5907\u534f\u8bae\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u751f\u7269\u533b\u5b66\u7814\u7a76\u573a\u666f\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002  \n\u25c6 \u5728\u9ad8\u901f\u6210\u50cf\u7684\u540c\u65f6\u517c\u987e\u4e86\u7a7a\u95f4\u5206\u8fa8\u7387\u3001\u4fe1\u566a\u6bd4\u548c\u5927\u89c6\u573a\u9700\u6c42\uff0c\u4e3a\u52a8\u6001\u751f\u7269\u8fc7\u7a0b\u89c2\u6d4b\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002|\n",
    "2506.13149": "|2025-06-16|Cognitive Synergy Architecture: SEGO for Human-Centric Collaborative Robots|Jaehong Oh|[2506.13149](http://arxiv.org/pdf/2506.13149)|\u65e0|\u25c6 \u63d0\u51faSEGO\uff08\u8bed\u4e49\u56fe\u8c31\u672c\u4f53\uff09\u8ba4\u77e5\u6620\u5c04\u67b6\u6784\uff0c\u9996\u6b21\u5c06\u51e0\u4f55\u611f\u77e5\u3001\u8bed\u4e49\u63a8\u7406\u548c\u89e3\u91ca\u751f\u6210\u6574\u5408\u4e3a\u7edf\u4e00\u6846\u67b6\uff0c\u5b9e\u73b0\u4eba\u673a\u534f\u4f5c\u673a\u5668\u4eba\u7684\u8ba4\u77e5\u534f\u540c\u3002  \n\u25c6 \u6784\u5efa\u52a8\u6001\u8ba4\u77e5\u573a\u666f\u56fe\uff0c\u7a81\u7834\u4f20\u7edfSLAM\u4ec5\u5173\u6ce8\u7a7a\u95f4\u51e0\u4f55\u7684\u5c40\u9650\uff0c\u540c\u65f6\u8868\u5f81\u73af\u5883\u4e2d\u7684\u8bed\u4e49\u5173\u7cfb\u548c\u672c\u4f53\u4e00\u81f4\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u878d\u5408\u57fa\u4e8eSLAM\u7684\u5b9a\u4f4d\u3001\u6df1\u5ea6\u5b66\u4e60\u7269\u4f53\u68c0\u6d4b\u8ddf\u8e2a\u4e0e\u672c\u4f53\u9a71\u52a8\u63a8\u7406\u4e09\u5927\u6a21\u5757\uff0c\u5b9e\u73b0\u5b9e\u65f6\u8bed\u4e49\u8fde\u8d2f\u7684\u73af\u5883\u5efa\u6a21\u3002  \n\u25c6 \u901a\u8fc7\u672c\u4f53\u8bba\u7ea6\u675f\u786e\u4fdd\u8bed\u4e49\u63a8\u7406\u7684\u903b\u8f91\u4e00\u81f4\u6027\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u7406\u89e3\"\u684c\u5b50\u4e0a\u7684\u676f\u5b50\"\u7b49\u590d\u6742\u8bed\u4e49\u5173\u7cfb\u3002  \n\u25c6 \u652f\u6301\u53ef\u89e3\u91ca\u6027\u8f93\u51fa\uff0c\u673a\u5668\u4eba\u53ef\u751f\u6210\u5bf9\u4eba\u7c7b\u53cb\u597d\u7684\u573a\u666f\u89e3\u91ca\uff0c\u663e\u8457\u63d0\u5347\u4eba\u673a\u534f\u4f5c\u7684\u900f\u660e\u5ea6\u548c\u4fe1\u4efb\u5ea6\u3002  \n\u25c6 \u8be5\u67b6\u6784\u4e3a\u4eba\u7c7b\u4e2d\u5fc3\u534f\u4f5c\u673a\u5668\u4eba\u63d0\u4f9b\u6807\u51c6\u5316\u8ba4\u77e5\u5904\u7406\u6d41\u7a0b\uff0c\u5728\u5de5\u4e1a\u88c5\u914d\u3001\u5bb6\u5ead\u670d\u52a1\u7b49\u573a\u666f\u5c55\u73b0\u5e94\u7528\u6f5c\u529b\u3002|\n",
    "2506.13100": "|2025-06-16|A Novel ViDAR Device With Visual Inertial Encoder Odometry and Reinforcement Learning-Based Active SLAM Method|Zhanhua Xin\u7b49|[2506.13100](http://arxiv.org/pdf/2506.13100)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578bViDAR\u8bbe\u5907\uff0c\u7ed3\u5408\u89c6\u89c9\u3001\u60ef\u6027\u548c\u7535\u673a\u7f16\u7801\u5668\uff0c\u6784\u5efa\u7d27\u8026\u5408\u7684\u89c6\u89c9-\u60ef\u6027-\u7f16\u7801\u5668\u91cc\u7a0b\u8ba1\uff08VIEO\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86SLAM\u7cfb\u7edf\u7684\u4e3b\u52a8\u80fd\u529b\u548c\u89c6\u91ce\u8303\u56f4\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86ViDAR\u6821\u51c6\u65b9\u6cd5\uff0c\u786e\u4fddVIEO\u7b97\u6cd5\u7684\u7cbe\u786e\u521d\u59cb\u5316\uff0c\u89e3\u51b3\u4e86\u591a\u4f20\u611f\u5668\u878d\u5408\u4e2d\u7684\u6807\u5b9a\u96be\u9898\u3002  \n\u25c6 \u9996\u6b21\u5c06\u7535\u673a\u7f16\u7801\u5668\u5f15\u5165SLAM\u7cfb\u7edf\uff0c\u4ee5\u6781\u4f4e\u7684\u6210\u672c\u548c\u7ed3\u6784\u590d\u6742\u5ea6\u589e\u5f3a\u4e86\u8de8\u5e27\u5171\u89c6\u5173\u7cfb\uff0c\u63d0\u9ad8\u4e86\u72b6\u6001\u4f30\u8ba1\u7cbe\u5ea6\u3002  \n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u7684\u5e73\u53f0\u8fd0\u52a8\u89e3\u8026\u4e3b\u52a8SLAM\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u4e3b\u4f18\u5316\u8fd0\u52a8\u7b56\u7565\u4ee5\u589e\u52a0\u7279\u5f81\u70b9\u591a\u6837\u6027\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0VIEO\u7b97\u6cd5\u76f8\u6bd4\u4f20\u7edfVIO\u7b97\u6cd5\u5728\u5171\u89c6\u5173\u7cfb\u548c\u4f30\u8ba1\u7cbe\u5ea6\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e14DRL\u4e3b\u52a8SLAM\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u7cfb\u7edf\u6027\u80fd\u3002  \n\u25c6 \u4e3a\u590d\u6742\u73af\u5883\u4e0b\u4e3b\u52a8SLAM\u7cfb\u7edf\u7684\u5e73\u53f0\u8bbe\u8ba1\u548c\u8fd0\u52a8\u89e3\u8026\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u517c\u5177\u7406\u8bba\u521b\u65b0\u548c\u5b9e\u7528\u4ef7\u503c\u3002|\n",
    "2506.13089": "|2025-06-16|SuperPoint-SLAM3: Augmenting ORB-SLAM3 with Deep Features, Adaptive NMS, and Learning-Based Loop Closure|Shahram Najam Syed\u7b49|[2506.13089](http://arxiv.org/pdf/2506.13089)|[\u4ee3\u7801](https://github.com/shahram95/superpointslam3)|\u25c6 \u7528\u81ea\u76d1\u7763\u7684SuperPoint\u7279\u5f81\u68c0\u6d4b-\u63cf\u8ff0\u5b50\u66ff\u4ee3\u4f20\u7edfORB\u7279\u5f81\uff0c\u63d0\u5347\u4e86\u5728\u6781\u7aef\u89c6\u89d2\u3001\u5c3a\u5ea6\u548c\u5149\u7167\u53d8\u5316\u4e0b\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5f15\u5165\u81ea\u9002\u5e94\u975e\u6781\u5927\u503c\u6291\u5236(ANMS)\u6280\u672f\uff0c\u5b9e\u73b0\u7a7a\u95f4\u5206\u5e03\u66f4\u5747\u5300\u7684\u5173\u952e\u70b9\u63d0\u53d6\uff0c\u589e\u5f3a\u573a\u666f\u8986\u76d6\u5ea6\u3002  \n\u25c6 \u96c6\u6210\u8f7b\u91cf\u7ea7NetVLAD\u6a21\u5757\u4f5c\u4e3a\u5b66\u4e60\u5f0f\u56de\u73af\u68c0\u6d4b\u5668\uff0c\u663e\u8457\u6539\u5584\u4e86\u4f20\u7edf\u8bcd\u888b\u6a21\u578b\u7684\u8bc6\u522b\u80fd\u529b\u3002  \n\u25c6 \u5728KITTI\u6570\u636e\u96c6\u4e0a\u5c06\u5e73\u5747\u5e73\u79fb\u8bef\u5dee\u4ece4.15%\u964d\u81f30.34%\uff0c\u65cb\u8f6c\u8bef\u5dee\u4ece0.0027\u5ea6/\u7c73\u964d\u81f30.0010\u5ea6/\u7c73\u3002  \n\u25c6 \u5728EuRoC MAV\u6570\u636e\u96c6\u4e0a\u6240\u6709\u5e8f\u5217\u8bef\u5dee\u964d\u4f4e\u7ea650%\uff08\u5982V2_03\u4ece1.58%\u964d\u81f30.79%\uff09\u3002  \n\u25c6 \u4fdd\u6301ORB-SLAM3\u5b9e\u65f6\u6027\u80fd\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u7279\u5f81\u4e0e\u5b66\u4e60\u5f0f\u56de\u73af\u7684\u878d\u5408\u5b9e\u73b0\u4e86\u7cbe\u5ea6\u7a81\u7834\u3002|\n",
    "2506.15402": "|2025-06-18|MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System|Miaoxin Pan\u7b49|[2506.15402](http://arxiv.org/pdf/2506.15402)|\u65e0|\u25c6 \u63d0\u51faMCOO-SLAM\u7cfb\u7edf\uff0c\u9996\u6b21\u5c06\u591a\u76f8\u673a\u5168\u666f\u914d\u7f6e\u5f15\u5165\u7269\u4f53\u7ea7SLAM\uff0c\u89e3\u51b3\u4f20\u7edf\u5355\u76ee\u6216RGB-D\u7cfb\u7edf\u89c6\u573a\u7a84\u3001\u906e\u6321\u654f\u611f\u548c\u6df1\u5ea6\u611f\u77e5\u53d7\u9650\u7684\u95ee\u9898\u3002  \n\u25c6 \u878d\u5408\u70b9\u7279\u5f81\u4e0e\u5f00\u653e\u8bcd\u6c47\u8bed\u4e49\u589e\u5f3a\u7684\u7269\u4f53\u7ea7\u5730\u6807\uff0c\u5b9e\u73b0\u590d\u6742\u6237\u5916\u573a\u666f\u4e2d\u66f4\u9c81\u68d2\u4e14\u8bed\u4e49\u4e30\u5bcc\u7684\u5efa\u56fe\u3002  \n\u25c6 \u8bbe\u8ba1\u8bed\u4e49-\u51e0\u4f55-\u65f6\u5e8f\u591a\u6a21\u6001\u878d\u5408\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u8de8\u89c6\u89d2\u7269\u4f53\u5173\u8054\u7684\u51c6\u786e\u6027\uff0c\u6539\u5584\u7269\u4f53\u5efa\u6a21\u4e00\u81f4\u6027\u3002  \n\u25c6 \u521b\u65b0\u5168\u666f\u95ed\u73af\u68c0\u6d4b\u6a21\u5757\uff0c\u901a\u8fc7\u573a\u666f\u7ea7\u63cf\u8ff0\u7b26\u5b9e\u73b0\u89c6\u89d2\u65e0\u5173\u7684\u5730\u70b9\u8bc6\u522b\uff0c\u589e\u5f3a\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u7a33\u5b9a\u6027\u3002  \n\u25c6 \u6784\u5efa\u5206\u5c423D\u573a\u666f\u56fe\u8c31\u62bd\u8c61\u5730\u56fe\uff0c\u4e3a\u673a\u5668\u4eba\u9ad8\u5c42\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u7ed3\u6784\u5316\u8bed\u4e49\u652f\u6301\u3002  \n\u5b9e\u9a8c\u8bc1\u660e\u8be5\u7cfb\u7edf\u5728\u906e\u6321\u3001\u4f4d\u59ff\u53d8\u5316\u548c\u590d\u6742\u73af\u5883\u4e0b\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u4e0e\u53ef\u6269\u5c55\u6027\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002|\n",
    "2506.15242": "|2025-06-24|RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories|Qingsong Yan\u7b49|[2506.15242](http://arxiv.org/pdf/2506.15242)|\u65e0|\u25c6 \u63d0\u51faRA-NeRF\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u590d\u6742\u76f8\u673a\u8f68\u8ff9\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfNeRF\u548c3DGS\u4f9d\u8d56\u51c6\u786e\u4f4d\u59ff\u5148\u9a8c\u7684\u95ee\u9898\u3002  \n\u25c6 \u91c7\u7528\u589e\u91cf\u5f0f\u91cd\u5efa\u6d41\u7a0b\uff0c\u7ed3\u5408\u5149\u5ea6\u4e00\u81f4\u6027\u7ea6\u675f\u548c\u5149\u6d41\u9a71\u52a8\u7684\u4f4d\u59ff\u8c03\u8282\u673a\u5236\uff0c\u63d0\u5347\u4e86\u521d\u59cb\u5316\u548c\u5b9a\u4f4d\u9636\u6bb5\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u9690\u5f0f\u4f4d\u59ff\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u6355\u6349\u76f8\u673a\u8fd0\u52a8\u6a21\u5f0f\u6709\u6548\u6d88\u9664\u4f4d\u59ff\u4f30\u8ba1\u4e2d\u7684\u566a\u58f0\u5e72\u6270\u3002  \n\u25c6 \u5728Tanks&Temple\u548cNeRFBuster\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5176\u4e2dNeRFBuster\u5305\u542b\u6781\u5177\u6311\u6218\u6027\u7684\u76f8\u673a\u8f68\u8ff9\u573a\u666f\u3002  \n\u25c6 \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRA-NeRF\u5728\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u7cbe\u5ea6\u548c\u573a\u666f\u91cd\u5efa\u89c6\u89c9\u8d28\u91cf\u4e0a\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5c24\u5176\u5728\u590d\u6742\u8f68\u8ff9\u6761\u4ef6\u4e0b\u8868\u73b0\u7a81\u51fa\u3002|\n",
    "2506.15175": "|2025-06-18|SHeRLoc: Synchronized Heterogeneous Radar Place Recognition for Cross-Modal Localization|Hanjun Kim\u7b49|[2506.15175](http://arxiv.org/pdf/2506.15175)|\u65e0|\u25c6 \u63d0\u51faSHeRLoc\uff0c\u9996\u4e2a\u4e13\u4e3a\u5f02\u6784\u96f7\u8fbe\u8bbe\u8ba1\u7684\u6df1\u5ea6\u7f51\u7edc\uff0c\u586b\u8865\u4e86\u8de8\u6a21\u6001\u96f7\u8fbe\u5b9a\u4f4d\u7814\u7a76\u7684\u7a7a\u767d\u3002  \n\u25c6 \u91c7\u7528RCS\u6781\u5750\u6807\u5339\u914d\u6280\u672f\uff0c\u6709\u6548\u5bf9\u9f50\u591a\u6a21\u6001\u96f7\u8fbe\u6570\u636e\uff0c\u89e3\u51b3\u5f02\u6784\u4f20\u611f\u5668\u6570\u636e\u878d\u5408\u96be\u9898\u3002  \n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u5206\u5c42\u6700\u4f18\u4f20\u8f93\u7684\u7279\u5f81\u805a\u5408\u65b9\u6cd5\uff0c\u751f\u6210\u5177\u6709\u65cb\u8f6c\u9c81\u68d2\u6027\u7684\u591a\u5c3a\u5ea6\u63cf\u8ff0\u7b26\u3002  \n\u25c6 \u7ed3\u5408FFT\u76f8\u4f3c\u6027\u6570\u636e\u6316\u6398\u548c\u81ea\u9002\u5e94\u8fb9\u754c\u4e09\u5143\u7ec4\u635f\u5931\uff0c\u5b9e\u73b0\u89c6\u573a\u611f\u77e5\u7684\u5ea6\u91cf\u5b66\u4e60\u3002  \n\u25c6 \u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u53ec\u56de\u7387@1\u4ece\u4e0d\u8db30.1\u63d0\u5347\u81f30.9\uff0c\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002  \n\u25c6 \u6269\u5c55\u6027\u5f3a\uff0c\u53ef\u5e94\u7528\u4e8eLiDAR\u7b49\u4f20\u611f\u5668\uff0c\u4e3a\u8de8\u6a21\u6001\u5730\u70b9\u8bc6\u522b\u548c\u5f02\u6784SLAM\u5f00\u8f9f\u65b0\u9014\u5f84\u3002|\n",
    "2506.15126": "|2025-06-18|VIMS: A Visual-Inertial-Magnetic-Sonar SLAM System in Underwater Environments|Bingbing Zhang\u7b49|[2506.15126](http://arxiv.org/pdf/2506.15126)|\u65e0|\u25c6 \u63d0\u51faVIMS\u7cfb\u7edf\uff0c\u9996\u6b21\u5c06\u89c6\u89c9-\u60ef\u6027-\u78c1\u529b-\u58f0\u7eb3\u591a\u6a21\u6001\u878d\u5408\u7528\u4e8e\u6c34\u4e0bSLAM\uff0c\u89e3\u51b3\u4f20\u7edf\u89c6\u89c9-\u60ef\u6027\u65b9\u6cd5\u5728\u6c34\u4e0b\u73af\u5883\u4e2d\u7684\u5c3a\u5ea6\u4f30\u8ba1\u548c\u95ed\u73af\u96be\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5f15\u5165\u4f4e\u6210\u672c\u5355\u6ce2\u675f\u58f0\u7eb3\uff0c\u6709\u6548\u63d0\u5347\u6c34\u4e0b\u5c3a\u5ea6\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u514b\u670d\u7eaf\u89c6\u89c9\u65b9\u6cd5\u56e0\u6c34\u4f53\u6298\u5c04\u5bfc\u81f4\u7684\u5c3a\u5ea6\u6f02\u79fb\u95ee\u9898\u3002  \n\u25c6 \u5229\u7528\u9ad8\u91c7\u6837\u7387\u78c1\u529b\u8ba1\u914d\u5408\u7ecf\u6d4e\u578b\u78c1\u573a\u7ebf\u5708\u751f\u6210\u78c1\u7279\u5f81\uff0c\u5b9e\u73b0\u57fa\u4e8e\u78c1\u573a\u6307\u7eb9\u7684\u573a\u6240\u8bc6\u522b\uff0c\u586b\u8865\u6c34\u4e0b\u65e0\u7eb9\u7406\u533a\u57df\u7684\u611f\u77e5\u7a7a\u767d\u3002  \n\u25c6 \u8bbe\u8ba1\u5206\u5c42\u5f0f\u89c6\u89c9-\u78c1\u529b\u6df7\u5408\u95ed\u73af\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u6570\u636e\u4e92\u8865\u589e\u5f3a\u95ed\u73af\u9c81\u68d2\u6027\uff0c\u663e\u8457\u964d\u4f4e\u8bef\u5339\u914d\u7387\u3002  \n\u25c6 \u4f18\u5316\u524d\u7aef\u8ba1\u7b97\u8d1f\u8f7d\uff0c\u5e73\u8861\u5c40\u90e8\u7279\u5f81\u8ddf\u8e2a\u4e0e\u5168\u5c40\u63cf\u8ff0\u5b50\u5339\u914d\uff0c\u5728\u4e0d\u589e\u52a0\u524d\u7aef\u8d1f\u62c5\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u9ad8\u6548\u95ed\u73af\u3002  \n\u25c6 \u5b9e\u9a8c\u9a8c\u8bc1\u7cfb\u7edf\u5728\u590d\u6742\u6c34\u4e0b\u73af\u5883\u4e2d\u7684\u4f18\u8d8a\u6027\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5b9a\u4f4d\u7cbe\u5ea6\u63d0\u534730%\u4ee5\u4e0a\uff0c\u4e3a\u4f4e\u6210\u672c\u6c34\u4e0b\u81ea\u4e3b\u5bfc\u822a\u63d0\u4f9b\u65b0\u65b9\u6848\u3002|\n",
    "2506.18885": "|2025-06-23|GRAND-SLAM: Local Optimization for Globally Consistent Large-Scale Multi-Agent Gaussian SLAM|Annika Thomas\u7b49|[2506.18885](http://arxiv.org/pdf/2506.18885)|\u65e0|\u25c6 \u63d0\u51fa\u4e86GRAND-SLAM\u65b9\u6cd5\uff0c\u9996\u6b21\u5c063D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u5e94\u7528\u4e8e\u5927\u89c4\u6a21\u6237\u5916\u591a\u667a\u80fd\u4f53SLAM\u573a\u666f\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u4ec5\u9650\u4e8e\u5c0f\u89c4\u6a21\u5ba4\u5185\u73af\u5883\u7684\u9650\u5236\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u57fa\u4e8e\u5c40\u90e8\u5b50\u5730\u56fe\u4f18\u5316\u7684\u9690\u5f0f\u8ddf\u8e2a\u6a21\u5757\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u673a\u5668\u4eba\u5185/\u95f4\u95ed\u73af\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u4f4d\u59ff\u56fe\u4f18\u5316\u6846\u67b6\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u4e00\u81f4\u6027\u7684\u5927\u89c4\u6a21\u573a\u666f\u91cd\u5efa\u3002  \n\u25c6 \u5728Replica\u5ba4\u5185\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u5f53\u524d\u6700\u4f18\u7684\u8ddf\u8e2a\u6027\u80fd\uff0cPSNR\u6307\u6807\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534728%\u3002  \n\u25c6 \u5728\u5927\u578b\u6237\u5916Kimera-Multi\u6570\u636e\u96c6\u4e0a\uff0c\u591a\u667a\u80fd\u4f53\u8ddf\u8e2a\u8bef\u5dee\u964d\u4f4e91%\uff0c\u6e32\u67d3\u8d28\u91cf\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002  \n\u25c6 \u901a\u8fc7\u53ef\u6269\u5c55\u7684\u73af\u5883\u8868\u793a\u65b9\u6cd5\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u534f\u540c\u5feb\u901f\u63a2\u7d22\u4e0e\u91cd\u5efa\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2506.18678": "|2025-06-23|MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation|Tianchen Deng\u7b49|[2506.18678](http://arxiv.org/pdf/2506.18678)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u795e\u7ecfSLAM\u6846\u67b6MCN-SLAM\uff0c\u7ed3\u5408\u6df7\u5408\u9690\u5f0f\u795e\u7ecf\u573a\u666f\u8868\u793a\uff0c\u89e3\u51b3\u4f20\u7edf\u5355\u667a\u80fd\u4f53SLAM\u5728\u5927\u573a\u666f\u548c\u957f\u5e8f\u5217\u4e2d\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u521b\u65b0\u8bbe\u8ba1\u4e09\u5e73\u9762-\u7f51\u683c\u8054\u5408\u573a\u666f\u8868\u793a\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u573a\u666f\u91cd\u5efa\u8d28\u91cf\uff0c\u4f18\u4e8e\u73b0\u6709\u795e\u7ecf\u9690\u5f0f\u8868\u793a\u65b9\u6848\u3002  \n\u25c6 \u5f00\u53d1\u65b0\u578b\"\u5185\u90e8-\u8de8\u667a\u80fd\u4f53\"\u95ed\u73af\u68c0\u6d4b\u673a\u5236\uff0c\u9996\u6b21\u5b9e\u73b0\u5355\u667a\u80fd\u4f53\u5c40\u90e8\u4e0e\u591a\u667a\u80fd\u4f53\u5168\u5c40\u4e00\u81f4\u6027\u534f\u540c\u4f18\u5316\u3002  \n\u25c6 \u63d0\u51fa\u5728\u7ebf\u84b8\u998f\u65b9\u6cd5\u5b9e\u73b0\u591a\u5b50\u5730\u56fe\u878d\u5408\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u901a\u4fe1\u4f18\u5316\u89e3\u51b3NeRF\u7c7b\u7cfb\u7edf\u5e26\u5bbd\u53d7\u9650\u95ee\u9898\u3002  \n\u25c6 \u53d1\u5e03\u9996\u4e2a\u771f\u5b9e\u4e16\u754c\u5bc6\u96c6SLAM\u6570\u636e\u96c6DES\uff0c\u6db5\u76d6\u5355/\u591a\u667a\u80fd\u4f53\u573a\u666f\uff0c\u63d0\u4f9b\u8fde\u7eed\u8f68\u8ff9\u4e0e\u9ad8\u7cbe\u5ea63D\u7f51\u683c\u771f\u503c\uff0c\u586b\u8865\u9886\u57df\u7a7a\u767d\u3002  \n\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5efa\u56fe\u3001\u5b9a\u4f4d\u548c\u901a\u4fe1\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u5c06\u5f00\u6e90\u63a8\u52a8SLAM\u4e0e\u4e09\u7ef4\u91cd\u5efa\u7814\u7a76\u53d1\u5c55\u3002|\n",
    "2506.18204": "|2025-06-24|Multimodal Fusion SLAM with Fourier Attention|Youjie Zhou\u7b49|[2506.18204](http://arxiv.org/pdf/2506.18204)|\u65e0|\u25c6 \u63d0\u51faFMF-SLAM\u65b9\u6cd5\uff0c\u901a\u8fc7\u5feb\u901f\u5085\u91cc\u53f6\u53d8\u6362\uff08FFT\uff09\u63d0\u5347\u591a\u6a21\u6001SLAM\u7684\u7b97\u6cd5\u6548\u7387\uff0c\u89e3\u51b3\u4f20\u7edf\u5149\u6d41SLAM\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u5927\u7684\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u8bbe\u8ba1\u57fa\u4e8e\u5085\u91cc\u53f6\u7684\u81ea\u6ce8\u610f\u529b\u4e0e\u8de8\u6ce8\u610f\u529b\u673a\u5236\uff0c\u6709\u6548\u878d\u5408RGB\u548c\u6df1\u5ea6\u4fe1\u53f7\u7684\u7279\u5f81\u63d0\u53d6\u3002  \n\u25c6 \u5f15\u5165\u591a\u5c3a\u5ea6\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u6280\u672f\uff0c\u589e\u5f3a\u591a\u6a21\u6001\u7279\u5f81\u95f4\u7684\u4ea4\u4e92\u4e0e\u4e92\u8865\u6027\u3002  \n\u25c6 \u7ed3\u5408GNSS-RTK\u5168\u5c40\u5b9a\u4f4d\u6a21\u5757\u4e0e\u5168\u5c40Bundle Adjustment\uff0c\u5b9e\u73b0\u5b89\u5168\u673a\u5668\u4eba\u7684\u5b9e\u65f6\u5e94\u7528\u9a8c\u8bc1\u3002  \n\u25c6 \u5728TUM\u3001TartanAir\u53ca\u771f\u5b9e\u573a\u666f\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6027\u80fd\uff0c\u5728\u566a\u58f0\u3001\u5149\u7167\u53d8\u5316\u548c\u9ed1\u6697\u6761\u4ef6\u4e0b\u8fbe\u5230\u9886\u5148\u6c34\u5e73\u3002  \n\u25c6 \u516c\u5f00\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u591a\u6a21\u6001SLAM\u9886\u57df\u7684\u53ef\u590d\u73b0\u7814\u7a76\u3002|\n",
    "2506.18016": "|2025-06-22|ADA-DPM: A Neural Descriptors-based Adaptive Noise Point Filtering Strategy for SLAM|Yongxin Shao\u7b49|[2506.18016](http://arxiv.org/pdf/2506.18016)|\u65e0|\u25c6 \u63d0\u51faADA-DPM\u81ea\u9002\u5e94\u566a\u58f0\u8fc7\u6ee4\u7b56\u7565\uff0c\u5728\u52a8\u6001\u7269\u4f53\u5e72\u6270\u548c\u566a\u58f0\u73af\u5883\u4e0b\u540c\u65f6\u63d0\u5347SLAM\u5b9a\u4f4d\u7cbe\u5ea6\u4e0e\u7cfb\u7edf\u9c81\u68d2\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u52a8\u6001\u5206\u5272\u5934\uff08Dynamic Segmentation Head\uff09\uff0c\u901a\u8fc7\u9884\u6d4b\u7279\u5f81\u70b9\u7c7b\u522b\u4e3b\u52a8\u5254\u9664\u52a8\u6001\u7279\u5f81\u70b9\uff0c\u51cf\u5c11\u52a8\u6001\u5e72\u6270\u3002  \n\u25c6 \u5f15\u5165\u5168\u5c40\u91cd\u8981\u6027\u8bc4\u5206\u5934\uff08Global Importance Scoring Head\uff09\uff0c\u81ea\u9002\u5e94\u7b5b\u9009\u9ad8\u8d21\u732e\u7279\u5f81\u70b9\u5e76\u6291\u5236\u566a\u58f0\u5e72\u6270\uff0c\u4f18\u5316\u7279\u5f81\u9009\u62e9\u3002  \n\u25c6 \u6784\u5efa\u8de8\u5c42\u56fe\u5185\u5377\u79ef\u6a21\u5757\uff08GLI-GCN\uff09\uff0c\u878d\u5408\u591a\u5c3a\u5ea6\u90bb\u57df\u7ed3\u6784\uff0c\u589e\u5f3a\u91cd\u53e0\u7279\u5f81\u7684\u5224\u522b\u80fd\u529b\u3002  \n\u25c6 \u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002|\n",
    "2506.17775": "|2025-06-21|Optimizing Exploration with a New Uncertainty Framework for Active SLAM Systems|Sebastian Sansoni\u7b49|[2506.17775](http://arxiv.org/pdf/2506.17775)|\u65e0|\u25c6\u63d0\u51fa\u4e0d\u786e\u5b9a\u6027\u5730\u56fe\uff08UM\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6982\u7387\u5206\u5e03\u91cf\u5316\u5730\u56fe\u4e0d\u786e\u5b9a\u6027\uff0c\u4e3a\u4e3b\u52a8SLAM\u7cfb\u7edf\u5efa\u7acb\u65b0\u578b\u73af\u5883\u5efa\u6a21\u65b9\u6cd5\u3002  \n\u25c6\u5b9a\u4e49\u4e0d\u786e\u5b9a\u6027\u8fb9\u754c\uff08UF\uff09\u4f5c\u4e3a\u63a2\u7d22-\u5f00\u53d1\u7684\u5173\u952e\u76ee\u6807\u4e0e\u505c\u6b62\u51c6\u5219\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u63a2\u7d22\u7ec8\u6b62\u6761\u4ef6\u6a21\u7cca\u7684\u95ee\u9898\u3002  \n\u25c6\u521b\u65b0\u6027\u5f15\u5165\u57fa\u4e8eKL\u6563\u5ea6\u7684\u7b26\u53f7\u76f8\u5bf9\u71b5\uff08SiREn\uff09\uff0c\u9996\u6b21\u5b9e\u73b0\u8986\u76d6\u5ea6\u4e0e\u4e0d\u786e\u5b9a\u6027\u7684\u8054\u5408\u5ea6\u91cf\uff0c\u4ec5\u9700\u5355\u4e00\u53c2\u6570\u5373\u53ef\u5e73\u8861\u63a2\u7d22\u4e0e\u5f00\u53d1\u3002  \n\u25c6\u8bbe\u8ba1\u4f20\u611f\u5668\u65e0\u5173\u7684\u901a\u7528\u67b6\u6784\uff0c\u517c\u5bb9\u76f8\u673a\u3001\u6fc0\u5149\u96f7\u8fbe\u53ca\u591a\u4f20\u611f\u5668\u878d\u5408\u7cfb\u7edf\uff0c\u7a81\u7834\u73b0\u6709\u65b9\u6cd5\u5bf9\u7279\u5b9aSLAM\u914d\u7f6e\u7684\u4f9d\u8d56\u3002  \n\u25c6\u7ed3\u5408UF\u7684\u8def\u5f84\u89c4\u5212\u7cfb\u7edf\u9996\u6b21\u5b9e\u73b0\u5f00\u653e\u7a7a\u95f4\u7684\u81ea\u4e3b\u63a2\u7d22\u80fd\u529b\uff0c\u586b\u8865\u4e86\u4e3b\u52a8SLAM\u6587\u732e\u4e2d\u8be5\u884c\u4e3a\u7684\u7a7a\u767d\u3002  \n\u25c6\u5f00\u6e90ROS\u8282\u70b9\u4e0e\u5b8c\u6574\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u65b9\u6cd5\u9a8c\u8bc1\u4e0e\u793e\u533a\u5e94\u7528\uff0c\u589e\u5f3a\u7814\u7a76\u53ef\u590d\u73b0\u6027\u3002|\n",
    "2506.20394": "|2025-06-25|SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning|Mimo Shirasaka\u7b49|[2506.20394](http://arxiv.org/pdf/2506.20394)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u5728\u7ebf\u8bed\u4e49\u4fe1\u606f\u66f4\u65b0\u6846\u67b6SPARK\uff0c\u89e3\u51b3\u673a\u5668\u4eba\u4efb\u52a1\u6267\u884c\u4e2d\u8bed\u4e49\u4fe1\u606f\u5b9e\u65f6\u66f4\u65b0\u7684\u7a7a\u767d\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u79bb\u7ebf\u573a\u666f\u56fe\u8868\u793a\u6269\u5c55\u5230\u5728\u7ebf\u573a\u666f\uff0c\u63d0\u5347\u52a8\u6001\u73af\u5883\u4e0b\u7684\u8bed\u4e49\u4fe1\u606f\u5904\u7406\u80fd\u529b\u3002  \n\u25c6 \u901a\u8fc7\u73af\u5883\u5d4c\u5165\u7ebf\u7d22\uff08\u5982\u624b\u52bf\u7b49\u975e\u4f20\u7edf\u7a7a\u95f4\u63d0\u793a\uff09\u5b9e\u65f6\u66f4\u65b0\u573a\u666f\u56fe\uff0c\u589e\u5f3a\u673a\u5668\u4eba\u5bf9\u52a8\u6001\u73af\u5883\u7684\u9002\u5e94\u6027\u3002  \n\u25c6 \u9a8c\u8bc1\u4e86\u57fa\u4e8e\u56fe\u7684\u7a7a\u95f4\u5173\u7cfb\u8868\u793a\u80fd\u663e\u8457\u63d0\u5347\u4efb\u52a1\u89c4\u5212\u6548\u7387\uff0c\u5c24\u5176\u5728\u975e\u7ed3\u6784\u5316\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\u3002  \n\u25c6 \u7cfb\u7edf\u6574\u5408\u51e0\u4f55\u4e0e\u8bed\u4e49\u6570\u636e\uff0c\u4e3a\u901a\u7528\u670d\u52a1\u673a\u5668\u4eba\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u5728\u7ebf\u4fe1\u606f\u66f4\u65b0\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u52a8\u6001\u73af\u5883\u4e2d\u7684\u8bed\u4e49\u53d8\u5316\uff0c\u4e3a\u540e\u7eed\u4efb\u52a1\u89c4\u5212\u63d0\u4f9b\u53ef\u9760\u652f\u6301\u3002|\n",
    "2506.20311": "|2025-06-25|Real-Time Obstacle Avoidance Algorithms for Unmanned Aerial and Ground Vehicles|Jingwen Wei|[2506.20311](http://arxiv.org/pdf/2506.20311)|\u65e0|\u25c6 \u5f00\u53d1\u4e86\u9002\u7528\u4e8e\u590d\u67423D\u73af\u5883\u7684\u5b9e\u65f6\u907f\u969c\u7b97\u6cd5\uff0c\u7279\u522b\u9488\u5bf9\u68ee\u6797\u706b\u707e\u7b49\u707e\u5bb3\u573a\u666f\u4e2d\u7684\u65e0\u4eba\u673a\u5b89\u5168\u5bfc\u822a\u9700\u6c42\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u76842D\u878d\u5408\u5bfc\u822a\u7b56\u7565\uff0c\u6700\u521d\u4e3a\u5730\u9762\u79fb\u52a8\u673a\u5668\u4eba\u8bbe\u8ba1\uff0c\u5177\u5907\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b89\u5168\u79fb\u52a8\u80fd\u529b\uff0c\u5e76\u652f\u6301\u81ea\u9002\u5e94\u969c\u788d\u5904\u7406\u4e0e\u51b3\u7b56\u4f18\u5316\u3002  \n\u25c6 \u9996\u6b21\u8bbe\u8ba1\u4e86\u9488\u5bf9\u68ee\u6797\u706b\u707e\u6a21\u62df\u76843D\u53cd\u5e94\u5f0f\u5bfc\u822a\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u5728\u6b64\u7c7b\u7279\u6b8a\u573a\u666f\u4e2d\u7684\u907f\u969c\u96be\u9898\u3002  \n\u25c6 \u63d0\u51fa\u65e0\u4eba\u673a\u4e0e\u5730\u9762\u65e0\u4eba\u8f66\uff08UGV\uff09\u7684\u534f\u540c\u63a7\u5236\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u7a7a\u5730\u8f66\u8f86\u5728\u68ee\u6797\u6551\u63f4\u4efb\u52a1\u4e2d\u7684\u7edf\u4e00\u534f\u8c03\u4f5c\u4e1a\u3002  \n\u25c6 \u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u4e0e\u4eff\u771f\u9a8c\u8bc1\u4e86\u5404\u9636\u6bb5\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u81ea\u7136\u707e\u5bb3\u6551\u63f4\u4e2d\u65e0\u4eba\u7cfb\u7edf\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u517c\u5177\u5b9e\u7528\u4ef7\u503c\u4e0e\u5b66\u672f\u610f\u4e49\u7684\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2506.19957": "|2025-06-24|Posterior Cram\u00e9r-Rao Bounds on Localization and Mapping Errors in Distributed MIMO SLAM|Benjamin J. B. Deutschmann\u7b49|[2506.19957](http://arxiv.org/pdf/2506.19957)|\u65e0|\u25c6 \u9996\u6b21\u63d0\u51fa\u4e86\u9488\u5bf9\u5206\u5e03\u5f0fMIMO SLAM\u7cfb\u7edf\u4e2d\u955c\u9762\u53cd\u5c04\u9762\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u8bef\u5dee\u7684\u540e\u9a8c\u514b\u62c9\u7f8e\u7f57\u4e0b\u754c\uff08MEB\uff09\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u6027\u80fd\u8bc4\u4f30\u7684\u7406\u8bba\u7a7a\u767d\u3002  \n\u25c6 \u8003\u8651\u4e86\u5355\u6b21\u53cd\u5c04\u548c\u53cc\u6b21\u53cd\u5c04\u7684\u590d\u6742\u4f20\u64ad\u573a\u666f\uff0c\u5e76\u652f\u6301\u5206\u5e03\u5f0f\u951a\u70b9\u914d\u7f6e\uff0c\u6269\u5c55\u4e86\u4f20\u7edfSLAM\u6027\u80fd\u8fb9\u754c\u7684\u9002\u7528\u8303\u56f4\u3002  \n\u25c6 \u901a\u8fc7\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u73b0\u6709\u5148\u8fdbRF-SLAM\u7b97\u6cd5\u7684\u5efa\u56fe\u8bef\u5dee\u80fd\u6e10\u8fdb\u6536\u655b\u81f3MEB\uff0c\u4e3a\u7b97\u6cd5\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u51c6\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u6620\u5c04\u6027\u80fd\uff08\u955c\u9762\u4f4d\u7f6e/\u671d\u5411\uff09\u4e0e\u7528\u6237\u5b9a\u4f4d\u6027\u80fd\u7edf\u4e00\u7eb3\u5165\u5168\u5c40\u7279\u5f81\u8bc4\u4f30\u6846\u67b6\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u4ec5\u5173\u6ce8\u5b9a\u4f4d\u7cbe\u5ea6\u7684\u5c40\u9650\u3002  \n\u25c6 \u6240\u63d0\u8fb9\u754c\u7406\u8bba\u53ef\u63d0\u5347\u591a\u5f84\u4fe1\u9053\u4e2d\u975e\u89c6\u8ddd\u4fe1\u53f7\u7684\u5229\u7528\u6548\u7387\uff0c\u4e3a\u901a\u4fe1-\u5b9a\u4f4d\u4e00\u4f53\u5316\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u652f\u6491\u3002|\n",
    "2506.21420": "|2025-06-26|EndoFlow-SLAM: Real-Time Endoscopic SLAM with Flow-Constrained Gaussian Splatting|Taoyu Wu\u7b49|[2506.21420](http://arxiv.org/pdf/2506.21420)|\u65e0|\u25c6 \u63d0\u51faEndoFlow-SLAM\u7cfb\u7edf\uff0c\u9996\u6b21\u5c06\u5149\u6d41\u635f\u5931\u4f5c\u4e3a\u51e0\u4f55\u7ea6\u675f\u5f15\u5165\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7684SLAM\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5185\u7aa5\u955c\u573a\u666f\u4e2d\u975e\u6717\u4f2f\u8868\u9762\u548c\u547c\u5438\u8fd0\u52a8\u5bfc\u81f4\u7684\u4f4d\u59ff\u4f30\u8ba1\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u6df1\u5ea6\u6b63\u5219\u5316\u7b56\u7565\uff0c\u7f13\u89e3\u5185\u7aa5\u955c\u573a\u666f\u7684\u5149\u5ea6\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u786e\u4fdd3DGS\u6df1\u5ea6\u6e32\u67d3\u7684\u53ef\u9760\u6027\u3002  \n\u25c6 \u6539\u8fdb3DGS\u4f18\u5316\u7b56\u7565\uff0c\u9488\u5bf9\u5173\u952e\u5e27\u4e2d\u6e32\u67d3\u8d28\u91cf\u8f83\u5dee\u7684\u89c6\u89d2\u8fdb\u884c\u91cd\u70b9\u4f18\u5316\uff0c\u63d0\u5347\u573a\u666f\u8868\u793a\u7cbe\u5ea6\u3002  \n\u25c6 \u5728\u9759\u6001\uff08C3VD\u6570\u636e\u96c6\uff09\u548c\u52a8\u6001\uff08StereoMIS\u6570\u636e\u96c6\uff09\u624b\u672f\u573a\u666f\u4e2d\u5747\u5b9e\u73b0\u9886\u5148\u6027\u80fd\uff0c\u5728\u65b0\u89c6\u89d2\u5408\u6210\u548c\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002  \n\u25c6 \u7cfb\u7edf\u652f\u6301\u5b9e\u65f6\u8fd0\u884c\uff0c\u4e3a\u5185\u7aa5\u955c\u624b\u672f\u63d0\u4f9b\u9ad8\u6548\u7684\u4e09\u7ef4\u91cd\u5efa\u4e0e\u53ef\u89c6\u5316\u80fd\u529b\u3002|\n",
    "2506.21077": "|2025-06-26|CURL-SLAM: Continuous and Compact LiDAR Mapping|Kaicheng Zhang\u7b49|[2506.21077](http://arxiv.org/pdf/2506.21077)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578bLiDAR SLAM\u8303\u5f0fCURL-SLAM\uff0c\u5229\u7528\u8fde\u7eed\u8d85\u7d27\u51d1\u8868\u793a\uff08CURL\uff09\u5b9e\u73b0\u53ef\u66f4\u65b0\u3001\u53ef\u5b9a\u4f4d\u7684\u5730\u56fe\u8868\u793a\u3002  \n\u25c6 \u91c7\u7528\u7403\u8c10\u51fd\u6570\u9690\u5f0f\u7f16\u7801\u6280\u672f\uff0c\u751f\u6210\u652f\u6301\u53ef\u53d8\u5bc6\u5ea6\u8fde\u7eed\u91cd\u5efa\u7684\u7d27\u51d13D\u5730\u56fe\uff0c\u663e\u8457\u964d\u4f4e\u5b58\u50a8\u9700\u6c42\u3002  \n\u25c6 \u901a\u8fc7\u72ec\u7279\u7684CURL\u5b9a\u5236\u4f18\u5316\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49LiDAR\u4f4d\u59ff\u4f30\u8ba1\uff0c\u66ff\u4ee3\u4f20\u7edfICP\u65b9\u6cd5\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u6269\u5c55\u5c40\u90e8\u5149\u675f\u6cd5\u5e73\u5dee\uff08BA\uff09\u6280\u672f\uff0c\u5b9e\u73b0\u4f4d\u59ff\u7cbe\u4fee\u4e0e\u5730\u56fe\u6821\u6b63\u540c\u6b65\u8fdb\u884c\uff0c\u786e\u4fdd\u95ed\u73af\u540e\u7684\u5168\u5c40\u4e00\u81f4\u6027\u3002  \n\u25c6 \u5728CPU\u4e0a\u8fbe\u523010Hz\u5b9e\u65f6\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u9886\u5148\u76843D\u5efa\u56fe\u8d28\u91cf\u548c\u8f68\u8ff9\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u573a\u666f\u3002  \n\u25c6 \u5f00\u6e90CURL-SLAM\u5b9e\u73b0\uff0c\u63a8\u52a8\u8fde\u7eed\u7d27\u51d1\u5730\u56fe\u8868\u793a\u9886\u57df\u7684\u7814\u7a76\u4e0e\u5e94\u7528\u3002|\n",
    "2506.21798": "|2025-06-26|Adaptive Multipath-Based SLAM for Distributed MIMO Systems|Xuhong Li\u7b49|[2506.21798](http://arxiv.org/pdf/2506.21798)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5206\u5e03\u5f0fMIMO\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u591a\u8def\u5f84SLAM\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u975e\u51f8\u51e0\u4f55\u73af\u5883\u4e2d\u65e0\u6cd5\u8fdb\u884c\u5149\u7ebf\u8ffd\u8e2a\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u5229\u7528\u632f\u5e45\u7edf\u8ba1\u91cf\u5efa\u7acb\u81ea\u9002\u5e94\u65f6\u53d8\u68c0\u6d4b\u6982\u7387\uff0c\u5b9e\u73b0\u4e86\"\u8f6f\"\u5149\u7ebf\u8ffd\u8e2a\u7b56\u7565\uff0c\u80fd\u591f\u5728\u975e\u51f8\u51e0\u4f55\u7684\u5c04\u9891\u73af\u5883\u4e2d\u8de8\u4f20\u64ad\u8def\u5f84\u878d\u5408\u4fe1\u606f\u3002  \n\u25c6 \u901a\u8fc7\u5c06\u548c\u79ef\u7b97\u6cd5(SPA)\u7684\u6d88\u606f\u4f20\u9012\u89c4\u5219\u5e94\u7528\u4e8e\u6240\u63d0\u51fa\u7684\u7edf\u8ba1\u6a21\u578b\u56e0\u5b50\u56fe\uff0c\u5efa\u7acb\u4e86\u5730\u56fe\u7279\u5f81\u548c\u667a\u80fd\u4f53\u4f4d\u7f6e\u8054\u5408\u4f30\u8ba1\u7684\u8d1d\u53f6\u65af\u4f30\u8ba1\u65b9\u6cd5\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5efa\u8bae\u6982\u7387\u5bc6\u5ea6\u51fd\u6570(PDF)\uff0c\u7528\u4e8e\u57fa\u4e8e\u7c92\u5b50\u7684SPA\u6d88\u606f\u8ba1\u7b97\uff0c\u80fd\u591f\u65e9\u671f\u68c0\u6d4b\u4ec5\u7531\u53cc\u8df3\u8def\u5f84\u652f\u6301\u7684\u65b0\u8868\u9762\u3002  \n\u25c6 \u5728\u5177\u6709\u975e\u51f8\u51e0\u4f55\u5f62\u72b6\u7684\u6311\u6218\u6027\u573a\u666f\u4e2d\u4f7f\u7528\u5408\u6210\u5c04\u9891\u6d4b\u91cf\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\uff0c\u7ed3\u679c\u8868\u660e\u5176\u80fd\u591f\u63d0\u4f9b\u51c6\u786e\u7684\u5b9a\u4f4d\u548c\u5efa\u56fe\u4f30\u8ba1\uff0c\u5e76\u8fbe\u5230\u540e\u9a8cCRLB\u754c\u3002|\n",
    "2506.21628": "|2025-06-24|Ark: An Open-source Python-based Framework for Robot Learning|Magnus Dierking\u7b49|[2506.21628](http://arxiv.org/pdf/2506.21628)|\u65e0|\u25c6 \u63d0\u51faARK\u6846\u67b6\uff0c\u9996\u4e2a\u4ee5Python\u4e3a\u6838\u5fc3\u7684\u673a\u5668\u4eba\u5b66\u4e60\u5f00\u6e90\u5e73\u53f0\uff0c\u5f25\u5408\u673a\u5668\u4eba\u6280\u672f\u4e0e\u73b0\u4ee3AI\u5de5\u5177\u94fe\u7684\u9e3f\u6c9f\u3002  \n\u25c6 \u91c7\u7528Gym\u98ce\u683c\u63a5\u53e3\u8bbe\u8ba1\uff0c\u652f\u6301\u6570\u636e\u91c7\u96c6\u3001\u9884\u5904\u7406\u5230\u7b56\u7565\u8bad\u7ec3\u7684\u5168\u6d41\u7a0b\uff0c\u517c\u5bb9\u4eff\u771f\u4e0e\u5b9e\u4f53\u673a\u5668\u4eba\u65e0\u7f1d\u5207\u6362\u3002  \n\u25c6 \u72ec\u521b\u8f7b\u91cf\u7ea7\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u67b6\u6784\uff0c\u5b9e\u73b0\u7f51\u7edc\u5316\u53d1\u5e03-\u8ba2\u9605\u901a\u4fe1\uff0c\u5e76\u4fdd\u7559C/C++\u7ed1\u5b9a\u9009\u9879\u4fdd\u969c\u5b9e\u65f6\u6027\u80fd\u9700\u6c42\u3002  \n\u25c6 \u5185\u7f6e\u63a7\u5236\u3001SLAM\u3001\u8fd0\u52a8\u89c4\u5212\u7b49\u6a21\u5757\u5316\u7ec4\u4ef6\uff0c\u539f\u751f\u652f\u6301ROS\u4ea4\u4e92\uff0c\u63d0\u4f9b\u5f00\u7bb1\u5373\u7528\u7684\u673a\u5668\u4eba\u529f\u80fd\u5957\u4ef6\u3002  \n\u25c6 \u901a\u8fc7\u8be6\u5b9e\u6587\u6863\u548c\u6848\u4f8b\uff08\u5982\u64cd\u4f5c\u4e0e\u5bfc\u822a\u4efb\u52a1\uff09\uff0c\u9a8c\u8bc1\u5176\u5feb\u901f\u539f\u578b\u5f00\u53d1\u3001\u786c\u4ef6\u7075\u6d3b\u5207\u6362\u53ca\u7aef\u5230\u7aef\u6d41\u6c34\u7ebf\u4f18\u52bf\u3002  \n\u25c6 \u7edf\u4e00Python\u751f\u6001\u4e0e\u673a\u5668\u4eba\u5f00\u53d1\uff0c\u663e\u8457\u964d\u4f4e\u5b66\u4e60\u95e8\u69db\uff0c\u52a0\u901f\u5b66\u672f\u7814\u7a76\u4e0e\u5546\u4e1a\u573a\u666f\u7684\u673a\u5668\u4eba\u81ea\u4e3b\u6027\u843d\u5730\u3002|\n",
    "2506.23207": "|2025-06-29|TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints|Zhen Tan\u7b49|[2506.23207](http://arxiv.org/pdf/2506.23207)|\u65e0|TVG-SLAM\u662f\u4e00\u79cd\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7684RGB-only SLAM\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u89c6\u56fe\u51e0\u4f55\u7ea6\u675f\u63d0\u5347\u9c81\u68d2\u6027\u548c\u573a\u666f\u91cd\u5efa\u8d28\u91cf\u3002\u5176\u6838\u5fc3\u8d21\u732e\u548c\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u4e09\u89c6\u56fe\u51e0\u4f55\u8303\u5f0f\uff0c\u901a\u8fc7\u5bc6\u96c6\u4e09\u89c6\u56fe\u5339\u914d\u6a21\u5757\u805a\u5408\u53ef\u9760\u7684\u5e27\u95f4\u5bf9\u5e94\u5173\u7cfb\uff0c\u5f62\u6210\u8de8\u5e27\u7684\u9c81\u68d2\u51e0\u4f55\u7ea6\u675f\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5149\u5ea6\u635f\u5931\u7684\u5c40\u9650\u6027\u3002\n\n\u25c6 \u8bbe\u8ba1\u6df7\u5408\u51e0\u4f55\u7ea6\u675f\uff08Hybrid Geometric Constraints\uff09\uff0c\u7ed3\u5408\u4e09\u89c6\u56fe\u5339\u914d\u7684\u51e0\u4f55\u7ebf\u7d22\u4e0e\u5149\u5ea6\u635f\u5931\uff0c\u663e\u8457\u63d0\u5347\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5c24\u5176\u5728\u89c6\u89d2\u7a81\u53d8\u548c\u5149\u7167\u53d8\u5316\u573a\u666f\u3002\n\n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u6982\u7387\u7684\u521d\u59cb\u5316\u7b56\u7565\uff0c\u5c06\u4e09\u89c6\u56fe\u5bf9\u5e94\u5173\u7cfb\u7684\u51e0\u4f55\u4e0d\u786e\u5b9a\u6027\u7f16\u7801\u5230\u65b0\u521d\u59cb\u5316\u7684\u9ad8\u65af\u6a21\u578b\u4e2d\uff0c\u63d0\u5347\u6620\u5c04\u8d28\u91cf\u3002\n\n\u25c6 \u5f15\u5165\u52a8\u6001\u6e32\u67d3\u4fe1\u4efb\u8870\u51cf\u673a\u5236\uff08Dynamic Attenuation of Rendering Trust\uff09\uff0c\u6709\u6548\u7f13\u89e3\u56e0\u5efa\u56fe\u5ef6\u8fdf\u5bfc\u81f4\u7684\u8ddf\u8e2a\u6f02\u79fb\u95ee\u9898\u3002\n\n\u5b9e\u9a8c\u8868\u660e\uff0cTVG-SLAM\u5728\u6237\u5916\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709RGB-only 3DGS SLAM\u7cfb\u7edf\uff0c\u5728\u6700\u6311\u6218\u6027\u6570\u636e\u96c6\u4e2d\u5c06\u8f68\u8ff9\u8bef\u5dee\uff08ATE\uff09\u964d\u4f4e69.0%\uff0c\u540c\u65f6\u4fdd\u6301\u9876\u5c16\u7684\u6e32\u67d3\u8d28\u91cf\u3002|\n",
    "2506.23078": "|2025-06-29|Event-based Stereo Visual-Inertial Odometry with Voxel Map|Zhaoxing Zhang\u7b49|[2506.23078](http://arxiv.org/pdf/2506.23078)|\u65e0|\u25c6 \u63d0\u51faVoxel-ESVIO\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e8b\u4ef6\u76f8\u673a\u548c\u7acb\u4f53\u89c6\u89c9\u60ef\u6027\u91cc\u7a0b\u8ba1\uff0c\u5229\u7528\u4f53\u7d20\u5730\u56fe\u7ba1\u7406\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\u3002  \n\u25c6 \u91c7\u7528\u57fa\u4e8e\u4f53\u7d20\u7684\u70b9\u9009\u62e9\u65b9\u6cd5\uff0c\u6709\u6548\u8fc7\u6ee4\u4e8b\u4ef6\u6d41\u4e2d\u7684\u566a\u58f0\uff0c\u7b5b\u9009\u9ad8\u8d28\u91cf3D\u5730\u56fe\u70b9\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u4f53\u7d20\u611f\u77e5\u7684\u70b9\u7ba1\u7406\u673a\u5236\uff0c\u52a8\u6001\u4f18\u5316\u6bcf\u4e2a\u4f53\u7d20\u5185\u5730\u56fe\u70b9\u7684\u66f4\u65b0\u548c\u9009\u62e9\u3002  \n\u25c6 \u901a\u8fc7\u534f\u540c\u7b56\u7565\u9ad8\u6548\u63d0\u53d6\u6297\u566a\u58f0\u4e14\u89c2\u6d4b\u6982\u7387\u6700\u9ad8\u7684\u5730\u56fe\u70b9\uff0c\u786e\u4fdd\u72b6\u6001\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002  \n\u25c6 \u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002|\n",
    "2507.00937": "|2025-07-01|RaGNNarok: A Light-Weight Graph Neural Network for Enhancing Radar Point Clouds on Unmanned Ground Vehicles|David Hunt\u7b49|[2507.00937](http://arxiv.org/pdf/2507.00937)|\u65e0|\u25c6\u63d0\u51faRaGNNarok\uff0c\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u7528\u4e8e\u589e\u5f3a\u96f7\u8fbe\u70b9\u4e91\u6570\u636e\uff0c\u89e3\u51b3\u73b0\u6709\u96f7\u8fbe\u5b9a\u4f4d\u4e2d\u7a00\u758f\u70b9\u4e91\u3001\u566a\u58f0\u548c\u8bef\u68c0\u6d4b\u95ee\u9898\u3002  \n\u25c6\u8be5\u6846\u67b6\u5728\u4f4e\u6210\u672c\u8bbe\u5907\uff08\u5982\u6811\u8393\u6d3e5\uff09\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u5904\u7406\uff0c\u63a8\u7406\u65f6\u95f4\u4ec57.3\u6beb\u79d2\uff0c\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u8d44\u6e90\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u79fb\u52a8\u673a\u5668\u4eba\u3002  \n\u25c6\u901a\u8fc7GNN\u6a21\u578b\u4f18\u5316\u96f7\u8fbe\u70b9\u4e91\uff0c\u663e\u8457\u63d0\u5347\u5728\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u6fc0\u5149\u96f7\u8fbe\u548c\u76f8\u673a\u5728\u89c6\u89c9\u906e\u6321\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\u3002  \n\u25c6\u5728\u5b9a\u4f4d\u3001SLAM\u548c\u81ea\u4e3b\u5bfc\u822a\u7b49\u5173\u952e\u4efb\u52a1\u4e2d\u8fdb\u884c\u4e86\u591a\u73af\u5883\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u53ef\u9760\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6\u4e3a\u4f4e\u6210\u672c\u5ba4\u5185\u79fb\u52a8\u673a\u5668\u4eba\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u6beb\u7c73\u6ce2\u96f7\u8fbe\u7684\u4f4e\u6210\u672c\u4f18\u52bf\uff0c\u63a8\u52a8\u81ea\u52a8\u5316\u5728\u5bb6\u5ead\u548c\u5546\u4e1a\u7a7a\u95f4\u7684\u5e94\u7528\u3002|\n",
    "2507.00552": "|2025-07-01|Generation of Indoor Open Street Maps for Robot Navigation from CAD Files|Jiajie Zhang\u7b49|[2507.00552](http://arxiv.org/pdf/2507.00552)|\u65e0|\u25c6 \u63d0\u51fa\u5168\u81ea\u52a8\u7cfb\u7edf\uff0c\u5c06\u5efa\u7b51CAD\u6587\u4ef6\u8f6c\u6362\u4e3a\u5206\u5c42\u62d3\u6251OpenStreetMap\uff08OSM\uff09\u8868\u793a\uff0c\u4e13\u4e3a\u673a\u5668\u4eba\u7ec8\u8eab\u5bfc\u822a\u8bbe\u8ba1\uff0c\u89e3\u51b3SLAM\u5728\u52a8\u6001\u5927\u5c3a\u5ea6\u5ba4\u5185\u73af\u5883\u4e2d\u8017\u65f6\u3001\u8106\u5f31\u4e14\u6613\u8fc7\u65f6\u7684\u95ee\u9898\u3002  \n\u25c6 \u5f00\u53d1\u591a\u9636\u6bb5\u5904\u7406\u6d41\u7a0b\uff0c\u4ece\u539f\u59cbCAD\u6570\u636e\u4e2d\u63d0\u53d6\u5173\u952e\u7ed3\u6784\u5c42\uff0c\u5e76\u57fa\u4e8eAreaGraph\u8fdb\u884c\u62d3\u6251\u5206\u5272\uff0c\u751f\u6210\u5c42\u6b21\u5316\u53ef\u5bfc\u822a\u7a7a\u95f4\u56fe\uff0c\u5b9e\u73b0\u8bed\u4e49\u4e30\u5bcc\u7684\u73af\u5883\u5efa\u6a21\u3002  \n\u25c6 \u81ea\u52a8\u5173\u8054CAD\u6e90\u6587\u4ef6\u4e2d\u7684\u6587\u672c\u6807\u7b7e\uff0c\u589e\u5f3a\u5730\u56fe\u8bed\u4e49\u4fe1\u606f\uff0c\u540c\u65f6\u652f\u6301\u591a\u697c\u5c42\u65e0\u7f1d\u5408\u5e76\uff0c\u6784\u5efa\u62d3\u6251\u6b63\u786e\u7684\u7edf\u4e00\u6a21\u578b\uff0c\u63d0\u5347\u5bfc\u822a\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5229\u7528CAD\u6587\u4ef6\u56fa\u6709\u7684\u6c38\u4e45\u7ed3\u6784\u4fe1\u606f\uff0c\u89c4\u907fSLAM\u7684\u56fa\u6709\u7f3a\u9677\uff0c\u4e3a\u590d\u6742\u5ba4\u5185\u573a\u666f\u63d0\u4f9b\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u96c6\u6210\u76f4\u89c2\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u5c01\u88c5\u8f6f\u4ef6\uff0c\u964d\u4f4e\u4f7f\u7528\u95e8\u69db\uff0c\u5e76\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u4fc3\u8fdb\u793e\u533a\u5e94\u7528\u4e0e\u7814\u7a76\u3002|\n",
    "2507.00243": "|2025-06-30|VOCAL: Visual Odometry via ContrAstive Learning|Chi-Yao Huang\u7b49|[2507.00243](http://arxiv.org/pdf/2507.00243)|\u65e0|\u25c6 VOCAL\u5c06\u89c6\u89c9\u91cc\u7a0b\u8ba1\uff08VO\uff09\u91cd\u65b0\u5b9a\u4e49\u4e3a\u6807\u7b7e\u6392\u5e8f\u95ee\u9898\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u57fa\u4e8e\u51e0\u4f55\u5047\u8bbe\u7684\u5c40\u9650\uff0c\u4e3a\u6570\u636e\u9a71\u52a8\u6846\u67b6\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002  \n\u25c6 \u901a\u8fc7\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u7406\u4e0e\u8868\u5f81\u5b66\u4e60\uff0c\u8be5\u6846\u67b6\u4f7f\u89c6\u89c9\u7279\u5f81\u4e0e\u76f8\u673a\u72b6\u6001\u5bf9\u9f50\uff0c\u63d0\u5347\u4e86\u7279\u5f81\u7684\u53ef\u89e3\u91ca\u6027\u3002  \n\u25c6 \u63d0\u51fa\u7684\u6392\u5e8f\u673a\u5236\u8feb\u4f7f\u76f8\u4f3c\u76f8\u673a\u72b6\u6001\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5f62\u6210\u4e00\u81f4\u4e14\u7a7a\u95f4\u8fde\u8d2f\u7684\u8868\u5f81\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u6846\u67b6\u652f\u6301\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\uff0c\u4e3a\u590d\u6742\u573a\u666f\u4e0b\u7684VO\u5e94\u7528\u63d0\u4f9b\u4e86\u7075\u6d3b\u6027\u3002  \n\u25c6 \u5728KITTI\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86VOCAL\u5728\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u6027\u4e0a\u7684\u663e\u8457\u4f18\u52bf\uff0c\u63a8\u52a8\u4e86\u7a7a\u95f4\u667a\u80fd\u5411\u66f4\u901a\u7528\u3001\u53ef\u89e3\u91ca\u7684\u65b9\u5411\u53d1\u5c55\u3002|\n",
    "2507.04662": "|2025-07-07|Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR|Tao Du\u7b49|[2507.04662](http://arxiv.org/pdf/2507.04662)|\u65e0|\u25c6 \u63d0\u51fa\u5229\u7528\u6beb\u7c73\u6ce25G NR\u7cfb\u7edf\u8fdb\u884c\u4e3b\u52a8\u611f\u77e5\uff0c\u5b9e\u73b0\u7c7b\u4f3c\u6fc0\u5149\u96f7\u8fbe\u7684\u70b9\u4e91\u751f\u6210\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u88ab\u52a8\u611f\u77e5SLAM\u6280\u672f\u5bf9\u955c\u9762\u53cd\u5c04\u5047\u8bbe\u548c\u7b80\u5316\u5730\u56fe\u8868\u793a\u7684\u4f9d\u8d56\u3002  \n\u25c6 \u91c7\u7528\u4e8c\u8fdb\u5236\u641c\u7d22\u65b9\u6cd5\u4ece\u6bcf\u4e2a\u6ce2\u675f\u65b9\u5411\u7684\u529f\u7387\u5ef6\u8fdf\u5256\u9762\u4e2d\u63d0\u53d6\u70b9\u4e91\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u73af\u5883\u611f\u77e5\u7684\u7cbe\u5ea6\u548c\u7ec6\u8282\u3002  \n\u25c6 \u901a\u8fc7\u591a\u4e2a\u9884\u5b9a\u4e49\u76ee\u6807\u70b9\u6821\u51c6\u786c\u4ef6\u5ef6\u8fdf\uff0c\u786e\u4fdd\u70b9\u4e91\u6570\u636e\u7684\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86\u786c\u4ef6\u8bef\u5dee\u5bf9\u5b9a\u4f4d\u7684\u5f71\u54cd\u3002  \n\u25c6 \u5229\u7528\u70b9\u4e91\u914d\u51c6\u7b97\u6cd5\u4ece\u8fde\u7eed\u8f68\u8ff9\u89c6\u89d2\u7684\u70b9\u4e91\u6570\u636e\u4e2d\u4f30\u8ba1\u7ec8\u7aef\u4f4d\u59ff\u53d8\u5316\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u7ec8\u7aef\u5b9a\u4f4d\u3002  \n\u25c6 \u5f15\u5165\u95ed\u73af\u68c0\u6d4b\u548c\u4f4d\u59ff\u56fe\u4f18\u5316\u6280\u672f\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u611f\u77e5\u7ed3\u679c\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u7ec8\u7aef\u5b9a\u4f4d\u548c\u8be6\u7ec6\u7684\u65e0\u7ebf\u7535\u5730\u56fe\u91cd\u5efa\u3002  \n\u25c6 \u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u4e3a5G NR\u5728SLAM\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8df5\u652f\u6301\u3002|\n",
    "2507.04321": "|2025-07-06|Lidar Variability: A Novel Dataset and Comparative Study of Solid-State and Spinning Lidars|Doumegna Mawuto Koudjo Felix\u7b49|[2507.04321](http://arxiv.org/pdf/2507.04321)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u5305\u542b\u7a79\u9876\u5f0f\u56fa\u6001\u6fc0\u5149\u96f7\u8fbe\uff08\u5982Livox Mid-360\uff09\u4e0e\u5176\u4ed6\u56fa\u6001\u53ca\u65cb\u8f6c\u5f0f\u6fc0\u5149\u96f7\u8fbe\uff08\u5982Ouster\u7cfb\u5217\uff09\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u586b\u8865\u4e86\u591a\u7c7b\u578b\u6fc0\u5149\u96f7\u8fbe\u5bf9\u6bd4\u7814\u7a76\u7684\u7a7a\u767d\u3002  \n\u25c6 \u9996\u6b21\u5728\u65e0IMU\u652f\u6301\u7684\u91cc\u7a0b\u8ba1\u573a\u666f\u4e0b\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4f4e\u6210\u672c\u56fa\u6001\u6fc0\u5149\u96f7\u8fbe\uff08Livox Avia/Mid-360\uff09\u4e0e\u9ad8\u7aef\u65cb\u8f6c\u5f0f\u6fc0\u5149\u96f7\u8fbe\u7684\u6027\u80fd\u5dee\u5f02\u3002  \n\u25c6 \u57fa\u4e8e\u8be5\u6570\u636e\u96c6\uff0c\u5bf9\u4e3b\u6d41SLAM\u7b97\u6cd5\u8fdb\u884c\u4e86\u8de8\u4f20\u611f\u5668\u5e73\u53f0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e3a\u5f02\u6784\u6fc0\u5149\u96f7\u8fbe\u7684\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u53c2\u8003\u3002  \n\u25c6 \u9488\u5bf9\u70b9\u4e91\u914d\u51c6\u6280\u672f\uff0c\u901a\u8fc7\u5ba4\u5185\u5916\u5b9e\u6d4b\u6570\u636e\u5b9a\u91cf\u6bd4\u8f83\u4e86\u70b9\u5bf9\u70b9\u3001\u70b9\u5bf9\u5e73\u9762\u53ca\u6df7\u5408\u65b9\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u3002  \n\u25c6 \u7814\u7a76\u7ed3\u679c\u4e3aSLAM\u548c3D\u91cd\u5efa\u9886\u57df\u5728\u4f4e\u6210\u672c\u56fa\u6001\u6fc0\u5149\u96f7\u8fbe\uff08\u5c24\u5176\u662f\u7a79\u9876\u5f0f\u8bbe\u8ba1\uff09\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6570\u636e\u652f\u6301\u4e0e\u65b9\u6cd5\u6307\u5bfc\u3002  \n\u25c6 \u6570\u636e\u96c6\u4e0e\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u4e3a\u672a\u6765\u5f02\u6784\u6fc0\u5149\u96f7\u8fbe\u7cfb\u7edf\u7684\u7b97\u6cd5\u5f00\u53d1\u4e0e\u6027\u80fd\u4f18\u5316\u5960\u5b9a\u4e86\u57fa\u7840\u3002|\n",
    "2507.04004": "|2025-07-09|Gaussian-LIC2: LiDAR-Inertial-Camera Gaussian Splatting SLAM|Xiaolei Lang\u7b49|[2507.04004](http://arxiv.org/pdf/2507.04004)|\u65e0|\u25c6 \u9996\u6b21\u63d0\u51fa\u7ed3\u5408LiDAR-\u60ef\u6027-\u76f8\u673a\u76843D\u9ad8\u65af\u6cfc\u6e85SLAM\u7cfb\u7edf\uff0c\u540c\u6b65\u4f18\u5316\u89c6\u89c9\u8d28\u91cf\u3001\u51e0\u4f55\u7cbe\u5ea6\u548c\u5b9e\u65f6\u6027\u80fd\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f3D\u9ad8\u65af\u5730\u56fe\u7684\u5b9e\u65f6\u6784\u5efa\u4e0eRGB/\u6df1\u5ea6\u6e32\u67d3\u3002  \n\u25c6 \u9488\u5bf9LiDAR\u8986\u76d6\u4e0d\u8db3\u533a\u57df\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u96f6\u6837\u672c\u6df1\u5ea6\u6a21\u578b\uff0c\u878d\u5408RGB\u5916\u89c2\u7ebf\u7d22\u4e0e\u7a00\u758fLiDAR\u6570\u636e\u751f\u6210\u7a20\u5bc6\u6df1\u5ea6\u56fe\uff0c\u663e\u8457\u63d0\u5347\u7a00\u758fLiDAR\u4f20\u611f\u5668\u7684\u573a\u666f\u9002\u7528\u6027\u3002  \n\u25c6 \u5229\u7528\u9ad8\u7cbe\u5ea6\u7a00\u758fLiDAR\u6df1\u5ea6\u76d1\u7763\u9ad8\u65af\u5730\u56fe\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u5b9a\u5236CUDA\u52a0\u901f\u7b56\u7565\u63d0\u5347\u6548\u7387\uff0c\u589e\u5f3a\u51e0\u4f55\u51c6\u786e\u6027\u3002  \n\u25c6 \u521b\u65b0\u5730\u5c06\u589e\u91cf\u91cd\u5efa\u7684\u9ad8\u65af\u5730\u56fe\u5149\u5ea6\u7ea6\u675f\u878d\u5165\u8fde\u7eed\u65f6\u95f4\u56e0\u5b50\u56fe\u4f18\u5316\uff0c\u5728LiDAR\u6027\u80fd\u9000\u5316\u65f6\u63d0\u5347\u4f4d\u59ff\u4f30\u8ba1\u9c81\u68d2\u6027\u3002  \n\u25c6 \u6269\u5c55\u7cfb\u7edf\u529f\u80fd\u81f3\u4e0b\u6e38\u5e94\u7528\uff08\u5982\u89c6\u9891\u5e27\u63d2\u503c\u4e0e\u5feb\u901f3D\u7f51\u683c\u63d0\u53d6\uff09\uff0c\u5e76\u6784\u5efa\u5305\u542b\u771f\u503c\u4f4d\u59ff\u3001\u6df1\u5ea6\u56fe\u548c\u5916\u63a8\u8f68\u8ff9\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u652f\u6301\u4e25\u683c\u8bc4\u4f30\u3002  \n\u25c6 \u5728\u516c\u5f00\u4e0e\u81ea\u91c7\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u7cfb\u7edf\u5bf9\u591a\u79cd\u5bc6\u5ea6LiDAR\u7684\u4f18\u8d8a\u6027\uff0c\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u5c06\u5f00\u6e90\u3002|\n",
    "2507.03737": "|2025-07-04|Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps|Chong Cheng\u7b49|[2507.03737](http://arxiv.org/pdf/2507.03737)|\u65e0|\u25c6 \u63d0\u51faS3PO-GS\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u57fa\u4e8eRGB\u5355\u76ee\u76f8\u673a\u7684\u6237\u5916\u5168\u5c40\u5c3a\u5ea6\u4e00\u81f43D\u9ad8\u65af\u70b9\u5efa\u56feSLAM\u7cfb\u7edf\u3002  \n\u25c6 \u8bbe\u8ba1\u81ea\u4e00\u81f4\u8ddf\u8e2a\u6a21\u5757\uff0c\u4ee53D\u9ad8\u65af\u70b9\u56fe\u4e3a\u951a\u70b9\uff0c\u907f\u514d\u7d2f\u79ef\u5c3a\u5ea6\u6f02\u79fb\uff0c\u5b9e\u73b0\u66f4\u7cbe\u51c6\u9c81\u68d2\u7684\u76f8\u673a\u8ddf\u8e2a\uff08\u8fed\u4ee3\u6b21\u6570\u66f4\u5c11\uff09\u3002  \n\u25c6 \u521b\u65b0\u6027\u63d0\u51fa\u57fa\u4e8e\u5206\u5757\u7684\u52a8\u6001\u70b9\u56fe\u5efa\u56fe\u6a21\u5757\uff0c\u5f15\u5165\u51e0\u4f55\u5148\u9a8c\u77e5\u8bc6\u7684\u540c\u65f6\u89c4\u907f\u5c3a\u5ea6\u6b67\u4e49\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u6237\u5916\u573a\u666f\u7684\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u91cd\u5efa\u8d28\u91cf\u3002  \n\u25c6 \u901a\u8fc7\u878d\u5408\u51e0\u4f55\u5148\u9a8c\u4e0e3DGS\u6e32\u67d3\u4f18\u52bf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6237\u5916\u573a\u666f\u7f3a\u4e4f\u51e0\u4f55\u7ea6\u675f\u6216\u4f9d\u8d56\u72ec\u7acb\u8ddf\u8e2a\u6a21\u5757\u5bfc\u81f4\u7684\u5c3a\u5ea6\u6f02\u79fb\u95ee\u9898\u3002  \n\u25c6 \u5728Waymo\u3001KITTI\u548cDL3DV\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u5728\u65b0\u89c6\u89d2\u5408\u6210\u548c\u8ddf\u8e2a\u7cbe\u5ea6\u4e0a\u5747\u8d85\u8d8a\u73b0\u67093DGS SLAM\u65b9\u6cd5\u3002|\n",
    "2507.05718": "|2025-07-08|Cooperative Mapping, Localization, and Beam Management via Multi-Modal SLAM in ISAC Systems|Hang Que\u7b49|[2507.05718](http://arxiv.org/pdf/2507.05718)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001SLAM\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u534f\u540c\u591a\u7528\u6237SLAM\u5728ISAC\u7cfb\u7edf\u4e2d\u7684\u7406\u8bba\u5efa\u6a21\u548c\u901a\u4fe1\u5c42\u96c6\u6210\u4e0d\u8db3\u7684\u95ee\u9898\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u57fa\u4e8e\u8d1d\u53f6\u65af\u4f30\u8ba1\u7684\u534f\u540c\u591a\u7528\u6237SLAM\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u9636\u6bb5\u7b97\u6cd5\uff0c\u5728\u52a8\u6001\u5f02\u6784\u611f\u77e5\u6761\u4ef6\u4e0b\u5b9e\u73b0\u9c81\u68d2\u7684\u65e0\u7ebf\u7535\u5730\u56fe\u6784\u5efa\u3002  \n\u25c6 \u5f15\u5165\u591a\u6a21\u6001\u5b9a\u4f4d\u7b56\u7565\uff0c\u901a\u8fc7\u8bef\u5dee\u611f\u77e5\u6a21\u578b\u878d\u5408SLAM\u7ed3\u679c\u3001\u6444\u50cf\u5934\u591a\u76ee\u6807\u8ddf\u8e2a\u548cIMU\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u7528\u6237\u573a\u666f\u4e0b\u7684UE\u5b9a\u4f4d\u7cbe\u5ea6\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u611f\u77e5\u8f85\u52a9\u7684\u6ce2\u675f\u7ba1\u7406\u65b9\u6848\uff0c\u5229\u7528\u5168\u5c40\u65e0\u7ebf\u7535\u5730\u56fe\u548c\u5b9a\u4f4d\u6570\u636e\u751f\u6210UE\u7279\u5b9a\u7684\u5148\u9a8c\u4fe1\u606f\uff0c\u4f18\u5316\u6ce2\u675f\u9009\u62e9\uff0c\u964d\u4f4e\u7528\u6237\u95f4\u5e72\u6270\u5e76\u63d0\u5347\u4e0b\u884c\u9891\u8c31\u6548\u7387\u3002  \n\u25c6 \u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5c06\u65e0\u7ebf\u7535\u5730\u56fe\u7cbe\u5ea6\u63d0\u5347\u9ad8\u8fbe60%\uff0c\u5b9a\u4f4d\u7cbe\u5ea6\u63d0\u9ad837.5%\uff0c\u5728\u5ba4\u5185\u5916\u73af\u5883\u4e2d\u5747\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002|\n",
    "2507.06397": "|2025-07-08|Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System|Michalis Chatzispyrou\u7b49|[2507.06397](http://arxiv.org/pdf/2507.06397)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u7684\u6c34\u4e0b\u6d1e\u7a74\u6d4b\u7ed8\u6846\u67b6\uff0c\u5e76\u5e94\u7528\u4e8e\u4f5b\u7f57\u91cc\u8fbe\u5ddeGinnie Springs\u7684Devil's Eye\u6d1e\u7a74\u7cfb\u7edf\u3002  \n\n\u25c6 \u4f7f\u7528\u5ec9\u4ef7\u8fd0\u52a8\u76f8\u673a\u7ed3\u5408\u6f5c\u6c34\u7535\u8111\uff0c\u5b9e\u73b0\u4e86\u6c34\u4e0b\u6d1e\u7a74\u8f68\u8ff9\u4f30\u8ba1\u548c\u7a00\u758f\u70b9\u4e91\u91cd\u5efa\uff0c\u964d\u4f4e\u4e86\u6d4b\u7ed8\u6210\u672c\u3002  \n\u25c6 \u901a\u8fc7\u6f5c\u6c34\u7535\u8111\u6570\u636e\u589e\u5f3a\u4e86\u89c6\u89c9/\u60ef\u6027\u6846\u67b6\uff08SVIn2\uff09\uff0c\u5b9e\u73b0\u4e86Z\u8f74\u7ef4\u5ea6\u53ca\u6a2a\u6eda/\u4fef\u4ef0\u89d2\u5ea6\u7684\u89c2\u6d4b\uff0c\u5f25\u8865\u4e86\u7eaf\u89c6\u89c9\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u5c06SVIn2\u751f\u6210\u7684\u5173\u952e\u5e27\u4e0e\u76f8\u673a\u4f4d\u59ff\u4f5c\u4e3a\u8f93\u5165\uff0c\u7ed3\u5408\u5168\u5c40\u4f18\u5316\u6846\u67b6COLMAP\uff0c\u91cd\u5efa\u4e86\u5c40\u90e8\u533a\u57df\u7684\u9ad8\u5bc6\u5ea6\u4e09\u7ef4\u6a21\u578b\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u6d1e\u7a74\u901a\u9053\u7684\u4e00\u7ef4\u62bd\u8c61\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u5747\u8f68\u8ff9\u4e0e\u8fb9\u754c\uff08\u4e0a\u4e0b\u5de6\u53f3\uff09\u63cf\u8ff0\u6d1e\u7a74\u8f6e\u5ed3\u3002  \n\u25c6 \u91c7\u7528MNemo V2\u4eea\u5668\u8fdb\u884c\u4eba\u5de5\u6d4b\u7ed8\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u8868\u660e\u8fd0\u52a8\u76f8\u673a\u8db3\u4ee5\u6784\u5efa\u6d1e\u7a74\u5730\u56fe\u7684\u57fa\u672c\u8981\u7d20\u3002  \n\u25c6 \u901a\u8fc7VI-SLAM\u4e0e\u5168\u5c40\u4f18\u5316\u6846\u67b6\u7684\u534f\u540c\uff0c\u5b9e\u73b0\u4e86\u9009\u5b9a\u533a\u57df\u7684\u903c\u771f\u5bc6\u96c6\u4e09\u7ef4\u91cd\u5efa\uff0c\u4e3a\u6c34\u6587\u5730\u8d28\u548c\u8003\u53e4\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002|\n",
    "2507.07903": "|2025-07-10|Hardware-Aware Feature Extraction Quantisation for Real-Time Visual Odometry on FPGA Platforms|Mateusz Wasala\u7b49|[2507.07903](http://arxiv.org/pdf/2507.07903)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5316SuperPoint\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u5d4c\u5165\u5f0f\u65e0\u76d1\u7763\u67b6\u6784\uff0c\u7528\u4e8e\u5b9e\u65f6\u89c6\u89c9\u91cc\u7a0b\u8ba1\u4e2d\u7684\u7279\u5f81\u70b9\u68c0\u6d4b\u4e0e\u63cf\u8ff0\u3002  \n\u25c6 \u901a\u8fc7\u786c\u4ef6\u611f\u77e5\u7684\u6a21\u578b\u91cf\u5316\u6280\u672f\uff08\u4f7f\u7528Brevitas\u5e93\u548cFINN\u6846\u67b6\uff09\uff0c\u5728\u4fdd\u8bc1\u9ad8\u68c0\u6d4b\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u9700\u6c42\u3002  \n\u25c6 \u5728AMD/Xilinx Zynq UltraScale+ FPGA\u5e73\u53f0\u4e0a\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\uff0c\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u5904\u7406\u5355\u5143\uff08DPU\uff09\u4f18\u5316\u6027\u80fd\u3002  \n\u25c6 \u5b9e\u73b0\u4e86640\u00d7480\u5206\u8fa8\u7387\u56fe\u50cf54\u5e27/\u79d2\u7684\u5904\u7406\u901f\u5ea6\uff0c\u4f18\u4e8e\u5f53\u524d\u540c\u7c7b\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u5728TUM\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u4e0d\u540c\u91cf\u5316\u6280\u672f\u5bf9\u6a21\u578b\u7cbe\u5ea6\u4e0e\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\uff08\u5982\u79fb\u52a8/\u5d4c\u5165\u5f0f\u7cfb\u7edf\uff09\u63d0\u4f9b\u4e86\u5b9e\u7528\u4f18\u5316\u65b9\u6848\u3002|\n",
    "2507.07752": "|2025-07-10|IRAF-SLAM: An Illumination-Robust and Adaptive Feature-Culling Front-End for Visual SLAM in Challenging Environments|Thanh Nguyen Canh\u7b49|[2507.07752](http://arxiv.org/pdf/2507.07752)|\u65e0|\u25c6 IRAF-SLAM\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u590d\u6742\u5149\u7167\u73af\u5883\u7684\u89c6\u89c9SLAM\u524d\u7aef\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u673a\u5236\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u56fe\u50cf\u589e\u5f3a\u65b9\u6848\uff0c\u52a8\u6001\u9884\u5904\u7406\u4e0d\u540c\u5149\u7167\u6761\u4ef6\u4e0b\u7684\u56fe\u50cf\u8d28\u91cf\uff0c\u6539\u5584\u7279\u5f81\u63d0\u53d6\u57fa\u7840\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u57fa\u4e8e\u56fe\u50cf\u71b5\u3001\u50cf\u7d20\u5f3a\u5ea6\u548c\u68af\u5ea6\u5206\u6790\u7684\u81ea\u9002\u5e94\u7279\u5f81\u63d0\u53d6\u673a\u5236\uff0c\u6839\u636e\u73af\u5883\u52a8\u6001\u8c03\u6574\u68c0\u6d4b\u7075\u654f\u5ea6\u3002  \n\u25c6 \u63d0\u51fa\u65b0\u578b\u7279\u5f81\u7b5b\u9009\u7b56\u7565\uff0c\u7ed3\u5408\u5bc6\u5ea6\u5206\u5e03\u5206\u6790\u548c\u5149\u7167\u5f71\u54cd\u56e0\u5b50\uff0c\u6709\u6548\u8fc7\u6ee4\u4e0d\u53ef\u9760\u7279\u5f81\u70b9\u3002  \n\u25c6 \u5728TUM-VI\u548cEuRoC\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u8ddf\u8e2a\u5931\u8d25\u7387\uff0c\u5e76\u5728\u6076\u52a3\u5149\u7167\u4e0b\u5b9e\u73b0\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u8f68\u8ff9\u7cbe\u5ea6\u3002  \n\u25c6 \u6574\u4e2a\u7cfb\u7edf\u5728\u63d0\u5347\u9c81\u68d2\u6027\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.07142": "|2025-07-09|g2o vs. Ceres: Optimizing Scan Matching in Cartographer SLAM|Quanjie Qiu\u7b49|[2507.07142](http://arxiv.org/pdf/2507.07142)|\u65e0|\u25c6 \u9996\u6b21\u5728Cartographer\u6846\u67b6\u4e2d\u5bf9g2o\u548cCeres\u4e24\u79cd\u4f18\u5316\u5668\u8fdb\u884c\u4e86\u7cfb\u7edf\u7684\u626b\u63cf\u5339\u914d\u6027\u80fd\u5bf9\u6bd4\u5206\u6790\u3002  \n\u25c6 \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86Ceres\u4f5c\u4e3aCartographer\u9ed8\u8ba4\u6c42\u89e3\u5668\u5728\u901f\u5ea6\u3001\u6536\u655b\u6548\u7387\u548c\u5730\u56fe\u6e05\u6670\u5ea6\u4e0a\u7684\u5168\u9762\u4f18\u52bf\u3002  \n\u25c6 \u53d1\u73b0Ceres\u5728\u771f\u5b9e\u573a\u666f\uff08AgileX LIMO\u673a\u5668\u4eba\uff09\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u6240\u9700\u8fed\u4ee3\u6b21\u6570\u66f4\u5c11\u4e14\u6536\u655b\u66f4\u5feb\u3002  \n\u25c6 \u63ed\u793a\u4e86g2o\u5728\u5c40\u90e8\u969c\u788d\u7269\u68c0\u6d4b\u65b9\u9762\u7684\u7279\u6b8a\u4f18\u52bf\uff0c\u4e3a\u5176\u5728\u7279\u5b9a\u573a\u666f\u7684\u5e94\u7528\u4ef7\u503c\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002  \n\u25c6 \u4e3aSLAM\u7cfb\u7edf\u4f18\u5316\u5668\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u53c2\u8003\uff0c\u6307\u51fa\u4e0d\u540c\u4f18\u5316\u5668\u7684\u9002\u7528\u573a\u666f\u5dee\u5f02\u3002  \n\u25c6 \u901a\u8fc7\u5b9a\u91cf\u5316\u6307\u6807\uff08\u5982\u8fed\u4ee3\u6b21\u6570\u3001\u6536\u655b\u65f6\u95f4\uff09\u5bf9\u6bd4\uff0c\u6df1\u5316\u4e86\u5bf9\u4e24\u79cd\u4f18\u5316\u5668\u6027\u80fd\u7279\u5f81\u7684\u7406\u89e3\u3002|\n",
    "2507.08364": "|2025-07-11|Towards Robust Sensor-Fusion Ground SLAM: A Comprehensive Benchmark and A Resilient Framework|Deteng Zhang\u7b49|[2507.08364](http://arxiv.org/pdf/2507.08364)|\u65e0|\u25c6 \u63d0\u51faM3DGR\u6570\u636e\u96c6\uff1a\u9996\u4e2a\u5305\u542b\u89c6\u89c9\u5e72\u6270\u3001\u6fc0\u5149\u96f7\u8fbe\u9000\u5316\u3001\u8f6e\u5f0f\u6253\u6ed1\u548cGNSS\u5931\u6548\u7b49\u7cfb\u7edf\u6027\u9000\u5316\u573a\u666f\u7684\u591a\u4f20\u611f\u5668\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u586b\u8865\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u5de5\u5177\u7684\u7a7a\u767d\u3002  \n\u25c6 \u5bf940\u79cdSLAM\u7cfb\u7edf\u8fdb\u884c\u5927\u89c4\u6a21\u8bc4\u6d4b\uff1a\u9996\u6b21\u5728\u591a\u6837\u5316\u9000\u5316\u6761\u4ef6\u4e0b\u5168\u9762\u5206\u6790\u73b0\u6709\u7b97\u6cd5\u7684\u9c81\u68d2\u6027\uff0c\u63ed\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5173\u952e\u6027\u80fd\u74f6\u9888\u3002  \n\u25c6 \u5f00\u53d1Ground-Fusion++\u6846\u67b6\uff1a\u521b\u65b0\u6027\u5730\u878d\u5408GNSS\u3001RGB-D\u3001\u6fc0\u5149\u96f7\u8fbe\u3001IMU\u548c\u8f6e\u5f0f\u91cc\u7a0b\u8ba1\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u5b9e\u73b0\u591a\u4f20\u611f\u5668\u81ea\u9002\u5e94\u9009\u62e9\u3002  \n\u25c6 \u89e3\u51b3\u4f20\u611f\u5668\u52a8\u6001\u9002\u914d\u95ee\u9898\uff1a\u63d0\u51fa\u73af\u5883\u53d8\u5316\u4e0b\u7684\u4f20\u611f\u5668\u4f18\u9009\u7b56\u7565\uff0c\u7a81\u7834\u4f20\u7edf\u6846\u67b6\u4ec5\u56fa\u5b9a\u878d\u5408\u5c11\u6570\u4f20\u611f\u5668\u7684\u5c40\u9650\u3002  \n\u25c6 \u516c\u5f00\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\uff1a\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u5b9e\u9a8c\u5e73\u53f0\u548c\u6027\u80fd\u5bf9\u6bd4\u57fa\u51c6\uff0c\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002|\n",
    "2507.12273": "|2025-07-17|Next-Gen Museum Guides: Autonomous Navigation and Visitor Interaction with an Agentic Robot|Luca Garello\u7b49|[2507.12273](http://arxiv.org/pdf/2507.12273)|\u65e0|\u25c6 \u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u6b3e\u540d\u4e3aAlter-Ego\u7684\u81ea\u4e3b\u535a\u7269\u9986\u5bfc\u89c8\u673a\u5668\u4eba\uff0c\u7ed3\u5408\u5148\u8fdb\u5bfc\u822a\u4e0e\u4ea4\u4e92\u529f\u80fd\uff0c\u63d0\u5347\u53c2\u89c2\u4f53\u9a8c\u3002  \n\u25c6 \u9996\u6b21\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e94\u7528\u4e8e\u535a\u7269\u9986\u573a\u666f\uff0c\u5b9e\u73b0\u5b9e\u65f6\u3001\u60c5\u5883\u611f\u77e5\u7684\u95ee\u7b54\u4ea4\u4e92\uff0c\u652f\u6301\u6e38\u5ba2\u4e0e\u673a\u5668\u4eba\u5c31\u5c55\u54c1\u5c55\u5f00\u5bf9\u8bdd\u3002  \n\u25c6 \u91c7\u7528\u9c81\u68d2\u7684SLAM\u6280\u672f\uff0c\u4f7f\u673a\u5668\u4eba\u80fd\u5728\u535a\u7269\u9986\u73af\u5883\u4e2d\u81ea\u4e3b\u5bfc\u822a\uff0c\u5e76\u6839\u636e\u7528\u6237\u9700\u6c42\u52a8\u6001\u8c03\u6574\u5bfc\u89c8\u8def\u7ebf\u3002  \n\u25c6 \u901a\u8fc7\u771f\u5b9e\u535a\u7269\u9986\u73af\u5883\u4e0b\u7684\u7528\u6237\u7814\u7a76\uff0834\u540d\u53c2\u4e0e\u8005\uff09\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u53ef\u7528\u6027\uff0c\u7ed3\u5408\u5bf9\u8bdd\u8d28\u91cf\u5206\u6790\u4e0e\u95ee\u5377\u8c03\u67e5\u91cf\u5316\u8bc4\u4f30\u6548\u679c\u3002  \n\u25c6 \u63ed\u793a\u4e86AI\u9a71\u52a8\u673a\u5668\u4eba\u5728\u6587\u5316\u7a7a\u95f4\u4e2d\u4eba\u673a\u4ea4\u4e92\uff08HRI\uff09\u7684\u6f5c\u529b\u4e0e\u6311\u6218\uff0c\u5305\u62ec\u77e5\u8bc6\u83b7\u53d6\u7684\u4fc3\u8fdb\u4e0e\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u6280\u672f\u5c40\u9650\u6027\u3002  \n\u25c6 \u4e3a\u516c\u5171\u670d\u52a1\u673a\u5668\u4eba\u9886\u57df\u63d0\u4f9b\u4e86\u517c\u5177\u6280\u672f\u521b\u65b0\u4e0e\u5b9e\u8bc1\u7814\u7a76\u7684\u8303\u4f8b\uff0c\u63a8\u52a8\u590d\u6742\u573a\u666f\u4e0b\u81ea\u4e3b\u7cfb\u7edf\u7684\u5e94\u7528\u63a2\u7d22\u3002|\n",
    "2507.12093": "|2025-07-16|Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards|David Rapado-Rincon\u7b49|[2507.12093](http://arxiv.org/pdf/2507.12093)|\u65e0|\u25c6 \u63d0\u51faTree-SLAM\uff0c\u4e00\u79cd\u4e13\u4e3a\u679c\u56ed\u73af\u5883\u8bbe\u8ba1\u7684\u8bed\u4e49SLAM\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edfSLAM\u5728\u6811\u6728\u91cd\u590d\u5916\u89c2\u4e0b\u6613\u6df7\u6dc6\u7684\u95ee\u9898\u3002  \n\u25c6 \u7ed3\u5408RGB-D\u56fe\u50cf\u548c\u5b9e\u4f8b\u5206\u5272\u6a21\u578b\uff0c\u5b9e\u73b0\u6811\u5e72\u68c0\u6d4b\u4e0e\u5b9a\u4f4d\uff0c\u5e76\u901a\u8fc7\u7ea7\u8054\u56fe\u6570\u636e\u5173\u8054\u7b97\u6cd5\u8fdb\u884c\u6811\u5e72\u91cd\u8bc6\u522b\u3002  \n\u25c6 \u5c06\u91cd\u8bc6\u522b\u7684\u6811\u5e72\u4f5c\u4e3a\u5730\u6807\uff0c\u878d\u5408\u566a\u58f0GPS\u4fe1\u53f7\u3001\u91cc\u7a0b\u8ba1\u548c\u6811\u5e72\u89c2\u6d4b\u6570\u636e\uff0c\u6784\u5efa\u56e0\u5b50\u56fe\u6846\u67b6\uff0c\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\u3002  \n\u25c6 \u7cfb\u7edf\u5728GPS\u4fe1\u53f7\u4e0d\u53ef\u9760\u65f6\u4ecd\u80fd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u5355\u68f5\u6811\u7684\u5730\u7406\u5b9a\u4f4d\u8bef\u5dee\u4f4e\u81f318\u5398\u7c73\uff0c\u4f4e\u4e8e\u79cd\u690d\u95f4\u8ddd\u768420%\u3002  \n\u25c6 \u5728\u82f9\u679c\u56ed\u548c\u68a8\u56ed\u7684\u4e0d\u540c\u5b63\u8282\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u7cbe\u51c6\u519c\u4e1a\u4e2d\u7684\u76ee\u6807\u64cd\u4f5c\u548c\u5355\u6811\u76d1\u6d4b\u4efb\u52a1\u3002|\n",
    "2507.13145": "|2025-07-17|DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model|Maulana Bisyir Azhari\u7b49|[2507.13145](http://arxiv.org/pdf/2507.13145)|\u65e0|\u25c6 \u63d0\u51faDINO-VO\u7cfb\u7edf\uff0c\u9996\u6b21\u5c06\u89c6\u89c9\u57fa\u7840\u6a21\u578bDINOv2\u7684\u9c81\u68d2\u8bed\u4e49\u7279\u5f81\u5e94\u7528\u4e8e\u5355\u76ee\u89c6\u89c9\u91cc\u7a0b\u8ba1\uff08VO\uff09\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5b66\u4e60\u578bVO\u5728\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u9488\u5bf9DINOv2\u7c97\u7c92\u5ea6\u7279\u5f81\u7684\u663e\u8457\u5173\u952e\u70b9\u68c0\u6d4b\u5668\uff0c\u514b\u670d\u4e86\u57fa\u7840\u6a21\u578b\u7279\u5f81\u5728VO\u4efb\u52a1\u4e2d\u7c92\u5ea6\u4e0d\u8db3\u7684\u96c6\u6210\u96be\u9898\u3002  \n\u25c6 \u7ed3\u5408DINOv2\u7684\u8bed\u4e49\u7279\u5f81\u4e0e\u7ec6\u7c92\u5ea6\u51e0\u4f55\u7279\u5f81\uff0c\u751f\u6210\u66f4\u5177\u5c40\u90e8\u5316\u80fd\u529b\u7684\u6df7\u5408\u7279\u5f81\u8868\u793a\uff0c\u63d0\u5347\u4e86\u4f4d\u59ff\u4f30\u8ba1\u7cbe\u5ea6\u3002  \n\u25c6 \u91c7\u7528\u57fa\u4e8eTransformer\u7684\u5339\u914d\u5668\u548c\u53ef\u5fae\u5206\u4f4d\u59ff\u4f30\u8ba1\u5c42\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u5b66\u4e60\u4f18\u5316\u7279\u5f81\u5339\u914d\u4e0e\u8fd0\u52a8\u4f30\u8ba1\u6027\u80fd\u3002  \n\u25c6 \u5728TartanAir\u3001KITTI\u7b49\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4f20\u7edf\u5e27\u95f4VO\u65b9\u6cd5\uff08\u5982SuperPoint\uff09\uff0c\u5e76\u5728\u5ba4\u5916\u9a7e\u9a76\u573a\u666f\u4e2d\u4e0e\u89c6\u89c9SLAM\u7cfb\u7edf\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u630172 FPS\u7684\u9ad8\u6548\u5b9e\u65f6\u6027\uff08GPU\u5185\u5b58<1GB\uff09\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eDINOv2\u7279\u5f81\u7ecf\u6539\u8fdb\u540e\uff0c\u5176\u63cf\u8ff0\u5b50\u7cbe\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u663e\u8457\u4f18\u4e8e\u539f\u59cb\u7c97\u7c92\u5ea6\u7279\u5f81\uff0c\u5c24\u5176\u5728\u5149\u7167\u53d8\u5316\u3001\u52a8\u6001\u7269\u4f53\u7b49\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u7a81\u51fa\u3002|\n",
    "2507.12920": "|2025-07-17|MoCap2GT: A High-Precision Ground Truth Estimator for SLAM Benchmarking Based on Motion Capture and IMU Fusion|Zichao Shu\u7b49|[2507.12920](http://arxiv.org/pdf/2507.12920)|\u65e0|MoCap2GT\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u4f5c\u6355\u6349\u548cIMU\u878d\u5408\u7684\u9ad8\u7cbe\u5ea6SLAM\u57fa\u51c6\u6d4b\u8bd5\u771f\u503c\u4f30\u8ba1\u65b9\u6cd5\uff0c\u6838\u5fc3\u8d21\u732e\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u8054\u5408\u4f18\u5316\u6846\u67b6\uff0c\u878d\u5408MoCap\u6570\u636e\u548c\u8bbe\u5907IMU\u6d4b\u91cf\u503c\uff0c\u663e\u8457\u63d0\u5347\u8f68\u8ff9\u771f\u503c\u7684\u7cbe\u5ea6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u56e0\u65f6\u7a7a\u6807\u5b9a\u8bef\u5dee\u548cMoCap\u6296\u52a8\u5bfc\u81f4\u7684\u7cbe\u5ea6\u9650\u5236\u95ee\u9898\u3002\n\n\u25c6 \u8bbe\u8ba1\u9c81\u68d2\u7684\u72b6\u6001\u521d\u59cb\u5316\u5668\uff0c\u786e\u4fdd\u5168\u5c40\u6536\u655b\u6027\uff0c\u907f\u514d\u4e86\u4f18\u5316\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u5c40\u90e8\u6700\u4f18\u95ee\u9898\u3002\n\n\u25c6 \u5f15\u5165SE(3)\u6d41\u5f62\u4e0a\u7684\u9ad8\u9636B\u6837\u6761\u4f4d\u59ff\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u5e76\u91c7\u7528\u53ef\u53d8\u65f6\u95f4\u504f\u79fb\u5efa\u6a21\uff0c\u6709\u6548\u5904\u7406MoCap\u56e0\u7d20\uff0c\u63d0\u9ad8\u4e86\u8f68\u8ff9\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002\n\n\u25c6 \u63d0\u51fa\u9000\u5316\u611f\u77e5\u7684\u6d4b\u91cf\u5254\u9664\u7b56\u7565\uff0c\u80fd\u591f\u8bc6\u522b\u5e76\u5254\u9664\u4e0d\u53ef\u9760\u7684\u6d4b\u91cf\u6570\u636e\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4f30\u8ba1\u7cbe\u5ea6\u3002\n\n\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMoCap2GT\u5728\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3aSLAM\u7b97\u6cd5\u7684\u5168\u9762\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u57fa\u51c6\u771f\u503c\u3002\u8be5\u65b9\u6cd5\u5f00\u6e90\u53ef\u7528\uff0c\u5c06\u4fc3\u8fdbSLAM\u7814\u7a76\u793e\u533a\u7684\u53d1\u5c55\u3002|\n",
    "2507.15716": "|2025-07-21|DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models|Ziyu Wan\u7b49|[2507.15716](http://arxiv.org/pdf/2507.15716)|\u65e0|\u25c6 DiffPF\u9996\u6b21\u5c06\u6761\u4ef6\u6269\u6563\u6a21\u578b\u878d\u5165\u7c92\u5b50\u6ee4\u6ce2\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u540e\u9a8c\u91c7\u6837\uff0c\u663e\u8457\u63d0\u5347\u4e86\u72b6\u6001\u4f30\u8ba1\u7cbe\u5ea6\u3002  \n\u25c6 \u76f8\u6bd4\u4f20\u7edf\u53ef\u5fae\u5206\u7c92\u5b50\u6ee4\u6ce2\u4f9d\u8d56\u9884\u5b9a\u4e49\u6216\u4f4e\u5bb9\u91cf\u63d0\u8bae\u5206\u5e03\uff0cDiffPF\u901a\u8fc7\u6761\u4ef6\u6269\u6563\u6a21\u578b\u5b66\u4e60\u7075\u6d3b\u7684\u91c7\u6837\u5668\uff0c\u76f4\u63a5\u751f\u6210\u7b49\u6743\u7c92\u5b50\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u80fd\u591f\u4ece\u590d\u6742\u3001\u9ad8\u7ef4\u3001\u591a\u6a21\u6001\u7684\u6ee4\u6ce2\u5206\u5e03\u4e2d\u8fdb\u884c\u7cbe\u786e\u91c7\u6837\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u590d\u6742\u5206\u5e03\u4e0b\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u5728\u5168\u5c40\u5b9a\u4f4d\u548cKITTI\u89c6\u89c9\u91cc\u7a0b\u8ba1\u7b49\u4efb\u52a1\u4e2d\uff0cDiffPF\u5206\u522b\u4ee582.8%\u548c26%\u7684\u7cbe\u5ea6\u4f18\u52bf\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u53ef\u5fae\u5206\u6ee4\u6ce2\u5668\u3002  \n\u25c6 \u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0cDiffPF\u5728\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u573a\u666f\u4e0b\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u52a8\u6001\u7cfb\u7edf\u72b6\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002|\n",
    "2507.15496": "|2025-07-21|Dense-depth map guided deep Lidar-Visual Odometry with Sparse Point Clouds and Images|JunYing Huang\u7b49|[2507.15496](http://arxiv.org/pdf/2507.15496)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684LiDAR-\u89c6\u89c9\u91cc\u7a0b\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u878d\u5408\u7a00\u758fLiDAR\u70b9\u4e91\u548c\u56fe\u50cf\u6570\u636e\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u4f4d\u59ff\u4f30\u8ba1\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u7528\u6df1\u5ea6\u8865\u5168\u6280\u672f\u751f\u6210\u7a20\u5bc6\u6df1\u5ea6\u56fe\uff0c\u4e3a\u8fd0\u52a8\u4f30\u8ba1\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u51e0\u4f55\u7ea6\u675f\u4fe1\u606f\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u5e26\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u7f51\u7edc\uff0c\u80fd\u591f\u81ea\u9002\u5e94\u751f\u6210\u6df1\u5ea6\u611f\u77e5\u7684\u7279\u5f81\u8868\u793a\u3002  \n\u25c6 \u91c7\u7528\u7a20\u5bc6\u6df1\u5ea6\u4fe1\u606f\u4f18\u5316\u5149\u6d41\u4f30\u8ba1\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u906e\u6321\u533a\u57df\u7684\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u5206\u5c42\u4f4d\u59ff\u4f18\u5316\u6a21\u5757\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u8fd0\u52a8\u4f30\u8ba1\u63d0\u5347\u52a8\u6001\u73af\u5883\u548c\u5c3a\u5ea6\u6a21\u7cca\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u3002  \n\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728KITTI\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u4e0e\u5f53\u524d\u6700\u4f18\u89c6\u89c9/LiDAR\u91cc\u7a0b\u8ba1\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002|\n",
    "2507.15474": "|2025-07-21|All-UWB SLAM Using UWB Radar and UWB AOA|Charith Premachandra\u7b49|[2507.15474](http://arxiv.org/pdf/2507.15474)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408UWB\u96f7\u8fbe\u548cUWB\u5230\u8fbe\u89d2\uff08AOA\uff09\u6d4b\u91cf\u7684\u65b0\u578bSLAM\u65b9\u6cd5\uff0c\u7528\u4e8e\u89c6\u89c9\u53d7\u9650\u4e14\u7279\u5f81\u7a00\u7f3a\u7684\u73af\u5883\u3002  \n\u25c6 \u901a\u8fc7\u52a8\u6001\u90e8\u7f72UWB\u951a\u70b9-\u6807\u7b7e\u5355\u5143\uff0c\u5728\u73af\u5883\u7279\u5f81\u4e0d\u8db3\u7684\u533a\u57df\u8865\u5145AOA\u6d4b\u91cf\u6570\u636e\uff0c\u63d0\u5347\u4e86SLAM\u7684\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u73b0\u6709UWB\u96f7\u8fbeSLAM\u65b9\u6cd5\u4f9d\u8d56\u73af\u5883\u7279\u5f81\u6570\u91cf\u7684\u5c40\u9650\u6027\uff0c\u6269\u5c55\u4e86\u5176\u5728\u65e0\u7279\u5f81\u73af\u5883\u4e2d\u7684\u5e94\u7528\u80fd\u529b\u3002  \n\u25c6 \u8be6\u7ec6\u5206\u6790\u4e86UWB AOA\u6d4b\u91cf\u5355\u5143\u7684\u5e38\u89c1\u7ea6\u675f\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u89c6\u89c9\u53d7\u9650\u4e14\u7279\u5f81\u7a00\u7f3a\u7684\u73af\u5883\u4e2d\u4ecd\u80fd\u6709\u6548\u5b9e\u73b0SLAM\uff0c\u4e3a\u6076\u52a3\u6761\u4ef6\u4e0b\u7684\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2507.15321": "|2025-07-21|BenchDepth: Are We on the Right Way to Evaluate Depth Foundation Models?|Zhenyu Li\u7b49|[2507.15321](http://arxiv.org/pdf/2507.15321)|\u65e0|\u25c6\u63d0\u51faBenchDepth\u65b0\u57fa\u51c6\uff0c\u901a\u8fc7\u4e94\u4e2a\u4e0b\u6e38\u4ee3\u7406\u4efb\u52a1\uff08\u6df1\u5ea6\u8865\u5168\u3001\u7acb\u4f53\u5339\u914d\u3001\u5355\u76ee3D\u573a\u666f\u91cd\u5efa\u3001SLAM\u548c\u89c6\u89c9\u8bed\u8a00\u7a7a\u95f4\u7406\u89e3\uff09\u8bc4\u4f30\u6df1\u5ea6\u57fa\u7840\u6a21\u578b\uff08DFMs\uff09\uff0c\u7a81\u7834\u4f20\u7edf\u8bc4\u4f30\u5c40\u9650\u3002  \n\u25c6\u6452\u5f03\u4f9d\u8d56\u5bf9\u9f50\u6307\u6807\u7684\u56fa\u6709\u65b9\u6cd5\uff0c\u89e3\u51b3\u4f20\u7edf\u8bc4\u4f30\u4e2d\u56e0\u5bf9\u9f50\u504f\u5dee\u3001\u6df1\u5ea6\u8868\u793a\u504f\u597d\u5bfc\u81f4\u7684\u4e0d\u516c\u5e73\u6bd4\u8f83\u95ee\u9898\u3002  \n\u25c6\u9996\u6b21\u4ece\u5b9e\u9645\u5e94\u7528\u6548\u7528\u89d2\u5ea6\u8bc4\u4f30DFMs\uff0c\u5f3a\u8c03\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u800c\u975e\u5355\u7eaf\u6307\u6807\u5206\u6570\u3002  \n\u25c6\u7cfb\u7edf\u5730\u5bf98\u79cd\u524d\u6cbfDFMs\u8fdb\u884c\u6a2a\u5411\u5bf9\u6bd4\uff0c\u63ed\u793a\u5173\u952e\u53d1\u73b0\uff0c\u4e3a\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002  \n\u25c6\u63a8\u52a8\u6df1\u5ea6\u4f30\u8ba1\u9886\u57df\u8bc4\u4f30\u6807\u51c6\u9769\u65b0\uff0c\u5f15\u53d1\u793e\u533a\u5bf9\u8bc4\u4f30\u6700\u4f73\u5b9e\u8df5\u7684\u8ba8\u8bba\uff0c\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u53d1\u5c55\u3002|\n",
    "2507.15109": "|2025-07-20|LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM|Mohammad-Maher Nakshbandi\u7b49|[2507.15109](http://arxiv.org/pdf/2507.15109)|\u65e0|\u25c6 \u63d0\u51faLoopNet\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u5c11\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u5927\u89c4\u6a21SLAM\u4e2d\u7684\u95ed\u73af\u68c0\u6d4b\u95ee\u9898\uff0c\u517c\u987e\u7cbe\u5ea6\u4e0e\u5b9e\u65f6\u6027\u9700\u6c42\u3002  \n\u25c6 \u91c7\u7528\u6539\u8fdb\u7684ResNet\u591a\u4efb\u52a1\u67b6\u6784\uff0c\u652f\u6301\u52a8\u6001\u89c6\u89c9\u6570\u636e\u96c6\u7684\u5728\u7ebf\u91cd\u8bad\u7ec3\uff0c\u5e76\u9488\u5bf9\u5d4c\u5165\u5f0f\u8bbe\u5907\u8fdb\u884c\u4f18\u5316\uff0c\u9002\u5e94\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u3002  \n\u25c6 \u521b\u65b0\u6027\u7ed3\u5408\u5c11\u6837\u672c\u5b66\u4e60\u7b56\u7565\u8fdb\u884c\u5728\u7ebf\u8bad\u7ec3\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u65b0\u73af\u5883\u4e2d\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u9002\u5e94\u6027\u3002  \n\u25c6 \u9996\u6b21\u5728\u95ed\u73af\u68c0\u6d4b\u4e2d\u540c\u65f6\u8f93\u51fa\u573a\u666f\u7d22\u5f15\u548c\u9884\u6d4b\u8d28\u91cf\u8bc4\u4f30\uff0c\u589e\u5f3a\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u907f\u514d\u8bef\u5339\u914d\u3002  \n\u25c6 \u5229\u7528DISK\u63cf\u8ff0\u7b26\u66ff\u4ee3\u4f20\u7edf\u624b\u5de5\u7279\u5f81\u6216\u7eaf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u5149\u7167\u3001\u89c6\u89d2\u53d8\u5316\u7b49\u590d\u6742\u6761\u4ef6\u4e0b\u8868\u73b0\u66f4\u4f18\u3002  \n\u25c6 \u5f00\u6e90\u4e86\u65b0\u578b\u95ed\u73af\u68c0\u6d4b\u6570\u636e\u96c6LoopDB\uff0c\u586b\u8865\u9886\u57df\u5185\u6807\u51c6\u5316\u8bc4\u4f30\u6570\u636e\u7684\u7a7a\u767d\uff0c\u63a8\u52a8\u540e\u7eed\u7814\u7a76\u3002|\n",
    "2507.14501": "|2025-07-19|Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey|Jiahui Zhang\u7b49|[2507.14501](http://arxiv.org/pdf/2507.14501)|\u65e0|\u25c6 \u7cfb\u7edf\u68b3\u7406\u4e86\u57fa\u4e8e\u524d\u9988\u5f0f\u6df1\u5ea6\u5b66\u4e60\u76843D\u91cd\u5efa\u4e0e\u89c6\u56fe\u5408\u6210\u6280\u672f\uff0c\u9996\u6b21\u63d0\u51fa\u6309\u8868\u793a\u67b6\u6784\uff08\u5982\u70b9\u4e91\u30013D\u9ad8\u65af\u6cfc\u6e85\u3001\u795e\u7ecf\u8f90\u5c04\u573a\u7b49\uff09\u7684\u5206\u7c7b\u4f53\u7cfb\u3002  \n\u25c6 \u91cd\u70b9\u5206\u6790\u4e86\u65e0\u59ff\u6001\u91cd\u5efa\u3001\u52a8\u60013D\u91cd\u5efa\u30013D\u611f\u77e5\u56fe\u50cf/\u89c6\u9891\u5408\u6210\u7b49\u5173\u952e\u4efb\u52a1\uff0c\u62d3\u5c55\u4e86\u5728\u6570\u5b57\u4eba\u3001SLAM\u7b49\u9886\u57df\u7684\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u5bf9\u6bd4\u4f20\u7edf\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\uff0c\u7a81\u663e\u524d\u9988\u65b9\u6cd5\u5728\u5b9e\u65f6\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\u4e0a\u7684\u7a81\u7834\u6027\u8fdb\u5c55\uff0c\u4e3aAR/VR\u7b49\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002  \n\u25c6 \u5168\u9762\u6c47\u603b\u4e86\u4e3b\u6d41\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u534f\u8bae\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u6807\u51c6\u5316\u8bc4\u6d4b\u5de5\u5177\u7684\u7efc\u8ff0\u7a7a\u767d\u3002  \n\u25c6 \u6307\u51fa\u52a8\u6001\u573a\u666f\u5efa\u6a21\u3001\u8ba1\u7b97\u6548\u7387\u4e0e\u8868\u793a\u80fd\u529b\u5e73\u8861\u7b49\u5f00\u653e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002|\n",
    "2507.17406": "|2025-07-23|Physics-based Human Pose Estimation from a Single Moving RGB Camera|Ayce Idil Aytekin\u7b49|[2507.17406](http://arxiv.org/pdf/2507.17406)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u975e\u5408\u6210\u7684\u771f\u5b9e\u6570\u636e\u96c6MoviCam\uff0c\u5305\u542b\u52a8\u6001\u79fb\u52a8\u7684\u5355\u76eeRGB\u76f8\u673a\u8f68\u8ff9\u3001\u573a\u666f\u51e0\u4f55\u548c3D\u4eba\u4f53\u8fd0\u52a8\u6570\u636e\uff0c\u5e76\u6807\u6ce8\u4e86\u4eba-\u573a\u666f\u63a5\u89e6\u4fe1\u606f\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u7a7a\u767d\u3002  \n\u25c6 \u5f00\u53d1\u4e86PhysDynPose\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u573a\u666f\u51e0\u4f55\u548c\u7269\u7406\u7ea6\u675f\u6574\u5408\u5230\u57fa\u4e8e\u7269\u7406\u7684\u4eba\u4f53\u59ff\u6001\u8ddf\u8e2a\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79fb\u52a8\u76f8\u673a\u548c\u975e\u5e73\u9762\u573a\u666f\u4e0b\u7684\u8ddf\u8e2a\u7cbe\u5ea6\u3002  \n\u25c6 \u7ed3\u5408\u4e86\u5148\u8fdb\u8fd0\u52a8\u5b66\u4f30\u8ba1\u5668\u548c\u9c81\u68d2SLAM\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u4e16\u754c\u5750\u6807\u7cfb\u4e0b\u4eba\u4f53\u59ff\u6001\u4e0e\u76f8\u673a\u8f68\u8ff9\u7684\u540c\u6b65\u6062\u590d\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u76f8\u673a\u5e26\u6765\u7684\u53c2\u8003\u7cfb\u6f02\u79fb\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u573a\u666f\u611f\u77e5\u7684\u7269\u7406\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u7269\u7406\u7ea6\u675f\u4fee\u6b63\u8fd0\u52a8\u5b66\u4f30\u8ba1\u7ed3\u679c\uff0c\u4f7f\u59ff\u6001\u4f30\u8ba1\u66f4\u7b26\u5408\u771f\u5b9e\u7269\u7406\u89c4\u5f8b\u3002  \n\u25c6 \u901a\u8fc7\u65b0\u57fa\u51c6\u6d4b\u8bd5\u53d1\u73b0\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u79fb\u52a8\u76f8\u673a\u548c\u975e\u5e73\u9762\u573a\u666f\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u800c\u672c\u65b9\u6cd5\u5728\u6b64\u6311\u6218\u6027\u573a\u666f\u4e2d\u4ecd\u80fd\u7a33\u5b9a\u8f93\u51fa\u4eba\u4f53\u4e0e\u76f8\u673a\u4f4d\u59ff\u3002  \n\u25c6 \u4e3a\u590d\u6742\u771f\u5b9e\u573a\u666f\uff08\u5982\u4e0d\u5e73\u5730\u9762\u3001\u52a8\u6001\u89c6\u89d2\uff09\u7684\u7269\u7406\u53ef\u4fe1\u4eba\u4f53\u8fd0\u52a8\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.17312": "|2025-07-23|CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance|Peiqi Chen\u7b49|[2507.17312](http://arxiv.org/pdf/2507.17312)|\u65e0|\u25c6 \u63d0\u51faCasP\u65b0\u6d41\u7a0b\uff0c\u901a\u8fc7\u7ea7\u8054\u5bf9\u5e94\u5148\u9a8c\u5f15\u5bfc\u534a\u7a20\u5bc6\u7279\u5f81\u5339\u914d\uff0c\u6539\u8fdb\u4f20\u7edf\u5168\u5c40\u641c\u7d22\u65b9\u5f0f\uff0c\u63d0\u5347\u7cbe\u5ea6\u548c\u6548\u7387\u3002  \n\u25c6 \u5c06\u5339\u914d\u8fc7\u7a0b\u5206\u89e3\u4e3a\u4e24\u4e2a\u6e10\u8fdb\u9636\u6bb5\uff0c\u4e2d\u95f4\u5f15\u5165\u57fa\u4e8e\u533a\u57df\u7684\u9009\u62e9\u6027\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u589e\u5f3a\u7279\u5f81\u533a\u5206\u5ea6\u3002  \n\u25c6 \u5728\u7b2c\u4e8c\u9636\u6bb5\u5c06\u641c\u7d22\u8303\u56f4\u9650\u5236\u5728\u7b2c\u4e00\u9636\u6bb5\u8bc6\u522b\u7684\u4e00\u5bf9\u591a\u5148\u9a8c\u533a\u57df\uff0c\u5b9e\u73b0\u4e00\u5bf9\u4e00\u5339\u914d\u7684\u7cbe\u786e\u5b9a\u4f4d\u3002  \n\u25c6 \u7ed3\u5408\u9ad8\u5c42\u7279\u5f81\u964d\u4f4e\u4f4e\u5c42\u7279\u5f81\u63d0\u53d6\u8ba1\u7b97\u6210\u672c\uff0c\u5206\u8fa8\u7387\u8d8a\u9ad8\u52a0\u901f\u6548\u679c\u8d8a\u663e\u8457\uff081152\u5206\u8fa8\u7387\u4e0b\u6bd4ELoFTR\u5feb2.2\u500d\uff09\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u51e0\u4f55\u4f30\u8ba1\uff08\u5c24\u5176\u662f\u8de8\u57df\u6cdb\u5316\uff09\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\uff0c\u9002\u7528\u4e8eSLAM\u3001\u65e0\u4eba\u673a\u7b49\u9ad8\u5b9e\u65f6\u6027\u9ad8\u9c81\u68d2\u6027\u573a\u666f\u3002|\n",
    "2507.18344": "|2025-07-24|G2S-ICP SLAM: Geometry-aware Gaussian Splatting ICP SLAM|Gyuhyeon Pak\u7b49|[2507.18344](http://arxiv.org/pdf/2507.18344)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51e0\u4f55\u611f\u77e5\u7684\u9ad8\u65af\u6cfc\u6e85SLAM\u7cfb\u7edf\uff08G2S-ICP SLAM\uff09\uff0c\u901a\u8fc7\u5c06\u573a\u666f\u5143\u7d20\u8868\u793a\u4e3a\u5c40\u90e8\u5207\u5e73\u9762\u7ea6\u675f\u7684\u9ad8\u65af\u5206\u5e03\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f3D\u91cd\u5efa\u548c\u5b9e\u65f6\u76f8\u673a\u4f4d\u59ff\u8ddf\u8e2a\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u5c40\u90e8\u8868\u9762\u5efa\u6a21\u4e3a\u4e0e\u51e0\u4f55\u5bf9\u9f50\u76842D\u9ad8\u65af\u5706\u76d8\uff0c\u76f8\u6bd4\u4f20\u7edf\u5404\u5411\u540c\u60273D\u692d\u7403\u8868\u793a\uff0c\u80fd\u66f4\u4e00\u81f4\u5730\u5904\u7406\u591a\u89c6\u89d2\u6df1\u5ea6\u4fe1\u606f\u3002  \n\u25c6 \u5c06\u8868\u9762\u5bf9\u9f50\u7684\u9ad8\u65af\u5706\u76d8\u5d4c\u5165\u5e7f\u4e49ICP\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u5404\u5411\u5f02\u6027\u534f\u65b9\u5dee\u5148\u9a8c\uff0c\u5728\u4e0d\u6539\u53d8\u914d\u51c6\u516c\u5f0f\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u51e0\u4f55\u4e00\u81f4\u6027\u3002  \n\u25c6 \u63d0\u51fa\u51e0\u4f55\u611f\u77e5\u635f\u5931\u51fd\u6570\uff0c\u8054\u5408\u4f18\u5316\u5149\u5ea6\u3001\u6df1\u5ea6\u548c\u6cd5\u5411\u4e00\u81f4\u6027\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u91cd\u5efa\u548c\u8ddf\u8e2a\u7cbe\u5ea6\u3002  \n\u25c6 \u7cfb\u7edf\u5728Replica\u548cTUM-RGBD\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5728\u5b9a\u4f4d\u7cbe\u5ea6\u3001\u91cd\u5efa\u5b8c\u6574\u6027\u548c\u6e32\u67d3\u8d28\u91cf\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709SLAM\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u6027\u3002|\n",
    "2507.19474": "|2025-07-25|DINO-SLAM: DINO-informed RGB-D SLAM for Neural Implicit and Explicit Representations|Ziren Gong\u7b49|[2507.19474](http://arxiv.org/pdf/2507.19474)|\u65e0|\u25c6 \u63d0\u51faDINO-SLAM\uff0c\u4e00\u79cd\u57fa\u4e8eDINO\u7279\u5f81\u7684\u8bbe\u8ba1\u7b56\u7565\uff0c\u7528\u4e8e\u589e\u5f3aSLAM\u7cfb\u7edf\u4e2d\u795e\u7ecf\u9690\u5f0f\uff08NeRF\uff09\u548c\u663e\u5f0f\uff083DGS\uff09\u8868\u793a\u7684\u573a\u666f\u5efa\u6a21\u80fd\u529b\u3002  \n\u25c6 \u8bbe\u8ba1\u573a\u666f\u7ed3\u6784\u7f16\u7801\u5668\uff08SSE\uff09\uff0c\u5c06DINO\u7279\u5f81\u5347\u7ea7\u4e3a\u589e\u5f3a\u7248EDINO\uff0c\u4ee5\u6355\u6349\u573a\u666f\u7684\u5c42\u6b21\u5316\u5143\u7d20\u53ca\u5176\u7ed3\u6784\u5173\u7cfb\u3002  \n\u25c6 \u63d0\u51fa\u4e24\u79cd\u57fa\u4e8eEDINO\u7279\u5f81\u7684\u57fa\u7840\u8303\u5f0f\uff0c\u5206\u522b\u96c6\u6210\u5230NeRF\u548c3DGS\u7684SLAM\u7cfb\u7edf\u4e2d\uff0c\u63d0\u5347\u573a\u666f\u8868\u793a\u7684\u5168\u9762\u6027\u3002  \n\u25c6 \u5728Replica\u3001ScanNet\u548cTUM\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u6280\u672f\u3002  \n\u25c6 \u901a\u8fc7\u878d\u5408DINO\u7279\u5f81\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfSLAM\u7cfb\u7edf\u5728\u590d\u6742\u573a\u666f\u4e2d\u7ec6\u8282\u6355\u6349\u548c\u7ed3\u6784\u5173\u7cfb\u5efa\u6a21\u7684\u4e0d\u8db3\u3002|\n",
    "2507.19308": "|2025-07-25|The Eloquence team submission for task 1 of MLC-SLM challenge|Lorenzo Concina\u7b49|[2507.19308](http://arxiv.org/pdf/2507.19308)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u9488\u5bf9MLC-SLM\u6311\u6218\u8d5b\u4efb\u52a11\uff0c\u63d0\u51fa\u4e86\u591a\u8bed\u8a00\u4f1a\u8bdd\u8bed\u97f3\u8bc6\u522b\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u6838\u5fc3\u8d21\u732e\u5982\u4e0b\uff1a\n\n\u25c6 \u8bc4\u4f30\u4e86\u5b98\u65b9\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u8bad\u7ec3\u7ebf\u6027\u6295\u5f71\u5668\u548cqformer\u4e24\u79cd\u6295\u5f71\u5668\uff0c\u7ed3\u5408\u4e0d\u540c\u57fa\u7840\u6a21\u578b\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u57fa\u7ebf\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u3002\n\n\u25c6 \u5229\u7528SLAM-ASR\u6846\u67b6\u8bad\u7ec3\u4e86\u81ea\u5b9a\u4e49\u7684\u591a\u8bed\u8a00\u7ebf\u6027\u6295\u5f71\u5668\uff0c\u4f18\u5316\u4e86\u6a21\u578b\u5728\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u7684\u9002\u5e94\u6027\u3002\n\n\u25c6 \u63a2\u7d22\u4e86\u5bf9\u6bd4\u5b66\u4e60\u5728\u63d0\u5347\u8bed\u97f3\u8bc6\u522b\u9c81\u68d2\u6027\u4e2d\u7684\u4f5c\u7528\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u673a\u5236\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u591a\u6837\u5316\u8bed\u97f3\u8f93\u5165\u7684\u8bc6\u522b\u80fd\u529b\u3002\n\n\u25c6 \u7814\u7a76\u4e86\u6269\u5c55\u4f1a\u8bdd\u4e0a\u4e0b\u6587\u5bf9\u8bc6\u522b\u6548\u679c\u7684\u5f71\u54cd\uff0c\u9a8c\u8bc1\u4e86\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u5728\u6539\u5584\u4f1a\u8bdd\u8bed\u97f3\u8bc6\u522b\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\n\n\u25c6 \u7efc\u5408\u4e09\u79cd\u65b9\u6cd5\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u591a\u8bed\u8a00\u4f1a\u8bdd\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\u548c\u7406\u8bba\u652f\u6301\u3002|\n",
    "2507.19079": "|2025-07-25|SmartPNT-MSF: A Multi-Sensor Fusion Dataset for Positioning and Navigation Research|Feng Zhu\u7b49|[2507.19079](http://arxiv.org/pdf/2507.19079)|\u65e0|\u25c6 \u63d0\u51faSmartPNT-MSF\u591a\u6e90\u878d\u5408\u6570\u636e\u96c6\uff0c\u6574\u5408GNSS\u3001IMU\u3001\u5149\u5b66\u76f8\u673a\u548c\u6fc0\u5149\u96f7\u8fbe\u7b49\u591a\u4f20\u611f\u5668\u6570\u636e\uff0c\u5f25\u8865\u73b0\u6709\u6570\u636e\u96c6\u5728\u4f20\u611f\u5668\u591a\u6837\u6027\u4e0a\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u8be6\u7ec6\u8bb0\u5f55\u6570\u636e\u96c6\u6784\u5efa\u8fc7\u7a0b\uff0c\u5305\u62ec\u4f20\u611f\u5668\u914d\u7f6e\u3001\u5750\u6807\u7cfb\u5b9a\u4e49\u53ca\u76f8\u673a\u4e0e\u6fc0\u5149\u96f7\u8fbe\u6807\u5b9a\u6d41\u7a0b\uff0c\u786e\u4fdd\u6570\u636e\u7684\u4e00\u81f4\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u6807\u51c6\u5316\u6570\u636e\u91c7\u96c6\u4e0e\u5904\u7406\u6846\u67b6\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5206\u6790\u5e76\u5177\u5907\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u591a\u4f20\u611f\u5668\u878d\u5408\u7814\u7a76\u63d0\u4f9b\u7ed3\u6784\u5316\u57fa\u7840\u3002  \n\u25c6 \u901a\u8fc7VINS-Mono\u3001LIO-SAM\u7b49\u5148\u8fdbSLAM\u7b97\u6cd5\u9a8c\u8bc1\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6027\uff0c\u8bc1\u660e\u5176\u9002\u7528\u4e8e\u9ad8\u7cbe\u5ea6\u5bfc\u822a\u4e0e\u5b9a\u4f4d\u7b97\u6cd5\u5f00\u53d1\u3002  \n\u25c6 \u8986\u76d6\u57ce\u5e02\u3001\u6821\u56ed\u3001\u96a7\u9053\u53ca\u90ca\u533a\u7b49\u591a\u79cd\u771f\u5b9e\u573a\u666f\uff0c\u589e\u5f3a\u590d\u6742\u73af\u5883\u4e0b\u7684\u5bfc\u822a\u6280\u672f\u7814\u7a76\u80fd\u529b\uff0c\u586b\u8865\u73af\u5883\u591a\u6837\u6027\u7a7a\u767d\u3002  \n\u25c6 \u516c\u5f00\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u4fc3\u8fdb\u5bfc\u822a\u9886\u57df\u7b97\u6cd5\u6d4b\u8bd5\u4e0e\u6bd4\u8f83\uff0c\u63a8\u52a8\u591a\u4f20\u611f\u5668\u878d\u5408\u6280\u672f\u7684\u521b\u65b0\u4e0e\u53d1\u5c55\u3002|\n",
    "2507.18886": "|2025-07-25|A Fast and Light-weight Non-Iterative Visual Odometry with RGB-D Cameras|Zheng Yang\u7b49|[2507.18886](http://arxiv.org/pdf/2507.18886)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u8026\u7684\u975e\u8fed\u4ee3\u89c6\u89c9\u91cc\u7a0b\u8ba1\u65b9\u6cd5\uff0c\u5c066\u81ea\u7531\u5ea6\u4f4d\u59ff\u4f30\u8ba1\u5206\u4e3a\u65cb\u8f6c\u548c\u5e73\u79fb\u4e24\u6b65\u8ba1\u7b97\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u8fed\u4ee3\u4f18\u5316\u5e26\u6765\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002  \n\u25c6 \u5229\u7528\u573a\u666f\u4e2d\u7684\u91cd\u53e0\u5e73\u9762\u7279\u5f81\u76f4\u63a5\u8ba1\u7b97\u65cb\u8f6c\u77e9\u9635\uff0c\u7b80\u5316\u4e86\u65cb\u8f6c\u4f30\u8ba1\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u91c7\u7528\u6838\u4e92\u76f8\u5173\u5668(KCC)\u8ba1\u7b97\u5e73\u79fb\u91cf\uff0c\u7701\u53bb\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7279\u5f81\u63d0\u53d6\u4e0e\u5339\u914d\u7684\u8017\u65f6\u6b65\u9aa4\u3002  \n\u25c6 \u6574\u4e2a\u6d41\u7a0b\u65e0\u9700\u8fed\u4ee3\u4f18\u5316\uff0c\u5728\u4f4e\u7aefi5 CPU\u4e0a\u5b9e\u73b0\u4e8671Hz\u7684\u9ad8\u5b9e\u65f6\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u4e0d\u4f9d\u8d56\u7279\u5f81\u70b9\u7684\u7279\u6027\u4f7f\u7b97\u6cd5\u5728\u4f4e\u7eb9\u7406\u6216\u9000\u5316\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u9c81\u68d2\u6027\u66f4\u5f3a\u3002  \n\u25c6 \u901a\u8fc7\u5206\u79bb\u65cb\u8f6c\u4e0e\u5e73\u79fb\u4f30\u8ba1\u5e76\u5229\u7528\u5e73\u9762\u7279\u5f81\uff0c\u5728\u4fdd\u6301\u8f7b\u91cf\u7ea7\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5feb\u901f\u4f4d\u59ff\u4f30\u8ba1\u3002|\n",
    "2507.20854": "|2025-07-28|$S^3$LAM: Surfel Splatting SLAM for Geometrically Accurate Tracking and Mapping|Ruoyu Fan\u7b49|[2507.20854](http://arxiv.org/pdf/2507.20854)|\u65e0|\u25c6 \u63d0\u51faS\u00b3LAM\u7cfb\u7edf\uff0c\u91c7\u75282D\u9762\u5143\uff08surfel\uff09\u4f5c\u4e3a\u57fa\u672c\u8868\u793a\u5355\u5143\uff0c\u66ff\u4ee3\u4f20\u7edf3D\u9ad8\u65af\u692d\u7403\u4f53\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u573a\u666f\u51e0\u4f55\u5efa\u6a21\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u75282D\u9ad8\u65af\u9762\u5143\u8fdb\u884c\u573a\u666f\u8868\u9762\u91cd\u5efa\uff0c\u663e\u8457\u63d0\u5347\u51e0\u4f55\u7cbe\u5ea6\uff0c\u540c\u65f6\u4f18\u5316\u8ddf\u8e2a\u4e0e\u5efa\u56fe\u6027\u80fd\u3002  \n\u25c6 \u8bbe\u8ba1\u81ea\u9002\u5e94\u8868\u9762\u6e32\u67d3\u7b56\u7565\uff0c\u89e3\u51b3SLAM\u5728\u6709\u9650\u89c6\u89d2\u4e0b\u7684\u5b9e\u65f6\u4f18\u5316\u95ee\u9898\uff0c\u517c\u987e\u8ba1\u7b97\u6548\u7387\u4e0e\u5efa\u56fe\u51c6\u786e\u6027\u3002  \n\u25c6 \u76f4\u63a5\u4ece2D\u9762\u5143\u6e32\u67d3\u516c\u5f0f\u63a8\u5bfc\u76f8\u673a\u4f4d\u59ff\u96c5\u53ef\u6bd4\u77e9\u9635\uff0c\u51f8\u663e\u51e0\u4f55\u7cbe\u786e\u8868\u793a\u5bf9\u8ddf\u8e2a\u6536\u655b\u6027\u7684\u5173\u952e\u4f5c\u7528\u3002  \n\u25c6 \u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86S\u00b3LAM\u7684\u4f18\u8d8a\u6027\uff0c\u6027\u80fd\u8fbe\u5230\u5f53\u524d\u6700\u4f18\u6c34\u5e73\u3002|\n",
    "2507.20516": "|2025-07-28|Large-Scale LiDAR-Inertial Dataset for Degradation-Robust High-Precision Mapping|Xiaofeng Jin\u7b49|[2507.20516](http://arxiv.org/pdf/2507.20516)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u5927\u89c4\u6a21\u3001\u9ad8\u7cbe\u5ea6\u7684LiDAR-\u60ef\u6027\u91cc\u7a0b\u8ba1\uff08LIO\uff09\u6570\u636e\u96c6\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u5728\u590d\u6742\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e0d\u8db3\u7684\u7a7a\u767d\u3002  \n\u25c6 \u6570\u636e\u96c6\u8986\u76d6\u56db\u79cd\u591a\u6837\u5316\u771f\u5b9e\u73af\u5883\uff086\u4e07\u81f375\u4e07\u5e73\u65b9\u7c73\uff09\uff0c\u901a\u8fc7\u5b9a\u5236\u80cc\u5305\u5f0f\u5e73\u53f0\u91c7\u96c6\uff0c\u96c6\u6210\u591a\u7ebf\u6fc0\u5149\u96f7\u8fbe\u3001\u5de5\u4e1a\u7ea7IMU\u548cRTK-GNSS\u6a21\u5757\u3002  \n\u25c6 \u63d0\u4f9b\u957f\u8f68\u8ff9\u3001\u590d\u6742\u573a\u666f\u548c\u9ad8\u7cbe\u5ea6\u771f\u503c\uff0c\u7ed3\u5408SLAM\u4f18\u5316\u4e0eRTK-GNSS\u951a\u5b9a\u6280\u672f\u751f\u6210\uff0c\u5e76\u901a\u8fc7\u503e\u659c\u6444\u5f71\u4e0eRTK-GNSS\u878d\u5408\u9a8c\u8bc1\u8f68\u8ff9\u7cbe\u5ea6\u3002  \n\u25c6 \u9996\u6b21\u5728\u6570\u636e\u96c6\u4e2d\u878d\u5408\u591a\u4f20\u611f\u5668\u5197\u4f59\u6570\u636e\uff08\u5982LiDAR-IMU-RTK\uff09\uff0c\u652f\u6301\u9000\u5316\u573a\u666f\uff08\u5982\u96a7\u9053\u3001\u690d\u88ab\uff09\u4e0b\u7684\u9c81\u68d2\u6027\u8bc4\u4f30\u3002  \n\u25c6 \u4e3a\u9ad8\u7cbe\u5ea6\u5730\u56fe\u6784\u5efa\u4efb\u52a1\u63d0\u4f9b\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u91cd\u70b9\u9a8c\u8bc1LIO\u7cfb\u7edf\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u4e0e\u9000\u5316\u9002\u5e94\u6027\u3002|\n",
    "2507.19742": "|2025-07-26|DOA: A Degeneracy Optimization Agent with Adaptive Pose Compensation Capability based on Deep Reinforcement Learning|Yanbin Li\u7b49|[2507.19742](http://arxiv.org/pdf/2507.19742)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u7684\u81ea\u9002\u5e94\u9000\u5316\u4f18\u5316\u667a\u80fd\u4f53\uff08DOA\uff09\uff0c\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3SLAM\u5728\u957f\u76f4\u8d70\u5eca\u7b49\u9000\u5316\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u7cfb\u7edf\u6027\u65b9\u6cd5\u89e3\u51b3\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u7684\u4e09\u5927\u6311\u6218\uff1a\u9000\u5316\u6570\u636e\u96c6\u83b7\u53d6\u74f6\u9888\u3001\u8bad\u7ec3\u6837\u672c\u8d28\u91cf\u4e0b\u964d\u95ee\u9898\u4ee5\u53ca\u6807\u6ce8\u534f\u8bae\u8bbe\u8ba1\u7684\u6a21\u7cca\u6027\u3002  \n\u25c6 \u5f00\u53d1\u4e13\u7528\u5956\u52b1\u51fd\u6570\uff0c\u5f15\u5bfc\u667a\u80fd\u4f53\u5b66\u4e60\u9000\u5316\u73af\u5883\u611f\u77e5\u80fd\u529b\uff0c\u5e76\u57fa\u4e8e\u9000\u5316\u56e0\u5b50\u52a8\u6001\u8c03\u6574\u4e0d\u540c\u4f20\u611f\u5668\u5bf9\u4f4d\u59ff\u4f18\u5316\u7684\u8d21\u732e\u6743\u91cd\u3002  \n\u25c6 \u63d0\u51fa\u7ebf\u6027\u63d2\u503c\u516c\u5f0f\u63a7\u5236\u89c2\u6d4b\u5206\u5e03\u5411\u8fd0\u52a8\u6a21\u578b\u5206\u5e03\u7684\u504f\u79fb\u6b65\u957f\uff0c\u5b9e\u73b0\u4f4d\u59ff\u8865\u507f\u7684\u81ea\u9002\u5e94\u8c03\u6574\u3002  \n\u25c6 \u5f15\u5165\u8fc1\u79fb\u5b66\u4e60\u6a21\u5757\u63d0\u5347\u667a\u80fd\u4f53\u8de8\u73af\u5883\u6cdb\u5316\u80fd\u529b\uff0c\u89e3\u51b3\u9000\u5316\u73af\u5883\u4e2d\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u6a21\u578b\u8bbe\u8ba1\u5408\u7406\u6027\uff0c\u5e76\u8bc1\u660eDOA\u5728\u591a\u79cd\u73af\u5883\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u9000\u5316\u68c0\u6d4b\u4e0e\u4f18\u5316\u6027\u80fd\u3002|\n",
    "2507.21715": "|2025-07-29|Impact of Underwater Image Enhancement on Feature Matching|Jason M. Summers\u7b49|[2507.21715](http://arxiv.org/pdf/2507.21715)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u5c40\u90e8\u5339\u914d\u7a33\u5b9a\u6027\u548c\u6700\u8fdc\u53ef\u5339\u914d\u5e27\u6570\u4e24\u9879\u91cf\u5316\u6307\u6807\uff0c\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u6c34\u4e0b\u56fe\u50cf\u589e\u5f3a\u6548\u679c\u3002  \n\u25c6 \u9488\u5bf9\u6c34\u4e0b\u73af\u5883\u7279\u6709\u7684\u5149\u5438\u6536\u3001\u6563\u5c04\u3001\u751f\u7269\u9644\u7740\u7b49\u9000\u5316\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u9762\u5411\u589e\u5f3a\u6280\u672f\u7684\u5e27\u5339\u914d\u6027\u80fd\u8bc4\u4f30\u6846\u67b6\u3002  \n\u25c6 \u901a\u8fc7\u5ea6\u91cf\u5206\u6790\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\uff0c\u9996\u6b21\u6307\u51fa\u5176\u5728\u771f\u5b9e\u573a\u666f\u9002\u7528\u6027\u8bc4\u4f30\u65b9\u9762\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u5b9e\u9645\u5339\u914d\u7b56\u7565\u878d\u5165\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5efa\u7acb\u4e86\u7ed3\u5408\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u589e\u5f3a\u65b9\u6cd5\u5bf9\u6bd4\u57fa\u51c6\u3002  \n\u25c6 \u901a\u8fc7SLAM\u7cfb\u7edf\u7684\u5168\u6d41\u7a0b\u9a8c\u8bc1\uff0c\u8bc1\u5b9e\u4e86\u89c6\u89c9\u8d28\u91cf\u63d0\u5347\u5bf9\u6c34\u4e0b\u81ea\u4e3b\u5bfc\u822a\u7b97\u6cd5\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u5f3a\u5316\u4e86\u6846\u67b6\u7684\u5de5\u7a0b\u4ef7\u503c\u3002  \n\u25c6 \u8be5\u7814\u7a76\u586b\u8865\u4e86\u6c34\u4e0b\u56fe\u50cf\u589e\u5f3a\u6280\u672f\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u5173\u8054\u6027\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u7b97\u6cd5\u4f18\u5316\u63d0\u4f9b\u4e86\u660e\u786e\u65b9\u5411\u3002|\n",
    "2507.21709": "|2025-07-29|Adaptive Prior Scene-Object SLAM for Dynamic Environments|Haolan Zhang\u7b49|[2507.21709](http://arxiv.org/pdf/2507.21709)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u573a\u666f-\u7269\u4f53\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5f53\u524d\u5e27\u8d28\u91cf\u6307\u6807\u548c\u76f8\u5bf9\u4e8e\u53ef\u9760\u53c2\u8003\u5e27\u7684\u573a\u666f\u53d8\u5316\uff0c\u5168\u9762\u8bc4\u4f30SLAM\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u3002  \n\u25c6 \u9488\u5bf9\u73b0\u6709\u7cfb\u7edf\u5728\u59ff\u6001\u4f30\u8ba1\u4e0d\u53ef\u9760\u65f6\u7f3a\u4e4f\u7ea0\u9519\u673a\u5236\u7684\u95ee\u9898\uff0c\u91c7\u7528\u59ff\u6001\u4f18\u5316\u7b56\u7565\uff0c\u5229\u7528\u53ef\u9760\u5e27\u4fe1\u606f\u4f18\u5316\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\uff0c\u6709\u6548\u51cf\u5c11\u52a8\u6001\u5e72\u6270\u7684\u8d1f\u9762\u5f71\u54cd\u3002  \n\u25c6 \u5728\u52a8\u6001\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u7cfb\u7edf\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u89c6\u89d2\u7a81\u53d8\u548c\u8fd0\u52a8\u7269\u4f53\u7279\u5f81\u4e0d\u660e\u786e\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u4f18\u5f02\u3002  \n\u25c6 \u901a\u8fc7TUM RGB-D\u6570\u636e\u96c6\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u6311\u6218\u6027\u52a8\u6001\u573a\u666f\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002  \n\u25c6 \u7ed3\u5408\u5f53\u524d\u5e27\u8d28\u91cf\u4e0e\u573a\u666f\u53d8\u5316\u8bc4\u4f30\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u5168\u9762\u7684\u52a8\u6001\u73af\u5883SLAM\u7a33\u5b9a\u6027\u5224\u65ad\u65b9\u6cd5\u3002  \n\u25c6 \u63d0\u51fa\u7684\u59ff\u6001\u4f18\u5316\u7b56\u7565\u4e3a\u52a8\u6001\u73af\u5883\u4e0b\u7684SLAM\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bef\u5dee\u6821\u6b63\u673a\u5236\u3002|\n",
    "2507.21553": "|2025-08-01|Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments|Federica Di Lauro\u7b49|[2507.21553](http://arxiv.org/pdf/2507.21553)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5730\u4e0b\u96a7\u9053\u73af\u5883\u7684\u53bb\u4e2d\u5fc3\u5316\u591a\u673a\u5668\u4ebaLiDAR SLAM\u7cfb\u7edf\uff0c\u5206\u6790\u4e86\u73b0\u6709\u6280\u672f\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u53d1\u73b0\u5f53\u524d\u95ed\u73af\u68c0\u6d4b\u5b58\u5728\u5927\u91cf\u8bef\u62a5\u95ee\u9898\uff0c\u8fd9\u662f\u5bfc\u81f4\u7cfb\u7edf\u5931\u8d25\u7684\u4e3b\u8981\u539f\u56e0\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u95ed\u73af\u68c0\u6d4b\u4e2d\u7684\u8bef\u62a5\u60c5\u51b5\u3002  \n\u25c6 \u5728\u5730\u4e0b\u96a7\u9053\u8fd9\u4e00\u6781\u5177\u6311\u6218\u6027\u7684\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u6307\u51fa\u4e86\u8be5\u9886\u57df\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u6f5c\u5728\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u4e86\u53c2\u8003\u3002|\n",
    "2507.22791": "|2025-07-30|Modality-Aware Feature Matching: A Comprehensive Review of Single- and Cross-Modality Techniques|Weide Liu\u7b49|[2507.22791](http://arxiv.org/pdf/2507.22791)|\u65e0|\u25c6 \u5168\u9762\u7efc\u8ff0\u4e86\u5355\u6a21\u6001\u4e0e\u8de8\u6a21\u6001\u7279\u5f81\u5339\u914d\u6280\u672f\uff0c\u6db5\u76d6RGB\u56fe\u50cf\u3001\u6df1\u5ea6\u56fe\u50cf\u30013D\u70b9\u4e91\u3001LiDAR\u626b\u63cf\u3001\u533b\u5b66\u56fe\u50cf\u53ca\u89c6\u89c9-\u8bed\u8a00\u4ea4\u4e92\u7b49\u591a\u79cd\u6a21\u6001\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7cfb\u7edf\u6027\u603b\u7ed3\u7684\u7a7a\u767d\u3002  \n\u25c6 \u5bf9\u6bd4\u5206\u6790\u4e86\u4f20\u7edf\u624b\u5de5\u65b9\u6cd5\uff08\u5982Harris\u89d2\u70b9\u3001SIFT\u548cORB\u63cf\u8ff0\u5b50\uff09\u4e0e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08\u5982SuperPoint\u548cLoFTR\uff09\uff0c\u6307\u51fa\u540e\u8005\u5728\u8de8\u6a21\u6001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u4e0a\u7684\u663e\u8457\u4f18\u52bf\u3002  \n\u25c6 \u91cd\u70b9\u4ecb\u7ecd\u4e86\u6a21\u6001\u611f\u77e5\u6280\u672f\u8fdb\u5c55\uff0c\u5305\u62ec\u9488\u5bf9\u6df1\u5ea6\u56fe\u50cf\u7684\u51e0\u4f55\u4e0e\u6df1\u5ea6\u4e13\u7528\u63cf\u8ff0\u5b50\u30013D\u70b9\u4e91\u7684\u7a00\u758f\u4e0e\u7a20\u5bc6\u5b66\u4e60\u65b9\u6cd5\u3001LiDAR\u626b\u63cf\u7684\u6ce8\u610f\u529b\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u53ca\u533b\u5b66\u56fe\u50cf\u5339\u914d\u7684MIND\u63cf\u8ff0\u5b50\u7b49\u521b\u65b0\u65b9\u6848\u3002  \n\u25c6 \u6df1\u5165\u63a2\u8ba8\u8de8\u6a21\u6001\u5e94\u7528\u573a\u666f\uff0c\u5982\u533b\u5b66\u56fe\u50cf\u914d\u51c6\u548c\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\uff0c\u63ed\u793a\u4e86\u7279\u5f81\u5339\u914d\u6280\u672f\u5904\u7406\u591a\u6837\u5316\u6570\u636e\u4ea4\u4e92\u7684\u6700\u65b0\u53d1\u5c55\u8d8b\u52bf\u3002  \n\u25c6 \u5f3a\u8c03\u68c0\u6d4b\u5668\u65e0\u5173\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08\u5982\u57fa\u4e8eCNN\u548cTransformer\u7684\u6a21\u578b\uff09\u5bf9\u8de8\u6a21\u6001\u5339\u914d\u6027\u80fd\u7684\u63d0\u5347\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002|\n",
    "2507.22412": "|2025-07-30|UAVScenes: A Multi-Modal Dataset for UAVs|Sijie Wang\u7b49|[2507.22412](http://arxiv.org/pdf/2507.22412)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u652f\u6301\u591a\u6a21\u6001\uff08\u76f8\u673a\u56fe\u50cf\u548cLiDAR\u70b9\u4e91\uff09\u5e27\u7ea7\u6807\u6ce8\u7684\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u6570\u636e\u96c6UAVScenes\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u96c6\u4ec5\u652f\u6301\u5b9a\u4f4d\u6216\u5730\u56fe\u7ea7\u8bed\u4e49\u5206\u5272\u7684\u7a7a\u767d\u3002  \n\u25c6 \u57fa\u4e8eMARS-LVIG\u6570\u636e\u96c6\u8fdb\u884c\u5347\u7ea7\uff0c\u65b0\u589e\u4e86\u4eba\u5de5\u6807\u6ce8\u7684\u9010\u5e27\u56fe\u50cf\u548c\u70b9\u4e91\u8bed\u4e49\u6807\u7b7e\uff0c\u4ee5\u53ca\u9ad8\u7cbe\u5ea66\u81ea\u7531\u5ea6\u4f4d\u59ff\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u5b9e\u7528\u6027\u3002  \n\u25c6 \u9996\u6b21\u652f\u6301\u65e0\u4eba\u673a\u573a\u666f\u4e0b\u7684\u591a\u4efb\u52a1\u8054\u5408\u8bc4\u6d4b\uff0c\u5305\u62ec\u5206\u5272\u3001\u6df1\u5ea6\u4f30\u8ba1\u30016-DoF\u5b9a\u4f4d\u3001\u5730\u70b9\u8bc6\u522b\u548c\u65b0\u89c6\u89d2\u5408\u6210\uff08NVS\uff09\u7b49\u9ad8\u7ea7\u611f\u77e5\u4efb\u52a1\u3002  \n\u25c6 \u901a\u8fc7\u4e25\u683c\u7684\u4f20\u611f\u5668\u6807\u5b9a\u548c\u540c\u6b65\uff0c\u786e\u4fdd\u591a\u6a21\u6001\u6570\u636e\u7684\u65f6\u95f4-\u7a7a\u95f4\u5bf9\u9f50\uff0c\u4e3a\u8de8\u6a21\u6001\u878d\u5408\u7814\u7a76\u63d0\u4f9b\u53ef\u9760\u57fa\u51c6\u3002  \n\u25c6 \u5f00\u6e90\u6570\u636e\u96c6\u5e76\u8bbe\u8ba1\u6807\u51c6\u5316\u8bc4\u6d4b\u534f\u8bae\uff0c\u63a8\u52a8\u65e0\u4eba\u673a\u591a\u6a21\u6001\u611f\u77e5\u9886\u57df\u7684\u7b97\u6cd5\u53d1\u5c55\u548c\u516c\u5e73\u6bd4\u8f83\u3002|\n",
    "2507.23677": "|2025-07-31|Stereo 3D Gaussian Splatting SLAM for Outdoor Urban Scenes|Xiaohan Li\u7b49|[2507.23677](http://arxiv.org/pdf/2507.23677)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u9762\u5411\u6237\u5916\u573a\u666f\u7684\u53cc\u76ee3D\u9ad8\u65af\u6cfc\u6e85SLAM\u7cfb\u7edf\uff08BGS-SLAM\uff09\uff0c\u586b\u8865\u4e86\u73b0\u67093DGS-SLAM\u4e3b\u8981\u9488\u5bf9\u5ba4\u5185\u73af\u5883\u4e14\u4f9d\u8d56\u4e3b\u52a8\u6df1\u5ea6\u4f20\u611f\u5668\u7684\u7a7a\u767d\u3002  \n\u25c6 \u4ec5\u4f7f\u7528RGB\u7acb\u4f53\u56fe\u50cf\u5bf9\uff0c\u65e0\u9700LiDAR\u6216\u4e3b\u52a8\u4f20\u611f\u5668\uff0c\u964d\u4f4e\u4e86\u786c\u4ef6\u6210\u672c\u5e76\u63d0\u5347\u4e86\u7cfb\u7edf\u9002\u7528\u6027\u3002  \n\u25c6 \u5229\u7528\u9884\u8bad\u7ec3\u6df1\u5ea6\u7acb\u4f53\u7f51\u7edc\u7684\u6df1\u5ea6\u4f30\u8ba1\u6307\u5bfc3D\u9ad8\u65af\u4f18\u5316\uff0c\u901a\u8fc7\u591a\u635f\u5931\u7b56\u7565\u540c\u65f6\u63d0\u5347\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u89c6\u89c9\u8d28\u91cf\u3002  \n\u25c6 \u5728\u590d\u6742\u6237\u5916\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u4f18\u4e8e\u5176\u4ed6\u57fa\u4e8e3DGS\u65b9\u6848\u7684\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u5efa\u56fe\u6027\u80fd\u3002  \n\u25c6 \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u4f18\u8d8a\u6027\uff0c\u4e3a\u6237\u5916\u5927\u89c4\u6a21\u573a\u666f\u7684\u5b9e\u65f6\u9ad8\u4fdd\u771fSLAM\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.23629": "|2025-07-31|DRACo-SLAM2: Distributed Robust Acoustic Communication-efficient SLAM for Imaging Sonar EquippedUnderwater Robot Teams with Object Graph Matching|Yewei Huang\u7b49|[2507.23629](http://arxiv.org/pdf/2507.23629)|\u65e0|\u25c6 \u63d0\u51faDRACo-SLAM2\u6846\u67b6\uff0c\u4e3a\u914d\u5907\u591a\u6ce2\u675f\u6210\u50cf\u58f0\u7eb3\u7684\u6c34\u4e0b\u673a\u5668\u4eba\u56e2\u961f\u8bbe\u8ba1\u5206\u5e03\u5f0fSLAM\u7cfb\u7edf\uff0c\u6539\u8fdb\u539f\u6709DRACo-SLAM\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u58f0\u7eb3\u5730\u56fe\u8868\u793a\u4e3a\u5bf9\u8c61\u56fe\uff0c\u5229\u7528\u5bf9\u8c61\u56fe\u5339\u914d\u5b9e\u73b0\u9ad8\u6548\u8de8\u673a\u5668\u4eba\u56de\u73af\u68c0\u6d4b\uff0c\u65e0\u9700\u4f9d\u8d56\u5148\u9a8c\u51e0\u4f55\u4fe1\u606f\u3002  \n\u25c6 \u9488\u5bf9\u6c34\u4e0b\u626b\u63cf\u5339\u914d\u7279\u70b9\uff0c\u63d0\u51fa\u589e\u91cf\u5f0f\u7ec4\u95f4\u4e00\u81f4\u6d4b\u91cf\u96c6\u6700\u5927\u5316\uff08GCM\uff09\u65b9\u6cd5\uff0c\u6539\u8fdb\u539f\u6709\u7684PCM\u7b97\u6cd5\u3002  \n\u25c6 GCM\u65b9\u6cd5\u6709\u6548\u5904\u7406\u76f8\u90bb\u8de8\u673a\u5668\u4eba\u56de\u73af\u5171\u4eab\u76f8\u4f3c\u914d\u51c6\u8bef\u5dee\u7684\u573a\u666f\uff0c\u63d0\u5347\u5339\u914d\u9c81\u68d2\u6027\u3002  \n\u25c6 \u901a\u8fc7\u5927\u91cf\u4eff\u771f\u548c\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002|\n",
    "2507.23273": "|2025-07-31|GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting|Jaeseok Park\u7b49|[2507.23273](http://arxiv.org/pdf/2507.23273)|\u65e0|\u25c6 \u63d0\u51faGSFusion\u7cfb\u7edf\uff0c\u9996\u6b21\u5c06\u6fc0\u5149\u96f7\u8fbe\uff08LiDAR\uff09\u3001\u60ef\u6027\u6d4b\u91cf\u5355\u5143\uff08IMU\uff09\u4e0e\u89c6\u89c9\u4f20\u611f\u5668\u878d\u5408\uff0c\u5b9e\u73b0\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7684\u5728\u7ebf\u5efa\u56fe\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7eaf\u89c6\u89c9\u65b9\u6cd5\u5728\u5f31\u7eb9\u7406\u3001\u5149\u7167\u4e0d\u8db3\u548c\u8fdc\u8ddd\u79bb\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u5f15\u5165\u5168\u5c40\u4f4d\u59ff\u56fe\u4f18\u5316\u4e2d\u7684\u9762\u5143\u5230\u9762\u5143\uff08surfel-to-surfel\uff09\u7ea6\u675f\uff0c\u663e\u8457\u63d0\u5347\u5730\u56fe\u7684\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u786e\u4fdd\u9ad8\u7cbe\u5ea6\u5efa\u56fe\u8d28\u91cf\u3002  \n\u25c6 \u8bbe\u8ba1\u50cf\u7d20\u611f\u77e5\u7684\u9ad8\u65af\u521d\u59cb\u5316\u7b56\u7565\uff0c\u6709\u6548\u5229\u7528\u7a00\u758f\u6fc0\u5149\u96f7\u8fbe\u6570\u636e\u5feb\u901f\u751f\u6210\u9ad8\u65af\u8868\u793a\uff0c\u5927\u5e45\u7f29\u77ed\u4f18\u5316\u65f6\u95f4\u3002  \n\u25c6 \u63d0\u51fa\u6709\u754cSigmoid\u7ea6\u675f\u673a\u5236\uff0c\u9632\u6b62\u9ad8\u65af\u5206\u5e03\u65e0\u9650\u5236\u6269\u5f20\uff0c\u63d0\u5347\u573a\u666f\u8868\u793a\u7684\u7a33\u5b9a\u6027\u548c\u6e32\u67d3\u6548\u7387\u3002  \n\u25c6 \u5728\u516c\u5f00\u548c\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u6e32\u67d3\u8d28\u91cf\u548c\u5efa\u56fe\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u67093DGS SLAM\u65b9\u6848\uff0c\u5c24\u5176\u5728\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u7a81\u51fa\u3002|\n",
    "2508.00568": "|2025-08-01|CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry|Jingchao Xie\u7b49|[2508.00568](http://arxiv.org/pdf/2508.00568)|\u65e0|\u25c6 \u63d0\u51faCoProU-VO\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u8de8\u5e27\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\u4e0e\u878d\u5408\u5f15\u5165\u65e0\u76d1\u7763\u5355\u76ee\u89c6\u89c9\u91cc\u7a0b\u8ba1\uff0c\u901a\u8fc7\u6982\u7387\u5316\u5efa\u6a21\u7ed3\u5408\u5f53\u524d\u5e27\u4e0e\u53c2\u8003\u5e27\u7684\u4e0d\u786e\u5b9a\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u57fa\u4e8e\u89c6\u89c9Transformer\u4e3b\u5e72\u7f51\u7edc\uff0c\u540c\u6b65\u5b66\u4e60\u6df1\u5ea6\u3001\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u76f8\u673a\u4f4d\u59ff\uff0c\u65e0\u9700\u52a8\u6001\u7269\u4f53\u663e\u5f0f\u6807\u6ce8\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u7528\u6295\u5f71\u673a\u5236\u5c06\u53c2\u8003\u5e27\u4e0d\u786e\u5b9a\u6027\u4f20\u9012\u81f3\u76ee\u6807\u5e27\uff0c\u6709\u6548\u8bc6\u522b\u52a8\u6001\u573a\u666f\u4e2d\u7684\u4e0d\u53ef\u9760\u533a\u57df\uff0c\u7a81\u7834\u4f20\u7edf\u5355\u5e27\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u7684\u5c40\u9650\u3002  \n\u25c6 \u5728KITTI\u548cnuScenes\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65e0\u76d1\u7763\u5355\u76ee\u4e24\u5e27\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u52a8\u6001\u7269\u4f53\u5bc6\u96c6\u7684\u9ad8\u901f\u516c\u8def\u573a\u666f\u8868\u73b0\u7a81\u51fa\u3002  \n\u25c6 \u901a\u8fc7\u8be6\u5b9e\u7684\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u8de8\u5e27\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\u7684\u6709\u6548\u6027\uff0c\u4e3a\u52a8\u6001\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u4f4d\u59ff\u4f30\u8ba1\u63d0\u4f9b\u65b0\u601d\u8def\u3002|\n",
    "2508.00088": "|2025-07-31|The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking|Mateo de Mayo\u7b49|[2508.00088](http://arxiv.org/pdf/2508.00088)|\u65e0|\u25c6 \u63d0\u51fa\u4e86Monado SLAM\u6570\u636e\u96c6\uff0c\u4e13\u95e8\u9488\u5bf9\u5934\u6234\u5f0f\u8bbe\u5907\u7684\u89c6\u89c9-\u60ef\u6027\u8ddf\u8e2a\u6311\u6218\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u6570\u636e\u96c6\u5305\u542b\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u9ad8\u52a8\u6001\u8fd0\u52a8\u3001\u52a8\u6001\u906e\u6321\u3001\u957f\u65f6\u95f4\u8ddf\u8e2a\u7b49\u590d\u6742\u60c5\u51b5\uff0c\u66f4\u8d34\u8fd1\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u3002  \n\u25c6 \u8986\u76d6\u4e86\u4f4e\u7eb9\u7406\u533a\u57df\u3001\u6076\u52a3\u5149\u7167\u6761\u4ef6\u548c\u4f20\u611f\u5668\u9971\u548c\u7b49\u73b0\u6709\u6570\u636e\u96c6\u8f83\u5c11\u6d89\u53ca\u7684\u96be\u70b9\u573a\u666f\u3002  \n\u25c6 \u6570\u636e\u6765\u81ea\u591a\u6b3e\u865a\u62df\u73b0\u5b9e\u5934\u663e\u8bbe\u5907\uff0c\u5177\u6709\u591a\u6837\u6027\u548c\u4ee3\u8868\u6027\uff0c\u9002\u7528\u4e8e\u5934\u6234\u5f0f\u4f20\u611f\u5668\u7814\u7a76\u3002  \n\u25c6 \u91c7\u7528CC BY 4.0\u8bb8\u53ef\u534f\u8bae\u516c\u5f00\u6570\u636e\u96c6\uff0c\u4fc3\u8fdb\u89c6\u89c9-\u60ef\u6027\u91cc\u7a0b\u8ba1\uff08VIO\uff09\u548cSLAM\u6280\u672f\u7684\u7814\u53d1\u8fdb\u6b65\u3002  \n\u25c6 \u901a\u8fc7\u771f\u5b9e\u573a\u666f\u6570\u636e\u66b4\u9732\u73b0\u6709VIO/SLAM\u7cfb\u7edf\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u7b97\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u63d0\u5347\u3002|\n",
    "2508.02187": "|2025-08-04|A Moment Matching-Based Method for Sparse and Noisy Point Cloud Registration|Xingyi Li\u7b49|[2508.02187](http://arxiv.org/pdf/2508.02187)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u77e9\u5339\u914d\u7684\u70b9\u4e91\u914d\u51c6\u6846\u67b6\uff0c\u5c06\u70b9\u4e91\u89c6\u4e3a\u540c\u5206\u5e03\u72ec\u7acb\u6837\u672c\uff0c\u901a\u8fc7\u5339\u914d\u5e7f\u4e49\u9ad8\u65af\u5f84\u5411\u57fa\u77e9\u4f30\u8ba1\u521a\u4f53\u53d8\u6362\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u5bf9\u663e\u5f0f\u70b9\u5bf9\u70b9\u5bf9\u5e94\u5173\u7cfb\u7684\u4f9d\u8d56\u3002  \n\u25c6 \u5728\u7406\u8bba\u5c42\u9762\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6570\u5b66\u4e00\u81f4\u6027\uff0c\u4e3a\u7b97\u6cd5\u6709\u6548\u6027\u63d0\u4f9b\u7406\u8bba\u652f\u6491\u3002  \n\u25c6 \u9488\u5bf9\u7a00\u758f\u548c\u5f3a\u566a\u58f0\u573a\u666f\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86ICP\u3001NDT\u7b49\u4f20\u7edf\u65b9\u6cd5\u5728\u6b64\u7c7b\u6076\u52a3\u6761\u4ef6\u4e0b\u7684\u914d\u51c6\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u5b9e\u73b0\u66f4\u9ad8\u7cbe\u5ea6\uff0c\u5c24\u5176\u57284D\u96f7\u8fbeSLAM\u7cfb\u7edf\u4e2d\u8fbe\u5230\u4e0e\u6fc0\u5149\u96f7\u8fbe\u7cfb\u7edf\u76f8\u5f53\u7684\u5b9a\u4f4d\u6027\u80fd\u3002  \n\u25c6 \u9996\u6b21\u5c06\u77e9\u5339\u914d\u6280\u672f\u7cfb\u7edf\u6027\u5730\u5e94\u7528\u4e8e\u70b9\u4e91\u914d\u51c6\u9886\u57df\uff0c\u4e3a\u7a00\u758f\u566a\u58f0\u73af\u5883\u4e0b\u7684\u673a\u5668\u4eba\u611f\u77e5\u4efb\u52a1\u5f00\u8f9f\u65b0\u601d\u8def\u3002|\n",
    "2508.02140": "|2025-08-04|AID4AD: Aerial Image Data for Automated Driving Perception|Daniel Lengerer\u7b49|[2508.02140](http://arxiv.org/pdf/2508.02140)|\u65e0|\u25c6 \u63d0\u51faAID4AD\u6570\u636e\u96c6\uff0c\u9996\u6b21\u5c06\u9ad8\u5206\u8fa8\u7387\u822a\u62cd\u56fe\u50cf\u4e0enuScenes\u81ea\u52a8\u9a7e\u9a76\u6570\u636e\u96c6\u7684\u7a7a\u95f4\u5750\u6807\u7cfb\u7cbe\u786e\u5bf9\u9f50\uff0c\u586b\u8865\u4e86\u822a\u62cd\u6570\u636e\u5728\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u7a7a\u767d\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u4e00\u5957\u57fa\u4e8eSLAM\u70b9\u4e91\u5730\u56fe\u7684\u5bf9\u9f50\u6d41\u7a0b\uff0c\u901a\u8fc7\u5b9a\u4f4d\u548c\u6295\u5f71\u5931\u771f\u6821\u6b63\u6280\u672f\u786e\u4fdd\u7a7a\u95f4\u4fdd\u771f\u5ea6\uff0c\u5e76\u4eba\u5de5\u7b5b\u9009\u9ad8\u8d28\u91cf\u5bf9\u9f50\u6837\u672c\u4f5c\u4e3a\u57fa\u51c6\u771f\u503c\u3002  \n\u25c6 \u9a8c\u8bc1\u4e86\u822a\u62cd\u56fe\u50cf\u5728\u81ea\u52a8\u9a7e\u9a76\u4e24\u5927\u6838\u5fc3\u4efb\u52a1\u4e2d\u7684\u4ef7\u503c\uff1a\u5728\u7ebf\u5730\u56fe\u6784\u5efa\u4e2d\u4f5c\u4e3a\u8865\u5145\u8f93\u5165\u63d0\u534715-23%\u7cbe\u5ea6\uff0c\u8fd0\u52a8\u9884\u6d4b\u4e2d\u66ff\u4ee3\u9ad8\u7cbe\u5730\u56fe\u5b9e\u73b02%\u6027\u80fd\u63d0\u5347\u3002  \n\u25c6 \u63ed\u793a\u4e86\u822a\u62cd\u56fe\u50cf\u4f5c\u4e3a\u53ef\u6269\u5c55\u73af\u5883\u4e0a\u4e0b\u6587\u6e90\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9ad8\u7cbe\u5730\u56fe\u7f3a\u5931\u3001\u8fc7\u65f6\u6216\u7ef4\u62a4\u6210\u672c\u9ad8\u7684\u573a\u666f\u3002  \n\u25c6 \u5f00\u6e90\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u4ee3\u7801\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u6807\u51c6\u5316\u57fa\u51c6\uff08https://github.com/DriverlessMobility/AID4AD\uff09\u3002|\n",
    "2508.03672": "|2025-08-05|Inland-LOAM: Voxel-Based Structural Semantic Mapping for Inland Waterways|Zhongbi Luo\u7b49|[2508.03672](http://arxiv.org/pdf/2508.03672)|\u65e0|\u25c6 \u63d0\u51faInland-LOAM\u6846\u67b6\uff0c\u9488\u5bf9\u5185\u6cb3\u822a\u9053\u73af\u5883\u4f18\u5316LiDAR SLAM\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u5782\u76f4\u6f02\u79fb\u548c\u8bed\u4e49\u7f3a\u5931\u65b9\u9762\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u6539\u8fdb\u7279\u5f81\u63d0\u53d6\u65b9\u6cd5\u5e76\u5f15\u5165\u6c34\u9762\u5e73\u9762\u7ea6\u675f\uff0c\u6709\u6548\u6291\u5236SLAM\u7cfb\u7edf\u7684\u5782\u76f4\u6f02\u79fb\u95ee\u9898\uff0c\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u901a\u8fc7\u4f53\u7d20\u5316\u51e0\u4f55\u5206\u6790\u5c063D\u70b9\u4e91\u8f6c\u5316\u4e3a\u7ed3\u6784\u53162D\u8bed\u4e49\u5730\u56fe\uff0c\u5b9e\u65f6\u8ba1\u7b97\u6865\u6881\u51c0\u7a7a\u7b49\u5173\u952e\u5bfc\u822a\u53c2\u6570\u3002  \n\u25c6 \u5f00\u53d1\u81ea\u52a8\u5316\u6a21\u5757\u63d0\u53d6\u5cb8\u7ebf\u8f6e\u5ed3\uff0c\u5e76\u8f93\u51fa\u8f7b\u91cf\u5316\u3001\u517c\u5bb9\u56fd\u9645\u7535\u5b50\u822a\u9053\u56fe\uff08IENC\uff09\u7684\u6807\u51c6\u683c\u5f0f\u3002  \n\u25c6 \u5728\u771f\u5b9e\u822a\u9053\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5b9a\u4f4d\u7cbe\u5ea6\u8d85\u8d8a\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u751f\u6210\u7684\u8bed\u4e49\u5730\u56fe\u4e0e\u5cb8\u7ebf\u6570\u636e\u7b26\u5408\u5b9e\u9645\u573a\u666f\u9700\u6c42\u3002  \n\u25c6 \u516c\u5f00\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\uff0c\u4e3a\u5185\u6cb3\u81ea\u4e3b\u822a\u884c\u63d0\u4f9b\u53ef\u9760\u7684\u73af\u5883\u611f\u77e5\u4e0e\u5730\u7406\u4fe1\u606f\u652f\u6301\u3002|\n",
    "2508.05149": "|2025-08-07|Speech LLMs in Low-Resource Scenarios: Data Volume Requirements and the Impact of Pretraining on High-Resource Languages|Seraphina Fong\u7b49|[2508.05149](http://arxiv.org/pdf/2508.05149)|\u65e0|\u25c6 \u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u8bed\u97f3\u5927\u6a21\u578b(Speech LLMs)\u5728\u4f4e\u8d44\u6e90\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b(ASR)\u573a\u666f\u4e0b\u7684\u6570\u636e\u91cf\u9700\u6c42\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7814\u7a76\u7a7a\u767d\u3002  \n\u25c6 \u63d0\u51fa\u57fa\u4e8eSLAM-ASR\u6846\u67b6\u7684\u8f7b\u91cf\u7ea7\u53ef\u8bad\u7ec3\u6295\u5f71\u5668\u65b9\u6848\uff0c\u6709\u6548\u8fde\u63a5\u8bed\u97f3\u7f16\u7801\u5668\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u9002\u914d\u4f4e\u8d44\u6e90\u6761\u4ef6\u3002  \n\u25c6 \u91cf\u5316\u5206\u6790\u4e86\u8fbe\u5230Whisper\u6a21\u578b\u6027\u80fd\u6240\u9700\u7684\u6700\u4f4e\u8bad\u7ec3\u6570\u636e\u91cf\uff0c\u5b9e\u8bc1\u63ed\u793a\u4e86\u6570\u636e\u7a00\u7f3a\u5e26\u6765\u7684\u6838\u5fc3\u6311\u6218\u3002  \n\u25c6 \u521b\u65b0\u6027\u53d1\u73b0\uff1a\u5229\u7528\u9ad8\u8d44\u6e90\u8bed\u8a00\u9884\u8bad\u7ec3\u7684\u5355\u4e00/\u591a\u8bed\u8a00\u6295\u5f71\u5668\u80fd\u663e\u8457\u7f13\u89e3\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u7279\u522b\u5728\u5c0f\u89c4\u6a21\u8bad\u7ec3\u96c6\u65f6\u6548\u679c\u7a81\u51fa\u3002  \n\u25c6 \u901a\u8fc7EuroLLM\u548cSalamandra\u7b49\u591a\u8bed\u8a00\u5927\u6a21\u578b\u4e0ewhisper-large-v3-turbo\u7684\u7ec4\u5408\u5b9e\u9a8c\uff0c\u4e3a\u4f4e\u8d44\u6e90\u591a\u8bed\u8a00\u8bed\u97f3\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u4f18\u5316\u601d\u8def\u3002  \n\u25c6 \u5728\u591a\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4e3a\u672a\u6765\u4f4e\u8d44\u6e90\u8bed\u97f3\u5927\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8bbe\u8ba1\u53c2\u8003\u548c\u65b9\u6cd5\u8bba\u6307\u5bfc\u3002|\n",
    "2508.04597": "|2025-08-06|Pseudo Depth Meets Gaussian: A Feed-forward RGB SLAM Baseline|Linqing Zhao\u7b49|[2508.04597](http://arxiv.org/pdf/2508.04597)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e3D\u9ad8\u65af\u6620\u5c04\u7684RGB SLAM\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6df1\u5ea6\u4f30\u8ba1\u5668\u548c3D\u9ad8\u65af\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u957f\u5e8f\u5217\u5904\u7406\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\u3002  \n\u25c6 \u5f15\u5165\u524d\u9988\u5faa\u73af\u9884\u6d4b\u6a21\u5757\uff0c\u76f4\u63a5\u4ece\u5149\u6d41\u63a8\u65ad\u76f8\u673a\u4f4d\u59ff\uff0c\u66ff\u4ee3\u4e86\u8017\u65f6\u7684\u6d4b\u8bd5\u65f6\u4f18\u5316\uff0c\u5c06\u8ddf\u8e2a\u901f\u5ea6\u63d0\u534790%\u4ee5\u4e0a\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u5c40\u90e8\u56fe\u6e32\u67d3\u6280\u672f\uff0c\u589e\u5f3a\u4e86\u524d\u9988\u4f4d\u59ff\u9884\u6d4b\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u9ad8\u4e86\u7cfb\u7edf\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u7a33\u5b9a\u6027\u3002  \n\u25c6 \u5728Replica\u548cTUM-RGBD\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6027\u80fd\u4e0e\u5f53\u524d\u6700\u4f18\u7684SplaTAM\u76f8\u5f53\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\u3002  \n\u25c6 \u901a\u8fc7\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u65f63D\u91cd\u5efa\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u51c6\u786e\u6027\u3002|\n",
    "2508.07003": "|2025-08-09|EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events|Siyu Chen\u7b49|[2508.07003](http://arxiv.org/pdf/2508.07003)|\u65e0|EGS-SLAM\u7684\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u878d\u5408\u4e8b\u4ef6\u76f8\u673a\u6570\u636e\u4e0eRGB-D\u8f93\u5165\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u6a21\u7cca\u573a\u666f\u4e0b\u7684SLAM\u6027\u80fd\u3002\u5177\u4f53\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\n\u25c6 \u63d0\u51fa\u9996\u4e2a\u7ed3\u5408\u4e8b\u4ef6\u6570\u636e\u4e0eRGB-D\u8f93\u5165\u7684GS-SLAM\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u4e25\u91cd\u8fd0\u52a8\u6a21\u7cca\u4e0b\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\u3002\n\n\u25c6 \u521b\u65b0\u6027\u5730\u5efa\u6a21\u76f8\u673a\u66dd\u5149\u671f\u95f4\u7684\u8fde\u7eed\u8fd0\u52a8\u8f68\u8ff9\uff0c\u5b9e\u73b0\u4e8b\u4ef6\u611f\u77e5\u4e0e\u6a21\u7cca\u611f\u77e5\u7684\u8054\u5408\u8ddf\u8e2a\u4e0e\u4e09\u7ef4\u9ad8\u65af\u6cfc\u6e85\u5efa\u56fe\u3002\n\n\u25c6 \u8bbe\u8ba1\u53ef\u5b66\u4e60\u7684\u76f8\u673a\u54cd\u5e94\u51fd\u6570\uff0c\u52a8\u6001\u5bf9\u9f50\u4e8b\u4ef6\u6d41\u4e0eRGB\u56fe\u50cf\u7684\u4eae\u5ea6\u8303\u56f4\u5dee\u5f02\u3002\n\n\u25c6 \u5f15\u5165\u65e0\u4e8b\u4ef6\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u6291\u5236\u91cd\u5efa\u8fc7\u7a0b\u4e2d\u7684\u632f\u94c3\u4f2a\u5f71\u3002\n\n\u25c6 \u6784\u5efa\u5305\u542b\u5408\u6210\u4e0e\u771f\u5b9e\u573a\u666f\u7684\u65b0\u6570\u636e\u96c6\uff0c\u9a8c\u8bc1\u65b9\u6cd5\u5728\u6781\u7aef\u8fd0\u52a8\u6a21\u7cca\u6761\u4ef6\u4e0b\u7684\u4f18\u8d8a\u6027\u3002\n\n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u8f68\u8ff9\u7cbe\u5ea6\u548c\u4e09\u7ef4\u91cd\u5efa\u8d28\u91cf\u4e0a\u5747\u8d85\u8d8a\u73b0\u6709GS-SLAM\u65b9\u6cd5\uff0c\u4e3a\u9ad8\u52a8\u6001\u573a\u666f\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2508.08890": "|2025-08-12|Transient Noise Removal via Diffusion-based Speech Inpainting|Mordehay Moradi\u7b49|[2508.08890](http://arxiv.org/pdf/2508.08890)|\u65e0|\u25c6 \u63d0\u51faPGDI\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u6269\u6563\u6a21\u578b\u5e94\u7528\u4e8e\u8bed\u97f3\u4fee\u590d\u4efb\u52a1\uff0c\u80fd\u7cbe\u51c6\u91cd\u5efa\u957f\u8fbe1\u79d2\u7684\u7f3a\u5931\u6216\u4e25\u91cd\u635f\u574f\u8bed\u97f3\u6bb5\u3002  \n\u25c6 \u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u9650\u5236\uff0c\u5728\u4fdd\u6301\u8bf4\u8bdd\u4eba\u8eab\u4efd\u3001\u97f5\u5f8b\u548c\u73af\u5883\u7279\u5f81\uff08\u5982\u6df7\u54cd\uff09\u7684\u540c\u65f6\uff0c\u6709\u6548\u5904\u7406\u8bf4\u8bdd\u4eba\u5dee\u5f02\u548c\u957f\u95f4\u9699\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5f15\u5165\u5206\u7c7b\u5668\u5f15\u5bfc\u673a\u5236\uff0c\u7279\u522b\u662f\u97f3\u7d20\u7ea7\u5f15\u5bfc\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u91cd\u5efa\u4fdd\u771f\u5ea6\u3002  \n\u25c6 \u5b9e\u73b0\u4e0e\u8bf4\u8bdd\u4eba\u65e0\u5173\u7684\u9c81\u68d2\u4fee\u590d\uff0c\u5373\u4f7f\u8bed\u97f3\u6bb5\u88ab\u5f3a\u70c8\u77ac\u6001\u566a\u58f0\uff08\u5982\u70df\u82b1\u3001\u6454\u95e8\u58f0\uff09\u5b8c\u5168\u906e\u853d\u4ecd\u80fd\u7a33\u5b9a\u5de5\u4f5c\u3002  \n\u25c6 \u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u6a21\u578b\u4f18\u8d8a\u6027\uff0c\u8bc1\u660e\u5176\u5728\u65e0\u6587\u672c\u8f6c\u5f55\u6761\u4ef6\u4e0b\u4ecd\u4fdd\u6301\u9ad8\u6548\uff0c\u6709\u6587\u672c\u8f85\u52a9\u65f6\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u3002  \n\u25c6 \u9488\u5bf9\u5b9e\u9645\u566a\u58f0\u573a\u666f\uff08\u65bd\u5de5\u566a\u97f3\u3001\u6572\u51fb\u58f0\u7b49\uff09\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u8bed\u97f3\u4fee\u590d\u6280\u672f\u7684\u73b0\u5b9e\u5e94\u7528\u3002|\n",
    "2508.10398": "|2025-08-14|Super LiDAR Reflectance for Robotic Perception|Wei Gao\u7b49|[2508.10398](http://arxiv.org/pdf/2508.10398)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u7a00\u758f\u626b\u63cf\u6570\u636e\u751f\u6210\u9ad8\u5bc6\u5ea6\u7684LiDAR\u53cd\u5c04\u7387\u56fe\u50cf\uff0c\u89e3\u51b3\u4e86\u4f4e\u6210\u672cLiDAR\u56e0\u6570\u636e\u7a00\u758f\u6027\u5bfc\u81f4\u7684\u5e94\u7528\u53d7\u9650\u95ee\u9898\u3002  \n\u25c6 \u9488\u5bf9\u975e\u91cd\u590d\u626b\u63cfLiDAR\uff08NRS-LiDAR\uff09\u7684\u7279\u6027\uff0c\u8bbe\u8ba1\u4e86\u4e13\u7528\u7684\u53cd\u5c04\u7387\u56fe\u50cf\u7a20\u5bc6\u5316\u7f51\u7edc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7a00\u758f\u6570\u636e\u7684\u5229\u7528\u7387\u3002  \n\u25c6 \u653b\u514b\u4e86\u53cd\u5c04\u7387\u6821\u51c6\u548c\u4ece\u9759\u6001\u573a\u666f\u5230\u52a8\u6001\u573a\u666f\u8fc1\u79fb\u7684\u5173\u952e\u6280\u672f\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u7a20\u5bc6\u53cd\u5c04\u7387\u56fe\u50cf\u91cd\u5efa\u3002  \n\u25c6 \u6784\u5efa\u4e86\u4e00\u4e2a\u5168\u9762\u7684LiDAR\u53cd\u5c04\u7387\u56fe\u50cf\u7a20\u5bc6\u5316\u6570\u636e\u96c6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002  \n\u25c6 \u5c55\u793a\u4e86\u7a20\u5bc6\u53cd\u5c04\u7387\u56fe\u50cf\u5728\u673a\u5668\u4eba\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u591a\u6837\u5316\u5e94\u7528\uff0c\u5982\u95ed\u73af\u68c0\u6d4b\u548c\u4ea4\u901a\u8f66\u9053\u8bc6\u522b\uff0c\u9a8c\u8bc1\u4e86\u5176\u5b9e\u9645\u4ef7\u503c\u3002  \n\u25c6 \u901a\u8fc7\u4e3b\u52a8\u5149\u5b66\u4f20\u611f\u91cd\u65b0\u5b9a\u4e49\u89c6\u89c9\u8fb9\u754c\uff0c\u63a8\u52a8\u4e86\u4e3b\u52a8\u89c6\u89c9\u65b0\u8303\u5f0f\u7684\u53d1\u5c55\u3002|\n",
    "2508.14014": "|2025-08-19|Online 3D Gaussian Splatting Modeling with Novel View Selection|Byeonggwon Lee\u7b49|[2508.14014](http://arxiv.org/pdf/2508.14014)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u4ec5\u4f7f\u7528RGB\u56fe\u50cf\u8fdb\u884c\u5728\u7ebf3D\u9ad8\u65af\u6cfc\u6e85\u5efa\u6a21\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u81ea\u9002\u5e94\u89c6\u56fe\u9009\u62e9\u663e\u8457\u63d0\u5347\u4e86\u5728\u7ebf\u91cd\u5efa\u6a21\u578b\u7684\u5b8c\u6574\u6027\u3002\n\n\u25c6 \u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u65b0\u9896\u89c6\u56fe\u9009\u62e9\u673a\u5236\uff0c\u5728\u7ebf\u5206\u6790\u91cd\u5efa\u8d28\u91cf\u5e76\u52a8\u6001\u9009\u62e9\u6700\u4f18\u7684\u975e\u5173\u952e\u5e27\u8fdb\u884c\u8865\u5145\u8bad\u7ec3\u3002\n\u25c6 \u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5173\u952e\u5e27\u7684\u5c40\u9650\uff0c\u901a\u8fc7\u878d\u5408\u5173\u952e\u5e27\u548c\u7cbe\u9009\u7684\u975e\u5173\u952e\u5e27\uff0c\u4ece\u591a\u6837\u5316\u89c6\u89d2\u7ec6\u5316\u4e0d\u5b8c\u6574\u533a\u57df\u3002\n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u96c6\u6210\u5728\u7ebf\u591a\u89c6\u56fe\u7acb\u4f53\u89c6\u89c9\u7684\u6846\u67b6\uff0c\u786e\u4fdd\u6574\u4e2a3D\u9ad8\u65af\u6cfc\u6e85\u5efa\u6a21\u8fc7\u7a0b\u4e2d\u4e09\u7ef4\u4fe1\u606f\u7684\u4e00\u81f4\u6027\u3002\n\u25c6 \u5b9e\u73b0\u4e86\u5728\u5728\u7ebf\u5904\u7406\u7684\u4e25\u683c\u9650\u5236\u4e0b\uff08\u65e0\u6cd5\u4f7f\u7528\u5927\u91cf\u5e27\u6216\u8fc7\u591a\u8bad\u7ec3\u8fed\u4ee3\uff09\uff0c\u4ecd\u80fd\u6784\u5efa\u9ad8\u8d28\u91cf\u901a\u7528\u6a21\u578b\u7684\u76ee\u6807\u3002\n\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u590d\u6742\u6237\u5916\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u8868\u73b0\u3002|\n",
    "2508.13488": "|2025-08-19|ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments|Jingwen Yu\u7b49|[2508.13488](http://arxiv.org/pdf/2508.13488)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u91cd\u590d\u73af\u5883\u4e0b\u56de\u73af\u95ed\u5408\u9a8c\u8bc1\u7684\u9c81\u68d2\u65b9\u6cd5ROVER\uff0c\u5176\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u5229\u7528\u5386\u53f2\u8f68\u8ff9\u5148\u9a8c\u7ea6\u675f\u6765\u8bc6\u522b\u9519\u8bef\u56de\u73af\u3002  \n\u25c6 \u9996\u6b21\u5c06\u673a\u5668\u4eba\u65f6\u7a7a\u8fd0\u52a8\u8f68\u8ff9\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\u5f15\u5165\u56de\u73af\u9a8c\u8bc1\u6846\u67b6\uff0c\u7a81\u7834\u4f20\u7edf\u4ec5\u4f9d\u8d56\u5916\u89c2\u7279\u5f81\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u63d0\u51fa\u901a\u8fc7\u4f4d\u59ff\u56fe\u4f18\u5316\u751f\u6210\u5019\u9009\u56de\u73af\u7684\u8f68\u8ff9\u5047\u8bbe\uff0c\u5e76\u8bbe\u8ba1\u8bc4\u5206\u673a\u5236\u8bc4\u4f30\u5176\u4e0e\u539f\u59cb\u8f68\u8ff9\u5148\u9a8c\u7684\u4e00\u81f4\u6027\u3002  \n\u25c6 \u5728\u9ad8\u5ea6\u91cd\u590d\u73af\u5883\u4e2d\u80fd\u6709\u6548\u62d2\u7edd\u865a\u5047\u56de\u73af\uff0c\u89e3\u51b3\u4e86\u5916\u89c2\u76f8\u4f3c\u6027\u5bfc\u81f4\u7684\u8bef\u68c0\u6d4b\u96be\u9898\u3002  \n\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u516c\u5f00\u6570\u636e\u96c6\u548c\u771f\u5b9e\u573a\u666f\u4e2d\u5747\u663e\u8457\u63d0\u5347\u9a8c\u8bc1\u51c6\u786e\u6027\uff0c\u4e14\u53ef\u65e0\u7f1d\u96c6\u6210\u81f3\u73b0\u6709SLAM\u7cfb\u7edf\u589e\u5f3a\u9c81\u68d2\u6027\u3002|\n",
    "2508.14235": "|2025-08-19|SLAM-based Safe Indoor Exploration Strategy|Omar Mostafa\u7b49|[2508.14235](http://arxiv.org/pdf/2508.14235)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSLAM\u7684\u5ba4\u5185\u5b89\u5168\u63a2\u7d22\u7b56\u7565\uff0c\u4e3b\u8981\u9762\u5411\u5177\u6709\u5706\u5f62\u8f6e\u5ed3\u7684\u975e\u5b8c\u6574\u79fb\u52a8\u673a\u5668\u4eba\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u5c06\u5b89\u5168\u6027\u4f5c\u4e3a\u6700\u9ad8\u4f18\u5148\u7ea7\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u63a2\u7d22\u4e0e\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\u3002\n\n\u25c6 \u9488\u5bf9\u975e\u5b8c\u6574\u5706\u5f62\u673a\u5668\u4eba\u7cfb\u7edf\uff08\u53cc\u8f6e\u5dee\u901f\u9a71\u52a8\uff09\uff0c\u63d0\u51fa\u4e13\u7528\u63a2\u7d22\u7b56\u7565\uff0c\u800c\u975e\u5047\u8bbe\u7406\u60f3\u70b9\u673a\u5668\u4eba\u6a21\u578b\u3002\n\u25c6 \u91c7\u7528\u591a\u4f20\u611f\u5668\u878d\u5408\u65b9\u6848\uff0c\u7ed3\u5408IMU\u30013D-LiDAR\u8fdb\u884cRTAB-SLAM\uff0c\u5e76\u7528RGB-D\u76f8\u673a\u8fdb\u884c\u56de\u73af\u68c0\u6d4b\uff0c\u63d0\u9ad8\u4e86\u5efa\u56fe\u4e0e\u5b9a\u4f4d\u7684\u7a33\u5b9a\u6027\u3002\n\u25c6 \u63d0\u51fa\u201c\u5b89\u5168\u9aa8\u67b6\u201d\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff0c\u4f7f\u673a\u5668\u4eba\u5728\u63a2\u7d22\u8fc7\u7a0b\u4e2d\u59cb\u7ec8\u5c3d\u53ef\u80fd\u8fdc\u79bb\u9759\u6001\u969c\u788d\u7269\uff0c\u6781\u5927\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u3002\n\u25c6 \u63a2\u7d22\u7b56\u7565\u4ee5\u5b89\u5168\u907f\u969c\u4e3a\u9996\u8981\u76ee\u6807\uff0c\u5176\u6b21\u624d\u662f\u672a\u77e5\u533a\u57df\u63a2\u7d22\uff0c\u5bfc\u5411\u7a7a\u95f4\u4e2d\u7684\u5f00\u653e\u533a\u57df\u8fdb\u884c\u524d\u8fdb\u3002\n\u25c6 \u901a\u8fc7ROS\u79fb\u52a8\u673a\u5668\u4eba\u5e73\u53f0\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5b8c\u6574\u7684\u5b9e\u65f6\u8def\u5f84\u89c4\u5212\u4e0e\u63a2\u7d22\u8fc7\u7a0b\u3002|\n",
    "2508.16459": "|2025-08-22|GPL-SLAM: A Laser SLAM Framework with Gaussian Process Based Extended Landmarks|Ali Emre Balc\u0131\u7b49|[2508.16459](http://arxiv.org/pdf/2508.16459)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u5730\u6807\u7684\u65b0\u578b\u6fc0\u5149SLAM\u6846\u67b6GPL-SLAM\u3002\u5176\u6838\u5fc3\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u91c7\u7528\u9ad8\u65af\u8fc7\u7a0b\u5bf9\u73af\u5883\u4e2d\u7269\u4f53\u7684\u8f6e\u5ed3\u8fdb\u884c\u5efa\u6a21\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u6805\u683c\u5730\u56fe\u6216\u70b9\u4e91\u914d\u51c6\u65b9\u6cd5\u3002\n\u25c6 \u63d0\u51fa\u5728\u7ebf\u9012\u5f52\u66f4\u65b0\u65b9\u6848\uff0c\u80fd\u591f\u9ad8\u6548\u66f4\u65b0\u5730\u6807\u8f6e\u5ed3\u5e76\u663e\u8457\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u3002\n\u25c6 \u5728\u5b8c\u5168\u8d1d\u53f6\u65af\u6846\u67b6\u4e0b\u5f62\u5f0f\u5316SLAM\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u673a\u5668\u4eba\u4f4d\u59ff\u4e0e\u7269\u4f53\u5730\u56fe\u7684\u8054\u5408\u63a8\u7406\u3002\n\u25c6 \u63d0\u4f9b\u8bed\u4e49\u4fe1\u606f\u8f93\u51fa\uff0c\u5982\u7269\u4f53\u6570\u91cf\u548c\u9762\u79ef\uff0c\u5e76\u652f\u6301\u6982\u7387\u6d4b\u91cf\u7684\u7269\u4f53\u5173\u8054\u3002\n\u25c6 \u901a\u8fc7\u9ad8\u65af\u8fc7\u7a0b\u751f\u6210\u7269\u4f53\u5f62\u72b6\u7684\u7f6e\u4fe1\u8fb9\u754c\uff0c\u4e3a\u5b89\u5168\u5bfc\u822a\u548c\u63a2\u7d22\u7b49\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u5173\u952e\u4fe1\u606f\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u80fd\u5b9e\u73b0\u7cbe\u786e\u7684\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u3002|\n",
    "2508.15990": "|2025-08-21|GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System|Hung-Jui Huang\u7b49|[2508.15990](http://arxiv.org/pdf/2508.15990)|\u65e0|GelSLAM\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u4f9d\u9760\u89e6\u89c9\u611f\u77e5\u5373\u53ef\u5b9e\u73b0\u5b9e\u65f6\u4e09\u7ef4SLAM\u7684\u7cfb\u7edf\uff0c\u7528\u4e8e\u957f\u65f6\u95f4\u4f30\u8ba1\u7269\u4f53\u4f4d\u59ff\u5e76\u9ad8\u7cbe\u5ea6\u91cd\u5efa\u7269\u4f53\u5f62\u72b6\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u7528\u89e6\u89c9\u884d\u751f\u7684\u8868\u9762\u6cd5\u7ebf\u548c\u66f2\u7387\u4fe1\u606f\u8fdb\u884c\u4f4d\u59ff\u8ddf\u8e2a\u4e0e\u56de\u73af\u68c0\u6d4b\uff0c\u66ff\u4ee3\u4e86\u4f20\u7edf\u7684\u70b9\u4e91\u65b9\u6cd5\u3002  \n\u25c6 \u5b9e\u73b0\u4e86\u5b9e\u65f6\u4f4e\u8bef\u5dee\u3001\u4f4e\u6f02\u79fb\u7684\u8fd0\u52a8\u8ddf\u8e2a\u80fd\u529b\uff0c\u5373\u4f7f\u5bf9\u4e8e\u6728\u8d28\u5de5\u5177\u7b49\u4f4e\u7eb9\u7406\u7269\u4f53\u4e5f\u80fd\u4fdd\u6301\u7a33\u5b9a\u3002  \n\u25c6 \u80fd\u591f\u4ee5\u4e9a\u6beb\u7c73\u7ea7\u7cbe\u5ea6\u91cd\u5efa\u7269\u4f53\u5f62\u72b6\uff0c\u8fbe\u5230\u9ad8\u4fdd\u771f\u5ea6\u7684\u51e0\u4f55\u590d\u539f\u6548\u679c\u3002  \n\u25c6 \u5c06\u89e6\u89c9\u611f\u77e5\u4ece\u5c40\u90e8\u63a5\u89e6\u6269\u5c55\u81f3\u5168\u5c40\u957f\u65f6\u5e8f\u7a7a\u95f4\u611f\u77e5\uff0c\u4e3a\u9ad8\u7cbe\u5ea6\u64cd\u4f5c\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u57fa\u7840\u3002  \n\u8be5\u7cfb\u7edf\u5728\u906e\u6321\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u5f25\u8865\u4e86\u89c6\u89c9\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u9002\u7528\u4e8e\u624b\u5185\u64cd\u4f5c\u7b49\u7cbe\u5bc6\u4ea4\u4e92\u573a\u666f\u3002|\n",
    "2508.17255": "|2025-08-24|SEER-VAR: Semantic Egocentric Environment Reasoner for Vehicle Augmented Reality|Yuzhi Lai\u7b49|[2508.17255](http://arxiv.org/pdf/2508.17255)|\u65e0|SEER-VAR\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u8f66\u8f86\u589e\u5f3a\u73b0\u5b9e\uff08AR\uff09\u7684\u8bed\u4e49\u81ea\u4e2d\u5fc3\u73af\u5883\u63a8\u7406\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u4e0e\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u91c7\u7528\u6df1\u5ea6\u5f15\u5bfc\u7684\u89c6\u89c9-\u8bed\u8a00 grounding \u6280\u672f\uff0c\u52a8\u6001\u5206\u79bb\u8f66\u5185\u4e0e\u8f66\u5916\u573a\u666f\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u9759\u6001\u6216\u5355\u89c6\u89d2\u8bbe\u5b9a\u7684\u9650\u5236\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u7684SLAM\u5206\u652f\uff08CASB\uff09\uff0c\u901a\u8fc7\u53cc\u8defSLAM\u7cfb\u7edf\u5206\u522b\u7a33\u5065\u5730\u8ddf\u8e2a\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u81ea\u4e2d\u5fc3\u8fd0\u52a8\u3002  \n\u25c6 \u5f15\u5165\u57fa\u4e8eGPT\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6a21\u5757\uff0c\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u7684AR\u53e0\u52a0\u5185\u5bb9\uff0c\u5982\u4eea\u8868\u76d8\u63d0\u793a\u548c\u5371\u9669\u9884\u8b66\u3002  \n\u25c6 \u6784\u5efa\u5e76\u5f00\u6e90EgoSLAM-Drive\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u591a\u573a\u666f\u540c\u6b65\u7684\u81ea\u4e2d\u5fc3\u89c6\u56fe\u30016DoF\u771f\u503c\u4f4d\u59ff\u4e0eAR\u6807\u6ce8\uff0c\u652f\u6301\u7cfb\u7edf\u8bc4\u4f30\u3002  \n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u591a\u79cd\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u7a7a\u95f4\u5bf9\u9f50\u4e0e\u611f\u77e5\u4e00\u81f4\u7684AR\u6e32\u67d3\uff0c\u5e76\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u5728\u573a\u666f\u7406\u89e3\u3001\u4fe1\u606f\u76f8\u5173\u6027\u548c\u9a7e\u9a76\u4f53\u9a8c\u65b9\u9762\u7684\u663e\u8457\u63d0\u5347\u3002|\n",
    "2508.17172": "|2025-08-24|VROOM - Visual Reconstruction over Onboard Multiview|Yajat Yadav\u7b49|[2508.17172](http://arxiv.org/pdf/2508.17172)|\u65e0|VROOM\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u4f9d\u9760F1\u8d5b\u8f66\u7684\u8f66\u8f7d\u6444\u50cf\u5934\u89c6\u9891\u6765\u91cd\u5efa\u8d5b\u90533D\u6a21\u578b\u7684\u7cfb\u7edf\u3002\u5176\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u89e3\u51b3\u4e86\u6781\u7aef\u9ad8\u901f\u8fd0\u52a8\u548c\u89c6\u9891\u5e27\u5267\u70c8\u5207\u6362\u5e26\u6765\u7684\u6311\u6218\u3002\n\u25c6 \u9996\u521b\u4e86\u57fa\u4e8eF1\u8d5b\u8f66\u8f66\u8f7d\u5355\u76ee\u89c6\u9891\u8fdb\u884c\u5927\u89c4\u6a21\u8d5b\u90534D\u91cd\u5efa\u7684\u53ef\u884c\u65b9\u6848\u3002\n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u5957\u7ed3\u5408DROID-SLAM\u3001AnyCam\u548cMonst3r\u7b49\u591a\u79cd\u65b9\u6cd5\u7684\u5904\u7406\u6d41\u7a0b\uff0c\u5e76\u9488\u5bf9\u52a8\u6001\u573a\u666f\u8fdb\u884c\u4f18\u5316\u3002\n\u25c6 \u91c7\u7528\u4e86\u5305\u62ec\u63a9\u7801\u3001\u65f6\u95f4\u5206\u5757\u548c\u5206\u8fa8\u7387\u7f29\u653e\u7b49\u9884\u5904\u7406\u6280\u672f\uff0c\u4ee5\u5e94\u5bf9\u52a8\u6001\u6a21\u7cca\u548c\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u3002\n\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u5728\u6469\u7eb3\u54e5\u7ad9\u7b49\u590d\u6742\u73af\u5883\u4e2d\u90e8\u5206\u6062\u590d\u8d5b\u9053\u548c\u8f66\u8f86\u8f68\u8ff9\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5b9e\u666f scalable 4D\u91cd\u5efa\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2508.17034": "|2025-08-23|DualReg: Dual-Space Filtering and Reinforcement for Rigid Registration|Jiayi Li\u7b49|[2508.17034](http://arxiv.org/pdf/2508.17034)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u7a7a\u95f4\u521a\u6027\u914d\u51c6\u65b9\u6cd5DualReg\uff0c\u6709\u6548\u7ed3\u5408\u4e86\u57fa\u4e8e\u7279\u5f81\u5339\u914d\u548c\u5c40\u90e8\u51e0\u4f55\u5339\u914d\u7684\u4f18\u52bf\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u53cc\u7a7a\u95f4\u8303\u5f0f\uff0c\u5206\u522b\u5904\u7406\u5927\u53d8\u6362\u5dee\u5f02\u7684\u521d\u59cb\u5bf9\u9f50\u548c\u7cbe\u7ec6\u5c40\u90e8\u914d\u51c6\uff0c\u514b\u670d\u4e86\u5355\u4e00\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u9ad8\u6548\u8fc7\u6ee4\u673a\u5236\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u5355\u70b9RANSAC\u7b97\u6cd5\u548c\u7ec6\u5316\u6a21\u5757\u5feb\u901f\u5254\u9664\u4e0d\u53ef\u9760\u7684\u7279\u5f81\u5bf9\u5e94\u70b9\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u63d0\u51fa\u5c06\u8fc7\u6ee4\u540e\u7684\u5bf9\u5e94\u70b9\u4f5c\u4e3a\u951a\u70b9\uff0c\u63d0\u53d6\u51e0\u4f55\u4ee3\u7406\u5e76\u6784\u5efa\u4f18\u5316\u76ee\u6807\u51fd\u6570\uff0c\u914d\u5408\u5b9a\u5236\u6c42\u89e3\u5668\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u53d8\u6362\u4f30\u8ba1\u3002  \n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728KITTI\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e0eMAC\u76f8\u5f53\u7cbe\u5ea6\u7684\u540c\u65f6\uff0cCPU\u8ba1\u7b97\u901f\u5ea6\u63d0\u5347\u9ad8\u8fbe32\u500d\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002|\n",
    "2508.16856": "|2025-08-23|A Workflow for Map Creation in Autonomous Vehicle Simulations|Zubair Islam\u7b49|[2508.16856](http://arxiv.org/pdf/2508.16856)|\u65e0|\u672c\u6587\u9488\u5bf9\u81ea\u52a8\u9a7e\u9a76\u4eff\u771f\u4e2d\u9ad8\u7cbe\u5ea6\u5730\u56fe\u521b\u5efa\u56f0\u96be\u4e14\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u5730\u56fe\u5236\u4f5c\u5de5\u4f5c\u6d41\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5b9a\u5236\u5316\u6d41\u7a0b\uff0c\u663e\u8457\u7b80\u5316\u4e86\u4eff\u771f\u5c31\u7eea\u5730\u56fe\u7684\u521b\u5efa\uff0c\u964d\u4f4e\u4e86\u8d44\u6e90\u6d88\u8017\u3002  \n\u25c6 \u4ee5CARLA\u7b49\u4e3b\u6d41\u4eff\u771f\u5668\u4e3a\u80cc\u666f\uff0c\u4f46\u907f\u514d\u4e86\u5bf9\u5176\u7279\u5b9a\u4f9d\u8d56\uff0c\u63d0\u5347\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u548c\u7075\u6d3b\u6027\u3002  \n\u25c6 \u901a\u8fc7\u751f\u6210\u52a0\u62ff\u5927\u5b89\u5927\u7565\u7406\u5de5\u5927\u5b66\u505c\u8f66\u573a\u76843D\u5730\u56fe\u5b9e\u4f8b\uff0c\u9a8c\u8bc1\u4e86\u5de5\u4f5c\u6d41\u7684\u53ef\u884c\u6027\u4e0e\u6709\u6548\u6027\u3002  \n\u672a\u6765\u5de5\u4f5c\u5c06\u96c6\u6210SLAM\u6280\u672f\u5e76\u4f18\u5316\u7ecf\u7eac\u5ea6\u5904\u7406\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u7cbe\u5ea6\u548c\u517c\u5bb9\u6027\u3002|\n",
    "2508.16731": "|2025-08-22|COSMO-Bench: A Benchmark for Collaborative SLAM Optimization|Daniel McGann\u7b49|[2508.16731](http://arxiv.org/pdf/2508.16731)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u8bbe\u8ba1\u5e76\u53d1\u5e03\u4e86\u9996\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u591a\u673a\u5668\u4eba\u534f\u540cSLAM\uff08C-SLAM\uff09\u4f18\u5316\u7b97\u6cd5\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6COSMO-Bench\uff0c\u4ee5\u89e3\u51b3\u8be5\u9886\u57df\u7f3a\u4e4f\u6807\u51c6\u8bc4\u4f30\u5de5\u5177\u7684\u95ee\u9898\u3002\n\u25c6 \u9996\u6b21\u6784\u5efa\u4e86\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u591a\u673a\u5668\u4eba\u534f\u540cSLAM\u540e\u7aef\u4f18\u5316\u7b97\u6cd5\u7684\u6807\u51c6\u5316\u8bc4\u6d4b\u57fa\u51c6\u3002\n\u25c6 \u63d0\u4f9b\u4e8624\u4e2a\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6570\u636e\u6e90\u81ea\u771f\u5b9e\u4e16\u754c\u7684LiDAR\u6570\u636e\u548c\u6700\u5148\u8fdb\u7684C-SLAM\u524d\u7aef\u5904\u7406\u7ed3\u679c\uff0c\u786e\u4fdd\u4e86\u6570\u636e\u7684\u771f\u5b9e\u6027\u548c\u6311\u6218\u6027\u3002\n\u25c6 \u586b\u8865\u4e86\u591a\u673a\u5668\u4ebaSLAM\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u3001\u516c\u8ba4\u8bc4\u4f30\u6807\u51c6\u7684\u7a7a\u767d\uff0c\u4e3a\u4e0d\u540c\u7b97\u6cd5\u7684\u516c\u5e73\u6bd4\u8f83\u63d0\u4f9b\u4e86\u5e73\u53f0\u3002\n\u25c6 \u6240\u6709\u6570\u636e\u96c6\u5747\u5df2\u5f00\u6e90\uff0c\u65e8\u5728\u4fc3\u8fdb\u8be5\u7814\u7a76\u9886\u57df\u7684\u534f\u4f5c\u3001\u590d\u73b0\u4e0e\u53d1\u5c55\u3002|\n",
    "2508.20526": "|2025-08-28|Adam SLAM - the last mile of camera calibration with 3DGS|Matthieu Gendrin\u7b49|[2508.20526](http://arxiv.org/pdf/2508.20526)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u75283D\u9ad8\u65af\u6563\u5c04\uff083DGS\uff09\u4f18\u5316\u76f8\u673a\u6807\u5b9a\u7684\u65b0\u65b9\u6cd5\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u901a\u8fc73DGS\u6a21\u578b\u7684\u53cd\u5411\u4f20\u64ad\uff0c\u5229\u7528\u65b0\u89c6\u89d2\u989c\u8272\u635f\u5931\u5bf9\u76f8\u673a\u53c2\u6570\u8fdb\u884c\u7aef\u5230\u7aef\u7cbe\u7ec6\u4f18\u5316\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u76f8\u673a\u6807\u5b9a\u4e2d1\u50cf\u7d20\u8bef\u5dee\u5bf9\u91cd\u5efa\u8d28\u91cf\u4ea7\u751f\u663e\u8457\u5f71\u54cd\u7684\u5173\u952e\u95ee\u9898\uff0c\u76f4\u63a5\u63d0\u5347\u4e86\u65b0\u89c6\u89d2\u5408\u6210\u8d28\u91cf\u3002  \n\u25c6 \u57283DGS\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u5e26\u67650.4 dB PSNR\u7684\u6027\u80fd\u63d0\u5347\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6807\u5b9a\u65b9\u6cd5\u3002  \n\u25c6 \u867d\u7136\u4f18\u5316\u8fc7\u7a0b\u8017\u65f6\u8f83\u957f\uff0c\u4f46\u4e3a\u53c2\u8003\u573a\u666f\uff08\u5982Mip-NeRF 360\uff09\u7684\u6807\u5b9a\u63d0\u4f9b\u4e86\u4ee5\u8d28\u91cf\u4e3a\u4f18\u5148\u7684\u89e3\u51b3\u65b9\u6848\u3002  \n\u8be5\u65b9\u6cd5\u5c24\u5176\u9002\u7528\u4e8e\u5bf9\u6807\u5b9a\u7cbe\u5ea6\u8981\u6c42\u6781\u9ad8\u7684\u9ad8\u8d28\u91cf\u65b0\u89c6\u56fe\u5408\u6210\u4efb\u52a1\u3002|\n",
    "2508.21635": "|2025-08-29|The Rosario Dataset v2: Multimodal Dataset for Agricultural Robotics|Nicolas Soncini\u7b49|[2508.21635](http://arxiv.org/pdf/2508.21635)|\u65e0|\u672c\u6587\u4ecb\u7ecd\u4e86\u4e13\u4e3a\u519c\u4e1a\u673a\u5668\u4eba\u8bbe\u8ba1\u7684Rosario v2\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u4e3a\u590d\u6742\u519c\u7530\u73af\u5883\u4e0b\u7684\u7b97\u6cd5\u5f00\u53d1\u63d0\u4f9b\u4e86\u5168\u9762\u57fa\u51c6\u3002\u4e3b\u8981\u521b\u65b0\u70b9\u5305\u62ec\uff1a  \n\u25c6 \u63d0\u4f9b\u8d85\u8fc7\u4e24\u5c0f\u65f6\u7684\u591a\u6a21\u6001\u4f20\u611f\u5668\u6570\u636e\uff0c\u6db5\u76d6\u7ea2\u5916/\u5f69\u8272\u76f8\u673a\u3001IMU\u3001\u591a\u6a21\u5f0fGNSS\u548c\u8f6e\u5f0f\u91cc\u7a0b\u8ba1\uff0c\u786c\u4ef6\u7ea7\u540c\u6b65\u786e\u4fdd\u6570\u636e\u4e00\u81f4\u6027\u3002  \n\u25c6 \u7cbe\u51c6\u6355\u6349\u519c\u4e1a\u573a\u666f\u5178\u578b\u6311\u6218\uff1a\u5149\u7167\u7a81\u53d8\u3001\u8fd0\u52a8\u6a21\u7cca\u3001\u98a0\u7c38\u5730\u5f62\u53ca\u957f\u8ddd\u79bb\u89c6\u89c9\u76f8\u4f3c\u8def\u5f84\uff0c\u9ad8\u5ea6\u8fd8\u539f\u771f\u5b9e\u4f5c\u4e1a\u56f0\u96be\u3002  \n\u25c6 \u63d0\u4f9b\u516d\u81ea\u7531\u5ea6\u771f\u503c\u8f68\u8ff9\u548c\u95ed\u73af\u68c0\u6d4b\u6240\u9700\u7684\u957f\u8def\u5f84\u5faa\u73af\uff0c\u6ee1\u8db3\u591a\u6a21\u6001SLAM\u7cfb\u7edf\u4e25\u683c\u8bc4\u6d4b\u9700\u6c42\u3002  \n\u25c6 \u901a\u8fc7\u8fd0\u884c\u4e3b\u6d41SLAM\u7b97\u6cd5\u5e76\u63ed\u793a\u5176\u5728\u519c\u4e1a\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6027\u548c\u6311\u6218\u6027\u3002  \n\u8be5\u6570\u636e\u96c6\u516c\u5f00\u53ef\u7528\uff0c\u663e\u8457\u63a8\u52a8\u4e86\u519c\u4e1a\u673a\u5668\u4eba\u5b9a\u4f4d\u3001\u5efa\u56fe\u4e0e\u5bfc\u822a\u7b97\u6cd5\u7684\u7814\u53d1\u548c\u6027\u80fd\u8bc4\u4f30\u3002|\n",
    "2509.02972": "|2025-09-03|IL-SLAM: Intelligent Line-assisted SLAM Based on Feature Awareness for Dynamic Environments|Haolan Zhang\u7b49|[2509.02972](http://arxiv.org/pdf/2509.02972)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u611f\u77e5\u7684\u667a\u80fd\u7ebf\u8f85\u52a9\u52a8\u6001SLAM\u7cfb\u7edfIL-SLAM\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u89e3\u51b3\u4e86\u52a8\u6001\u73af\u5883\u4e0b\u7279\u5f81\u7ba1\u7406\u7684\u6548\u7387\u4e0e\u8d28\u91cf\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u7279\u5f81\u611f\u77e5\u673a\u5236\uff0c\u52a8\u6001\u8bc4\u4f30\u73b0\u6709\u70b9\u7279\u5f81\u7684\u5145\u8db3\u6027\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u6fc0\u6d3b\u7ebf\u7279\u5f81\u8865\u5145\uff0c\u907f\u514d\u76f2\u76ee\u5f15\u5165\u989d\u5916\u7279\u5f81\u3002  \n\u25c6 \u901a\u8fc7\u9009\u62e9\u6027\u5f15\u5165\u7ebf\u7279\u5f81\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u6709\u6548\u51cf\u5c11\u4e86\u4f4e\u8d28\u91cf\u7279\u5f81\u548c\u566a\u58f0\u7684\u7d2f\u79ef\u3002  \n\u25c6 \u5728\u7ebf\u7279\u5f81\u4f7f\u7528\u7b56\u7565\u4e0a\uff0c\u5141\u8bb8\u5176\u5728\u8ddf\u8e2a\u3001\u5c40\u90e8\u5efa\u56fe\u4e0e\u56de\u73af\u68c0\u6d4b\u4e2d\u8f85\u52a9\u63d0\u5347\u521d\u59cb\u4f4d\u59ff\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u4f46\u5c06\u5176\u6392\u9664\u5728\u5168\u5c40\u4f18\u5316\u4e4b\u5916\uff0c\u907f\u514d\u957f\u671f\u8fc7\u7a0b\u4e2d\u7684\u8d1f\u9762\u5e72\u6270\u3002  \n\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u7cfb\u7edf\u5728TUM\u6570\u636e\u96c6\u4e0a\u7684ATE\u548cRPE\u6307\u6807\u5747\u4f18\u4e8eORB-SLAM3\u57fa\u7ebf\u53ca\u5176\u4ed6\u52a8\u6001SLAM\u4e0e\u591a\u7279\u5f81\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u7684\u5e73\u8861\u3002|\n",
    "2509.02453": "|2025-09-02|Coral: A Unifying Abstraction Layer for Composable Robotics Software|Steven Swanbeck\u7b49|[2509.02453](http://arxiv.org/pdf/2509.02453)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Coral\uff0c\u4e00\u4e2a\u7528\u4e8e\u7ec4\u5408\u5f0f\u673a\u5668\u4eba\u8f6f\u4ef6\u7684\u7edf\u4e00\u62bd\u8c61\u5c42\uff0c\u65e8\u5728\u89e3\u51b3\u673a\u5668\u4eba\u7cfb\u7edf\u96c6\u6210\u56f0\u96be\u7684\u6838\u5fc3\u95ee\u9898\u3002  \n\u25c6\u5f15\u5165\u4e86\u4e00\u4e2a\u66f4\u9ad8\u5c42\u6b21\u7684\u62bd\u8c61\u5c42\uff0c\u5728\u4e0d\u4fee\u6539\u5e95\u5c42\u4ee3\u7801\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u8f6f\u4ef6\u7ec4\u4ef6\u7684\u5feb\u901f\u96c6\u6210\u4e0e\u534f\u8c03\u3002  \n\u25c6\u901a\u8fc7\u8bed\u4e49\u5316\u7ea6\u675f\u96c6\u6210\u8fc7\u7a0b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u914d\u7f6e\u590d\u6742\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5bf9\u4e0d\u540c\u9886\u57df\u548c\u4efb\u52a1\u7684\u5e7f\u6cdb\u9002\u5e94\u6027\u3002  \n\u25c6\u4e0e\u73b0\u6709\u5de5\u5177\u517c\u5bb9\u800c\u975e\u66ff\u4ee3\uff0c\u589e\u5f3a\u4e86\u7ec4\u4ef6\u590d\u7528\u6027\u548c\u7cfb\u7edf\u53ef\u91cd\u6784\u6027\u3002  \n\u25c6\u5728\u590d\u6742\u573a\u666f\uff08\u5982LiDAR SLAM\u548c\u591a\u673a\u5668\u4eba\u534f\u4f5c\uff09\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u89e3\u51b3\u96c6\u6210\u6311\u6218\u7684\u5b9e\u7528\u4ef7\u503c\u3002  \n\u25c6\u5f00\u6e90\u53d1\u5e03Coral\uff0c\u63d0\u5347\u4e86\u4e13\u5bb6\u4e0e\u975e\u4e13\u5bb6\u7528\u6237\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u63a8\u52a8\u673a\u5668\u4eba\u8f6f\u4ef6\u5f00\u53d1\u7684\u6807\u51c6\u5316\u4e0e\u666e\u53ca\u3002|\n",
    "2509.01873": "|2025-09-02|Doctoral Thesis: Geometric Deep Learning For Camera Pose Prediction, Registration, Depth Estimation, and 3D Reconstruction|Xueyang Kang|[2509.01873](http://arxiv.org/pdf/2509.01873)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u51e0\u4f55\u5148\u9a8c\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u51e0\u4f55\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u4e09\u7ef4\u89c6\u89c9\u4e2d\u7684\u5173\u952e\u4efb\u52a1\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u9488\u5bf9\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u3001\u70b9\u4e91\u914d\u51c6\u3001\u6df1\u5ea6\u9884\u6d4b\u548c\u4e09\u7ef4\u91cd\u5efa\u7684\u51e0\u4f55\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7279\u5f81\u6a21\u7cca\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u901a\u8fc7\u5c06\u6df1\u5ea6\u4fe1\u606f\u3001\u8868\u9762\u6cd5\u7ebf\u548c\u7b49\u53d8\u7ea6\u675f\u7b49\u51e0\u4f55\u5148\u9a8c\u878d\u5165\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u589e\u5f3a\u4e86\u51e0\u4f55\u8868\u793a\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002  \n\u25c6 \u7cfb\u7edf\u7814\u7a76\u4e86\u4e09\u7ef4\u89c6\u89c9\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u6570\u5b57\u6587\u5316\u9057\u4ea7\u4fdd\u62a4\u548c\u6c89\u6d78\u5f0fVR/AR\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u4e09\u7ef4\u6570\u636e\u9ad8\u7ef4\u6027\u548c\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u5e26\u6765\u7684\u8bad\u7ec3\u6311\u6218\uff0c\u63a8\u52a8\u4e86\u4f20\u7edf\u51e0\u4f55\u6280\u672f\u4e0e\u6df1\u5ea6\u5b66\u4e60\u80fd\u529b\u7684\u878d\u5408\u3002  \n\u8be5\u7814\u7a76\u4e3a\u751f\u6210\u5177\u6709\u51e0\u4f55\u611f\u77e5\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\uff0c\u4fc3\u8fdb\u4e86\u4e09\u7ef4\u6620\u5c04\u6280\u672f\u548c\u573a\u666f\u91cd\u5efa\u7ba1\u9053\u7684\u53d1\u5c55\u3002|\n",
    "2509.01584": "|2025-09-01|ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association|Ganlin Zhang\u7b49|[2509.01584](http://arxiv.org/pdf/2509.01584)|\u65e0|ViSTA-SLAM\u662f\u4e00\u4e2a\u65e0\u9700\u5df2\u77e5\u76f8\u673a\u5185\u53c2\u5373\u53ef\u5b9e\u65f6\u8fd0\u884c\u7684\u5355\u76ee\u89c6\u89c9SLAM\u7cfb\u7edf\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u4e00\u4e2a\u8f7b\u91cf\u5316\u7684\u5bf9\u79f0\u5f0f\u53cc\u89c6\u56fe\u5173\u8054\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u4e0e\u9002\u7528\u6027\u3002\n\n\u25c6 \u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5bf9\u79f0\u53cc\u89c6\u56fe\u5173\u8054\uff08STA\uff09\u524d\u7aef\u6a21\u578b\uff0c\u4ec5\u9700\u4e24\u5f20RGB\u56fe\u50cf\u5373\u53ef\u540c\u65f6\u4f30\u8ba1\u76f8\u5bf9\u76f8\u673a\u4f4d\u59ff\u5e76\u56de\u5f52\u5c40\u90e8\u70b9\u4e91\u5730\u56fe\u3002\n\u25c6 \u8be5\u524d\u7aef\u8bbe\u8ba1\u6781\u5927\u964d\u4f4e\u4e86\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u5176\u6a21\u578b\u5927\u5c0f\u4ec5\u4e3a\u540c\u7c7b\u5148\u8fdb\u65b9\u6cd5\u768435%\uff0c\u540c\u65f6\u751f\u6210\u4e86\u66f4\u9ad8\u8d28\u91cf\u7684\u53cc\u89c6\u56fe\u7ea6\u675f\u7528\u4e8e\u540e\u7eed\u4f18\u5316\u3002\n\u25c6 \u540e\u7aef\u6784\u5efa\u4e86\u4e00\u4e2a\u7279\u6b8a\u7684Sim(3)\u4f4d\u59ff\u56fe\uff0c\u901a\u8fc7\u878d\u5165\u56de\u73af\u68c0\u6d4b\u6765\u6709\u6548\u5904\u7406\u7d2f\u79ef\u7684\u5c3a\u5ea6\u6f02\u79fb\u95ee\u9898\u3002\n\u25c6 \u6574\u4e2a\u7cfb\u7edf\u4e0d\u4f9d\u8d56\u76f8\u673a\u5185\u53c2\uff0c\u4f7f\u5176\u80fd\u591f\u5e7f\u6cdb\u9002\u7528\u4e8e\u5404\u79cd\u4e0d\u540c\u7684\u76f8\u673a\u8bbe\u7f6e\uff0c\u5177\u5907\u4e86\u5f88\u5f3a\u7684\u901a\u7528\u6027\u3002\n\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u76f8\u673a\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u7a20\u5bc6\u4e09\u7ef4\u91cd\u5efa\u8d28\u91cf\u4e0a\u5747\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u65b9\u6cd5\u3002|\n",
    "2509.01547": "|2025-09-01|FGO-SLAM: Enhancing Gaussian SLAM with Globally Consistent Opacity Radiance Field|Fan Zhu\u7b49|[2509.01547](http://arxiv.org/pdf/2509.01547)|\u65e0|FGO-SLAM\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5168\u5c40\u4e00\u81f4\u4e0d\u900f\u660e\u5ea6\u8f90\u5c04\u573a\u7684\u65b0\u578b\u9ad8\u65afSLAM\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u573a\u666f\u51e0\u4f55\u91cd\u5efa\u7684\u8d28\u91cf\u548c\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002\u5176\u521b\u65b0\u70b9\u4e3b\u8981\u4f53\u73b0\u5728\uff1a\n\n\u25c6\u91c7\u7528\u4e0d\u900f\u660e\u5ea6\u8f90\u5c04\u573a\u4f5c\u4e3a\u573a\u666f\u8868\u793a\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u51e0\u4f55\u5efa\u56fe\u6027\u80fd\u3002\n\u25c6\u5728\u521d\u59cb\u4f4d\u59ff\u4f30\u8ba1\u540e\uff0c\u5f15\u5165\u5168\u5c40\u8c03\u6574\u4f18\u5316\u7b56\u7565\uff0c\u540c\u65f6\u4f18\u5316\u76f8\u673a\u4f4d\u59ff\u548c\u7a00\u758f\u70b9\u4e91\uff0c\u786e\u4fdd\u4e86\u9c81\u68d2\u4e14\u7cbe\u786e\u7684\u8ddf\u8e2a\u3002\n\u25c6\u7ef4\u62a4\u4e86\u4e00\u4e2a\u57fa\u4e8e3D\u9ad8\u65af\u4e14\u5168\u5c40\u4e00\u81f4\u7684\u4e0d\u900f\u660e\u5ea6\u8f90\u5c04\u573a\uff0c\u5e76\u5f15\u5165\u4e86\u6df1\u5ea6\u5931\u771f\u548c\u6cd5\u5411\u4e00\u81f4\u6027\u7ea6\u675f\u6765\u7cbe\u7ec6\u5316\u573a\u666f\u8868\u793a\u3002\n\u25c6\u901a\u8fc7\u6784\u5efa\u56db\u9762\u4f53\u7f51\u683c\u5e76\u63d0\u53d6\u7b49\u503c\u9762\uff0c\u5b9e\u73b0\u4e86\u76f4\u63a5\u4ece3D\u9ad8\u65af\u4e2d\u63d0\u53d6\u8868\u9762\uff0c\u7b80\u5316\u4e86\u8868\u9762\u91cd\u5efa\u6d41\u7a0b\u3002\n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u771f\u5b9e\u548c\u5927\u578b\u5408\u6210\u6570\u636e\u96c6\u4e0a\u5747\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u5efa\u56fe\u6027\u80fd\u3002|\n",
    "2509.01111": "|2025-09-01|SR-SLAM: Scene-reliability Based RGB-D SLAM in Diverse Environments|Haolan Zhang\u7b49|[2509.01111](http://arxiv.org/pdf/2509.01111)|\u65e0|SR-SLAM\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u573a\u666f\u53ef\u9760\u6027\u7684RGB-D SLAM\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u5347\u89c6\u89c9SLAM\u7cfb\u7edf\u5728\u591a\u6837\u5316\u73af\u5883\u4e2d\u7684\u7cbe\u5ea6\u4e0e\u9c81\u68d2\u6027\u3002\u5176\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u5f15\u5165\u7edf\u4e00\u7684\u73af\u5883\u611f\u77e5\u4e0e\u53ef\u9760\u6027\u8bc4\u4f30\u673a\u5236\uff0c\u901a\u8fc7\u591a\u6307\u6807\u548c\u5386\u53f2\u89c2\u6d4b\u52a8\u6001\u6307\u5bfc\u7cfb\u7edf\u884c\u4e3a\u3002\u5177\u4f53\u8d21\u732e\u5305\u62ec\uff1a\n\u25c6\u63d0\u51fa\u81ea\u9002\u5e94\u52a8\u6001\u533a\u57df\u9009\u62e9\u65b9\u6cd5\uff0c\u7ed3\u5408\u7075\u6d3b\u51e0\u4f55\u7ea6\u675f\u4ee5\u63d0\u5347\u52a8\u6001\u76ee\u6807\u8bc6\u522b\u80fd\u529b\u3002\n\u25c6\u5f00\u53d1\u6df1\u5ea6\u8f85\u52a9\u7684\u81ea\u9002\u5e94\u805a\u7c7b\u7b97\u6cd5\uff0c\u5728\u9ad8\u7ef4\u73af\u5883\u4e0b\u9ad8\u6548\u5254\u9664\u52a8\u6001\u7279\u5f81\u70b9\u3002\n\u25c6\u8bbe\u8ba1\u53ef\u9760\u6027\u611f\u77e5\u7684\u4f4d\u59ff\u4f18\u5316\u7b56\u7565\uff0c\u5728\u7279\u5f81\u4e0d\u8db3\u65f6\u52a8\u6001\u878d\u5408\u76f4\u63a5\u6cd5\u4ee5\u63d0\u5347\u4f30\u8ba1\u7a33\u5b9a\u6027\u3002\n\u25c6\u63d0\u51fa\u57fa\u4e8e\u53ef\u9760\u6027\u7684\u5173\u952e\u5e27\u9009\u62e9\u4e0e\u52a0\u6743\u4f18\u5316\u65b9\u6848\uff0c\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002\n\u5b9e\u9a8c\u8bc1\u660e\u8be5\u7cfb\u7edf\u5728\u516c\u5f00\u6570\u636e\u96c6\u548c\u771f\u5b9e\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u52a8\u6001SLAM\u65b9\u6cd5\uff0c\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u63d0\u5347\u6700\u9ad8\u8fbe90%\u3002|\n",
    "2509.00741": "|2025-08-31|DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments|Yi Liu\u7b49|[2509.00741](http://arxiv.org/pdf/2509.00741)|\u65e0|DyPho-SLAM\u662f\u4e00\u79cd\u80fd\u591f\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u65f6\u8fd0\u884c\u7684\u89c6\u89c9SLAM\u7cfb\u7edf\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u662f\u89e3\u51b3\u4e86\u52a8\u6001\u7269\u4f53\u5e72\u6270\u5bfc\u81f4\u7684\u76f8\u673a\u8ddf\u8e2a\u6f02\u79fb\u548c\u5730\u56fe\u6a21\u7cca\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u7684\u5bc6\u96c6\u5730\u56fe\u91cd\u5efa\u3002\n\n\u25c6 \u7387\u5148\u5c06\u9ad8\u65af\u6cfc\u6e85\u8868\u793a\uff08Gaussian Splatting\uff09\u7528\u4e8e\u52a8\u6001\u73af\u5883SLAM\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u5149\u7535\u771f\u5b9e\u611f\u5efa\u56fe\u3002\n\u25c6 \u521b\u65b0\u5730\u6574\u5408\u5148\u9a8c\u56fe\u50cf\u4fe1\u606f\u6765\u751f\u6210\u7cbe\u7ec6\u5316\u63a9\u7801\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u56e0\u52a8\u6001\u7269\u4f53\u8bef\u5224\u800c\u4ea7\u751f\u7684\u566a\u58f0\u3002\n\u25c6 \u8bbe\u8ba1\u4e86\u81ea\u9002\u5e94\u7684\u7279\u5f81\u63d0\u53d6\u7b56\u7565\uff0c\u5728\u79fb\u9664\u52a8\u6001\u969c\u788d\u7269\u540e\u4e3a\u7cfb\u7edf\u4f18\u5316\u589e\u5f3a\u4e86\u7ea6\u675f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6574\u4e2a\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002\n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u516c\u5f00\u52a8\u6001RGB-D\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u548c\u5730\u56fe\u91cd\u5efa\u7cbe\u5ea6\u3002|\n",
    "2509.00433": "|2025-08-30|AGS: Accelerating 3D Gaussian Splatting SLAM via CODEC-Assisted Frame Covisibility Detection|Houshu He\u7b49|[2509.00433](http://arxiv.org/pdf/2509.00433)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86AGS\uff0c\u4e00\u4e2a\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u65e8\u5728\u663e\u8457\u52a0\u901f\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\u7684SLAM\u7cfb\u7edf\u3002\u5176\u6838\u5fc3\u521b\u65b0\u70b9\u5728\u4e8e\u5145\u5206\u5229\u7528\u4e86SLAM\u6d41\u5f0f\u5904\u7406\u4e2d\u76f8\u90bb\u5e27\u7684\u9ad8\u76f8\u4f3c\u6027\u3002  \n\u25c6 \u5728\u8f6f\u4ef6\u5c42\u9762\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6839\u636e\u673a\u5668\u4eba\u8fd0\u52a8\u8fdb\u884c\u5148\u7c97\u540e\u7cbe\u7684\u4f4d\u59ff\u8ddf\u8e2a\u65b9\u6cd5\u3002  \n\u25c6 \u901a\u8fc7\u5728\u5e27\u95f4\u5171\u4eab\u9ad8\u65af\u70b9\u7684\u8d21\u732e\u4fe1\u606f\uff0c\u907f\u514d\u4e86\u5927\u91cf\u5197\u4f59\u8ba1\u7b97\u3002  \n\u25c6 \u5728\u786c\u4ef6\u5c42\u9762\uff0c\u521b\u65b0\u5730\u5229\u7528\u89c6\u9891\u7f16\u89e3\u7801\u5668\u63d0\u53d6\u4e2d\u95f4\u6570\u636e\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5e27\u5171\u89c6\u6027\u68c0\u6d4b\u5f15\u64ce\u3002  \n\u25c6 \u8fd8\u5b9e\u73b0\u4e86\u914d\u5907\u5de5\u4f5c\u8d1f\u8f7d\u8c03\u5ea6\u5668\u7684\u4f4d\u59ff\u8ddf\u8e2a\u5f15\u64ce\u548c\u5efa\u56fe\u5f15\u64ce\uff0c\u4ee5\u9ad8\u6548\u90e8\u7f72\u6574\u4e2aAGS\u7b97\u6cd5\u3002  \n\u6700\u7ec8\uff0cAGS\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u5728\u79fb\u52a8GPU\u3001\u9ad8\u7aefGPU\u53ca\u4e13\u7528\u52a0\u901f\u5668\u4e0a\u5206\u522b\u5b9e\u73b0\u4e86\u6700\u9ad817.12\u500d\u30016.71\u500d\u548c5.41\u500d\u7684\u52a0\u901f\u3002|\n",
    "2509.04370": "|2025-09-04|Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage|Dor Cohen\u7b49|[2509.04370](http://arxiv.org/pdf/2509.04370)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u8ba1\u7b97\u673a\u89c6\u89c9\u6d41\u7a0b\uff0c\u5c06\u6267\u6cd5\u6216\u6025\u6551\u4eba\u5458\u4f69\u6234\u7684\u4f53\u6234\u76f8\u673a\u89c6\u9891\u8f6c\u5316\u4e3a\u7b80\u6d01\u7684\u5168\u666f\u4e8b\u4ef6\u6458\u8981\u56fe\u50cf\u3002  \n\u25c6 \u63d0\u51fa\u5229\u7528\u5355\u76eeSLAM\u6280\u672f\u4ece\u89c6\u9891\u4e2d\u4f30\u8ba1\u76f8\u673a\u8fd0\u52a8\u8f68\u8ff9\u5e76\u91cd\u5efa\u573a\u666f\u7a7a\u95f4\u5e03\u5c40\uff0c\u4e3a\u521b\u5efa\u7a7a\u95f4\u8fde\u8d2f\u7684\u6458\u8981\u5960\u5b9a\u57fa\u7840\u3002  \n\u25c6 \u901a\u8fc7\u6cbf\u8f68\u8ff9\u5bf9\u76f8\u673a\u4f4d\u59ff\u8fdb\u884c\u805a\u7c7b\u6765\u8bc6\u522b\u5173\u952e\u89c6\u89d2\uff0c\u786e\u4fdd\u6458\u8981\u80fd\u8986\u76d6\u573a\u666f\u7684\u91cd\u8981\u90e8\u5206\u3002  \n\u25c6 \u91c7\u7528\u591a\u5e27\u56fe\u50cf\u62fc\u63a5\u6280\u672f\uff0c\u5c06\u9009\u5b9a\u4ee3\u8868\u5e27\u878d\u5408\u6210\u9ad8\u8d28\u91cf\u5168\u666f\u56fe\uff0c\u4fdd\u6301\u7a7a\u95f4\u4e00\u81f4\u6027\u548c\u89c6\u89c9\u5b8c\u6574\u6027\u3002  \n\u25c6 \u6700\u7ec8\u751f\u6210\u7684\u5168\u666f\u6458\u8981\u56fe\u50cf\u652f\u6301\u5feb\u901f\u73af\u5883\u7406\u89e3\u548c\u51b3\u7b56\uff0c\u89e3\u51b3\u4e86\u5197\u957f\u89c6\u9891\u56de\u987e\u8017\u65f6\u4f4e\u6548\u7684\u75db\u70b9\u3002  \n\u8be5\u6280\u672f\u63d0\u5347\u4e86\u4f53\u6234\u76f8\u673a\u6570\u636e\u5728\u65f6\u95f4\u654f\u611f\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\uff0c\u9002\u7528\u4e8e\u4e8b\u540e\u5206\u6790\u548c\u5e94\u6025\u54cd\u5e94\u3002|\n",
    "2509.04016": "|2025-09-04|Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall Climbing Robot|Branimir \u0106aran\u7b49|[2509.04016](http://arxiv.org/pdf/2509.04016)|\u65e0|\u672c\u6587\u9488\u5bf9\u56db\u8f6e\u72ec\u7acb\u8f6c\u5411\u72ec\u7acb\u9a71\u52a8\uff084WIS4WID\uff09\u722c\u58c1\u673a\u5668\u4eba\u5728\u590d\u6742\u5efa\u7b51\u7acb\u9762\u4e0a\u7684\u5b9a\u4f4d\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u4f20\u611f\u5668\u878d\u5408\u7684\u4f4d\u59ff\u4f30\u8ba1\u5668\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u8f6e\u5f0f\u91cc\u7a0b\u8ba1\u3001\u89c6\u89c9\u91cc\u7a0b\u8ba1\u548cIMU\u6570\u636e\u901a\u8fc7\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\uff08EKF\uff09\u548c\u65e0\u8ff9\u5361\u5c14\u66fc\u6ee4\u6ce2\uff08UKF\uff09\u8fdb\u884c\u878d\u5408\uff0c\u6784\u5efa\u4e86\u9c81\u68d2\u7684\u4f4d\u59ff\u4f30\u8ba1\u7cfb\u7edf\u3002  \n\u25c6 \u9488\u5bf9\u91cc\u7a0b\u8ba1\u7684\u7cfb\u7edf\u8bef\u5dee\uff0c\u7ed3\u5408\u4f7f\u7528\u4e86\u975e\u7ebf\u6027\u4f18\u5316\u3001Levenberg-Marquardt\u7b49\u786e\u5b9a\u6027\u65b9\u6cd5\u4ee5\u53ca\u9057\u4f20\u7b97\u6cd5\u3001\u7c92\u5b50\u7fa4\u7b49\u968f\u673a\u4f18\u5316\u65b9\u6cd5\u8fdb\u884c\u8fd0\u52a8\u5b66\u6821\u51c6\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u7cfb\u7edf\u8bef\u5dee\u548c\u6f02\u79fb\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u5728\u65e0\u6cd5\u4f7f\u7528GPS\u3001\u6fc0\u5149\u96f7\u8fbe\u7b49\u4f20\u7edf\u4f20\u611f\u5668\u7684\u7279\u6b8a\u5de5\u4f5c\u73af\u5883\uff08\u5982\u94a2\u7b4b\u6df7\u51dd\u571f\u7acb\u9762\uff09\u4e2d\u7684\u7cbe\u786e\u5b9a\u4f4d\u95ee\u9898\u3002  \n\u8be5\u65b9\u6848\u901a\u8fc7\u5b9e\u7269\u673a\u5668\u4eba\u5b9e\u9a8c\u8be6\u7ec6\u9a8c\u8bc1\u4e86\u5176\u6821\u51c6\u65b9\u6cd5\u548c\u4f4d\u4f30\u8ba1\u7b97\u6cd5\u7684\u6709\u6548\u6027\u4e0e\u6027\u80fd\uff0c\u4e3a\u722c\u58c1\u673a\u5668\u4eba\u5728\u5b9e\u9645\u6d4b\u91cf\u548c\u7ef4\u62a4\u4efb\u52a1\u4e2d\u7684\u9ad8\u7cbe\u5ea6\u4f4d\u59ff\u611f\u77e5\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6280\u672f\u57fa\u7840\u3002|\n",
    "2509.06582": "|2025-09-08|Co-Located VR with Hybrid SLAM-based HMD Tracking and Motion Capture Synchronization|Carlos A. Pinheiro de Sousa\u7b49|[2509.06582](http://arxiv.org/pdf/2509.06582)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u7528\u6237\u534f\u540c\u5b9a\u4f4dVR\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u5916\u90e8\u52a8\u6355\u7cfb\u7edf\u548c\u5934\u663e\u5185\u7f6eSLAM\u8ddf\u8e2a\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u4f4e\u5ef6\u8fdf\u7684\u5171\u4eab\u865a\u62df\u7a7a\u95f4\u540c\u6b65\u3002  \n\u25c6 \u7ed3\u5408\u57fa\u4e8eSLAM\u7684\u5934\u663e\u5185\u5411\u5916\u8ffd\u8e2a\u4e0e\u8fd0\u52a8\u6355\u6349\u7cfb\u7edf\uff0c\u517c\u987e\u9ad8\u5e27\u7387\u3001\u4f4e\u5ef6\u8fdf\u6027\u80fd\u548c\u957f\u671f\u7a33\u5b9a\u6027\u3002  \n\u25c6 \u7a81\u7834\u4f20\u7edf\u4f9d\u8d56\u6301\u7eed\u5916\u90e8\u8ffd\u8e2a\uff08\u6613\u5ef6\u8fdf\u6296\u52a8\uff09\u6216\u4e00\u6b21\u6027\u6821\u51c6\uff08\u65e0\u6cd5\u6821\u6b63\u6f02\u79fb\uff09\u7684\u5c40\u9650\uff0c\u5b9e\u73b0\u52a8\u6001\u6309\u9700\u91cd\u5bf9\u9f50\u3002  \n\u25c6 \u652f\u6301\u8de8\u8bbe\u5907\u5b9e\u65f6\u59ff\u6001\u5171\u4eab\uff0c\u786e\u4fdd\u591a\u7528\u6237\u95f4\u7a7a\u95f4\u4e00\u81f4\u6027\u53ca\u4ea4\u4e92\u6c89\u6d78\u611f\u3002  \n\u25c6 \u5728\u4fdd\u6301\u9ad8\u7a7a\u95f4\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u8212\u9002\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002|\n",
    "2509.06433": "|2025-09-08|Real-time Photorealistic Mapping for Situational Awareness in Robot Teleoperation|Ian Page\u7b49|[2509.06433](http://arxiv.org/pdf/2509.06433)|\u65e0|\u8be5\u8bba\u6587\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u903c\u771f\u5730\u56fe\u6784\u5efa\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u672a\u77e5\u73af\u5883\u4e2d\u673a\u5668\u4eba\u9065\u64cd\u4f5c\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u9ad8\u65af\u6e85\u5c04SLAM\u6280\u672f\u4e0e\u5728\u7ebf\u5730\u56fe\u9065\u64cd\u4f5c\u7cfb\u7edf\u8fdb\u884c\u6a21\u5757\u5316\u96c6\u6210  \n\u25c6 \u91c7\u7528\u57fa\u4e8eGPU\u7684\u9ad8\u6548\u8ba1\u7b97\u67b6\u6784\u5b9e\u73b0\u5b9e\u65f6\u9ad8\u7cbe\u5ea6\u4e09\u7ef4\u5730\u56fe\u91cd\u5efa  \n\u25c6 \u7a81\u7834\u4f20\u7edf\u7cfb\u7edf\u56e0\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u5bfc\u81f4\u7684\u89c6\u89c9\u5730\u56fe\u8d28\u91cf\u4e0e\u5b9e\u65f6\u6027\u74f6\u9888  \n\u25c6 \u901a\u8fc7\u771f\u5b9e\u73af\u5883\u65e0\u4eba\u673a\u5b9e\u9a8c\u9a8c\u8bc1\u7cfb\u7edf\u80fd\u5927\u5e45\u63d0\u5347\u64cd\u4f5c\u8005\u51b3\u7b56\u901f\u5ea6\u548c\u73af\u5883\u4ea4\u4e92\u7cbe\u5ea6  \n\u8be5\u7cfb\u7edf\u9996\u6b21\u5b9e\u73b0\u5b9e\u65f6\u903c\u771f\u5730\u56fe\u751f\u6210\u4e0e\u9065\u64cd\u4f5c\u4efb\u52a1\u7684\u65e0\u7f1d\u878d\u5408\uff0c\u4e3a\u964c\u751f\u73af\u5883\u4e0b\u7684\u8fdc\u7a0b\u64cd\u63a7\u63d0\u4f9b\u4e86\u7a81\u7834\u6027\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2509.05728": "|2025-09-06|LiDAR-BIND-T: Improving SLAM with Temporally Consistent Cross-Modal LiDAR Reconstruction|Niels Balemans\u7b49|[2509.05728](http://arxiv.org/pdf/2509.05728)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86LiDAR-BIND-T\uff0c\u901a\u8fc7\u589e\u5f3a\u65f6\u95f4\u4e00\u81f4\u6027\u6539\u8fdb\u4e86\u591a\u6a21\u6001\u878d\u5408SLAM\u7cfb\u7edf\u3002\u5176\u6838\u5fc3\u8d21\u732e\u4e0e\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u5f15\u5165\u65f6\u95f4\u5d4c\u5165\u76f8\u4f3c\u6027\u635f\u5931\uff0c\u663e\u5f0f\u5bf9\u9f50\u8fde\u7eed\u65f6\u523b\u7684\u6f5c\u5728\u7279\u5f81\u4ee5\u4fdd\u6301\u65f6\u5e8f\u8fde\u8d2f\u3002\n\u25c6 \u63d0\u51fa\u8fd0\u52a8\u5bf9\u9f50\u53d8\u6362\u635f\u5931\uff0c\u786e\u4fdd\u9884\u6d4b\u70b9\u4e91\u4e0e\u771f\u5b9eLiDAR\u70b9\u4e91\u4e4b\u95f4\u7684\u4f4d\u79fb\u4e00\u81f4\u6027\u3002\n\u25c6 \u8bbe\u8ba1\u4e13\u7528\u65f6\u5e8f\u878d\u5408\u6a21\u5757\uff0c\u901a\u8fc7\u6ed1\u7a97\u65b9\u5f0f\u878d\u5408\u591a\u5e27\u4fe1\u606f\u4ee5\u63d0\u5347\u7a33\u5b9a\u6027\u3002\n\u25c6 \u4f18\u5316\u6a21\u578b\u67b6\u6784\u4ee5\u66f4\u597d\u5730\u4fdd\u7559\u7a7a\u95f4\u7ed3\u6784\uff0c\u63d0\u5347\u8de8\u6a21\u6001\uff08\u96f7\u8fbe/\u58f0\u7eb3\u5230LiDAR\uff09\u91cd\u5efa\u8d28\u91cf\u3002\n\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86SLAM\u7684\u8f68\u8ff9\u7cbe\u5ea6\u548c\u5730\u56fe\u8d28\u91cf\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eFVMD\u548c\u76f8\u5173\u5cf0\u503c\u8ddd\u79bb\u7684\u5b9e\u7528\u65f6\u5e8f\u8bc4\u4f30\u6307\u6807\u3002|\n",
    "2509.07775": "|2025-09-09|Sensing with Mobile Devices through Radio SLAM: Models, Methods, Opportunities, and Challenges|Yu Ge\u7b49|[2509.07775](http://arxiv.org/pdf/2509.07775)|\u65e0|\u672c\u6587\u63a2\u8ba8\u4e86\u65e0\u7ebf\u7535SLAM\u4f5c\u4e3a6G\u901a\u611f\u4e00\u4f53\u5316\uff08ISAC\uff09\u7684\u5173\u952e\u65b9\u6cd5\uff0c\u5229\u7528\u65e0\u7ebf\u4fe1\u53f7\u5b9e\u73b0\u540c\u6b65\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u3002  \n\u25c6 \u63d0\u51fa\u5c06\u65e0\u7ebf\u7535SLAM\u4f5c\u4e3a6G\u901a\u611f\u4e00\u4f53\u5316\u7684\u6838\u5fc3\u5b9e\u73b0\u8def\u5f84\uff0c\u901a\u8fc7\u5355\u4e00\u65e0\u7ebf\u4fe1\u53f7\u540c\u65f6\u652f\u6301\u901a\u4fe1\u4e0e\u73af\u5883\u611f\u77e5\u3002  \n\u25c6 \u7cfb\u7edf\u5206\u6790\u4e86\u4e0d\u540c\u9891\u6bb5\u4e0b\u65e0\u7ebf\u7535SLAM\u7684\u6027\u80fd\u6743\u8861\uff0c\u5305\u62ec\u8986\u76d6\u8303\u56f4\u3001\u5206\u8fa8\u7387\u548c\u786c\u4ef6\u9700\u6c42\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002  \n\u25c6 \u5f3a\u8c03\u4e86\u4e0e\u4f20\u611f\u3001\u5b9a\u4f4d\u53ca\u534f\u540c\u7f51\u7edc\u878d\u5408\u7684\u673a\u9047\uff0c\u63a8\u52a8\u591a\u6280\u672f\u534f\u540c\u53d1\u5c55\u3002  \n\u25c6 \u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u548c\u5de5\u4e1a\u673a\u5668\u4eba\u7b496G\u5e94\u7528\u9886\u57df\u7684\u6807\u51c6\u5316\u89e3\u51b3\u65b9\u6848\u5960\u5b9a\u57fa\u7840\uff0c\u4fc3\u8fdb\u6280\u672f\u843d\u5730\u3002  \n\u8bba\u6587\u901a\u8fc7\u6a21\u578b\u548c\u65b9\u6cd5\u521b\u65b0\uff0c\u4e3a\u672a\u67656G\u7f51\u7edc\u4e2d\u7684\u9ad8\u7cbe\u5ea6\u73af\u5883\u611f\u77e5\u4e0e\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002|\n",
    "2509.07683": "|2025-09-10|Robust Radar SLAM for Vehicle Parking Applications|Luis Diener\u7b49|[2509.07683](http://arxiv.org/pdf/2509.07683)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u81ea\u52a8\u6cca\u8f66\u573a\u666f\u4e2d\u7684\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u9700\u6c42\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96f7\u8fbe\u7684\u9c81\u68d2SLAM\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u4f20\u611f\u5668\u6807\u5b9a\u6210\u672c\u9ad8\u548c\u5bf9\u6076\u52a3\u5929\u6c14\u654f\u611f\u7684\u95ee\u9898\u3002\u5176\u6838\u5fc3\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\n\u25c6 \u63d0\u51fa\u4e00\u79cd\u591a\u666e\u52d2\u589e\u5f3a\u7684\u96f7\u8fbeSLAM\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u591a\u666e\u52d2\u901f\u5ea6\u548c\u7279\u5f81\u4f4d\u7f6e\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u6570\u636e\u5173\u8054\u4e0e\u6ee4\u6ce2\u5668\u6536\u655b  \n\u25c6 \u652f\u6301\u591a\u96f7\u8fbe\u4f20\u611f\u5668\u878d\u5408\uff0c\u63d0\u5347\u7cfb\u7edf\u7684\u611f\u77e5\u80fd\u529b\u548c\u73af\u5883\u9002\u5e94\u6027  \n\u25c6 \u8bbe\u8ba1\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u7279\u5f81\u7b5b\u9009\u7b56\u7565\uff0c\u4f18\u5316\u5730\u56fe\u7279\u5f81\u7ba1\u7406\u5e76\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387  \n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u80fd\u591f\u6ee1\u8db3\u81ea\u52a8\u6cca\u8f66\u5bf9\u5398\u7c73\u7ea7\u7cbe\u5ea6\u7684\u4e25\u683c\u8981\u6c42\u3002|\n",
    "2509.07362": "|2025-09-09|Aerial-ground Cross-modal Localization: Dataset, Ground-truth, and Benchmark|Yandi Yang\u7b49|[2509.07362](http://arxiv.org/pdf/2509.07362)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u6784\u5efa\u4e86\u4e00\u4e2a\u89e3\u51b3\u7a7a\u5730\u8de8\u6a21\u6001\u5b9a\u4f4d\u6311\u6218\u7684\u7efc\u5408\u57fa\u51c6\u3002\u5176\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u5927\u89c4\u6a21\u7a7a\u5730\u8de8\u6a21\u6001\u6570\u636e\u96c6\uff0c\u96c6\u6210\u4e86\u6765\u81ea\u79fb\u52a8\u6d4b\u91cf\u7cfb\u7edf\u7684\u5730\u9762\u56fe\u50cf\u548c\u4e09\u4e2a\u57ce\u5e02\uff08\u6b66\u6c49\u3001\u9999\u6e2f\u3001\u65e7\u91d1\u5c71\uff09\u7684\u673a\u8f7d\u6fc0\u5149\u626b\u63cf\uff08ALS\uff09\u70b9\u4e91\u3002\n\u25c6 \u89e3\u51b3\u4e86\u5e73\u53f0\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e3a\u7814\u7a76\u63d0\u4f9b\u4e86\u4e30\u5bcc\u4e14\u771f\u5b9e\u7684\u6570\u636e\u57fa\u7840\u3002\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u57ce\u5e02\u573a\u666f\u7684\u53ef\u9760\u5730\u9762\u771f\u503c\u751f\u6210\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u957f\u671f\u7f3a\u4e4f\u7cbe\u786e\u57fa\u51c6\u7684\u96be\u9898\u3002\n\u25c6 \u9996\u6b21\u5728\u7a7a\u5730\u8de8\u5e73\u53f0\u8bbe\u7f6e\u4e0b\u5bf9\u73b0\u6709\u7684\u56fe\u50cf\u5230\u70b9\u4e91\uff08I2P\uff09\u5b9a\u4f4d\u7b97\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u9a8c\u8bc1\u3002\n\u901a\u8fc7\u63d0\u4f9b\u6570\u636e\u96c6\u3001\u5730\u9762\u771f\u503c\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u5de5\u4f5c\u6781\u5927\u5730\u63a8\u52a8\u548c\u4fc3\u8fdb\u4e86\u57fa\u4e8eALS\u5148\u9a8c\u5730\u56fe\u7684\u3001\u53ef\u6269\u5c55\u4e14\u7cbe\u786e\u7684\u89c6\u89c9\u5b9a\u4f4d\u6280\u672f\u7684\u53d1\u5c55\u3002|\n",
    "2509.08333": "|2025-09-10|Good Deep Features to Track: Self-Supervised Feature Extraction and Tracking in Visual Odometry|Sai Puneeth Reddy Gottam\u7b49|[2509.08333](http://arxiv.org/pdf/2509.08333)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u89c6\u89c9\u91cc\u7a0b\u8ba1\u4e2d\u56e0\u5149\u7167\u53d8\u5316\u3001\u52a8\u6001\u573a\u666f\u7b49\u5bfc\u81f4\u7279\u5f81\u63d0\u53d6\u4e0e\u8ddf\u8e2a\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u76d1\u7763\u7684\u6df1\u5ea6\u7279\u5f81\u63d0\u53d6\u4e0e\u8ddf\u8e2a\u65b9\u6cd5\u3002  \n\u25c6 \u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u7ed3\u5408\u4efb\u52a1\u7279\u5b9a\u53cd\u9988\uff0c\u589e\u5f3a\u6df1\u5ea6\u7279\u5f81\u7684\u7a33\u5b9a\u6027\u548c\u4fe1\u606f\u91cf\u3002  \n\u25c6 \u63d0\u5347\u4e86\u5728\u6311\u6218\u6027\u73af\u5883\uff08\u5982\u5927\u5c3a\u5ea6\u6237\u5916\u573a\u666f\u548c\u957f\u671f\u8fd0\u884c\uff09\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u4e0e\u53ef\u9760\u6027\u3002  \n\u25c6 \u514b\u670d\u4e86\u5df2\u6709\u5b66\u4e60\u65b9\u6cd5\uff08\u5982SuperPoint\u548cSuperGlue\uff09\u5728\u5206\u5e03\u5916\u6570\u636e\u4e0a\u7684\u6cdb\u5316\u5c40\u9650\u3002  \n\u25c6 \u65e0\u9700\u4f9d\u8d56\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u673a\u5236\u4f18\u5316\u7279\u5f81\u8d28\u91cf\u3002  \n\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8fd0\u52a8\u4f30\u8ba1\u7684\u51c6\u786e\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u590d\u6742\u89c6\u89c9\u6761\u4ef6\u3002|\n",
    "2509.08242": "|2025-09-10|Behaviorally Heterogeneous Multi-Agent Exploration Using Distributed Task Allocation|Nirabhra Mandal\u7b49|[2509.08242](http://arxiv.org/pdf/2509.08242)|\u65e0|\u672c\u6587\u9488\u5bf9\u884c\u4e3a\u5f02\u6784\u591a\u673a\u5668\u4eba\u534f\u540c\u63a2\u7d22\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5206\u5e03\u5f0f\u4efb\u52a1\u5206\u914d\u4e0e\u535a\u5f08\u8bba\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u5f15\u5165\u884c\u4e3a\u71b5\uff08BE\uff09\u4f5c\u4e3a\u5f02\u6784\u673a\u5668\u4eba\u8bc4\u4f30\u63a2\u7d22\u6548\u7528\u7684\u6838\u5fc3\u6307\u6807\uff0c\u91cf\u5316\u4e0d\u540c\u884c\u4e3a\u7279\u6027\u5bf9\u4efb\u52a1\u9009\u62e9\u7684\u5f71\u54cd\u3002  \n\u25c6 \u5c06\u4efb\u52a1\u5206\u914d\u95ee\u9898\u8f6c\u5316\u4e3a\u975e\u5408\u4f5c\u535a\u5f08\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u5206\u5e03\u5f0f\u7b97\u6cd5d-PBRAG\u6536\u655b\u81f3\u7eb3\u4ec0\u5747\u8861\uff0c\u8bc1\u660e\u8be5\u5747\u8861\u5373\u6700\u4f18\u5206\u914d\u65b9\u6848\u3002  \n\u25c6 \u9488\u5bf9\u6548\u7528\u672a\u77e5\u573a\u666f\u63d0\u51fa\u8fd1\u4f3c\u5956\u52b1\u65b9\u6cd5\uff0c\u63d0\u4f9b\u5177\u6709\u9c81\u68d2\u6027\u7684\u6027\u80fd\u8fb9\u754c\u4fdd\u8bc1\u3002  \n\u25c6 \u7b97\u6cd5\u5177\u5907\u901a\u4fe1\u6210\u672c\u4f4e\u548c\u6536\u655b\u901f\u5ea6\u5feb\u7684\u7279\u70b9\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u884c\u4e3a\u5f02\u6784\u56e2\u961f\u5728\u63a2\u7d22\u6548\u7387\u548c\u8def\u5f84\u89c4\u5212\u4e0a\u7684\u4f18\u52bf\u3002  \n\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u884c\u4e3a\u5f02\u6784\u7684\u673a\u5668\u4eba\u56e2\u961f\u80fd\u663e\u8457\u63d0\u5347\u6574\u4f53\u63a2\u7d22\u6027\u80fd\u3002|\n",
    "2509.08235": "|2025-09-10|Deep Visual Odometry for Stereo Event Cameras|Sheng Zhong\u7b49|[2509.08235](http://arxiv.org/pdf/2509.08235)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u7acb\u4f53\u4e8b\u4ef6\u76f8\u673a\u89c6\u89c9\u91cc\u7a0b\u8ba1\u7cfb\u7edfStereo-DEVO\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u5b9e\u73b0\u4e86\u5728\u590d\u6742\u5149\u7167\u6761\u4ef6\u4e0b\u7684\u9ad8\u7cbe\u5ea6\u5b9e\u65f6\u4f4d\u59ff\u4f30\u8ba1\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u4e14\u9ad8\u6548\u7684\u9759\u6001-\u7acb\u4f53\u5173\u8054\u7b56\u7565\uff0c\u7528\u4e8e\u7a00\u758f\u6df1\u5ea6\u4f30\u8ba1\uff0c\u51e0\u4e4e\u4e0d\u589e\u52a0\u8ba1\u7b97\u8d1f\u62c5\u3002  \n\u25c6 \u5c06\u6df1\u5ea6\u4f30\u8ba1\u4e0e\u7d27\u8026\u5408\u7684\u675f\u8c03\u6574\u4f18\u5316\u65b9\u6848\u76f8\u7ed3\u5408\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5229\u7528\u57fa\u4e8e\u4f53\u7d20\u7684\u4e8b\u4ef6\u8868\u793a\u548c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u5149\u6d41\u4f30\u8ba1\u548c\u53ef\u9760\u7684\u56fe\u50cf\u5757\u5173\u8054\u3002  \n\u25c6 \u7cfb\u7edf\u80fd\u591f\u5b9e\u65f6\u5904\u7406VGA\u5206\u8fa8\u7387\u7684\u4e8b\u4ef6\u6d41\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684\u79bb\u7ebf\u65b9\u6848\u5b9e\u73b0\u4e86\u91cd\u5927\u7a81\u7834\u3002  \n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5927\u89c4\u6a21\u591c\u95f4\u9ad8\u52a8\u6001\u8303\u56f4\u573a\u666f\u4e2d\u4ecd\u80fd\u4fdd\u6301\u7a33\u5b9a\u7684\u4f4d\u59ff\u4f30\u8ba1\u3002|\n",
    "2509.08197": "|2025-09-10|Online Dynamic SLAM with Incremental Smoothing and Mapping|Jesse Morris\u7b49|[2509.08197](http://arxiv.org/pdf/2509.08197)|\u65e0|\u672c\u6587\u9996\u6b21\u5c06\u589e\u91cf\u4f18\u5316\u6280\u672f\u5e94\u7528\u4e8e\u52a8\u6001SLAM\uff0c\u5b9e\u73b0\u4e86\u5728\u7ebf\u5b9e\u65f6\u4f30\u8ba1\u80fd\u529b\u3002\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u56e0\u5b50\u56fe\u6a21\u578b\uff0c\u80fd\u591f\u8054\u5408\u4f30\u8ba1\u9759\u6001\u573a\u666f\u548c\u52a8\u6001\u7269\u4f53\u7684\u72b6\u6001\u3002\n\u25c6 \u8bbe\u8ba1\u4e86\u5168\u65b0\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u5145\u5206\u5229\u7528\u4e86\u73b0\u6709\u589e\u91cf\u4f18\u5316\u65b9\u6cd5\uff0c\u652f\u6301\u5728\u7ebf\u9ad8\u6548\u6c42\u89e3\u3002\n\u25c6 \u5728\u4fdd\u8bc1\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u5176\u76f8\u673a\u4f4d\u59ff\u548c\u7269\u4f53\u8fd0\u52a8\u4f30\u8ba1\u7cbe\u5ea6\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002\n\u25c6 \u901a\u8fc7\u95ee\u9898\u7ed3\u6784\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u589e\u91cf\u5f0f\u6c42\u89e3\u52a8\u6001SLAM\u7684\u5173\u952e\u6311\u6218\u3002\n\u6700\u7ec8\uff0c\u8be5\u7cfb\u7edf\u67b6\u6784\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5b9e\u73b0\u4e865\u500d\u7684\u52a0\u901f\u3002|\n",
    "2509.09509": "|2025-09-11|SMapper: A Multi-Modal Data Acquisition Platform for SLAM Benchmarking|Pedro Miguel Bastos Soares\u7b49|[2509.09509](http://arxiv.org/pdf/2509.09509)|\u65e0|SMapper\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3aSLAM\u7814\u7a76\u8bbe\u8ba1\u7684\u5f00\u6e90\u591a\u6a21\u6001\u6570\u636e\u91c7\u96c6\u5e73\u53f0\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u6570\u636e\u96c6\u5728\u4f20\u611f\u5668\u591a\u6837\u6027\u3001\u73af\u5883\u8986\u76d6\u548c\u5b9e\u9a8c\u53ef\u590d\u73b0\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002\u5176\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u91c7\u7528\u5f00\u6e90\u786c\u4ef6\u8bbe\u8ba1\uff0c\u96c6\u6210\u4e86\u540c\u6b65\u7684LiDAR\u3001\u591a\u76f8\u673a\u548c\u60ef\u6027\u6d4b\u91cf\u5355\u5143\uff0c\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u591a\u6a21\u6001\u611f\u77e5\u6570\u636e\u3002\n\u25c6 \u63d0\u4f9b\u4e86\u4e00\u5957\u53ef\u9760\u7684\u6807\u5b9a\u4e0e\u65f6\u95f4\u540c\u6b65\u6d41\u7a0b\uff0c\u786e\u4fdd\u4e86\u8de8\u6a21\u6001\u6570\u636e\u5728\u65f6\u7a7a\u4e0a\u7684\u7cbe\u786e\u5bf9\u9f50\u3002\n\u25c6 \u5177\u5907\u53ef\u6269\u5c55\u548c\u53ef\u590d\u7528\u7684\u7ed3\u6784\uff0c\u652f\u6301\u624b\u6301\u548c\u673a\u5668\u4eba\u642d\u8f7d\u4e24\u79cd\u4f7f\u7528\u573a\u666f\uff0c\u589e\u5f3a\u4e86\u5e73\u53f0\u7684\u9002\u5e94\u6027\u3002\n\u25c6 \u516c\u5f00\u53d1\u5e03\u4e86\u540d\u4e3aSMapper-light\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u5ba4\u5185\u5916\u5178\u578b\u573a\u666f\u7684\u9ad8\u7cbe\u5ea6\u771f\u503c\u8f68\u8ff9\u4e0e\u7a20\u5bc6\u4e09\u7ef4\u91cd\u5efa\u7ed3\u679c\u3002\n\u25c6 \u57fa\u4e8e\u6240\u91c7\u96c6\u6570\u636e\u5bf9\u4e3b\u6d41LiDAR\u4e0e\u89c6\u89c9SLAM\u7b97\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u80fd\u8bc4\u6d4b\uff0c\u4e3a\u7b97\u6cd5\u6bd4\u8f83\u4e0e\u590d\u73b0\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002\n\u901a\u8fc7\u786c\u4ef6\u5f00\u653e\u3001\u6570\u636e\u540c\u6b65\u548c\u8bc4\u6d4b\u4e00\u4f53\u5316\uff0cSMapper\u663e\u8457\u63d0\u5347\u4e86SLAM\u7814\u7a76\u7684\u53ef\u9760\u6027\u3001\u53ef\u6bd4\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002|\n",
    "2509.09110": "|2025-09-11|S-BEVLoc: BEV-based Self-supervised Framework for Large-scale LiDAR Global Localization|Chenghao Zhang\u7b49|[2509.09110](http://arxiv.org/pdf/2509.09110)|\u65e0|S-BEVLoc\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9e1f\u77b0\u56fe\uff08BEV\uff09\u7684\u81ea\u76d1\u7763\u6fc0\u5149\u96f7\u8fbe\u5168\u5c40\u5b9a\u4f4d\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u65e0\u9700\u5730\u9762\u771f\u503c\u59ff\u6001\u5373\u53ef\u5b9e\u73b0\u5927\u89c4\u6a21\u5b9a\u4f4d\u3002  \n\u25c6 \u9996\u6b21\u6784\u5efa\u4e86\u57fa\u4e8eBEV\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u5229\u7528\u5173\u952e\u70b9\u4e4b\u95f4\u7684\u5df2\u77e5\u5730\u7406\u8ddd\u79bb\u6784\u5efa\u8bad\u7ec3\u4e09\u5143\u7ec4\uff0c\u5b8c\u5168\u6446\u8131\u4e86\u5bf9GPS\u6216SLAM\u771f\u503c\u6570\u636e\u7684\u4f9d\u8d56\u3002  \n\u25c6 \u63d0\u51faSoftCos\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u589e\u5f3a\u4ece\u751f\u6210\u7684\u4e09\u5143\u7ec4\u4e2d\u5b66\u4e60\u7279\u5f81\u8868\u793a\u7684\u80fd\u529b\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u56f0\u96be\u6837\u672c\u4e0a\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u7ed3\u5408CNN\u5c40\u90e8\u7279\u5f81\u63d0\u53d6\u4e0eNetVLAD\u5168\u5c40\u63cf\u8ff0\u7b26\u805a\u5408\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u5224\u522b\u6027\u5f3a\u7684\u573a\u666f\u8868\u793a\u3002  \n\u5728KITTI\u548cNCLT\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4f4d\u7f6e\u8bc6\u522b\u3001\u56de\u73af\u68c0\u6d4b\u548c\u5168\u5c40\u5b9a\u4f4d\u4efb\u52a1\u4e0a\u8fbe\u5230\u9886\u5148\u6027\u80fd\uff0c\u540c\u65f6\u5c55\u73b0\u51fa\u8fdc\u8d85\u76d1\u7763\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u3002|\n",
    "2509.10433": "|2025-09-12|Robust Localization in Modern Cellular Networks using Global Map Features|Junshi Chen\u7b49|[2509.10433](http://arxiv.org/pdf/2509.10433)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u578b\u591a\u8def\u5f84\u540c\u65f6\u5b9a\u4f4d\u4e0e\u5efa\u56fe\uff08MP-SLAM\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u73b0\u4ee3\u8702\u7a9d\u7f51\u7edc\u4e2d\u7684\u9c81\u68d2\u5b9a\u4f4d\u3002  \n\u25c6\u5f15\u5165\u5168\u5c40\u5730\u56fe\u7279\u5f81\uff08GMF\uff09\u5b58\u50a8\u5e93\uff0c\u6574\u5408\u5386\u53f2\u904d\u5386\u4e2d\u6536\u96c6\u7684\u9ad8\u8d28\u91cf\u5730\u56fe\u7279\u5f81\uff08\u5982\u865a\u62df\u951a\u70b9\uff09\uff0c\u63d0\u5347\u7cfb\u7edf\u5bf9\u5148\u9a8c\u77e5\u8bc6\u7684\u5229\u7528\u80fd\u529b\u3002  \n\u25c6\u901a\u8fc7\u6982\u7387\u5047\u8bbe\u5bc6\u5ea6\uff08PHD\uff09\u6ee4\u6ce2\u5668\u52a8\u6001\u96c6\u6210\u5168\u5c40\u5730\u56fe\u7279\u5f81\uff0c\u5b9e\u73b0\u7279\u5f81\u5f3a\u5ea6\u51fd\u6570\u7684\u65f6\u5e8f\u4f20\u64ad\u4e0e\u878d\u5408\u3002  \n\u25c6\u5728\u4e25\u91cd\u591a\u5f84\u4f20\u64ad\u548c\u5c0f\u533a\u95f4\u5e72\u6270\u7684\u5bc6\u96c6\u57ce\u5e02\u73af\u5883\u4e2d\uff0c\u57fa\u4e8eLTE\u4fe1\u53f7\u8fdb\u884c\u4e86\u771f\u5b9e\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u5176\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002  \n\u25c6\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e5G/6G\u7b49\u73b0\u4ee3\u8702\u7a9d\u7f51\u7edc\uff0c\u5373\u4f7f\u5728\u975e\u89c6\u8ddd\uff08OLoS\uff09\u7b49\u6076\u52a3\u4fe1\u53f7\u6761\u4ef6\u4e0b\u4ecd\u80fd\u5b9e\u73b0\u53ef\u9760\u5b9a\u4f4d\u3002  \n\u25c6\u7a81\u7834\u4e86\u4f20\u7edfMP-SLAM\u548c\u57fa\u4e8e\u81ea\u611f\u77e5\u4f20\u611f\u5668\u7684\u5b9a\u4f4d\u5c40\u9650\uff0c\u4e3a\u590d\u6742\u73af\u5883\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2509.11653": "|2025-09-15|See What I Mean? Mobile Eye-Perspective Rendering for Optical See-through Head-mounted Displays|Gerlinde Emsenhuber\u7b49|[2509.11653](http://arxiv.org/pdf/2509.11653)|\u65e0|\u672c\u6587\u9488\u5bf9\u5149\u5b66\u900f\u89c6\u5934\u663e\u4e2d\u4e16\u754c\u76f8\u673a\u4e0e\u7528\u6237\u89c6\u89d2\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u773c\u89c6\u89d2\u6e32\u67d3\u6280\u672f\u4ee5\u63d0\u5347\u589e\u5f3a\u73b0\u5b9e\u89c6\u89c9\u5f15\u5bfc\u7684\u51c6\u786e\u6027\u3002  \n\u25c6 \u5b9e\u73b0\u4e86\u57fa\u4e8e\u5e73\u9762\u6295\u5f71\u7684Plane-Proxy EPR\u65b9\u6cd5\uff0c\u5728\u56fa\u5b9a\u5e73\u9762\u4e0a\u8fd1\u4f3c\u773c\u89c6\u89d2\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u57fa\u4e8eSLAM\u573a\u666f\u91cd\u5efa\u7684Mesh-Proxy EPR\u65b9\u6cd5\uff0c\u901a\u8fc7\u51e0\u4f55\u7f51\u683c\u63d0\u9ad8\u6295\u5f71\u7cbe\u5ea6\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u63d0\u51faGaze-Proxy EPR\u65b9\u6cd5\uff0c\u5229\u7528\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\u5c06\u6295\u5f71\u4e0e\u7528\u6237\u6ce8\u89c6\u6df1\u5ea6\u52a8\u6001\u5bf9\u9f50\u3002  \n\u901a\u8fc7\u771f\u5b9e\u4efb\u52a1\u7528\u6237\u7814\u7a76\u8bc1\u660e\uff0c\u7cbe\u786e\u7684\u773c\u89c6\u89d2\u6e32\u67d3\u5bf9\u4efb\u52a1\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4e14\u6240\u63d0\u6ce8\u89c6\u4ee3\u7406\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\u3002  \n\u7814\u7a76\u6700\u7ec8\u5f00\u6e90\u4e86\u5b8c\u6574\u7684\u773c\u89c6\u89d2\u6e32\u67d3\u6846\u67b6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u652f\u6301\u3002|\n",
    "2509.11574": "|2025-09-15|Gaussian-Plus-SDF SLAM: High-fidelity 3D Reconstruction at 150+ fps|Zhexi Peng\u7b49|[2509.11574](http://arxiv.org/pdf/2509.11574)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86GPS-SLAM\uff0c\u4e00\u79cd\u80fd\u5b9e\u73b0\u8d85\u8fc7150 fps\u5b9e\u65f6\u9ad8\u4fdd\u771f\u4e09\u7ef4\u91cd\u5efa\u7684\u65b0\u7cfb\u7edf\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u4e00\u79cd\u6df7\u5408\u8868\u793a\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u9ad8\u65afSLAM\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u74f6\u9888\u95ee\u9898\u3002\n\n\u25c6 \u521b\u65b0\u6027\u5730\u7ed3\u5408\u4e86\u5f69\u8272\u7b26\u53f7\u8ddd\u79bb\u573a\uff08SDF\uff09\u548c3D\u9ad8\u65af\u4e24\u79cd\u8868\u793a\uff0cSDF\u8d1f\u8d23\u9ad8\u6548\u6784\u5efa\u5e73\u6ed1\u7684\u51e0\u4f55\u4e0e\u5916\u89c2\uff0c\u800c\u9ad8\u65af\u5219\u4e13\u95e8\u7528\u4e8e\u8865\u8db3\u7ec6\u8282\u3002\n\u25c6 \u8be5\u6df7\u5408\u8868\u793a\u907f\u514d\u4e86\u5bf9\u6574\u4e2a\u573a\u666f\u90fd\u7528\u9ad8\u65af\u5efa\u6a21\uff0c\u4ece\u800c\u5c06\u6240\u9700\u7684\u9ad8\u65af\u6570\u91cf\u51cf\u5c11\u4e8650%\u3002\n\u25c6 \u901a\u8fc7\u8ba9SDF\u627f\u62c5\u5927\u90e8\u5206\u57fa\u7840\u8868\u793a\u5de5\u4f5c\uff0c\u9ad8\u65af\u4f18\u5316\u53ea\u9700\u8fdb\u884c\u9488\u5bf9\u6027\u7684\u5916\u89c2\u7ec6\u5316\uff0c\u4f7f\u5f97\u4f18\u5316\u8fed\u4ee3\u6b21\u6570\u5927\u5e45\u51cf\u5c1175%\u3002\n\u25c6 \u6700\u7ec8\u6784\u5efa\u7684GPS-SLAM\u7cfb\u7edf\u5728\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\u91cd\u5efa\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc7\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u52a0\u901f\uff0c\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fd0\u884c\u901f\u5ea6\u8d85\u8fc7150\u5e27/\u79d2\u3002|\n",
    "2509.10757": "|2025-09-13|FastTrack: GPU-Accelerated Tracking for Visual SLAM|Kimia Khabiri\u7b49|[2509.10757](http://arxiv.org/pdf/2509.10757)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528GPU\u52a0\u901f\u6765\u663e\u8457\u63d0\u5347\u89c6\u89c9-\u60ef\u6027SLAM\u7cfb\u7edf\u8ddf\u8e2a\u6a21\u5757\u6027\u80fd\u7684\u65b0\u65b9\u6cd5FastTrack\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u7528GPU\u5e76\u884c\u8ba1\u7b97\u80fd\u529b\u6765\u52a0\u901f\u8ddf\u8e2a\u8fc7\u7a0b\u4e2d\u6700\u8017\u65f6\u7684\u7ec4\u4ef6\uff0c\u5305\u62ec\u7acb\u4f53\u7279\u5f81\u5339\u914d\u548c\u5c40\u90e8\u5730\u56fe\u8ddf\u8e2a\u3002  \n\u25c6 \u5c06\u52a0\u901f\u8bbe\u8ba1\u5177\u4f53\u5b9e\u73b0\u5728\u4e3b\u6d41\u7684ORB-SLAM3\u6846\u67b6\u7684\u8ddf\u8e2a\u6d41\u7a0b\u4e2d\uff0c\u5e76\u4f7f\u7528CUDA\u8fdb\u884c\u5f00\u53d1\u3002  \n\u25c6 \u5728\u516c\u5f00\u6570\u636e\u96c6EuRoC\u548cTUM-VI\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u7acb\u4f53-\u60ef\u6027\u6a21\u5f0f\u4e0b\u8fd0\u884c\uff0c\u8ddf\u8e2a\u6027\u80fd\u6574\u4f53\u63d0\u5347\u6700\u9ad8\u8fbe2.8\u500d\u3002  \n\u25c6 \u9a8c\u8bc1\u4e86\u65b9\u6848\u5728\u4e24\u79cd\u786c\u4ef6\u5e73\u53f0\uff08\u684c\u9762GPU\u548c\u5d4c\u5165\u5f0fJetson Xavier NX\uff09\u4e0a\u7684\u6709\u6548\u6027\u4e0e\u901a\u7528\u6027\uff0c\u786e\u4fdd\u4e86\u5b9e\u65f6\u6027\u5e76\u964d\u4f4e\u4e86\u8ddf\u8e2a\u4e22\u5931\u7684\u98ce\u9669\u3002|\n",
    "2509.12924": "|2025-09-18|MATTER: Multiscale Attention for Registration Error Regression|Shipeng Liu\u7b49|[2509.12924](http://arxiv.org/pdf/2509.12924)|\u65e0|\u25c6 Point cloud registration (PCR) is crucial for many downstream tasks, such as simultaneous localization and mapping (SLAM) and object tracking.\n\u25c6 This makes detecting and quantifying registration misalignment, i.e.,~{\\it PCR quality validation}, an important task.\n\u25c6 All existing methods treat validation as a classification task, aiming to assign the PCR quality to a few classes.|\n",
    "2509.12592": "|2025-09-16|Match Chat: Real Time Generative AI and Generative Computing for Tennis|Aaron Baughman\u7b49|[2509.12592](http://arxiv.org/pdf/2509.12592)|\u65e0|\u25c6 We present Match Chat, a real-time, agent-driven assistant designed to enhance the tennis fan experience by delivering instant, accurate responses to match-related queries.\n\u25c6 Match Chat integrates Generative Artificial Intelligence (GenAI) with Generative Computing (GenComp) techniques to synthesize key insights during live tennis singles matches.\n\u25c6 The system debuted at the 2025 Wimbledon Championships and the 2025 US Open, where it provided about 1 million users with seamless access to streaming and static data through natural language queries.|\n",
    "2509.14191": "|2025-09-17|MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping|Zhihao Cao\u7b49|[2509.14191](http://arxiv.org/pdf/2509.14191)|\u65e0|\u25c6 Recent progress in dense SLAM has primarily targeted monocular setups, often at the expense of robustness and geometric coverage.\n\u25c6 We present MCGS-SLAM, the first purely RGB-based multi-camera SLAM system built on 3D Gaussian Splatting (3DGS).\n\u25c6 Unlike prior methods relying on sparse maps or inertial data, MCGS-SLAM fuses dense RGB inputs from multiple viewpoints into a unified, continuously optimized Gaussian map.|\n",
    "2509.13972": "|2025-09-17|BIM Informed Visual SLAM for Construction Monitoring|Asier Bikandi\u7b49|[2509.13972](http://arxiv.org/pdf/2509.13972)|\u65e0|\u25c6 Simultaneous Localization and Mapping (SLAM) is a key tool for monitoring construction sites, where aligning the evolving as-built state with the as-planned design enables early error detection and reduces costly rework.\n\u25c6 LiDAR-based SLAM achieves high geometric precision, but its sensors are typically large and power-demanding, limiting their use on portable platforms.\n\u25c6 Visual SLAM offers a practical alternative with lightweight cameras already embedded in most mobile devices.|\n",
    "2509.13713": "|2025-09-17|UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry|Tae-Wook Um\u7b49|[2509.13713](http://arxiv.org/pdf/2509.13713)|\u65e0|\u25c6 Monocular depth estimation has been increasingly adopted in robotics and autonomous driving for its ability to infer scene geometry from a single camera.\n\u25c6 In self-supervised monocular depth estimation frameworks, the network jointly generates and exploits depth and pose estimates during training, thereby eliminating the need for depth labels.\n\u25c6 However, these methods remain challenged by uncertainty in the input data, such as low-texture or dynamic regions, which can cause reduced depth accuracy.|\n",
    "2509.13649": "|2025-09-17|Barometer-Aided Attitude Estimation|M\u00e9lon\u00e9 Nyoba Tchonkeu\u7b49|[2509.13649](http://arxiv.org/pdf/2509.13649)|\u65e0|\u25c6 Accurate and robust attitude estimation is a central challenge for autonomous vehicles operating in GNSS-denied or highly dynamic environments.\n\u25c6 In such cases, Inertial Measurement Units (IMUs) alone are insufficient for reliable tilt estimation due to the ambiguity between gravitational and inertial accelerations.\n\u25c6 While auxiliary velocity sensors, such as GNSS, Pitot tubes, Doppler radar, or visual odometry, are often used, they can be unavailable, intermittent, or costly.|\n",
    "2509.13541": "|2025-09-16|Semantic 3D Reconstructions with SLAM for Central Airway Obstruction|Ayberk Acar\u7b49|[2509.13541](http://arxiv.org/pdf/2509.13541)|\u65e0|\u25c6 Central airway obstruction (CAO) is a life-threatening condition with increasing incidence, caused by tumors in and outside of the airway.\n\u25c6 Traditional treatment methods such as bronchoscopy and electrocautery can be used to remove the tumor completely; however, these methods carry a high risk of complications.\n\u25c6 Recent advances allow robotic interventions with lesser risk.|\n",
    "2509.13536": "|2025-09-16|MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM|Yinlong Bai\u7b49|[2509.13536](http://arxiv.org/pdf/2509.13536)|\u65e0|\u25c6 Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant impact on rendering and reconstruction techniques.\n\u25c6 Current research predominantly focuses on improving rendering performance and reconstruction quality using high-performance desktop GPUs, largely overlooking applications for embedded platforms like micro air vehicles (MAVs).\n\u25c6 These devices, with their limited computational resources and memory, often face a trade-off between system performance and reconstruction quality.|\n",
    "2509.14949": "|2025-09-18|Human Interaction for Collaborative Semantic SLAM using Extended Reality|Laura Ribeiro\u7b49|[2509.14949](http://arxiv.org/pdf/2509.14949)|\u65e0|\u25c6 Semantic SLAM (Simultaneous Localization and Mapping) systems enrich robot maps with structural and semantic information, enabling robots to operate more effectively in complex environments.\n\u25c6 However, these systems struggle in real-world scenarios with occlusions, incomplete data, or ambiguous geometries, as they cannot fully leverage the higher-level spatial and semantic knowledge humans naturally apply.\n\u25c6 We introduce HICS-SLAM, a Human-in-the-Loop semantic SLAM framework that uses a shared extended reality environment for real-time collaboration.|\n",
    "2509.14636": "|2025-09-18|BEV-ODOM2: Enhanced BEV-based Monocular Visual Odometry with PV-BEV Fusion and Dense Flow Supervision for Ground Robots|Yufei Wei\u7b49|[2509.14636](http://arxiv.org/pdf/2509.14636)|\u65e0|\u25c6 Bird's-Eye-View (BEV) representation offers a metric-scaled planar workspace, facilitating the simplification of 6-DoF ego-motion to a more robust 3-DoF model for monocular visual odometry (MVO) in intelligent transportation systems.\n\u25c6 However, existing BEV methods suffer from sparse supervision signals and information loss during perspective-to-BEV projection.\n\u25c6 We present BEV-ODOM2, an enhanced framework addressing both limitations without additional annotations.|\n",
    "2509.14516": "|2025-09-18|Event-LAB: Towards Standardized Evaluation of Neuromorphic Localization Methods|Adam D. Hines\u7b49|[2509.14516](http://arxiv.org/pdf/2509.14516)|\u65e0|\u25c6 Event-based localization research and datasets are a rapidly growing area of interest, with a tenfold increase in the cumulative total number of published papers on this topic over the past 10 years.\n\u25c6 Whilst the rapid expansion in the field is exciting, it brings with it an associated challenge: a growth in the variety of required code and package dependencies as well as data formats, making comparisons difficult and cumbersome for researchers to implement reliably.\n\u25c6 To address this challenge, we present Event-LAB: a new and unified framework for running several event-based localization methodologies across multiple datasets.|\n",
    "2509.16019": "|2025-09-19|SLaM-DiMM: Shared Latent Modeling for Diffusion Based Missing Modality Synthesis in MRI|Bhavesh Sandbhor\u7b49|[2509.16019](http://arxiv.org/pdf/2509.16019)|\u65e0|\u25c6 Brain MRI scans are often found in four modalities, consisting of T1-weighted with and without contrast enhancement (T1ce and T1w), T2-weighted imaging (T2w), and Flair.\n\u25c6 Leveraging complementary information from these different modalities enables models to learn richer, more discriminative features for understanding brain anatomy, which could be used in downstream tasks such as anomaly detection.\n\u25c6 However, in clinical practice, not all MRI modalities are always available due to various reasons.|\n",
    "2509.15673": "|2025-09-19|Omni-LIVO: Robust RGB-Colored Multi-Camera Visual-Inertial-LiDAR Odometry via Photometric Migration and ESIKF Fusion|Yinong Cao\u7b49|[2509.15673](http://arxiv.org/pdf/2509.15673)|\u65e0|\u25c6 Wide field-of-view (FoV) LiDAR sensors provide dense geometry across large environments, but most existing LiDAR-inertial-visual odometry (LIVO) systems rely on a single camera, leading to limited spatial coverage and degraded robustness.\n\u25c6 We present Omni-LIVO, the first tightly coupled multi-camera LIVO system that bridges the FoV mismatch between wide-angle LiDAR and conventional cameras.\n\u25c6 Omni-LIVO introduces a Cross-View direct tracking strategy that maintains photometric consistency across non-overlapping views, and extends the Error-State Iterated Kalman Filter (ESIKF) with multi-view updates and adaptive covariance weighting.|\n",
    "2509.17864": "|2025-09-22|ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos|Shi Chen\u7b49|[2509.17864](http://arxiv.org/pdf/2509.17864)|\u65e0|\u25c6 Achieving truly practical dynamic 3D reconstruction requires online operation, global pose and map consistency, detailed appearance modeling, and the flexibility to handle both RGB and RGB-D inputs.\n\u25c6 However, existing SLAM methods typically merely remove the dynamic parts or require RGB-D input, while offline methods are not scalable to long video sequences, and current transformer-based feedforward methods lack global consistency and appearance details.\n\u25c6 To this end, we achieve online dynamic scene reconstruction by disentangling the static and dynamic parts within a SLAM system.|\n",
    "2509.16909": "|2025-09-21|SLAM-Former: Putting SLAM into One Transformer|Yijun Yuan\u7b49|[2509.16909](http://arxiv.org/pdf/2509.16909)|\u65e0|\u25c6 We present SLAM-Former, a novel neural approach that integrates full SLAM capabilities into a single transformer.\n\u25c6 Similar to traditional SLAM systems, SLAM-Former comprises both a frontend and a backend that operate in tandem.\n\u25c6 The frontend processes sequential monocular images in real-time for incremental mapping and tracking, while the backend performs global refinement to ensure a geometrically consistent result.|\n",
    "2509.16863": "|2025-09-21|ConfidentSplat: Confidence-Weighted Depth Fusion for Accurate 3D Gaussian Splatting SLAM|Amanuel T. Dufera\u7b49|[2509.16863](http://arxiv.org/pdf/2509.16863)|\u65e0|\u25c6 We introduce ConfidentSplat, a novel 3D Gaussian Splatting (3DGS)-based SLAM system for robust, highfidelity RGB-only reconstruction.\n\u25c6 Addressing geometric inaccuracies in existing RGB-only 3DGS SLAM methods that stem from unreliable depth estimation, ConfidentSplat incorporates a core innovation: a confidence-weighted fusion mechanism.\n\u25c6 This mechanism adaptively integrates depth cues from multiview geometry with learned monocular priors (Omnidata ViT), dynamically weighting their contributions based on explicit reliability estimates-derived predominantly from multi-view geometric consistency-to generate high-fidelity proxy depth for map supervision.|\n",
    "2509.18954": "|2025-09-23|Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation|Minoo Dolatabadi\u7b49|[2509.18954](http://arxiv.org/pdf/2509.18954)|\u65e0|\u25c6 LiDAR-based localization and SLAM often rely on iterative matching algorithms, particularly the Iterative Closest Point (ICP) algorithm, to align sensor data with pre-existing maps or previous scans.\n\u25c6 However, ICP is prone to errors in featureless environments and dynamic scenes, leading to inaccurate pose estimation.\n\u25c6 Accurately predicting the uncertainty associated with ICP is crucial for robust state estimation but remains challenging, as existing approaches often rely on handcrafted models or simplified assumptions.|\n",
    "2509.18342": "|2025-09-22|Semantic-Aware Particle Filter for Reliable Vineyard Robot Localisation|Rajitha de Silva\u7b49|[2509.18342](http://arxiv.org/pdf/2509.18342)|\u65e0|\u25c6 Accurate localisation is critical for mobile robots in structured outdoor environments, yet LiDAR-based methods often fail in vineyards due to repetitive row geometry and perceptual aliasing.\n\u25c6 We propose a semantic particle filter that incorporates stable object-level detections, specifically vine trunks and support poles into the likelihood estimation process.\n\u25c6 Detected landmarks are projected into a birds eye view and fused with LiDAR scans to generate semantic observations.|\n",
    "2509.20171": "|2025-09-24|Optical Ocean Recipes: Creating Realistic Datasets to Facilitate Underwater Vision Research|Patricia Sch\u00f6ntag\u7b49|[2509.20171](http://arxiv.org/pdf/2509.20171)|\u65e0|\u25c6 The development and evaluation of machine vision in underwater environments remains challenging, often relying on trial-and-error-based testing tailored to specific applications.\n\u25c6 This is partly due to the lack of controlled, ground-truthed testing environments that account for the optical challenges, such as color distortion from spectrally variant light attenuation, reduced contrast and blur from backscatter and volume scattering, and dynamic light patterns from natural or artificial illumination.\n\u25c6 Additionally, the appearance of ocean water in images varies significantly across regions, depths, and seasons.|\n",
    "2509.19522": "|2025-09-23|Bioinspired SLAM Approach for Unmanned Surface Vehicle|Fabio Coelho\u7b49|[2509.19522](http://arxiv.org/pdf/2509.19522)|\u65e0|\u25c6 This paper presents OpenRatSLAM2, a new version of OpenRatSLAM - a bioinspired SLAM framework based on computational models of the rodent hippocampus.\n\u25c6 OpenRatSLAM2 delivers low-computation-cost visual-inertial based SLAM, suitable for GPS-denied environments.\n\u25c6 Our contributions include a ROS2-based architecture, experimental results on new waterway datasets, and insights into system parameter tuning.|\n",
    "2509.19463": "|2025-09-23|CU-Multi: A Dataset for Multi-Robot Collaborative Perception|Doncey Albin\u7b49|[2509.19463](http://arxiv.org/pdf/2509.19463)|\u65e0|\u25c6 A central challenge for multi-robot systems is fusing independently gathered perception data into a unified representation.\n\u25c6 Despite progress in Collaborative SLAM (C-SLAM), benchmarking remains hindered by the scarcity of dedicated multi-robot datasets.\n\u25c6 Many evaluations instead partition single-robot trajectories, a practice that may only partially reflect true multi-robot operations and, more critically, lacks standardization, leading to results that are difficult to interpret or compare across studies.|\n",
    "2509.21006": "|2025-09-25|AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation|Konstantin Gubernatorov\u7b49|[2509.21006](http://arxiv.org/pdf/2509.21006)|\u65e0|\u25c6 We address natural language pick-and-place in unseen, unpredictable indoor environments with AnywhereVLA, a modular framework for mobile manipulation.\n\u25c6 A user text prompt serves as an entry point and is parsed into a structured task graph that conditions classical SLAM with LiDAR and cameras, metric semantic mapping, and a task-aware frontier exploration policy.\n\u25c6 An approach planner then selects visibility and reachability aware pre grasp base poses.|\n",
    "2509.20757": "|2025-09-29|MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM|Yuxuan Zhou\u7b49|[2509.20757](http://arxiv.org/pdf/2509.20757)|\u65e0|\u25c6 Visual SLAM is a cornerstone technique in robotics, autonomous driving and extended reality (XR), yet classical systems often struggle with low-texture environments, scale ambiguity, and degraded performance under challenging visual conditions.\n\u25c6 Recent advancements in feed-forward neural network-based pointmap regression have demonstrated the potential to recover high-fidelity 3D scene geometry directly from images, leveraging learned spatial priors to overcome limitations of traditional multi-view geometry methods.\n\u25c6 However, the widely validated advantages of probabilistic multi-sensor information fusion are often discarded in these pipelines.|\n",
    "2509.20739": "|2025-09-25|SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning|Guoyang Zhao\u7b49|[2509.20739](http://arxiv.org/pdf/2509.20739)|\u65e0|\u25c6 Conventional SLAM pipelines for legged robot navigation are fragile under rapid motion, calibration demands, and sensor drift, while offering limited semantic reasoning for task-driven exploration.\n\u25c6 To deal with these issues, we propose a vision-only, SLAM-free navigation framework that replaces dense geometry with semantic reasoning and lightweight topological representations.\n\u25c6 A hierarchical vision-language perception module fuses scene-level context with object-level cues for robust semantic inference.|\n",
    "2509.22288": "|2025-09-26|IMU-Preintegrated Radar Factors for Asynchronous Radar-LiDAR-Inertial SLAM|Johan Hatleskog\u7b49|[2509.22288](http://arxiv.org/pdf/2509.22288)|\u65e0|\u25c6 Fixed-lag Radar-LiDAR-Inertial smoothers conventionally create one factor graph node per measurement to compensate for the lack of time synchronization between radar and LiDAR.\n\u25c6 For a radar-LiDAR sensor pair with equal rates, this strategy results in a state creation rate of twice the individual sensor frequencies.\n\u25c6 This doubling of the number of states per second yields high optimization costs, inhibiting real-time performance on resource-constrained hardware.|\n",
    "2509.21602": "|2025-09-25|Real-Time Indoor Object SLAM with LLM-Enhanced Priors|Yang Jiao\u7b49|[2509.21602](http://arxiv.org/pdf/2509.21602)|\u65e0|\u25c6 Object-level Simultaneous Localization and Mapping (SLAM), which incorporates semantic information for high-level scene understanding, faces challenges of under-constrained optimization due to sparse observations.\n\u25c6 Prior work has introduced additional constraints using commonsense knowledge, but obtaining such priors has traditionally been labor-intensive and lacks generalizability across diverse object categories.\n\u25c6 We address this limitation by leveraging large language models (LLMs) to provide commonsense knowledge of object geometric attributes, specifically size and orientation, as prior factors in a graph-based SLAM framework.|\n",
    "2509.24236": "|2025-09-29|PROFusion: Robust and Accurate Dense Reconstruction via Camera Pose Regression and Optimization|Siyan Dong\u7b49|[2509.24236](http://arxiv.org/pdf/2509.24236)|\u65e0|\u25c6 Real-time dense scene reconstruction during unstable camera motions is crucial for robotics, yet current RGB-D SLAM systems fail when cameras experience large viewpoint changes, fast motions, or sudden shaking.\n\u25c6 Classical optimization-based methods deliver high accuracy but fail with poor initialization during large motions, while learning-based approaches provide robustness but lack sufficient accuracy for dense reconstruction.\n\u25c6 We address this challenge through a combination of learning-based initialization with optimization-based refinement.|\n",
    "2509.23737": "|2025-09-28|GRS-SLAM3R: Real-Time Dense SLAM with Gated Recurrent State|Guole Shen\u7b49|[2509.23737](http://arxiv.org/pdf/2509.23737)|\u65e0|\u25c6 DUSt3R-based end-to-end scene reconstruction has recently shown promising results in dense visual SLAM.\n\u25c6 However, most existing methods only use image pairs to estimate pointmaps, overlooking spatial memory and global consistency.To this end, we introduce GRS-SLAM3R, an end-to-end SLAM framework for dense scene reconstruction and pose estimation from RGB images without any prior knowledge of the scene or camera parameters.\n\u25c6 Unlike existing DUSt3R-based frameworks, which operate on all image pairs and predict per-pair point maps in local coordinate frames, our method supports sequentialized input and incrementally estimates metric-scale point clouds in the global coordinate.|\n",
    "2509.23555": "|2025-09-28|From Fields to Splats: A Cross-Domain Survey of Real-Time Neural Scene Representations|Javed Ahmad\u7b49|[2509.23555](http://arxiv.org/pdf/2509.23555)|\u65e0|\u25c6 Neural scene representations such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have transformed how 3D environments are modeled, rendered, and interpreted.\n\u25c6 NeRF introduced view-consistent photorealism via volumetric rendering; 3DGS has rapidly emerged as an explicit, efficient alternative that supports high-quality rendering, faster optimization, and integration into hybrid pipelines for enhanced photorealism and task-driven scene understanding.\n\u25c6 This survey examines how 3DGS is being adopted across SLAM, telepresence and teleoperation, robotic manipulation, and 3D content generation.|\n",
    "2509.23118": "|2025-09-27|EKF-Based Fusion of Wi-Fi/LiDAR/IMU for Indoor Localization and Navigation|Zeyi Li\u7b49|[2509.23118](http://arxiv.org/pdf/2509.23118)|\u65e0|\u25c6 Conventional Wi-Fi received signal strength indicator (RSSI) fingerprinting cannot meet the growing demand for accurate indoor localization and navigation due to its lower accuracy, while solutions based on light detection and ranging (LiDAR) can provide better localization performance but is limited by their higher deployment cost and complexity.\n\u25c6 To address these issues, we propose a novel indoor localization and navigation framework integrating Wi-Fi RSSI fingerprinting, LiDAR-based simultaneous localization and mapping (SLAM), and inertial measurement unit (IMU) navigation based on an extended Kalman filter (EKF).\n\u25c6 Specifically, coarse localization by deep neural network (DNN)-based Wi-Fi RSSI fingerprinting is refined by IMU-based dynamic positioning using a Gmapping-based SLAM to generate an occupancy grid map and output high-frequency attitude estimates, which is followed by EKF prediction-update integrating sensor information while effectively suppressing Wi-Fi-induced noise and IMU drift errors.|\n",
    "2509.22910": "|2025-09-26|Good Weights: Proactive, Adaptive Dead Reckoning Fusion for Continuous and Robust Visual SLAM|Yanwei Du\u7b49|[2509.22910](http://arxiv.org/pdf/2509.22910)|\u65e0|\u25c6 Given that Visual SLAM relies on appearance cues for localization and scene understanding, texture-less or visually degraded environments (e.g., plain walls or low lighting) lead to poor pose estimation and track loss.\n\u25c6 However, robots are typically equipped with sensors that provide some form of dead reckoning odometry with reasonable short-time performance but unreliable long-time performance.\n\u25c6 The Good Weights (GW) algorithm described here provides a framework to adaptively integrate dead reckoning (DR) with passive visual SLAM for continuous and accurate frame-level pose estimation.|\n",
    "2509.26639": "|2025-09-30|Benchmarking Egocentric Visual-Inertial SLAM at City Scale|Anusha Krishnan\u7b49|[2509.26639](http://arxiv.org/pdf/2509.26639)|\u65e0|\u25c6 Precise 6-DoF simultaneous localization and mapping (SLAM) from onboard sensors is critical for wearable devices capturing egocentric data, which exhibits specific challenges, such as a wider diversity of motions and viewpoints, prevalent dynamic visual content, or long sessions affected by time-varying sensor calibration.\n\u25c6 While recent progress on SLAM has been swift, academic research is still driven by benchmarks that do not reflect these challenges or do not offer sufficiently accurate ground truth poses.\n\u25c6 In this paper, we introduce a new dataset and benchmark for visual-inertial SLAM with egocentric, multi-modal data.|\n",
    "2509.26581": "|2025-09-30|Graphite: A GPU-Accelerated Mixed-Precision Graph Optimization Framework|Shishir Gopinath\u7b49|[2509.26581](http://arxiv.org/pdf/2509.26581)|\u65e0|\u25c6 We present Graphite, a GPU-accelerated nonlinear graph optimization framework.\n\u25c6 It provides a CUDA C++ interface to enable the sharing of code between a realtime application, such as a SLAM system, and its optimization tasks.\n\u25c6 The framework supports techniques to reduce memory usage, including in-place optimization, support for multiple floating point types and mixed-precision modes, and dynamically computed Jacobians.|\n",
    "2509.26558": "|2025-09-30|Radio-based Multi-Robot Odometry and Relative Localization|Andr\u00e9s Mart\u00ednez-Silva\u7b49|[2509.26558](http://arxiv.org/pdf/2509.26558)|\u65e0|\u25c6 Radio-based methods such as Ultra-Wideband (UWB) and RAdio Detection And Ranging (radar), which have traditionally seen limited adoption in robotics, are experiencing a boost in popularity thanks to their robustness to harsh environmental conditions and cluttered environments.\n\u25c6 This work proposes a multi-robot UGV-UAV localization system that leverages the two technologies with inexpensive and readily-available sensors, such as Inertial Measurement Units (IMUs) and wheel encoders, to estimate the relative position of an aerial robot with respect to a ground robot.\n\u25c6 The first stage of the system pipeline includes a nonlinear optimization framework to trilaterate the location of the aerial platform based on UWB range data, and a radar pre-processing module with loosely coupled ego-motion estimation which has been adapted for a multi-robot scenario.|\n",
    "2509.26498": "|2025-09-30|DEPTHOR++: Robust Depth Enhancement from a Real-World Lightweight dToF and RGB Guidance|Jijun Xiang\u7b49|[2509.26498](http://arxiv.org/pdf/2509.26498)|\u65e0|\u25c6 Depth enhancement, which converts raw dToF signals into dense depth maps using RGB guidance, is crucial for improving depth perception in high-precision tasks such as 3D reconstruction and SLAM.\n\u25c6 However, existing methods often assume ideal dToF inputs and perfect dToF-RGB alignment, overlooking calibration errors and anomalies, thus limiting real-world applicability.\n\u25c6 This work systematically analyzes the noise characteristics of real-world lightweight dToF sensors and proposes a practical and novel depth completion framework, DEPTHOR++, which enhances robustness to noisy dToF inputs from three key aspects.|\n",
    "2509.26121": "|2025-09-30|Side Scan Sonar-based SLAM for Autonomous Algae Farm Monitoring|Julian Valdez\u7b49|[2509.26121](http://arxiv.org/pdf/2509.26121)|\u65e0|\u25c6 The transition of seaweed farming to an alternative food source on an industrial scale relies on automating its processes through smart farming, equivalent to land agriculture.\n\u25c6 Key to this process are autonomous underwater vehicles (AUVs) via their capacity to automate crop and structural inspections.\n\u25c6 However, the current bottleneck for their deployment is ensuring safe navigation within farms, which requires an accurate, online estimate of the AUV pose and map of the infrastructure.|\n",
    "2509.25905": "|2025-09-30|User-Centric Communication Service Provision for Edge-Assisted Mobile Augmented Reality|Conghao Zhou\u7b49|[2509.25905](http://arxiv.org/pdf/2509.25905)|\u65e0|\u25c6 Future 6G networks are envisioned to facilitate edge-assisted mobile augmented reality (MAR) via strengthening the collaboration between MAR devices and edge servers.\n\u25c6 In order to provide immersive user experiences, MAR devices must timely upload camera frames to an edge server for simultaneous localization and mapping (SLAM)-based device pose tracking.\n\u25c6 In this paper, to cope with user-specific and non-stationary uplink data traffic, we develop a digital twin (DT)-based approach for user-centric communication service provision for MAR.|\n",
    "2510.02080": "|2025-10-02|EC3R-SLAM: Efficient and Consistent Monocular Dense SLAM with Feed-Forward 3D Reconstruction|Lingxiang Hu\u7b49|[2510.02080](http://arxiv.org/pdf/2510.02080)|\u65e0|\u25c6 The application of monocular dense Simultaneous Localization and Mapping (SLAM) is often hindered by high latency, large GPU memory consumption, and reliance on camera calibration.\n\u25c6 To relax this constraint, we propose EC3R-SLAM, a novel calibration-free monocular dense SLAM framework that jointly achieves high localization and mapping accuracy, low latency, and low GPU memory consumption.\n\u25c6 This enables the framework to achieve efficiency through the coupling of a tracking module, which maintains a sparse map of feature points, and a mapping module based on a feed-forward 3D reconstruction model that simultaneously estimates camera intrinsics.|\n",
    "2510.01665": "|2025-10-02|Non-Rigid Structure-from-Motion via Differential Geometry with Recoverable Conformal Scale|Yongbo Chen\u7b49|[2510.01665](http://arxiv.org/pdf/2510.01665)|\u65e0|\u25c6 Non-rigid structure-from-motion (NRSfM), a promising technique for addressing the mapping challenges in monocular visual deformable simultaneous localization and mapping (SLAM), has attracted growing attention.\n\u25c6 We introduce a novel method, called Con-NRSfM, for NRSfM under conformal deformations, encompassing isometric deformations as a subset.\n\u25c6 Our approach performs point-wise reconstruction using 2D selected image warps optimized through a graph-based framework.|\n",
    "2510.01119": "|2025-10-01|Instant4D: 4D Gaussian Splatting in Minutes|Zhanpeng Luo\u7b49|[2510.01119](http://arxiv.org/pdf/2510.01119)|\u65e0|\u25c6 Dynamic view synthesis has seen significant advances, yet reconstructing scenes from uncalibrated, casual video remains challenging due to slow optimization and complex parameter estimation.\n\u25c6 In this work, we present Instant4D, a monocular reconstruction system that leverages native 4D representation to efficiently process casual video sequences within minutes, without calibrated cameras or depth sensors.\n\u25c6 Our method begins with geometric recovery through deep visual SLAM, followed by grid pruning to optimize scene representation.|\n",
    "2510.00783": "|2025-10-01|Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions|Thanh Nguyen Canh\u7b49|[2510.00783](http://arxiv.org/pdf/2510.00783)|\u65e0|\u25c6 Semantic Simultaneous Localization and Mapping (SLAM) is a critical area of research within robotics and computer vision, focusing on the simultaneous localization of robotic systems and associating semantic information to construct the most accurate and complete comprehensive model of the surrounding environment.\n\u25c6 Since the first foundational work in Semantic SLAM appeared more than two decades ago, this field has received increasing attention across various scientific communities.\n\u25c6 Despite its significance, the field lacks comprehensive surveys encompassing recent advances and persistent challenges.|\n"
  },
  "SFM": {
    "2505.00866": "|**2025-05-01**|**Are Minimal Radial Distortion Solvers Really Necessary for Relative Pose Estimation?**|Viktor Kocur et.al.|[2505.00866](http://arxiv.org/abs/2505.00866)|**[link](https://github.com/kocurvik/rdnet)**|\n",
    "2505.05473": "|**2025-05-08**|**DiffusionSfM: Predicting Structure and Motion via Ray Origin and Endpoint Diffusion**|Qitao Zhao et.al.|[2505.05473](http://arxiv.org/abs/2505.05473)|null|\n",
    "2505.04612": "|**2025-05-20**|**FastMap: Revisiting Dense and Scalable Structure from Motion**|Jiahao Li et.al.|[2505.04612](http://arxiv.org/abs/2505.04612)|**[link](https://github.com/pals-ttic/fastmap)**|\n",
    "2505.03093": "|**2025-05-15**|**Estimating the Diameter at Breast Height of Trees in a Forest With a Single 360 Camera**|Siming He et.al.|[2505.03093](http://arxiv.org/abs/2505.03093)|null|\n",
    "2505.01799": "|**2025-05-03**|**AquaGS: Fast Underwater Scene Reconstruction with SfM-Free Gaussian Splatting**|Junhao Shi et.al.|[2505.01799](http://arxiv.org/abs/2505.01799)|null|\n",
    "2505.01729": "|**2025-05-03**|**PosePilot: Steering Camera Pose for Generative World Models with Self-supervised Depth**|Bu Jin et.al.|[2505.01729](http://arxiv.org/abs/2505.01729)|null|\n",
    "2505.08215": "|**2025-05-13**|**Unveiling the Best Practices for Applying Speech Foundation Models to Speech Intelligibility Prediction for Hearing-Impaired People**|Haoshuai Zhou et.al.|[2505.08215](http://arxiv.org/abs/2505.08215)|null|\n",
    "2505.08013": "|**2025-05-12**|**RDD: Robust Feature Detector and Descriptor using Deformable Transformer**|Gonglin Chen et.al.|[2505.08013](http://arxiv.org/abs/2505.08013)|null|\n",
    "2505.07373": "|**2025-05-12**|**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**|Lintao Xiang et.al.|[2505.07373](http://arxiv.org/abs/2505.07373)|null|\n",
    "2505.06868": "|**2025-05-11**|**Symmetry in Fundamental Parameters of Galaxies on the Star-forming Main Sequence**|Zhicheng He et.al.|[2505.06868](http://arxiv.org/abs/2505.06868)|null|\n",
    "2505.06743": "|**2025-05-10**|**TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility**|Marius Baden et.al.|[2505.06743](http://arxiv.org/abs/2505.06743)|null|\n",
    "2505.12226": "|**2025-05-18**|**Shallow Flow Matching for Coarse-to-Fine Text-to-Speech Synthesis**|Dong Yang et.al.|[2505.12226](http://arxiv.org/abs/2505.12226)|null|\n",
    "2505.10751": "|**2025-05-15**|**Mapping Semantic Segmentation to Point Clouds Using Structure from Motion for Forest Analysis**|Francisco Raverta Capua et.al.|[2505.10751](http://arxiv.org/abs/2505.10751)|**[link](https://github.com/lrse/sodm)**|\n",
    "2505.16882": "|**2025-05-22**|**Tracking the Flight: Exploring a Computational Framework for Analyzing Escape Responses in Plains Zebra (Equus quagga)**|Isla Duporge et.al.|[2505.16882](http://arxiv.org/abs/2505.16882)|**[link](https://github.com/neuroinformatics-unit/zebras-stitching)**|\n",
    "2505.15814": "|**2025-05-21**|**A Taxonomy of Structure from Motion Methods**|Federica Arrigoni et.al.|[2505.15814](http://arxiv.org/abs/2505.15814)|null|\n",
    "2505.23756": "|2025-05-29|Rooms from Motion: Un-posed Indoor 3D Object Detection as Localization and Mapping|Justin Lazarow\u7b49|[2505.23756](http://arxiv.org/pdf/2505.23756)|\u65e0|\u25c6 \u63d0\u51faRooms from Motion (RfM)\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u65e0\u9700\u5148\u9a8c\u76f8\u673a\u4f4d\u59ff\u7684\u5ba4\u51853D\u7269\u4f53\u68c0\u6d4b\uff0c\u901a\u8fc7\u7269\u4f53\u4e2d\u5fc3\u5316\u6846\u67b6\u540c\u65f6\u5b8c\u6210\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u7528\u56fe\u50cf\u884d\u751f\u76843D\u5b9a\u5411\u5305\u56f4\u76d2\u66ff\u4ee3\u4f20\u7edf\u57fa\u4e8e2D\u5173\u952e\u70b9\u7684\u5339\u914d\u5668\uff0c\u4ece\u800c\u4f30\u8ba1\u76f8\u673a\u4f4d\u59ff\u5e76\u751f\u6210\u5168\u5c40\u8bed\u4e493D\u7269\u4f53\u5730\u56fe\u3002  \n\u25c6 \u5728\u5df2\u6709\u76f8\u673a\u4f4d\u59ff\u65f6\uff0c\u901a\u8fc7\u5168\u5c403D\u5305\u56f4\u76d2\u4f18\u5316\u663e\u8457\u63d0\u5347\u5730\u56fe\u8d28\u91cf\uff0c\u4f18\u4e8e\u4f9d\u8d56\u70b9\u4e91\u6216\u591a\u89c6\u56fe\u7684\u8fc7\u53c2\u6570\u5316\u65b9\u6cd5\u3002  \n\u25c6 \u5b9e\u73b0\u7a00\u758f\u5b9a\u4f4d\u4e0e\u53c2\u6570\u5316\u5efa\u56fe\uff0c\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u4ec5\u4e0e\u573a\u666f\u4e2d\u7269\u4f53\u6570\u91cf\u6210\u6b63\u6bd4\uff0c\u6548\u7387\u66f4\u9ad8\u3002  \n\u25c6 \u5728CA-1M\u548cScanNet++\u6570\u636e\u96c6\u4e0a\uff0cRfM\u7684\u5b9a\u4f4d\u6027\u80fd\u4e0e\u5730\u56fe\u8d28\u91cf\u5747\u8d85\u8d8a\u57fa\u4e8e\u70b9\u4e91\u548c\u5bc6\u96c6\u4f53\u7d20\u7684\u9886\u5148\u65b9\u6cd5\u3002  \n\u25c6 \u6269\u5c55Cubify Anything\u81f3\u5168\u573a\u666f\uff0c\u5efa\u7acb\u901a\u7528\u7684\u7269\u4f53\u4e2d\u5fc3\u5316\u8868\u5f81\uff0c\u4e3a\u573a\u666f\u7406\u89e3\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002|\n",
    "2505.22759": "|2025-05-30|FAMA: The First Large-Scale Open-Sc...|Sara Papi\u7b49|[2505.22759](http://arxiv.org/pdf/2505.22759)|[\u4ee3\u7801](https://github.com/hlt-mt/fbk-fairseq)|\u25c6FAMA\u662f\u9996\u4e2a\u9762\u5411\u82f1\u8bed\u548c\u610f\u5927\u5229\u8bed\u7684\u5927\u89c4\u6a21\u5f00\u6e90\u8bed\u97f3\u57fa\u7840\u6a21\u578b\uff0c\u586b\u8865\u4e86\u8bed\u97f3\u9886\u57df\u5f00\u653e\u79d1\u5b66\u7684\u7a7a\u767d\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u4f7f\u752815\u4e07+\u5c0f\u65f6\u5f00\u6e90\u8bed\u97f3\u6570\u636e\u8bad\u7ec3\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b1.6\u4e07\u5c0f\u65f6\u6e05\u6d17\u548c\u4f2a\u6807\u6ce8\u6570\u636e\u7684\u65b0\u6570\u636e\u96c6\u3002 ...|\n",
    "2505.22098": "|**2025-05-28**|**UAVPairs: A Challenging Benchmark for Match Pair Retrieval of Large-scale UAV Images**|Junhuan Liu et.al.|[2505.22098](http://arxiv.org/abs/2505.22098)|null|\n",
    "2505.22089": "|**2025-05-28**|**Fast Feature Matching of UAV Images via Matrix Band Reduction-based GPU Data Schedule**|San Jiang et.al.|[2505.22089](http://arxiv.org/abs/2505.22089)|null|\n",
    "2505.21356": "|**2025-05-30**|**Towards Robust Assessment of Pathological Voices via Combined Low-Level Descriptors and Foundation Model Representations**|Whenty Ariyanti et.al.|[2505.21356](http://arxiv.org/abs/2505.21356)|null|\n",
    "2505.20729": "|**2025-05-27**|**Intern-GS: Vision Model Guided Sparse-View 3D Gaussian Splatting**|Xiangyu Sun et.al.|[2505.20729](http://arxiv.org/abs/2505.20729)|null|\n",
    "2505.20477": "|**2025-05-26**|**Robust fine-tuning of speech recognition models via model merging: application to disordered speech**|Alexandre Ducorroy et.al.|[2505.20477](http://arxiv.org/abs/2505.20477)|null|\n",
    "2505.19854": "|**2025-05-29**|**Sparse2DGS: Sparse-View Surface Reconstruction using 2D Gaussian Splatting with Dense Point Cloud**|Natsuki Takama et.al.|[2505.19854](http://arxiv.org/abs/2505.19854)|null|\n",
    "2505.19264": "|**2025-05-25**|**Improving Novel view synthesis of 360$^\\circ$ Scenes in Extremely Sparse Views by Jointly Training Hemisphere Sampled Synthetic Images**|Guangan Chen et.al.|[2505.19264](http://arxiv.org/abs/2505.19264)|**[link](https://github.com/angchen-dev/hemisparsegs)**|\n",
    "2505.18484": "|**2025-05-24**|**Token-Level Logits Matter: A Closer Look at Speech Foundation Models for Ambiguous Emotion Recognition**|Jule Valendo Halim et.al.|[2505.18484](http://arxiv.org/abs/2505.18484)|null|\n",
    "2506.04225": "|2025-06-04|Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation|Tianyu Huang\u7b49|[2506.04225](http://arxiv.org/pdf/2506.04225)|\u65e0|\u25c6 Voyager\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u89c6\u9891\u6269\u6563\u6846\u67b6\uff0c\u80fd\u591f\u4ece\u5355\u5f20\u56fe\u50cf\u751f\u6210\u7528\u6237\u81ea\u5b9a\u4e49\u76f8\u673a\u8def\u5f84\u4e0b\u76843D\u70b9\u4e91\u5e8f\u5217\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u4e16\u754c\u4e00\u81f4\u573a\u666f\u751f\u6210\uff0c\u65e0\u9700\u4f9d\u8d56\u4f20\u7edf3D\u91cd\u5efa\u6d41\u7a0b\u3002  \n\u25c6 \u8be5\u6846\u67b6\u9996\u6b21\u6574\u5408\u4e86RGB\u4e0e\u6df1\u5ea6\u89c6\u9891\u7684\u8054\u5408\u751f\u6210\uff0c\u901a\u8fc7\u73b0\u6709\u4e16\u754c\u89c2\u6d4b\u6761\u4ef6\u786e\u4fdd\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u89e3\u51b3\u4e86\u957f\u5e8f\u5217\u751f\u6210\u4e2d\u7684\u7d2f\u79ef\u8bef\u5dee\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u5e26\u70b9\u4e91\u5254\u9664\u7684\u4e16\u754c\u7f13\u5b58\u673a\u5236\u548c\u81ea\u56de\u5f52\u63a8\u7406\u65b9\u6cd5\uff0c\u652f\u6301\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u8fed\u4ee3\u573a\u666f\u6269\u5c55\uff0c\u5b9e\u73b0\u8d85\u957f\u8ddd\u79bb\uff08>100\u7c73\uff09\u76843D\u573a\u666f\u63a2\u7d22\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u53ef\u6269\u5c55\u7684\u6570\u636e\u5f15\u64ce\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u548c\u6df1\u5ea6\u9884\u6d4b\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u65e0\u4eba\u5de5\u6807\u6ce8\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u663e\u8457\u964d\u4f4e\u6570\u636e\u83b7\u53d6\u6210\u672c\u3002  \n\u25c6 \u5728\u89c6\u89c9\u8d28\u91cf\u548c\u51e0\u4f55\u7cbe\u5ea6\u4e0a\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u652f\u6301\u865a\u62df\u73b0\u5b9e\u3001\u6e38\u620f\u5f00\u53d1\u7b49\u9700\u8981\u52a8\u60013D\u573a\u666f\u6784\u5efa\u7684\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u6574\u4f53\u67b6\u6784\u6452\u5f03\u4e86\u591a\u9636\u6bb5\u5904\u7406\u6d41\u7a0b\uff0c\u9996\u6b21\u5b9e\u73b0\u5355\u6a21\u578b\u76f4\u63a5\u8f93\u51fa\u51e0\u4f55\u4e00\u81f4\u7684\u53ef\u63a2\u7d223D\u573a\u666f\uff0c\u4e3a\u751f\u6210\u5f0f3D\u5efa\u6a21\u5f00\u8f9f\u65b0\u65b9\u5411\u3002|\n",
    "2506.03667": "|2025-06-04|Accelerating SfM-based Pose Estimation with Dominating Set|Joji Joseph\u7b49|[2506.03667](http://arxiv.org/pdf/2506.03667)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u652f\u914d\u96c6\u7684\u9884\u5904\u7406\u6280\u672f\uff0c\u663e\u8457\u52a0\u901f\u57fa\u4e8eSfM\u7684\u4f4d\u59ff\u4f30\u8ba1\u8fc7\u7a0b\uff0c\u9002\u7528\u4e8eAR/VR\u548c\u673a\u5668\u4eba\u7b49\u5b9e\u65f6\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u9996\u6b21\u5c06\u56fe\u8bba\u4e2d\u7684\u652f\u914d\u96c6\u6982\u5ff5\u5f15\u5165SfM\u6a21\u578b\u4f18\u5316\uff0c\u5728\u4e0d\u663e\u8457\u635f\u5931\u7cbe\u5ea6\u524d\u63d0\u4e0b\u5b9e\u73b0\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002  \n\u25c6 \u5728OnePose\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u666e\u9002\u6027\uff0c\u517c\u5bb9\u591a\u79cdSfM\u4f4d\u59ff\u4f30\u8ba1\u6280\u672f\uff0c\u5c55\u73b0\u5e7f\u6cdb\u9002\u7528\u6027\u3002  \n\u25c6 \u5b9e\u73b01.5-14.48\u500d\u7684\u52a0\u901f\u6548\u679c\uff0c\u540c\u65f6\u5c06\u53c2\u8003\u56fe\u50cf\u6570\u91cf\u548c\u70b9\u4e91\u89c4\u6a21\u5206\u522b\u7f29\u51cf17-23\u500d\u548c2.27-4\u500d\u3002  \n\u25c6 \u901a\u8fc7\u5e73\u8861\u901f\u5ea6\u4e0e\u7cbe\u5ea6\uff0c\u4e3a\u5b9e\u65f63D\u4f4d\u59ff\u4f30\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u7834\u73b0\u6709\u6280\u672f\u74f6\u9888\u3002|\n",
    "2506.03265": "|2025-06-03|Nearby dwarf galaxies with extreme star formation rates: a window into dwarf-galaxy evolution in the early Universe|S. Kaviraj\u7b49|[2506.03265](http://arxiv.org/pdf/2506.03265)|\u65e0|\u25c6 \u7814\u7a76\u53d1\u73b0\u9644\u8fd1\u4f4e\u5149\u5ea6\u77ee\u661f\u7cfb\uff08\u8d28\u91cf10^7-10^8\u592a\u9633\u8d28\u91cf\uff09\u5b58\u5728\u6781\u7aef\u6052\u661f\u5f62\u6210\u7387\uff080.1-3\u592a\u9633\u8d28\u91cf/\u5e74\uff09\uff0c\u53ef\u4f5c\u4e3a\u65e9\u671f\u5b87\u5b99\uff08z~5.5\uff09\u77ee\u661f\u7cfb\u7684\u7c7b\u6bd4\u6837\u672c\u3002  \n\u25c6 \u901a\u8fc7\u5bf9\u6bd4\u6b63\u5e38\u77ee\u661f\u7cfb\u6837\u672c\uff0c\u53d1\u73b0\u6781\u7aef\u6052\u661f\u5f62\u6210\u7387\u5e76\u975e\u7531\u661f\u7cfb\u7ed3\u6784\u7d27\u51d1\u6027\u6216\u7279\u6b8a\u73af\u5883\uff08\u5982\u9760\u8fd1\u8282\u70b9/\u7ea4\u7ef4\u7ed3\u6784\uff09\u9a71\u52a8\u3002  \n\u25c6 \u63ed\u793a\u5177\u6709\u6781\u7aef\u6052\u661f\u5f62\u6210\u7387\u7684\u77ee\u661f\u7cfb\u4e2d\u76f8\u4e92\u4f5c\u7528\u661f\u7cfb\u548c\u65e9\u578b\u5f62\u6001\u6bd4\u4f8b\u663e\u8457\u5347\u9ad8\uff08\u5206\u522b\u589e\u52a0\u7ea65.6\u500d\u548c9\u500d\uff09\uff0c\u8868\u660e\u661f\u7cfb\u76f8\u4e92\u4f5c\u7528\u662f\u5173\u952e\u89e6\u53d1\u673a\u5236\u3002  \n\u25c6 \u6307\u51fa\u5f53\u524d\u57fa\u4e8e\u4e2d\u4f4e\u7ea2\u79fb\u6570\u636e\u7684\u4e3b\u5e8f\u661f\u5f62\u6210\u7387\u6f14\u5316\u6a21\u578b\u4f1a\u4f4e\u4f30\u65e9\u671f\u5b87\u5b99\uff08z~5.5\uff09\u77ee\u661f\u7cfb\u7684\u6052\u661f\u5f62\u6210\u7387\u3002  \n\u25c6 \u63d0\u51fa\u65e9\u671f\u5b87\u5b99\u77ee\u661f\u7cfb\u901a\u8fc7\u66f4\u9ad8\u6c14\u4f53\u4e30\u5ea6\u4e0e\u9891\u7e41\u76f8\u4e92\u4f5c\u7528\u7684\u5171\u540c\u4f5c\u7528\uff0c\u9a71\u52a8\u5176\u6052\u661f\u8d28\u91cf\u5feb\u901f\u7d2f\u79ef\u7684\u65b0\u6f14\u5316\u56fe\u666f\u3002|\n",
    "2506.01940": "|2025-06-02|Fast and Robust Rotation Averaging with Anisotropic Coordinate Descent|Yaroslava Lochman\u7b49|[2506.01940](http://arxiv.org/pdf/2506.01940)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u4e14\u9c81\u68d2\u7684\u5404\u5411\u5f02\u6027\u65cb\u8f6c\u5e73\u5747\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5757\u5750\u6807\u4e0b\u964d\u6cd5\u5bb6\u65cf\uff0c\u7b80\u5316\u4e86\u539f\u6709\u548c\u5f26\u8ddd\u79bb\u4f18\u5316\u7684\u590d\u6742\u5f62\u5f0f\u3002  \n\u25c6 \u9996\u6b21\u5c06\u5404\u5411\u5f02\u6027\u6269\u5c55\u5e94\u7528\u4e8e\u5757\u5750\u6807\u4e0b\u964d\u6cd5\uff0c\u5f00\u53d1\u51fa\u4e00\u4e2a\u901a\u7528\u7684\u5feb\u901f\u6c42\u89e3\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u5c06\u8be5\u6c42\u89e3\u5668\u96c6\u6210\u5230\u5927\u89c4\u6a21\u9c81\u68d2\u65cb\u8f6c\u5e73\u5747\u6d41\u7a0b\u4e2d\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u95ee\u9898\u89c4\u6a21\u589e\u5927\u65f6\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u516c\u5f00\u7684\u7ed3\u6784\u8fd0\u52a8\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u8868\u73b0\u3002  \n\u25c6 \u514b\u670d\u4e86\u4f20\u7edf\u5c40\u90e8\u65b9\u6cd5\u5bf9\u521d\u59cb\u5316\u7684\u654f\u611f\u6027\uff0c\u907f\u514d\u4e86\u6700\u5c0f\u751f\u6210\u6811\u65b9\u6cd5\u4e2d\u5e38\u89c1\u7684\u6f02\u79fb\u7d2f\u79ef\u548c\u5c40\u90e8\u6781\u5c0f\u503c\u9677\u9631\u95ee\u9898\u3002  \n\u25c6 \u5728\u5168\u5c40\u6700\u4f18\u6027\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u5404\u5411\u5f02\u6027\u65cb\u8f6c\u5e73\u5747\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2505.24200": "|2025-06-03|Improving Multilingual Speech Models on ML-SUPERB 2.0: Fine-tuning with Data Augmentation and LID-Aware CTC|Qingzheng Wang\u7b49|[2505.24200](http://arxiv.org/pdf/2505.24200)|\u65e0|\u25c6 \u63d0\u51fa\u591a\u79cd\u5fae\u8c03\u7b56\u7565\uff08\u51bb\u7ed3\u4e0a\u6e38\u8bad\u7ec3\u3001\u90e8\u5206\u5fae\u8c03\u3001\u4f4e\u79e9\u9002\u5e94\uff09\u4f18\u5316\u591a\u8bed\u8a00\u8bed\u97f3\u57fa\u7840\u6a21\u578b\uff08SFM\uff09\u5728ML-SUPERB 2.0\u4e0a\u7684\u8868\u73b0\u3002  \n\u25c6 \u91c7\u7528\u6570\u636e\u589e\u5f3a\u6280\u672f\u7f13\u89e3\u5c11\u6837\u672c\u573a\u666f\u4e0b\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u8bed\u8a00\u8bc6\u522b\uff08LID\uff09\u611f\u77e5\u7684CTC\u635f\u5931\u51fd\u6570\u4f5c\u4e3a\u6b63\u5219\u5316\u624b\u6bb5\uff0c\u8054\u5408\u4f18\u5316LID\u548cASR\u4efb\u52a1\u3002  \n\u25c6 \u5728ML-SUPERB 2.0\u57fa\u51c6\u4e0a\u5b9e\u73b0\u663e\u8457\u63d0\u5347\uff1aLID\u51c6\u786e\u7387\u76f8\u5bf9\u63d0\u9ad814%\uff0cASR\u5b57\u9519\u8bef\u7387\uff08CER\uff09\u76f8\u5bf9\u964d\u4f4e30%\u3002  \n\u25c6 \u7efc\u5408\u65b9\u6cd5\u5728Interspeech 2025 ML-SUPERB 2.0\u6311\u6218\u8d5b\u4e2d\u65a9\u83b7\u7b2c\u4e8c\u540d\uff0c\u9a8c\u8bc1\u4e86\u7b56\u7565\u7684\u6709\u6548\u6027\u3002|\n",
    "2506.05935": "|2025-06-06|SurGSplat: Progressive Geometry-Constrained Gaussian Splatting for Surgical Scene Reconstruction|Yuchao Zheng\u7b49|[2506.05935](http://arxiv.org/pdf/2506.05935)|\u65e0|\u25c6\u63d0\u51faSurGSplat\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u51e0\u4f55\u7ea6\u675f\u4f18\u53163D\u9ad8\u65af\u6cfc\u6e85(3DGS)\u6280\u672f\uff0c\u89e3\u51b3\u5185\u7aa5\u955c\u573a\u666f\u7a00\u758f\u7279\u5f81\u548c\u5149\u7167\u4e0d\u5747\u5bfc\u81f4\u7684\u4f20\u7edfSfM\u65b9\u6cd5\u91cd\u5efa\u5931\u8d25\u95ee\u9898\u3002  \n\u25c6\u9996\u521b\u5c06\u51e0\u4f55\u7ea6\u675f\u878d\u51653DGS\u4f18\u5316\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u8840\u7ba1\u7b49\u5173\u952e\u89e3\u5256\u7ed3\u6784\u7684\u9ad8\u7cbe\u5ea6\u91cd\u5efa\uff0c\u663e\u8457\u63d0\u5347\u624b\u672f\u573a\u666f\u7684\u89c6\u89c9\u6e05\u6670\u5ea6\u3002  \n\u25c6\u5f00\u53d1\u6e10\u8fdb\u5f0f\u4f18\u5316\u6846\u67b6\uff0c\u9010\u6b65\u7ec6\u5316\u91cd\u5efa\u7ec6\u8282\uff0c\u5728\u4fdd\u6301\u5b9e\u65f6\u6027\u7684\u540c\u65f6\u7a81\u7834\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u624b\u672f\u73af\u5883\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u3002  \n\u25c6\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u65b0\u578b\u89c6\u89d2\u5408\u6210(NVS)\u548c\u4f4d\u59ff\u4f30\u8ba1\u7cbe\u5ea6\u4e0a\u5747\u8d85\u8d8a\u73b0\u6709\u6280\u672f\uff0c\u4e3a\u672f\u4e2d\u5bfc\u822a\u63d0\u4f9b\u9ad8\u4fdd\u771f\u91cd\u5efa\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6\u901a\u8fc7\u4e13\u5c5e\u51e0\u4f55\u7ea6\u675f\u673a\u5236\u6709\u6548\u514b\u670d\u5185\u7aa5\u955c\u56fe\u50cf\u7279\u5f81\u7a00\u758f\u7684\u56fa\u6709\u6311\u6218\uff0c\u4e3a\u5fae\u521b\u624b\u672f\u63d0\u4f9b\u66f4\u53ef\u9760\u76843D\u573a\u666f\u7406\u89e3\u652f\u6301\u3002  \n\u25c6\u5f00\u6e90\u9879\u76ee\u7f51\u7ad9\u63d0\u4f9b\u5b8c\u6574\u6280\u672f\u7ec6\u8282\u548c\u53ef\u89c6\u5316\u7ed3\u679c\uff0c\u63a8\u52a8\u624b\u672f\u5bfc\u822a\u9886\u57df\u7684\u53ef\u91cd\u590d\u7814\u7a76\u3002|\n",
    "2506.05558": "|2025-06-05|On-the-fly Reconstruction for Large-Scale Novel View Synthesis from Unposed Images|Andreas Meuleman\u7b49|[2506.05558](http://arxiv.org/pdf/2506.05558)|\u65e0|\u25c6 \u63d0\u51fa\u5b9e\u65f6\u91cd\u5efa\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u56fe\u50cf\u91c7\u96c6\u5b8c\u6210\u540e\u7acb\u5373\u751f\u6210\u76f8\u673a\u4f4d\u59ff\u548c\u8bad\u7ec3\u597d\u76843D\u9ad8\u65af\u6cfc\u6e85\u6a21\u578b\uff0c\u663e\u8457\u7f29\u77ed\u4f20\u7edf\u65b9\u6cd5\u6240\u9700\u7684\u5206\u949f\u5230\u5c0f\u65f6\u7ea7\u8ba1\u7b97\u65f6\u95f4\u3002  \n\u25c6 \u9488\u5bf9\u5927\u573a\u666f\u548c\u5bbd\u57fa\u7ebf\u56fe\u50cf\u5e8f\u5217\uff0c\u8bbe\u8ba1\u4e86\u5feb\u901f\u521d\u59cb\u4f4d\u59ff\u4f30\u8ba1\u65b9\u6848\uff0c\u7ed3\u5408\u5b66\u4e60\u7279\u5f81\u548cGPU\u53cb\u597d\u7684\u5c0f\u578b\u675f\u8c03\u6574\uff0c\u63d0\u5347\u5904\u7406\u6548\u7387\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u9ad8\u65af\u56fe\u5143\u4f4d\u7f6e\u4e0e\u5f62\u72b6\u7684\u76f4\u63a5\u91c7\u6837\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u91cf\u5f0f\u751f\u6210\u56fe\u5143\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4f4d\u59ff\u4e0e\u9ad8\u65af\u56fe\u5143\u7684\u5feb\u901f\u8054\u5408\u4f18\u5316\u3002  \n\u25c6 \u63d0\u51fa\u53ef\u6269\u5c55\u7684\u8f90\u5c04\u573a\u6784\u5efa\u6280\u672f\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u805a\u7c7b\u5c063DGS\u56fe\u5143\u5b58\u50a8\u5728\u951a\u70b9\u4e2d\u5e76\u4eceGPU\u5378\u8f7d\uff0c\u6709\u6548\u7ba1\u7406\u5927\u89c4\u6a21\u573a\u666f\u7684\u5185\u5b58\u9700\u6c42\u3002  \n\u25c6 \u5f15\u5165\u52a8\u6001\u56fe\u5143\u5408\u5e76\u673a\u5236\uff0c\u6839\u636e\u89c6\u70b9\u9700\u6c42\u81ea\u9002\u5e94\u8c03\u65743DGS\u89c4\u6a21\uff0c\u4fdd\u6301\u6e32\u67d3\u8d28\u91cf\u7684\u540c\u65f6\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\u4f7f\u7528\u3002  \n\u25c6 \u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u80fd\u5b9e\u65f6\u5904\u7406\u591a\u79cd\u91c7\u96c6\u573a\u666f\u548c\u4e0d\u540c\u89c4\u6a21\u7684\u6570\u636e\u96c6\uff0c\u5728\u901f\u5ea6\u3001\u56fe\u50cf\u8d28\u91cf\u6216\u4e24\u8005\u517c\u5907\u65b9\u9762\u4f18\u4e8e\u4ec5\u9488\u5bf9\u7279\u5b9a\u573a\u666f\u7684\u73b0\u6709\u65b9\u6cd5\u3002|\n",
    "2506.04803": "|2025-06-05|SupeRANSAC: One RANSAC to Rule Them All|Daniel Barath|[2506.04803](http://arxiv.org/pdf/2506.04803)|[\u4ee3\u7801](https://github.com/danini/superansac)|\u25c6 SupeRANSAC\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684RANSAC\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfRANSAC\u5728\u4e0d\u540c\u89c6\u89c9\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7\u7cfb\u7edf\u5206\u6790RANSAC\u5728\u7279\u5b9a\u89c6\u89c9\u4efb\u52a1\uff08\u5982\u5355\u5e94\u6027\u77e9\u9635\u3001\u57fa\u7840\u77e9\u9635\u3001\u4f4d\u59ff\u4f30\u8ba1\u7b49\uff09\u4e2d\u7684\u6709\u6548\u6280\u672f\uff0c\u4f18\u5316\u4e86\u6574\u4f53\u6d41\u7a0b\u3002  \n\u25c6 \u76f8\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\uff0cSupeRANSAC\u5728\u57fa\u7840\u77e9\u9635\u4f30\u8ba1\u4efb\u52a1\u4e2d\u5e73\u5747\u63d0\u5347\u4e866\u4e2aAUC\u70b9\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002  \n\u25c6 \u8be5\u6846\u67b6\u514b\u670d\u4e86\u73b0\u6709\u5e93\uff08\u5982OpenCV\u548cPoseLib\uff09\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4e00\u81f4\u7684\u7f3a\u9677\uff0c\u5b9e\u73b0\u4e86\u8de8\u4efb\u52a1\u7684\u7a33\u5b9a\u9ad8\u6027\u80fd\u3002  \n\u25c6 \u8bba\u6587\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u5b9e\u73b0\u7ec6\u8282\u548c\u4efb\u52a1\u7279\u5b9a\u4f18\u5316\uff0c\u4e3a\u9c81\u68d2\u4f30\u8ba1\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u4fbf\u4e8e\u793e\u533a\u9a8c\u8bc1\u548c\u5e94\u7528\uff0c\u5df2\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u95ee\u9898\u4e0a\u5c55\u793a\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002|\n",
    "2506.09448": "|2025-06-11|OWSM-Biasing: Contextualizing Open Whisper-Style Speech Models for Automatic Speech Recognition with Dynamic Vocabulary|Yui Sudo\u7b49|[2506.09448](http://arxiv.org/pdf/2506.09448)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4e0a\u4e0b\u6587\u504f\u7f6e\uff08CB\uff09\u65b9\u6cd5\u4e0e\u9884\u8bad\u7ec3\u7684\u5f00\u653eWhisper\u98ce\u683c\u8bed\u97f3\u6a21\u578b\uff08OWSM v3.1\uff09\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u65e0\u9700\u5fae\u8c03\u9884\u8bad\u7ec3\u53c2\u6570\u3002  \n\u25c6 \u901a\u8fc7\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u97f3\u57fa\u7840\u6a21\u578b\uff08SFMs\uff09\u7684\u5d4c\u5165\u77e5\u8bc6\uff0c\u5373\u4f7f\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u4e5f\u80fd\u6709\u6548\u63d0\u5347\u7f55\u89c1\u8bcd\u548c\u672a\u767b\u5f55\u8bcd\u7684\u8bc6\u522b\u51c6\u786e\u7387\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u5728\u4fdd\u6301SFMs\u539f\u6709\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u504f\u7f6e\u8bcd\u9519\u8bef\u7387\uff08B-WER\uff09\uff0c\u5728LibriSpeech\u6d4b\u8bd5\u96c6\u4e0a\u63d0\u534711.6\u4e2a\u767e\u5206\u70b9\u3002  \n\u25c6 \u6574\u4f53\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u6539\u55840.9\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u5b9e\u65f6\u56e0\u5b50\uff08RTF\uff09\u51cf\u5c117.5%\uff0c\u517c\u987e\u6027\u80fd\u4e0e\u6548\u7387\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4ece\u5934\u8bad\u7ec3\u7684CB\u65b9\u6cd5\uff0c\u51f8\u663e\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u77e5\u8bc6\u8fc1\u79fb\u7684\u91cd\u8981\u6027\u3002|\n",
    "2506.18792": "|2025-06-23|ViDAR: Video Diffusion-Aware 4D Reconstruction From Monocular Inputs|Michal Nazarczuk\u7b49|[2506.18792](http://arxiv.org/pdf/2506.18792)|\u65e0|\u25c6 \u63d0\u51faViDAR\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u4e2a\u6027\u5316\u6269\u6563\u6a21\u578b\u5f15\u5165\u5355\u76ee\u89c6\u9891\u76844D\u91cd\u5efa\u4efb\u52a1\uff0c\u901a\u8fc7\u751f\u6210\u4f2a\u591a\u89c6\u89d2\u76d1\u7763\u4fe1\u53f7\u89e3\u51b3\u5355\u76ee\u8f93\u5165\u7684\u7ed3\u6784-\u8fd0\u52a8\u6b67\u4e49\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u7528\u573a\u666f\u7279\u5b9a\u7279\u5f81\u8fdb\u884c\u6761\u4ef6\u6269\u6563\uff0c\u5728\u4fdd\u6301\u5916\u89c2\u7ec6\u8282\u7684\u540c\u65f6\u6709\u6548\u7f13\u89e3\u5355\u76ee\u6a21\u7cca\u6027\u5bfc\u81f4\u7684\u4f2a\u5f71\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u6269\u6563\u611f\u77e5\u635f\u5931\u51fd\u6570\uff0c\u4e13\u95e8\u5904\u7406\u6269\u6563\u751f\u6210\u89c6\u56fe\u7684\u65f6\u7a7a\u4e0d\u4e00\u81f4\u6027\uff0c\u63d0\u5347\u5408\u6210\u89c6\u56fe\u4e0e\u771f\u5b9e\u51e0\u4f55\u7684\u5bf9\u9f50\u7cbe\u5ea6\u3002  \n\u25c6 \u63d0\u51fa\u76f8\u673a\u4f4d\u59ff\u4f18\u5316\u7b56\u7565\uff0c\u52a8\u6001\u8c03\u6574\u5408\u6210\u89c6\u89d2\u4e0e\u5e95\u5c42\u573a\u666f\u51e0\u4f55\u7684\u5339\u914d\u5173\u7cfb\uff0c\u589e\u5f3a\u52a8\u6001\u533a\u57df\u7684\u51e0\u4f55\u4e00\u81f4\u6027\u3002  \n\u25c6 \u5728\u6781\u7aef\u89c6\u89d2\u53d8\u5316\u7684DyCheck\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5168\u9762\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u8fd0\u52a8\u4e30\u5bcc\u533a\u57df\u91cd\u5efa\u8d28\u91cf\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002  \n\u25c6 \u53d1\u5e03\u65b0\u8bc4\u6d4b\u57fa\u51c6\uff0c\u9996\u6b21\u9488\u5bf9\u573a\u666f\u4e2d\u9ad8\u52a8\u6001\u90e8\u5206\u7684\u91cd\u5efa\u6027\u80fd\u8fdb\u884c\u7cfb\u7edf\u5316\u6bd4\u8f83\uff0c\u63a8\u52a8\u9886\u57df\u8bc4\u4f30\u6807\u51c6\u53d1\u5c55\u3002|\n",
    "2506.18376": "|2025-06-23|Room temperature spin injection into commercial VCSELs at non-resonant wavelengths|Timur Almabetov\u7b49|[2506.18376](http://arxiv.org/pdf/2506.18376)|\u65e0|\u25c6 \u9996\u6b21\u5728\u5ba4\u6e29\u4e0b\u5b9e\u73b0\u4e86\u5bf9\u5546\u7528\u5782\u76f4\u8154\u9762\u53d1\u5c04\u6fc0\u5149\u5668\uff08VCSEL\uff09\u7684\u975e\u5171\u632f\u6ce2\u957f\u81ea\u65cb\u6ce8\u5165\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u5171\u632f\u6ce2\u957f\u9650\u5236\u3002  \n\u25c6 \u901a\u8fc7794 nm\u548c810 nm\u5149\u6cf5\u6d66\u5b9e\u9a8c\uff0c\u89c2\u5bdf\u523020%\u548c5%\u7684\u6700\u5927\u5706\u504f\u632f\u5ea6\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u6ce2\u957f\u5bf9\u81ea\u65cb\u6ce8\u5165\u6548\u7387\u7684\u5f71\u54cd\u673a\u5236\u3002  \n\u25c6 \u7ed3\u5408\u91cf\u5b50\u9631\u5149\u5b66\u53d6\u5411\u7814\u7a76\uff0c\u8bc1\u5b9e\u957f\u6ce2\u957f\u6fc0\u53d1\u4f1a\u5bfc\u81f4\u81ea\u65cb\u6ce8\u5165\u6548\u7387\u964d\u4f4e\uff0c\u4e3a\u5668\u4ef6\u4f18\u5316\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002  \n\u25c6 \u6269\u5c55\u81ea\u65cb\u7ffb\u8f6c\u6a21\u578b\uff08SFM\uff09\uff0c\u9996\u6b21\u7eb3\u5165\u5b9e\u9645\u6fc0\u53d1\u6761\u4ef6\uff0c\u4f7f\u7406\u8bba\u6a21\u578b\u80fd\u51c6\u786e\u590d\u73b0\u5b9e\u9a8c\u89c2\u6d4b\u8d8b\u52bf\u3002  \n\u25c6 \u8be5\u6210\u679c\u4e3a\u81ea\u65cb\u6fc0\u5149\u5668\u7684\u4f4e\u9608\u503c\u3001\u9ad8\u901f\u8c03\u5236\u548c\u5168\u5149\u6570\u636e\u5904\u7406\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u5b9e\u73b0\u8def\u5f84\u3002|\n",
    "2506.19491": "|2025-06-24|Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications|Gen\u00eds Castillo G\u00f3mez-Raya\u7b49|[2506.19491](http://arxiv.org/pdf/2506.19491)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u795e\u7ecf\u4e09\u7ef4\u91cd\u5efa\uff08N3DR\uff09\u6280\u672f\u4e0e\u5c0f\u578b\u65e0\u4eba\u673a\u7cfb\u7edf\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u7cbe\u7ec6\u4e09\u7ef4\u6570\u5b57\u91cd\u5efa\u9759\u6001\u5c0f\u7269\u4f53\u3002  \n\u25c6 \u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u5957\u57fa\u4e8eN3DR\u7684\u6d41\u7a0b\uff0c\u6574\u5408\u4e86Instant-ngp\u3001Nerfacto\u548cSplatfacto\u7b49\u5148\u8fdb\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91cd\u5efa\u8d28\u91cf\u3002  \n\u25c6 \u901a\u8fc7\u591a\u65e0\u4eba\u673a\u534f\u540c\u91c7\u96c6\u56fe\u50cf\uff0c\u89e3\u51b3\u4e86\u5c0f\u578b\u65e0\u4eba\u673a\u5728\u52a8\u6001\u98de\u884c\u548c\u529f\u8017\u9650\u5236\u4e0b\u7684\u81ea\u4e3b\u6027\u4e0e\u4efb\u52a1\u80fd\u529b\u95ee\u9898\u3002  \n\u25c6 \u91c7\u7528\u591a\u79cd\u56fe\u50cf\u548c\u70b9\u4e91\u6307\u6807\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u4e0e\u4f20\u7edf\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u7b97\u6cd5\u5bf9\u6bd4\uff0c\u9a8c\u8bc1\u4e86N3DR\u7684\u4f18\u8d8a\u6027\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6848\u80fd\u652f\u6301\u9ad8\u7cbe\u5ea6\u4e09\u7ef4\u5efa\u6a21\u548c\u5f02\u5e38\u68c0\u6d4b\uff0c\u62d3\u5c55\u4e86\u5c0f\u578b\u65e0\u4eba\u673a\u5728\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002  \n\u25c6 \u6574\u4f53\u7814\u7a76\u5c55\u793a\u4e86N3DR\u6280\u672f\u5728\u63d0\u5347\u5fae\u578b\u65e0\u4eba\u673a\u7cfb\u7edf\u80fd\u529b\u65b9\u9762\u7684\u5e7f\u9614\u524d\u666f\u3002|\n",
    "2506.21460": "|2025-07-08|Wild refitting for black box prediction|Martin J. Wainwright|[2506.21460](http://arxiv.org/pdf/2506.21460)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\"wild refitting\"\u7684\u9ad8\u6548\u8ba1\u7b97\u6d41\u7a0b\uff0c\u4ec5\u9700\u5355\u6b21\u6570\u636e\u96c6\u548c\u9884\u6d4b\u65b9\u6cd5\u7684\u9ed1\u7bb1\u8bbf\u95ee\uff0c\u901a\u8fc7\u6b8b\u5dee\u8ba1\u7b97\u3001\u5bf9\u79f0\u5316\u548c\u7f29\u653e\u4e09\u4e2a\u6b65\u9aa4\uff0c\u4e3a\u60e9\u7f5a\u975e\u53c2\u6570\u4f30\u8ba1\u63d0\u4f9b\u5b9e\u4f8b\u7ea7\u5747\u65b9\u9884\u6d4b\u8bef\u5dee\u7684\u9ad8\u6982\u7387\u4e0a\u754c\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528Rademacher\u6b8b\u5dee\u5bf9\u79f0\u5316\u6280\u672f\uff08\u7c7b\u4f3cwild bootstrap\u53d8\u4f53\uff09\uff0c\u901a\u8fc7\u9884\u5b9a\u4e49\u7f29\u653e\u56e0\u5b50\u03c1\u8c03\u6574\u6b8b\u5dee\uff0c\u6784\u5efa\u4ee5\u5f53\u524d\u4f30\u8ba1\u4e3a\u4e2d\u5fc3\u7684\u4fee\u6b63\u9884\u6d4b\u95ee\u9898\u3002  \n\u25c6 \u5728\u5141\u8bb8\u566a\u58f0\u5f02\u8d28\u6027\u7684\u8f83\u6e29\u548c\u6761\u4ef6\u4e0b\uff0c\u7406\u8bba\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u6027\u80fd\uff1a\u5f53wild\u566a\u58f0\u5c3a\u5ea6\u03c1\u9009\u62e9\u9002\u5f53\u65f6\uff0cwild refit\u80fd\u786e\u4fdd\u9884\u6d4b\u8bef\u5dee\u4e0a\u754c\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u5173\u952e\u8bbe\u8ba1\u6307\u5bfc\uff0c\u5305\u62ec\u6b8b\u5dee\u6784\u5efa\u65b9\u6cd5\u3001wild\u5b50\u95ee\u9898\u4e2d\u566a\u58f0\u7f29\u653e\u91cf\u7684\u9009\u62e9\u4f9d\u636e\uff0c\u4ee5\u53ca\u9ed1\u7bb1\u7a0b\u5e8f\u5c40\u90e8\u7a33\u5b9a\u6027\u7684\u5206\u6790\u6846\u67b6\u3002  \n\u25c6 \u5c55\u793a\u4e86\u65b9\u6cd5\u5728\u591a\u4e2a\u9886\u57df\u7684\u9002\u7528\u6027\uff0c\u5982\u57fa\u4e8e\u7ed3\u6784\u5316\u77e9\u9635\u60e9\u7f5a\u7684\u975e\u521a\u6027\u8fd0\u52a8\u6062\u590d\u3001\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5148\u9a8c\u7684\u5373\u63d2\u5373\u7528\u56fe\u50cf\u4fee\u590d\uff0c\u4ee5\u53ca\u6838\u65b9\u6cd5\u7684\u968f\u673a\u8349\u56fe\u6280\u672f\u3002|\n",
    "2506.22069": "|2025-06-27|Single-Scanline Relative Pose Estimation for Rolling Shutter Cameras|Petr Hruby\u7b49|[2506.22069](http://arxiv.org/pdf/2506.22069)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u626b\u63cf\u7ebf\u6295\u5f71\u4ea4\u70b9\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u6eda\u52a8\u5feb\u95e8\u76f8\u673a\u95f4\u7684\u76f8\u5bf9\u4f4d\u59ff\uff0c\u65e0\u9700\u663e\u5f0f\u5efa\u6a21\u76f8\u673a\u8fd0\u52a8\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5b9e\u73b0\u4e86\u5355\u89c6\u56fe\u5185\u626b\u63cf\u7ebf\u7684\u76f8\u5bf9\u4f4d\u59ff\u4f30\u8ba1\uff0c\u6269\u5c55\u4e86\u6eda\u52a8\u5feb\u95e8\u76f8\u673a\u7684\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u4f5c\u4e3a\u6eda\u52a8\u5feb\u95e8\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u7684\u57fa\u7840\u6a21\u5757\uff0c\u652f\u6301\u72ec\u7acb\u8ba1\u7b97\u6bcf\u6761\u626b\u63cf\u7ebf\u7684\u4f4d\u59ff\uff0c\u4e14\u65e0\u9700\u8fd0\u52a8\u6a21\u578b\u5047\u8bbe\u3002  \n\u25c6 \u5728\u5df2\u77e5\u5185\u53c2\u548c\u65e0\u955c\u5934\u7578\u53d8\u7684\u6761\u4ef6\u4e0b\uff0c\u5206\u7c7b\u4e86\u901a\u7528\u548c\u7279\u5b9a\u573a\u666f\uff08\u5982\u5e73\u884c\u7ebf\u548c\u5df2\u77e5\u91cd\u529b\u65b9\u5411\uff09\u7684\u6700\u5c0f\u6c42\u89e3\u5668\u3002  \n\u25c6 \u9488\u5bf9\u5e73\u884c\u7ebf\u573a\u666f\uff0c\u5f00\u53d1\u4e86\u5e26/\u4e0d\u5e26\u91cd\u529b\u5148\u9a8c\u7684\u6700\u5c0f\u6c42\u89e3\u5668\uff0c\u901a\u8fc7\u5c06\u5176\u4e0e1D\u76f8\u673a\u76842D\u7ed3\u6784\u4f30\u8ba1\u95ee\u9898\u5173\u8054\u5b9e\u73b0\u521b\u65b0\u6c42\u89e3\u3002  \n\u25c6 \u5728Fastec\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7528\u4e8e\u6eda\u52a8\u5feb\u95e8SfM\u521d\u59cb\u5316\u7684\u53ef\u884c\u6027\uff0c\u5c55\u73b0\u4e86\u8fdb\u4e00\u6b65\u5f00\u53d1\u7684\u6f5c\u529b\u3002|\n",
    "2506.21629": "|2025-06-24|ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes|Chenhao Zhang\u7b49|[2506.21629](http://arxiv.org/pdf/2506.21629)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700SfM\u9884\u5904\u7406\u7684\u65b9\u6cd5ICP-3DGS\uff0c\u5c06\u8fed\u4ee3\u6700\u8fd1\u70b9\uff08ICP\uff09\u4e0e\u57fa\u4e8e\u4f18\u5316\u7684\u4f4d\u59ff\u7ec6\u5316\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4e86\u5927\u8303\u56f4\u65e0\u8fb9\u754c\u573a\u666f\u4e2d\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u7684\u96be\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06ICP\u5f15\u51653D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u5728\u5927\u5e45\u5ea6\u76f8\u673a\u8fd0\u52a8\u4e0b\u7684\u9ad8\u7cbe\u5ea6\u4f4d\u59ff\u4f30\u8ba1\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u795e\u7ecf\u6e32\u67d3\u5bf9SfM\u5148\u9a8c\u7684\u4f9d\u8d56\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u57fa\u4e8e\u4f53\u7d20\u7684\u573a\u666f\u81f4\u5bc6\u5316\u7b56\u7565\uff0c\u6709\u6548\u6307\u5bfc\u5927\u89c4\u6a21\u573a\u666f\u7684\u91cd\u5efa\u8fc7\u7a0b\uff0c\u63d0\u5347\u4e86\u573a\u666f\u8986\u76d6\u7387\u548c\u51e0\u4f55\u7ec6\u8282\u7684\u5b8c\u6574\u6027\u3002  \n\u25c6 \u5728\u5ba4\u5185\u5916\u591a\u79cd\u5c3a\u5ea6\u573a\u666f\u7684\u5b9e\u9a8c\u4e2d\uff0cICP-3DGS\u5728\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u548c\u65b0\u89c6\u89d2\u5408\u6210\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u5f00\u6e90\u4e86\u5b8c\u6574\u4ee3\u7801\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u65e0\u9884\u8ba1\u7b97\u4f4d\u59ff\u7684\u795e\u7ecf\u6e32\u67d3\u6280\u672f\u7684\u53d1\u5c55\u3002|\n",
    "2506.23808": "|2025-06-30|Towards Initialization-free Calibrated Bundle Adjustment|Carl Olsson\u7b49|[2506.23808](http://arxiv.org/pdf/2506.23808)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u521d\u59cb\u5316\u7684\u6807\u5b9a\u675f\u8c03\u6574\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u521d\u59cb\u91cd\u5efa\u9636\u6bb5\u76f4\u63a5\u5229\u7528\u76f8\u673a\u6807\u5b9a\u4fe1\u606f\uff0c\u751f\u6210\u63a5\u8fd1\u5ea6\u91cf\u7cbe\u5ea6\u7684\u91cd\u5efa\u7ed3\u679c\uff08\u4ec5\u5dee\u4e00\u4e2a\u76f8\u4f3c\u53d8\u6362\uff09\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u5177\u6709\u6807\u5b9a\u4fe1\u606f\u7684\u6210\u5bf9\u76f8\u5bf9\u65cb\u8f6c\u4f30\u8ba1\uff0c\u8fd9\u4e9b\u65cb\u8f6c\u4f30\u8ba1\u4ec5\u5bf9\u76f8\u4f3c\u53d8\u6362\u4fdd\u6301\u4e0d\u53d8\uff0c\u4ece\u800c\u63a8\u52a8\u89e3\u4fdd\u6301\u771f\u5b9e\u573a\u666f\u7684\u5ea6\u91cf\u7279\u5f81\u3002  \n\u25c6 \u5c06\u65cb\u8f6c\u5e73\u5747\u6280\u672f\u6574\u5408\u5230\u4f2a\u7269\u4f53\u7a7a\u95f4\u8bef\u5dee\uff08pOSE\uff09\u6846\u67b6\u4e2d\uff0c\u5b9e\u73b0\u4e86\u6807\u5b9a\u4fe1\u606f\u4e0e\u521d\u59cb\u5316\u65e0\u5173\u7684SfM\uff08\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff09\u6d41\u7a0b\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u53ef\u9760\u4f18\u5316\u76ee\u6807\u51fd\u6570\uff0c\u5373\u4f7f\u4ece\u968f\u673a\u521d\u59cb\u89e3\u51fa\u53d1\u4e5f\u80fd\u9ad8\u6982\u7387\u6536\u655b\u5230\u5168\u5c40\u6700\u4f18\uff0c\u83b7\u5f97\u7cbe\u786e\u7684\u63a5\u8fd1\u5ea6\u91cf\u91cd\u5efa\u3002  \n\u25c6 \u76f8\u6bd4\u73b0\u6709\u57fa\u4e8epOSE\u7684\u65b9\u6cd5\uff08\u4ec5\u80fd\u83b7\u5f97\u5c04\u5f71\u53d8\u6362\u89e3\u4e14\u9700\u8981\u66f4\u591a\u6570\u636e\uff09\uff0c\u65b0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u91cd\u5efa\u7cbe\u5ea6\u548c\u6548\u7387\u3002|\n",
    "2506.23611": "|2025-06-30|AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention|Ziao Liu\u7b49|[2506.23611](http://arxiv.org/pdf/2506.23611)|\u65e0|\u25c6 \u63d0\u51faAttentionGS\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u65e0\u9700\u9ad8\u8d28\u91cf\u521d\u59cb\u70b9\u4e91\u76843D\u9ad8\u65af\u6cfc\u6e85\u91cd\u5efa\uff0c\u7a81\u7834\u4f20\u7edf3DGS\u5bf9SfM\u70b9\u4e91\u7684\u5f3a\u4f9d\u8d56\u3002  \n\u25c6 \u521b\u65b0\u6027\u5f15\u5165\u51e0\u4f55\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u8bad\u7ec3\u521d\u671f\u5feb\u901f\u6062\u590d\u573a\u666f\u5168\u5c40\u7ed3\u6784\uff0c\u89e3\u51b3\u968f\u673a\u521d\u59cb\u5316\u5bfc\u81f4\u7684\u6536\u655b\u96be\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u6e10\u8fdb\u5f0f\u7eb9\u7406\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5728\u8bad\u7ec3\u540e\u671f\u7cbe\u7ec6\u5316\u5c40\u90e8\u7ec6\u8282\uff0c\u663e\u8457\u63d0\u5347\u7eb9\u7406\u7f3a\u5931\u573a\u666f\u7684\u6e32\u67d3\u8d28\u91cf\u3002  \n\u25c6 \u5f00\u53d1\u4e0d\u900f\u660e\u5ea6\u52a0\u6743\u68af\u5ea6\u7b56\u7565\uff0c\u4f18\u5316\u9ad8\u65af\u5206\u5e03\u81f4\u5bc6\u5316\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u8868\u9762\u91cd\u5efa\u3002  \n\u25c6 \u5728\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u5168\u9762\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u4f4e\u7eb9\u7406/\u53d7\u9650\u89c6\u89d2\u573a\u666f\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u590d\u6742\u573a\u666f\u76843D\u91cd\u5efa\u63d0\u4f9b\u65b0\u601d\u8def\uff0c\u6269\u5c55\u4e863DGS\u6280\u672f\u7684\u9002\u7528\u8fb9\u754c\u3002|\n",
    "2507.03306": "|2025-07-04|MGSfM: Multi-Camera Geometry Driven Global Structure-from-Motion|Peilin Tao\u7b49|[2507.03306](http://arxiv.org/pdf/2507.03306)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u591a\u76f8\u673a\u7cfb\u7edf\u8bbe\u8ba1\u7684\u5168\u5c40\u8fd0\u52a8\u5e73\u5747\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u65cb\u8f6c\u5e73\u5747\u548c\u6df7\u5408\u5e73\u79fb\u5e73\u5747\u6a21\u5757\u63d0\u5347\u4f20\u7edf\u5168\u5c40SfM\u7684\u9c81\u68d2\u6027\u95ee\u9898\u3002  \n\u25c6 \u91c7\u7528\u5206\u5c42\u7b56\u7565\u7684\u65cb\u8f6c\u5e73\u5747\u65b9\u6cd5\uff1a\u5148\u4f30\u8ba1\u521a\u6027\u76f8\u673a\u5355\u5143\u5185\u7684\u76f8\u5bf9\u65cb\u8f6c\uff0c\u518d\u8ba1\u7b97\u5168\u5c40\u521a\u6027\u5355\u5143\u65cb\u8f6c\uff0c\u4f18\u5316\u591a\u76f8\u673a\u7cfb\u7edf\u7684\u65cb\u8f6c\u4f30\u8ba1\u7cbe\u5ea6\u3002  \n\u25c6 \u521b\u65b0\u6027\u878d\u5408\u76f8\u673a\u95f4\u7ea6\u675f\u548c\u76f8\u673a-\u70b9\u7ea6\u675f\u7684\u5e73\u79fb\u5e73\u5747\u6a21\u5757\uff0c\u901a\u8fc7\u51f8\u8ddd\u79bb\u76ee\u6807\u51fd\u6570\u521d\u59cb\u5316\u76f8\u673a\u4f4d\u59ff\u548c3D\u70b9\uff0c\u5e76\u91c7\u7528\u65e0\u504f\u975e\u53cc\u7ebf\u6027\u89d2\u5ea6\u76ee\u6807\u51fd\u6570\u8fdb\u884c\u7ec6\u5316\u3002  \n\u25c6 \u5728\u4fdd\u6301\u4e0e\u589e\u91cf\u5f0fSfM\u76f8\u5f53\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u5168\u5c40SfM\u65b9\u6cd5\u3002  \n\u25c6 \u6846\u67b6\u5145\u5206\u5229\u7528\u591a\u76f8\u673a\u7cfb\u7edf\u7684\u56fa\u6709\u76f8\u5bf9\u4f4d\u59ff\u7ea6\u675f\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u548c\u673a\u5668\u4eba\u73af\u5883\u611f\u77e5\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u5b9e\u65f6SfM\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u4fbf\u4e8e\u5b66\u672f\u548c\u5de5\u4e1a\u754c\u5e94\u7528\u9a8c\u8bc1\uff0c\u63a8\u52a8\u591a\u76f8\u673aSfM\u6280\u672f\u7684\u5b9e\u9645\u90e8\u7f72\u3002|\n",
    "2507.08448": "|2025-07-11|Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT|Wei Zhang\u7b49|[2507.08448](http://arxiv.org/pdf/2507.08448)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u524d\u9988\u5f0f3D\u91cd\u5efa\u65b0\u8303\u5f0f\uff0c\u4ee5DUSt3R\u4e3a\u4ee3\u8868\uff0c\u901a\u8fc7\u5355\u4e00\u524d\u5411\u4f20\u64ad\u76f4\u63a5\u4ece\u65e0\u7ea6\u675f\u56fe\u50cf\u4e2d\u8054\u5408\u63a8\u65ad\u76f8\u673a\u4f4d\u59ff\u548c\u7a20\u5bc6\u51e0\u4f55\u7ed3\u6784\uff0c\u98a0\u8986\u4e86\u4f20\u7edf\u8fed\u4ee3\u4f18\u5316\u6d41\u7a0b\u3002  \n\u25c6 \u91c7\u7528\u57fa\u4e8eTransformer\u7684\u5bf9\u5e94\u5173\u7cfb\u5efa\u6a21\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u8de8\u56fe\u50cf\u7684\u9ad8\u6548\u7279\u5f81\u5339\u914d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7eb9\u7406\u7f3a\u5931\u7b49\u6311\u6218\u6027\u573a\u666f\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u8054\u5408\u4f4d\u59ff\u4e0e\u51e0\u4f55\u56de\u5f52\u673a\u5236\uff0c\u5c06\u4f20\u7edf\u591a\u9636\u6bb5\u6d41\u7a0b\uff08\u5982SfM+MVS\uff09\u6574\u5408\u4e3a\u7aef\u5230\u7aef\u7f51\u7edc\uff0c\u5927\u5e45\u7b80\u5316\u4e86\u5de5\u4f5c\u6d41\u7a0b\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002  \n\u25c6 \u7cfb\u7edf\u5206\u6790\u4e86\u4ece\u53cc\u89c6\u56fe\u5230\u591a\u89c6\u56fe\u7684\u6269\u5c55\u7b56\u7565\uff0c\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u6280\u672f\u8def\u5f84\u3002  \n\u25c6 \u901a\u8fc7\u4e0e\u4f20\u7edf\u65b9\u6cd5\uff08\u5982SfM\uff09\u548c\u65e9\u671f\u5b66\u4e60\u578b\u65b9\u6cd5\uff08\u5982MVSNet\uff09\u7684\u5bf9\u6bd4\uff0c\u9610\u660e\u4e86\u8be5\u8303\u5f0f\u5728\u6548\u7387\u3001\u6cdb\u5316\u6027\u548c\u6613\u7528\u6027\u65b9\u9762\u7684\u7a81\u7834\u6027\u4f18\u52bf\u3002  \n\u25c6 \u63a2\u8ba8\u4e86\u52a8\u6001\u573a\u666f\u5904\u7406\u3001\u6a21\u578b\u7cbe\u5ea6\u4e0e\u53ef\u6269\u5c55\u6027\u7b49\u672a\u6765\u6311\u6218\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u6307\u660e\u4e86\u65b9\u5411\u3002|\n",
    "2507.10827": "|2025-07-20|Supporting SENCOTEN Language Documentation Efforts with Automatic Speech Recognition|Mengzhe Geng\u7b49|[2507.10827](http://arxiv.org/pdf/2507.10827)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u901a\u8fc7\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u6280\u672f\u652f\u6301\u6fd2\u5371\u8bed\u8a00SEN\u0106OTEN\u7684\u6587\u6863\u5316\u5de5\u4f5c\uff0c\u5177\u4f53\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cdASR\u9a71\u52a8\u7684\u6587\u6863\u5316\u6d41\u7a0b\uff0c\u7ed3\u5408\u6587\u672c\u8f6c\u8bed\u97f3\uff08TTS\uff09\u7cfb\u7edf\u589e\u5f3a\u6709\u9650\u7684\u8bed\u8a00\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002  \n\u25c6 \u5229\u7528\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b66\u4e60\u6280\u672f\uff0c\u501f\u52a9\u8bed\u97f3\u57fa\u7840\u6a21\u578b\uff08SFMs\uff09\u63d0\u5347ASR\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u6027\u80fd\u3002  \n\u25c6 \u5f15\u5165n-gram\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6d45\u5c42\u878d\u5408\u6216n-best\u6062\u590d\u6280\u672f\uff0c\u6700\u5927\u5316\u5229\u7528\u73b0\u6709\u8bcd\u6c47\u6570\u636e\u3002  \n\u25c6 \u5728SEN\u0106OTEN\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8619.34%\u7684\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u548c5.09%\u7684\u5b57\u7b26\u9519\u8bef\u7387\uff08CER\uff09\uff0c\u7ecf\u8fc7\u8fc7\u6ee4\u540e\u5206\u522b\u63d0\u5347\u81f314.32%\u548c3.45%\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u7279\u522b\u9488\u5bf9SEN\u0106OTEN\u7684\u591a\u5408\u6210\u7ed3\u6784\u548c\u91cd\u97f3\u9a71\u52a8\u7684\u97f3\u4f4d\u53d8\u6362\u7b49\u8bed\u8a00\u7279\u70b9\uff0c\u4f18\u5316\u4e86ASR\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u3002  \n\u25c6 \u4e3a\u6fd2\u5371\u8bed\u8a00\u7684\u6570\u5b57\u5316\u4fdd\u62a4\u548c\u6559\u5b66\u8d44\u6e90\u521b\u5efa\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\u3002|\n",
    "2507.12095": "|2025-07-16|BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images|Davide Di Nucci\u7b49|[2507.12095](http://arxiv.org/pdf/2507.12095)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u901a\u8fc7\u7a00\u758f\u89c6\u89d2\u8f93\u5165\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u76843D\u8f66\u8f86\u91cd\u5efa\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5bc6\u96c6\u89c6\u89d2\u7684\u5c40\u9650\u6027\u3002  \n\n\u25c6\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u56fe\u548c\u9c81\u68d2\u4f4d\u59ff\u4f30\u8ba1\u67b6\u6784\u7684\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u4ece\u7a00\u758f\u8f93\u5165\u5408\u6210\u65b0\u89c6\u89d2\u5e76\u589e\u5f3a\u8bad\u7ec3\u6570\u636e\u3002  \n\u25c6\u6539\u8fdb\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\uff0c\u5f15\u5165\u9009\u62e9\u6027\u5149\u5ea6\u635f\u5931\u51fd\u6570\uff0c\u4ec5\u5bf9\u9ad8\u7f6e\u4fe1\u5ea6\u50cf\u7d20\u8fdb\u884c\u8ba1\u7b97\uff0c\u63d0\u5347\u91cd\u5efa\u8d28\u91cf\u3002  \n\u25c6\u91c7\u7528DUSt3R\u67b6\u6784\u66ff\u4ee3\u4f20\u7edf\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002  \n\u25c6\u53d1\u5e03\u4e86\u4e00\u4e2a\u5305\u542b\u5408\u6210\u548c\u771f\u5b9e\u516c\u5171\u4ea4\u901a\u5de5\u5177\u8f66\u8f86\u7684\u65b0\u6570\u636e\u96c6\uff0c\u652f\u6301\u65b9\u6cd5\u7684\u5168\u9762\u8bc4\u4f30\u3002  \n\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5c24\u5176\u5728\u8f93\u5165\u6761\u4ef6\u53d7\u9650\u65f6\u4ecd\u80fd\u5b9e\u73b0\u9ad8\u8d28\u91cf\u91cd\u5efa\u3002|\n",
    "2507.11893": "|2025-07-23|Spatial Frequency Modulation for Semantic Segmentation|Linwei Chen\u7b49|[2507.11893](http://arxiv.org/pdf/2507.11893)|\u65e0|\u25c6 \u63d0\u51fa\u7a7a\u95f4\u9891\u7387\u8c03\u5236\uff08SFM\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u4e0b\u91c7\u6837\u524d\u5c06\u9ad8\u9891\u7279\u5f81\u8c03\u5236\u5230\u4f4e\u9891\uff0c\u4e0a\u91c7\u6837\u65f6\u518d\u89e3\u8c03\u56de\u6765\uff0c\u6709\u6548\u89e3\u51b3\u8bed\u4e49\u5206\u5272\u4e2d\u9ad8\u9891\u4fe1\u606f\u56e0\u4e0b\u91c7\u6837\u5bfc\u81f4\u7684\u6df7\u53e0\u5931\u771f\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u81ea\u9002\u5e94\u91cd\u91c7\u6837\uff08ARS\uff09\u6a21\u5757\uff0c\u901a\u8fc7\u5bc6\u96c6\u91c7\u6837\u9ad8\u9891\u533a\u57df\u6765\u7f29\u653e\u4fe1\u53f7\uff0c\u5229\u7528\u9891\u7387\u7f29\u653e\u7279\u6027\u964d\u4f4e\u9ad8\u9891\u6210\u5206\u7684\u9891\u7387\uff0c\u5b9e\u73b0\u9ad8\u6548\u8c03\u5236\u3002  \n\u25c6 \u63d0\u51fa\u591a\u5c3a\u5ea6\u81ea\u9002\u5e94\u4e0a\u91c7\u6837\uff08MSAU\uff09\u6a21\u5757\uff0c\u901a\u8fc7\u975e\u5747\u5300\u4e0a\u91c7\u6837\u89e3\u8c03\u7279\u5f81\u5e76\u6062\u590d\u9ad8\u9891\u4fe1\u606f\uff0c\u540c\u65f6\u5229\u7528\u591a\u5c3a\u5ea6\u5bc6\u96c6\u4e0e\u7a00\u758f\u91c7\u6837\u533a\u57df\u7684\u4ea4\u4e92\u589e\u5f3a\u5206\u5272\u7cbe\u5ea6\u3002  \n\u25c6 \u6a21\u5757\u8bbe\u8ba1\u8f7b\u91cf\u4e14\u901a\u7528\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230CNN\u548cTransformer\u7b49\u591a\u79cd\u67b6\u6784\u4e2d\uff0c\u6269\u5c55\u6027\u5f3a\u3002  \n\u25c6 \u901a\u8fc7\u7279\u5f81\u53ef\u89c6\u5316\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u6df7\u53e0\u5e76\u4fdd\u7559\u7ec6\u8282\uff0c\u8fdb\u4e00\u6b65\u5728\u56fe\u50cf\u5206\u7c7b\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u3001\u5b9e\u4f8b\u5206\u5272\u548c\u5168\u666f\u5206\u5272\u7b49\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5e7f\u6cdb\u9002\u7528\u6027\u3002|\n",
    "2507.12595": "|2025-07-16|Enhancing In-Domain and Out-Domain EmoFake Detection via Cooperative Multilingual Speech Foundation Models|Orchid Chetia Phukan\u7b49|[2507.12595](http://arxiv.org/pdf/2507.12595)|\u65e0|\u25c6 \u63d0\u51fa\u591a\u8bed\u8a00\u8bed\u97f3\u57fa\u7840\u6a21\u578b\uff08SFMs\uff09\u5728\u60c5\u611f\u4f2a\u9020\u68c0\u6d4b\uff08EFD\uff09\u4e2d\u7684\u6709\u6548\u6027\u5047\u8bbe\uff0c\u8ba4\u4e3a\u5176\u8de8\u8bed\u8a00\u9884\u8bad\u7ec3\u80fd\u66f4\u597d\u6355\u6349\u97f3\u9ad8\u3001\u97f3\u8c03\u548c\u5f3a\u5ea6\u7684\u7ec6\u5fae\u53d8\u5316\u3002  \n\u25c6 \u901a\u8fc7\u5168\u9762\u5bf9\u6bd4\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u591a\u8bed\u8a00SFMs\u5728\u540c\u8bed\u8a00\uff08\u57df\u5185\uff09\u548c\u8de8\u8bed\u8a00\uff08\u57df\u5916\uff09\u573a\u666f\u4e0b\u7684\u4f18\u8d8a\u6027\u80fd\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u63d0\u51faTHAMA\u878d\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408Tucker\u5206\u89e3\u548cHadamard\u4e58\u79ef\uff0c\u5b9e\u73b0\u57fa\u7840\u6a21\u578b\u7684\u9ad8\u6548\u4e92\u8865\u878d\u5408\u3002  \n\u25c6 THAMA\u4e0e\u591a\u8bed\u8a00SFMs\u534f\u540c\u5408\u4f5c\uff0c\u5728\u57df\u5185\u548c\u57df\u5916\u8bc4\u6d4b\u4e2d\u5747\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u8d85\u8d8a\u5355\u4e00\u6a21\u578b\u3001\u57fa\u7ebf\u878d\u5408\u65b9\u6cd5\u548c\u5148\u524dSOTA\u65b9\u6cd5\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u63a2\u7d22\u4e86\u591a\u8bed\u8a00SFMs\u5728EFD\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u8de8\u8bed\u8a00\u60c5\u611f\u4f2a\u9020\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2507.13486": "|2025-07-17|Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation|Debao Huang\u7b49|[2507.13486](http://arxiv.org/pdf/2507.13486)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u548c\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u8bef\u5dee\u4f20\u64ad\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5316\u822a\u7a7a\u548c\u65e0\u4eba\u673a\u6444\u5f71\u6d4b\u91cf\u4e2d\u4eceSfM\u5230MVS\u4e24\u9636\u6bb5\u7684\u5168\u6d41\u7a0b\u4e0d\u786e\u5b9a\u6027\uff0c\u586b\u8865\u4e86MVS\u9636\u6bb5\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u7684\u7814\u7a76\u7a7a\u767d\u3002\n\n\u25c6 \u9488\u5bf9MVS\u9636\u6bb5\u975e\u53ef\u5fae\u3001\u591a\u6a21\u6001\u7684\u7279\u6027\uff0c\u521b\u65b0\u6027\u5730\u63d0\u51fa\u57fa\u4e8e\u53ef\u9760\u591a\u89c6\u89d2\u70b9\uff08n\u22656\uff09\u7684\u81ea\u6821\u51c6\u65b9\u6cd5\uff0c\u901a\u8fc7\u5339\u914d\u4ee3\u4ef7\u7b49\u5173\u952e\u7279\u5f81\u56de\u5f52\u89c6\u5dee\u4e0d\u786e\u5b9a\u6027\u3002\n\n\u25c6 \u8be5\u65b9\u6cd5\u76f4\u63a5\u4eceMVS\u8fc7\u7a0b\u4e2d\u63d0\u53d6\u81ea\u5305\u542b\u7684\u53ef\u97603D\u70b9\uff0c\u5177\u6709\u81ea\u76d1\u7763\u7279\u6027\uff0c\u65e0\u9700\u5916\u90e8\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u3002\n\n\u25c6 \u63d0\u51fa\u7684\u8bef\u5dee\u534f\u65b9\u5dee\u77e9\u9635\u5efa\u6a21\u65b9\u6cd5\u4e25\u683c\u9075\u5faa\u6444\u5f71\u6d4b\u91cf\u8bef\u5dee\u4f20\u64ad\u8def\u5f84\uff0c\u80fd\u9002\u5e94\u4e0d\u540c\u573a\u666f\u7684\u9c81\u68d2\u6027\u9a8c\u8bc1\u9700\u6c42\u3002\n\n\u25c6 \u901a\u8fc7\u516c\u5f00\u6570\u636e\u96c6\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u9ad8\u8fb9\u754c\u8986\u76d6\u7387\u7684\u540c\u65f6\u907f\u514d\u4e86\u4e0d\u786e\u5b9a\u6027\u9ad8\u4f30\u95ee\u9898\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\n\n\u25c6 \u9996\u6b21\u5b9e\u73b0\u4e86\u6444\u5f71\u6d4b\u91cf\u70b9\u4e91\u9010\u70b9\u7cbe\u5ea6\u51ed\u8bc1\u7684\u6807\u51c6\u5316\u8f93\u51fa\uff0c\u4e3a\u573a\u666f\u4f9d\u8d56\u7684\u6444\u5f71\u6d4b\u91cf\u7cbe\u5ea6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u8ba4\u8bc1\u7684\u91cf\u5316\u5de5\u5177\u3002|\n",
    "2507.15683": "|2025-07-21|Hi^2-GSLoc: Dual-Hierarchical Gaussian-Specific Visual Relocalization for Remote Sensing|Boni Hu\u7b49|[2507.15683](http://arxiv.org/pdf/2507.15683)|\u65e0|\u25c6 \u63d0\u51faHi^2-GSLoc\u6846\u67b6\uff0c\u9996\u6b21\u5c063D\u9ad8\u65af\u6e85\u5c04\uff083DGS\uff09\u5f15\u5165\u9065\u611f\u89c6\u89c9\u91cd\u5b9a\u4f4d\u4efb\u52a1\uff0c\u5229\u7528\u5176\u7d27\u51d1\u7684\u51e0\u4f55\u4e0e\u5916\u89c2\u8868\u5f81\u80fd\u529b\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7cbe\u5ea6\u4e0e\u6548\u7387\u7684\u77db\u76fe\u3002  \n\u25c6 \u8bbe\u8ba1\u53cc\u5c42\u6b21\u7a00\u758f\u5230\u7a20\u5bc6\u3001\u7c97\u5230\u7cbe\u7684\u5b9a\u4f4d\u8303\u5f0f\uff1a\u7a00\u758f\u9636\u6bb5\u901a\u8fc7\u6e32\u67d3\u611f\u77e5\u91c7\u6837\u548c\u5730\u6807\u5f15\u5bfc\u68c0\u6d4b\u5668\u83b7\u53d6\u9c81\u68d2\u521d\u59cb\u4f4d\u59ff\uff0c\u7a20\u5bc6\u9636\u6bb5\u901a\u8fc7\u591a\u7ea7\u6805\u683c\u5316\u5339\u914d\u8fed\u4ee3\u4f18\u5316\u4f4d\u59ff\u3002  \n\u25c6 \u5f00\u53d1\u5206\u533a\u9ad8\u65af\u8bad\u7ec3\u3001GPU\u5e76\u884c\u5339\u914d\u548c\u52a8\u6001\u5185\u5b58\u7ba1\u7406\u7b56\u7565\uff0c\u7a81\u7834\u5927\u5c3a\u5ea6\u9065\u611f\u573a\u666f\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u5b9e\u73b0\u9ad8\u6548\u5904\u7406\u9ad8\u6d77\u62d4\u53d8\u5316\u548c\u8de8\u57df\u6570\u636e\u3002  \n\u25c6 \u521b\u65b0\u6027\u63d0\u51fa\u9ad8\u65af\u57fa\u5143\u4e00\u81f4\u6027\u6e32\u67d3\u611f\u77e5\u91c7\u6837\u65b9\u6cd5\uff0c\u7ed3\u5408\u53ef\u9760\u6027\u9a8c\u8bc1\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u7279\u5f81\u5339\u914d\u7684\u7a33\u5b9a\u6027\u548c\u4f4d\u59ff\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002  \n\u25c6 \u5728\u4eff\u771f\u6570\u636e\u3001\u516c\u5f00\u6570\u636e\u96c6\u548c\u771f\u5b9e\u98de\u884c\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u517c\u5177\u9ad8\u5b9a\u4f4d\u7cbe\u5ea6\uff08\u7ade\u4e89\u6027\u6307\u6807\uff09\u3001\u53ec\u56de\u7387\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5b9e\u9645\u9065\u611f\u5e94\u7528\u63d0\u4f9b\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.15308": "|2025-07-21|Few-Shot Object Detection via Spatial-Channel State Space Model|Zhimeng Xin\u7b49|[2507.15308](http://arxiv.org/pdf/2507.15308)|\u65e0|\u25c6 \u63d0\u51fa\u7a7a\u95f4-\u901a\u9053\u72b6\u6001\u7a7a\u95f4\u5efa\u6a21\uff08SCSM\uff09\u6a21\u5757\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u7a7a\u95f4\u548c\u901a\u9053\u5173\u7cfb\uff0c\u89e3\u51b3\u5c0f\u6837\u672c\u76ee\u6807\u68c0\u6d4b\u4e2d\u7279\u5f81\u63d0\u53d6\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u7a7a\u95f4\u7279\u5f81\u5efa\u6a21\uff08SFM\uff09\u6a21\u5757\uff0c\u5e73\u8861\u7a7a\u95f4\u5173\u7cfb\u548c\u901a\u9053\u5173\u7cfb\u7684\u5b66\u4e60\uff0c\u63d0\u5347\u7279\u5f81\u8868\u793a\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06Mamba\u6a21\u578b\u5f15\u5165\u901a\u9053\u5e8f\u5217\u5efa\u6a21\uff0c\u63d0\u51fa\u901a\u9053\u72b6\u6001\u5efa\u6a21\uff08CSM\uff09\u6a21\u5757\uff0c\u5229\u7528\u901a\u9053\u95f4\u76f8\u5173\u6027\u52a8\u6001\u8c03\u6574\u901a\u9053\u6743\u91cd\u3002  \n\u25c6 \u901a\u8fc7SCSM\u6a21\u5757\uff0c\u6a21\u578b\u80fd\u591f\u81ea\u52a8\u5f3a\u5316\u6709\u6548\u901a\u9053\u7279\u5f81\u5e76\u4fee\u6b63\u65e0\u6548\u901a\u9053\u7279\u5f81\uff0c\u4ece\u800c\u63d0\u5347\u5c0f\u6837\u672c\u6761\u4ef6\u4e0b\u7684\u68c0\u6d4b\u6027\u80fd\u3002  \n\u25c6 \u5728VOC\u548cCOCO\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002|\n",
    "2507.14798": "|2025-07-20|An Evaluation of DUSt3R/MASt3R/VGGT 3D Reconstruction on Photogrammetric Aerial Blocks|Xinyi Wu\u7b49|[2507.14798](http://arxiv.org/pdf/2507.14798)|\u65e0|\u25c6 \u9996\u6b21\u5bf9DUSt3R/MASt3R/VGGT\u4e09\u79cd\u57fa\u4e8eTransformer\u76843D\u91cd\u5efa\u6a21\u578b\u5728\u822a\u6444\u5f71\u50cf\u5757\u4e0a\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002  \n\u25c6 \u8bc1\u660e\u8fd9\u4e9b\u6a21\u578b\u5728\u6781\u7a00\u758f\u5f71\u50cf\uff08\u5c11\u4e8e10\u5f20\u3001\u5206\u8fa8\u7387\u4f4e\u81f3518\u50cf\u7d20\uff09\u4e0b\u4ecd\u80fd\u751f\u6210\u5b8c\u6574\u7a20\u5bc6\u70b9\u4e91\uff0c\u76f8\u6bd4\u4f20\u7edfCOLMAP\u65b9\u6cd5\u5b8c\u6574\u6027\u63d0\u5347\u9ad8\u8fbe50%\u3002  \n\u25c6 \u53d1\u73b0VGGT\u6a21\u578b\u5177\u6709\u663e\u8457\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u4f18\u52bf\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u80fd\u529b\u3002  \n\u25c6 \u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u9ad8\u5206\u8fa8\u7387\u5f71\u50cf\u548c\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u8868\u73b0\u4e3a\u4f4d\u59ff\u4f30\u8ba1\u53ef\u9760\u6027\u968f\u5f71\u50cf\u6570\u91cf\u589e\u52a0\u800c\u4e0b\u964d\u3002  \n\u25c6 \u63d0\u51faTransformer\u6a21\u578b\u867d\u65e0\u6cd5\u5b8c\u5168\u66ff\u4ee3\u4f20\u7edfSfM/MVS\u6d41\u7a0b\uff0c\u4f46\u5728\u4f4e\u5206\u8fa8\u7387\u3001\u7a00\u758f\u5f71\u50cf\u7b49\u6311\u6218\u6027\u573a\u666f\u4e2d\u53ef\u4f5c\u4e3a\u6709\u6548\u8865\u5145\u65b9\u6848\u3002  \n\u25c6 \u4e3a\u822a\u6d4b\u9886\u57df\u63d0\u4f9b\u4e86\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u76843D\u91cd\u5efa\u65b0\u601d\u8def\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5f71\u50cf\u91cd\u53e0\u7387\u6781\u4f4e\u6216\u7eb9\u7406\u7f3a\u5931\u533a\u57df\u7684\u5feb\u901f\u91cd\u5efa\u9700\u6c42\u3002|\n",
    "2507.16406": "|2025-07-22|Sparse-View 3D Reconstruction: Recent Advances and Open Challenges|Tanveer Younis\u7b49|[2507.16406](http://arxiv.org/pdf/2507.16406)|\u65e0|\u25c6 \u8be5\u8bba\u6587\u9996\u6b21\u5c06\u7a00\u758f\u89c6\u89d23D\u91cd\u5efa\u9886\u57df\u7684\u51e0\u4f55\u65b9\u6cd5\u3001\u795e\u7ecf\u9690\u5f0f\u6a21\u578b\uff08\u5982NeRF\uff09\u548c\u751f\u6210\u5f0f\u65b9\u6cd5\uff08\u5982\u6269\u6563\u6a21\u578b\uff09\u7eb3\u5165\u7edf\u4e00\u6846\u67b6\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002  \n\u25c6 \u91cd\u70b9\u5bf9\u6bd4\u4e86\u4e0d\u540c\u65b9\u6cd5\u5728\u51e0\u4f55\u6b63\u5219\u5316\u3001\u663e\u5f0f\u5f62\u72b6\u5efa\u6a21\u548c\u751f\u6210\u63a8\u7406\u65b9\u9762\u7684\u521b\u65b0\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u89e3\u51b3\u7a00\u758f\u89c6\u89d2\u4e0b\u6d6e\u6e38\u4f2a\u5f71\u548c\u4f4d\u59ff\u6a21\u7cca\u95ee\u9898\u4e0a\u7684\u72ec\u7279\u4f18\u52bf\u3002  \n\u25c6 \u63d0\u51fa\u5f53\u524d\u65b9\u6cd5\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9762\u4e34\u7684\u6838\u5fc3\u6743\u8861\uff1a\u91cd\u5efa\u7cbe\u5ea6\u3001\u8ba1\u7b97\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u4e4b\u95f4\u7684\u76f8\u4e92\u5236\u7ea6\u5173\u7cfb\u3002  \n\u25c6 \u533a\u522b\u4e8e\u4ee5\u5f80\u7efc\u8ff0\uff0c\u7279\u522b\u5f3a\u8c03\u4e86\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff08VFMs\uff09\u548c3D\u9ad8\u65af\u6cfc\u6e85\u7b49\u65b0\u5174\u6280\u672f\u5728\u7a00\u758f\u91cd\u5efa\u4e2d\u7684\u8fc1\u79fb\u5e94\u7528\u6f5c\u529b\u3002  \n\u25c6 \u660e\u786e\u6307\u51fa\u8be5\u9886\u57df\u5c1a\u672a\u89e3\u51b3\u7684\u4e24\u5927\u6311\u6218\uff1a\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u548c\u65e0\u4f4d\u59ff\u7ea6\u675f\u7684\u91cd\u5efa\uff0c\u5e76\u9996\u6b21\u63d0\u51fa\u53d1\u5c55\"3D\u539f\u751f\u751f\u6210\u5148\u9a8c\"\u7684\u672a\u6765\u65b9\u5411\u3002  \n\u25c6 \u901a\u8fc7\u6574\u5408\u5b9e\u65f6\u91cd\u5efa\u9700\u6c42\u4e0e\u65e0\u7ea6\u675f\u6761\u4ef6\u8bbe\u5b9a\uff0c\u4e3a\u7a00\u758f\u89c6\u89d23D\u91cd\u5efa\u7684\u5de5\u4e1a\u843d\u5730\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u7ebf\u56fe\u3002|\n",
    "2507.20117": "|2025-07-27|RESCUE: Crowd Evacuation Simulation via Controlling SDM-United Characters|Xiaolin Liu\u7b49|[2507.20117](http://arxiv.org/pdf/2507.20117)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f63D\u4eba\u7fa4\u758f\u6563\u6a21\u62df\u6846\u67b6RESCUE\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u611f\u77e5-\u51b3\u7b56-\u8fd0\u52a8\uff08SDM\uff09\u6d41\u7a0b\u6765\u63d0\u5347\u758f\u6563\u4eff\u771f\u7684\u771f\u5b9e\u6027\u548c\u52a8\u6001\u9002\u5e94\u6027\u3002  \n\n\u25c6 \u63d0\u51fa\u57fa\u4e8eSDM\u6d41\u7a0b\u7684\u4eff\u771f\u6846\u67b6\uff0c\u9996\u6b21\u5c063D\u81ea\u9002\u5e94\u793e\u4f1a\u529b\u6a21\u578b\uff08SFM\uff09\u51b3\u7b56\u673a\u5236\u4e0e\u4e2a\u6027\u5316\u6b65\u6001\u63a7\u5236\u8fd0\u52a8\u6a21\u5757\u7ed3\u5408\uff0c\u5b9e\u73b0\u66f4\u7b26\u5408\u4eba\u7c7b\u884c\u4e3a\u903b\u8f91\u7684\u758f\u6563\u6a21\u62df\u3002  \n\u25c6 \u5f15\u5165\u52a8\u6001\u7fa4\u4f53\u611f\u77e5\u673a\u5236\uff0c\u652f\u6301\u591a\u667a\u80fd\u4f53\u5e76\u884c\u8fd0\u52a8\uff0c\u80fd\u9002\u5e94\u4e0d\u540c\u5730\u5f62\u548c\u573a\u666f\u9700\u6c42\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u6a21\u578b\u5bf9\u590d\u6742\u73af\u5883\u9002\u5e94\u6027\u7684\u9650\u5236\u3002  \n\u25c6 \u5f00\u53d1\u4e2a\u6027\u5316\u6b65\u6001\u63a7\u5236\u6a21\u5757\uff0c\u901a\u8fc7\u8003\u8651\u4e2a\u4f53\u4f53\u578b\u5dee\u5f02\u548c\u5730\u5f62\u5f71\u54cd\uff0c\u9996\u6b21\u5b9e\u73b0\u758f\u6563\u8fc7\u7a0b\u4e2d\u4e2a\u4f53\u8fd0\u52a8\u7279\u5f81\u7684\u5dee\u5f02\u5316\u6a21\u62df\u3002  \n\u25c6 \u521b\u65b0\u63d0\u51fa\u90e8\u4ef6\u7ea7\u53d7\u529b\u53ef\u89c6\u5316\u6280\u672f\uff0c\u4e3a\u758f\u6563\u5206\u6790\u63d0\u4f9b\u76f4\u89c2\u7684\u529b\u5b66\u4ea4\u4e92\u6570\u636e\u652f\u6301\uff0c\u8f85\u52a9\u5b89\u5168\u7b56\u7565\u4f18\u5316\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u652f\u6301\u52a8\u6001\u8def\u5f84\u89c4\u5212\u548c\u5b9e\u65f6\u884c\u4e3a\u8c03\u6574\uff0c\u5728\u5d0e\u5c96\u5730\u5f62\u4e2d\u4ecd\u80fd\u751f\u6210\u89c6\u89c9\u53ef\u4fe1\u3001\u7b26\u5408\u73b0\u5b9e\u7684\u758f\u6563\u52a8\u753b\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u5e76\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5728\u771f\u5b9e\u6027\u548c\u5b9e\u7528\u6027\u4e0a\u7684\u4f18\u52bf\uff0c\u4e3a\u516c\u5171\u5b89\u5168\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u4eff\u771f\u5206\u6790\u5de5\u5177\u3002|\n",
    "2508.01936": "|2025-08-03|CVD-SfM: A Cross-View Deep Front-end Structure-from-Motion System for Sparse Localization in Multi-Altitude Scenes|Yaxuan Li\u7b49|[2508.01936](http://arxiv.org/pdf/2508.01936)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u9ad8\u5ea6\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u7cfb\u7edfCVD-SfM\uff0c\u4e13\u95e8\u9488\u5bf9\u7a00\u758f\u56fe\u50cf\u8f93\u5165\u4e0b\u4e0d\u540c\u9ad8\u5ea6\u573a\u666f\u7684\u9c81\u68d2\u7cbe\u51c6\u5b9a\u4f4d\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u8de8\u89c6\u89d2Transformer\u3001\u6df1\u5ea6\u7279\u5f81\u4e0e\u8fd0\u52a8\u6062\u590d\u7ed3\u6784(SfM)\u6280\u672f\u878d\u5408\u5230\u7edf\u4e00\u6846\u67b6\u4e2d\uff0c\u6709\u6548\u5e94\u5bf9\u590d\u6742\u73af\u5883\u6761\u4ef6\u548c\u89c6\u89d2\u53d8\u5316\u3002  \n\u25c6 \u4e3a\u89e3\u51b3\u8be5\u9886\u57df\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4e13\u95e8\u6536\u96c6\u5e76\u53d1\u5e03\u4e86\u4e24\u4e2a\u65b0\u7684\u591a\u9ad8\u5ea6\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u6570\u636e\u96c6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u57fa\u51c6\u5e73\u53f0\u3002  \n\u25c6 \u901a\u8fc7\u5927\u91cf\u5bf9\u6bd4\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u7cfb\u7edf\u5728\u591a\u9ad8\u5ea6\u7a00\u758f\u4f4d\u59ff\u4f30\u8ba1\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u7684\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002  \n\u25c6 \u6240\u63d0\u6846\u67b6\u7279\u522b\u9002\u5408\u65e0\u4eba\u673a\u5bfc\u822a\u3001\u641c\u6551\u884c\u52a8\u3001\u81ea\u52a8\u5316\u68c0\u6d4b\u7b49\u5b9e\u9645\u673a\u5668\u4eba\u5e94\u7528\u573a\u666f\uff0c\u5177\u6709\u91cd\u8981\u5b9e\u7528\u4ef7\u503c\u3002|\n",
    "2508.01063": "|2025-08-01|Counting topological interface modes using simplicial characteristic classes|N. Bohlsen\u7b49|[2508.01063](http://arxiv.org/pdf/2508.01063)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c31\u6d41-\u5355\u6781\u5b50\u5bf9\u5e94\u5173\u7cfb\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u5384\u7c73\u7cfb\u7edf\u4e2d\u62d3\u6251\u754c\u9762\u6a21\uff08TIMs\uff09\u7684\u6570\u91cf\u3002  \n\u25c6 \u901a\u8fc7\u8ba1\u7b97\u56f4\u7ed5\u5916\u5c14\u70b9\u7684\u76f8\u7a7a\u95f4\u7403\u4e0a\u5c40\u90e8\u6781\u5316\u5411\u91cf\u590d\u7ebf\u4e1b\u7684\u9648\u6570\uff0c\u786e\u5b9aTIMs\u6570\u91cf\uff0c\u521b\u65b0\u6027\u5730\u5c06\u62d3\u6251\u4e0d\u53d8\u91cf\u4e0e\u7269\u7406\u73b0\u8c61\u76f4\u63a5\u5173\u8054\u3002  \n\u25c6 \u91c7\u7528\u79bb\u6563\u5411\u91cf\u4e1b\u7684\u5355\u7eaf\u7b2c\u4e00\u9648\u7c7b\u6784\u9020\u65b9\u6cd5\u8ba1\u7b97\u9648\u6570\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u89c4\u8303\u4e0d\u53d8\u6027\u3001\u65e0\u9700\u5bfc\u6570\u8fd0\u7b97\u3001\u7ed3\u6784\u4fdd\u6301\u6027\u5f3a\u4e14\u6297\u566a\u58f0\u5e72\u6270\u7684\u7279\u70b9\u3002  \n\u25c6 \u7b97\u6cd5\u5728\u8d64\u9053\u6d41\u4f53\u6ce2\u548c\u62d3\u6251\u6717\u7f2a\u5c14\u56de\u65cb\u6ce2\u7684\u6848\u4f8b\u4e2d\u6210\u529f\u590d\u73b0\u4e86\u9884\u671f\u7684TIMs\u6570\u91cf\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002  \n\u25c6 \u63a2\u7d22\u4e86\u8be5\u7b97\u6cd5\u5728\u5b9e\u9a8c\u6d4b\u91cf\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u901a\u8fc7\u5408\u6210\u793a\u4f8b\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528\u4f53\u6ce2\u6781\u5316\u6570\u636e\u9884\u6d4bTIMs\u6570\u91cf\uff0c\u4e3a\u5b9e\u9a8c\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002|\n",
    "2508.01019": "|2025-08-01|3D Reconstruction via Incremental Structure From Motion|Muhammad Zeeshan\u7b49|[2508.01019](http://arxiv.org/pdf/2508.01019)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u548c\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u91cf\u5f0f\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u7684\u8be6\u7ec6\u5b9e\u73b0\u65b9\u6cd5\uff0c\u76f8\u6bd4\u5168\u5c40SfM\u6280\u672f\u66f4\u5177\u7075\u6d3b\u6027\u3002  \n\u25c6 \u901a\u8fc7\u9010\u6b65\u52a0\u5165\u65b0\u89c6\u56fe\u7684\u65b9\u5f0f\uff0c\u80fd\u591f\u5728\u7a00\u758f\u6216\u90e8\u5206\u91cd\u53e0\u7684\u6570\u636e\u96c6\u4e2d\u6062\u590d\u573a\u666f\u7ed3\u6784\u548c\u76f8\u673a\u8fd0\u52a8\u3002  \n\u25c6 \u91cd\u70b9\u7814\u7a76\u4e86\u51e0\u4f55\u4f30\u8ba1\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u901a\u8fc7\u5149\u675f\u6cd5\u5e73\u5dee\uff08bundle adjustment\uff09\u5b9e\u73b0\u8fed\u4ee3\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u91cd\u5efa\u7cbe\u5ea6\u3002  \n\u25c6 \u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u91cd\u6295\u5f71\u8bef\u5dee\u548c\u76f8\u673a\u8f68\u8ff9\u4e00\u81f4\u6027\u8bc4\u4f30\u4e86\u91cd\u5efa\u8d28\u91cf\u3002  \n\u25c6 \u8bc1\u660e\u4e86\u589e\u91cf\u5f0fSfM\u5728\u89c6\u89c9\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u662f\u4e00\u79cd\u53ef\u9760\u7684\u7a00\u758f3D\u91cd\u5efa\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002|\n",
    "2508.04410": "|2025-08-06|Bursting at the seams: the star-forming main sequence and its scatter at z=3-9 using NIRCam photometry from JADES|C. Simmonds\u7b49|[2508.04410](http://arxiv.org/pdf/2508.04410)|\u65e0|\u25c6 \u9996\u6b21\u5229\u7528JADES\u5de1\u5929\u7684NIRCam\u6d4b\u5149\u6570\u636e\u7cfb\u7edf\u7814\u7a76\u4e86\u7ea2\u79fbz=3-9\u8303\u56f4\u5185\u6052\u661f\u5f62\u6210\u4e3b\u5e8f(SFMS)\u53ca\u5176\u5f25\u6563\uff0c\u6837\u672c\u6052\u661f\u8d28\u91cf\u5b8c\u5907\u6027\u4e0b\u9650\u8fbelog(M\u22c6/M\u2299)\u22488.1\u3002  \n\u25c6 \u53d1\u73b010Myr\u65f6\u95f4\u5c3a\u5ea6\u4e0b\u7684SFMS\u6f14\u5316\u7b26\u5408sSFR\u221d(1+z)^2.30\u7684\u5173\u7cfb\uff0c\u4e0e\u6697\u7269\u8d28\u6655\u8d28\u91cf\u5438\u79ef\u7387\u7684\u7406\u8bba\u9884\u6d4b\u9ad8\u5ea6\u543b\u5408\u3002  \n\u25c6 \u63ed\u793a\u4e86SFMS\u5f52\u4e00\u5316\u968f\u6052\u661f\u5f62\u6210\u7387(SFR)\u5e73\u5747\u65f6\u95f4\u5c3a\u5ea6\u53d8\u5316\u7684\u590d\u6742\u89c4\u5f8b\uff0c\u53cd\u6620\u4e86\u7206\u53d1\u6027\u6052\u661f\u5f62\u6210\u4e0e\u4e0a\u5347\u578b\u6052\u661f\u5f62\u6210\u5386\u53f2\u7684\u7efc\u5408\u6548\u5e94\u3002  \n\u25c6 \u9996\u6b21\u5b9a\u91cf\u5206\u6790SFMS\u5f25\u6563\u968fSFR\u5e73\u5747\u65f6\u95f4\u5c3a\u5ea6\u7684\u6f14\u53d8\uff1a\u4ece10Myr\u76840.4-0.5dex\u964d\u81f3100Myr\u76840.2dex\uff0c\u8868\u660e\u77ed\u671f\u6ce2\u52a8\u4e3b\u5bfc\u5f25\u6563\uff0c\u4f46\u957f\u671f\u53d8\u5316\u4e5f\u5b58\u5728\u3002  \n\u25c6 \u53d1\u73b0\u4f4e\u8d28\u91cf\u661f\u7cfb\u4e2d\u7206\u53d1\u6027\u6052\u661f\u5f62\u6210\u5386\u53f2\u66f4\u663e\u8457\uff0c\u5e76\u6307\u51fa\u9700\u8981\u5f15\u5165\u521d\u59cb\u8d28\u91cf\u51fd\u6570\u504f\u91cd\u3001\u6052\u661f\u5f62\u6210\u6548\u7387\u63d0\u5347\u6216\u7206\u53d1\u6027\u589e\u5f3a\u7b49\u673a\u5236\u6765\u89e3\u91caz>10\u89c2\u6d4b\u5230\u7684UV\u4eae\u661f\u7cfb\u8fc7\u91cf\u73b0\u8c61\u3002  \n\u25c6 \u5f3a\u8c03\u5728\u62df\u5408SFMS\u65f6\uff08\u7279\u522b\u662f\u5bf9\u7206\u53d1\u6027\u6052\u661f\u5f62\u6210\u5386\u53f2\u7684\u661f\u7cfb\uff09\uff0c\u51c6\u786e\u786e\u5b9a\u6052\u661f\u8d28\u91cf\u5b8c\u5907\u6027\u9650\u7684\u91cd\u8981\u6027\u3002|\n",
    "2508.04236": "|2025-08-06|PIS3R: Very Large Parallax Image Stitching via Deep 3D Reconstruction|Muhua Zhu\u7b49|[2508.04236](http://arxiv.org/pdf/2508.04236)|\u65e0|\u25c6 \u63d0\u51faPIS3R\u65b9\u6cd5\uff0c\u9996\u6b21\u901a\u8fc7\u6df1\u5ea63D\u91cd\u5efa\u89e3\u51b3\u5927\u89c6\u5dee\u56fe\u50cf\u62fc\u63a5\u96be\u9898\uff0c\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u5728\u663e\u8457\u89c6\u5dee\u4e0b\u7684\u6027\u80fd\u74f6\u9888\u3002  \n\u25c6 \u91c7\u7528\u89c6\u89c9\u51e0\u4f55\u9a71\u52a8\u7684Transformer\u7f51\u7edc\uff0c\u4ece\u5927\u89c6\u5dee\u56fe\u50cf\u4e2d\u8054\u5408\u4f30\u8ba1\u76f8\u673a\u5185\u5916\u53c2\u6570\u5e76\u5b8c\u6210\u7a20\u5bc63D\u573a\u666f\u91cd\u5efa\uff0c\u5b9e\u73b0\u51e0\u4f55\u7cbe\u786e\u7684\u521d\u59cb\u5bf9\u9f50\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u91cd\u5efa\u76843D\u70b9\u4e91\u91cd\u6295\u5f71\u5230\u53c2\u8003\u89c6\u56fe\uff0c\u5b9e\u73b0\u50cf\u7d20\u7ea7\u7cbe\u51c6\u914d\u51c6\uff0c\u4fdd\u7559\u6240\u6709\u50cf\u7d20\u57283D\u6444\u5f71\u6d4b\u91cf\u4e2d\u7684\u51e0\u4f55\u5b8c\u6574\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u70b9\u4e91\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff0c\u9488\u5bf9\u521d\u59cb\u62fc\u63a5\u53ef\u80fd\u5b58\u5728\u7684\u7a7a\u6d1e\u6216\u566a\u58f0\u8fdb\u884c\u7cbe\u7ec6\u5316\u4fee\u590d\uff0c\u751f\u6210\u65e0\u7f1d\u9ad8\u8d28\u91cf\u7ed3\u679c\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5927\u89c6\u5dee\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u8f93\u51fa\u7ed3\u679c\u53ef\u76f4\u63a5\u652f\u6301SfM\u7b49\u4e0b\u6e383D\u89c6\u89c9\u4efb\u52a1\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002|\n",
    "2508.05205": "|2025-08-07|EndoMatcher: Generalizable Endoscopic Image Matcher via Multi-Domain Pre-training for Robot-Assisted Surgery|Bingyu Yang\u7b49|[2508.05205](http://arxiv.org/pdf/2508.05205)|\u65e0|\u25c6\u63d0\u51faEndoMatcher\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u9886\u57df\u9884\u8bad\u7ec3\u7684\u5185\u7aa5\u955c\u56fe\u50cf\u901a\u7528\u5339\u914d\u5668\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u8de8\u57df\u6570\u636e\u89e3\u51b3\u5185\u7aa5\u955c\u56fe\u50cf\u5339\u914d\u6cdb\u5316\u6027\u96be\u9898\u3002  \n\u25c6\u9996\u521b\u53cc\u5206\u652f\u89c6\u89c9Transformer\u67b6\u6784\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u4e0e\u53cc\u91cd\u4ea4\u4e92\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u5f31\u7eb9\u7406\u3001\u5927\u89c6\u89d2\u53d8\u5316\u7b49\u590d\u6742\u5185\u7aa5\u955c\u573a\u666f\u7684\u5339\u914d\u9c81\u68d2\u6027\u3002  \n\u25c6\u6784\u5efa\u9996\u4e2a\u591a\u9886\u57df\u5185\u7aa5\u955c\u5339\u914d\u6570\u636e\u96c6Endo-Mix6\uff0c\u5305\u542b6\u4e2a\u9886\u57df\u7ea6120\u4e07\u771f\u5b9e/\u5408\u6210\u56fe\u50cf\u5bf9\uff0c\u901a\u8fc7\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\u548c\u6a21\u62df\u53d8\u6362\u751f\u6210\u6807\u6ce8\uff0c\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u4e0e\u9886\u57df\u591a\u6837\u6027\u4e0d\u8db3\u95ee\u9898\u3002  \n\u25c6\u8bbe\u8ba1\u6e10\u8fdb\u5f0f\u591a\u76ee\u6807\u8bad\u7ec3\u7b56\u7565\uff0c\u6709\u6548\u5e94\u5bf9\u8de8\u57df\u6570\u636e\u89c4\u6a21\u5dee\u5f02\u3001\u5206\u5e03\u504f\u79fb\u548c\u8bef\u5dee\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e0d\u540c\u9886\u57df\u7684\u5747\u8861\u5b66\u4e60\u4e0e\u8868\u5f81\u4f18\u5316\u3002  \n\u25c6\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u8de8\u5668\u5b98\u548c\u6210\u50cf\u6761\u4ef6\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4ee5140%-201%\u7684\u5339\u914d\u5185\u70b9\u63d0\u5347\u7387\u548c9.4%\u7684\u65b9\u5411\u9884\u6d4b\u51c6\u786e\u7387\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002|\n",
    "2508.05187": "|2025-08-07|Refining Gaussian Splatting: A Volumetric Densification Approach|Mohamed Abdul Gafoor\u7b49|[2508.05187](http://arxiv.org/pdf/2508.05187)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u60ef\u6027\u4f53\u79ef\u7684\u65b0\u578b\u5bc6\u5ea6\u63a7\u5236\u65b9\u6cd5\uff0c\u5229\u7528\u9ad8\u65af\u51fd\u6570\u7684\u60ef\u6027\u4f53\u79ef\u6307\u5bfc3D\u9ad8\u65af\u5206\u5e03\u7684\u7cbe\u7ec6\u5316\u8fc7\u7a0b\uff0c\u514b\u670d\u539f\u59cb3DGS\u5bc6\u5ea6\u7b56\u7565\u7684\u7f3a\u9677\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u4f20\u7edfSfM\u4e0e\u6df1\u5ea6\u56fe\u50cf\u5339\u914d(DIM)\u4e24\u79cd\u70b9\u4e91\u521d\u59cb\u5316\u65b9\u6cd5\u5bf93DGS\u91cd\u5efa\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u4e3a\u521d\u59cb\u5316\u9009\u62e9\u63d0\u4f9b\u4f9d\u636e\u3002  \n\u25c6 \u5728Mip-NeRF 360\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e863DGS\u7684\u91cd\u5efa\u8d28\u91cf\uff0c\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002  \n\u25c6 \u6539\u8fdb\u4e86\u81ea\u9002\u5e94\u5bc6\u5ea6\u63a7\u5236(ADC)\u6d41\u7a0b\uff0c\u901a\u8fc7\u66f4\u667a\u80fd\u7684\u5bc6\u96c6\u5316\u548c\u4fee\u526a\u673a\u5236\u4f18\u5316\u70b9\u57fa\u5143\u7ba1\u7406\uff0c\u5b9e\u73b0\u66f4\u9ad8\u8d28\u91cf\u7684\u65b0\u89c6\u89d2\u5408\u6210\u3002  \n\u25c6 \u63d0\u51fa\u7684\u4f53\u79ef\u611f\u77e5\u7b56\u7565\u4e3a3D\u9ad8\u65af\u5206\u5e03\u7684\u5f62\u72b6\u548c\u7a7a\u95f4\u5206\u5e03\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u589e\u5f3a\u4e86\u573a\u666f\u8868\u793a\u7684\u51e0\u4f55\u51c6\u786e\u6027\u3002|\n",
    "2508.07355": "|2025-08-10|GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction|Qilin Zhang\u7b49|[2508.07355](http://arxiv.org/pdf/2508.07355)|\u65e0|\u25c6 \u63d0\u51faGS4Buildings\u65b9\u6cd5\uff0c\u5229\u7528\u8bed\u4e493D\u5efa\u7b51\u6a21\u578b\u4f5c\u4e3a\u5148\u9a8c\uff0c\u589e\u5f3a\u9ad8\u65af\u6cfc\u6e85\uff08GS\uff09\u5728\u5927\u89c4\u6a21\u590d\u6742\u57ce\u5e02\u573a\u666f\u4e2d\u7684\u91cd\u5efa\u80fd\u529b\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u56e0\u906e\u6321\u5bfc\u81f4\u7684\u4e0d\u5b8c\u6574\u95ee\u9898\u3002  \n\u25c6 \u76f4\u63a5\u57fa\u4e8e\u4f4e\u7ec6\u8282\u5c42\u6b21\uff08LoD2\uff09\u8bed\u4e49\u5efa\u7b51\u6a21\u578b\u521d\u59cb\u5316\u9ad8\u65af\u5206\u5e03\uff0c\u66ff\u4ee3\u4f20\u7edf\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u6d41\u7a0b\uff0c\u7b80\u5316\u91cd\u5efa\u6d41\u7a0b\u5e76\u63d0\u5347\u9c81\u68d2\u6027\u3002  \n\u25c6 \u901a\u8fc7\u5efa\u7b51\u51e0\u4f55\u751f\u6210\u5148\u9a8c\u6df1\u5ea6\u548c\u6cd5\u7ebf\u56fe\uff0c\u5e76\u5c06\u5176\u878d\u5165\u4f18\u5316\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u8868\u9762\u4e00\u81f4\u6027\u548c\u7ed3\u6784\u51c6\u786e\u6027\u3002  \n\u25c6 \u5f15\u5165\u53ef\u9009\u5efa\u7b51\u805a\u7126\u6a21\u5f0f\uff0c\u4ec5\u91cd\u5efa\u5efa\u7b51\u533a\u57df\uff0c\u51cf\u5c1171.8%\u7684\u9ad8\u65af\u57fa\u5143\u6570\u91cf\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7d27\u51d1\u7684\u8868\u793a\u3002  \n\u25c6 \u5728\u57ce\u5e02\u573a\u666f\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u91cd\u5efa\u5b8c\u6574\u5ea6\u63d0\u534720.5%\uff0c\u51e0\u4f55\u7cbe\u5ea6\u63d0\u9ad832.8%\uff0c\u4e3a\u667a\u6167\u57ce\u5e02\u548c\u6570\u5b57\u5b6a\u751f\u7b49\u5e94\u7528\u63d0\u4f9b\u65b0\u601d\u8def\u3002|\n",
    "2508.06968": "|2025-08-09|Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View|Ulas Gunes\u7b49|[2508.06968](http://arxiv.org/pdf/2508.06968)|\u65e0|\u25c6\u9996\u6b21\u5728\u771f\u5b9e\u8d85180\u5ea6\u9c7c\u773c\u56fe\u50cf\u4e0a\u8bc4\u4f30\u4e24\u79cd\u9c7c\u773c\u517c\u5bb9\u76843D\u9ad8\u65af\u6cfc\u6e85\u65b9\u6cd5\uff08Fisheye-GS\u548c3DGUT\uff09\uff0c\u586b\u8865\u4e86\u6781\u7aef\u7578\u53d8\u573a\u666f\u4e0b\u7684\u6280\u672f\u7a7a\u767d\u3002  \n\u25c6\u901a\u8fc7\u5ba4\u5185\u5916200\u5ea6\u9c7c\u773c\u76f8\u673a\u5b9e\u6d4b\uff0c\u7cfb\u7edf\u5206\u6790\u4e0d\u540c\u89c6\u573a\u89d2\uff08200/160/120\u5ea6\uff09\u4e0b\u4e24\u79cd\u65b9\u6cd5\u7684\u6027\u80fd\u5e73\u8861\uff1aFisheye-GS\u5728160\u5ea6\u8868\u73b0\u6700\u4f73\uff0c\u800c3DGUT\u5728\u5168200\u5ea6\u4e0b\u4ecd\u4fdd\u6301\u7a33\u5b9a\u9ad8\u8d28\u91cf\u3002  \n\u25c6\u63d0\u51fa\u57fa\u4e8eUniK3D\u9884\u6d4b\u7684\u6df1\u5ea6\u521d\u59cb\u5316\u7b56\u7565\uff0c\u4ec5\u97002-3\u5f20\u9c7c\u773c\u56fe\u5373\u53ef\u751f\u6210\u7a20\u5bc6\u70b9\u4e91\uff0c\u514b\u670d\u4f20\u7edfSfM\u5728\u5f3a\u7578\u53d8\u573a\u666f\u5931\u6548\u7684\u95ee\u9898\u3002  \n\u25c6\u9a8c\u8bc1UniK3D\u5728\u672a\u8bad\u7ec3\u771f\u5b9e\u9c7c\u773c\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u96fe\u973e\u3001\u7729\u5149\u3001\u5929\u7a7a\u7b49\u590d\u6742\u573a\u666f\u4ecd\u80fd\u5b9e\u73b0\u4e0eSfM\u76f8\u5f53\u76843D\u91cd\u5efa\u8d28\u91cf\u3002  \n\u25c6\u7814\u7a76\u6210\u679c\u8bc1\u5b9e\u4e86\u9c7c\u773c3DGS\u65b9\u6cd5\u5728\u7a00\u758f\u9ad8\u7578\u53d8\u56fe\u50cf\u4e2d\u8fdb\u884c\u5e7f\u89d23D\u91cd\u5efa\u7684\u5b9e\u7528\u4ef7\u503c\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u91cd\u8981\u53c2\u8003\u3002|\n",
    "2508.12292": "|2025-08-17|HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization|Hyebin Ahn\u7b49|[2508.12292](http://arxiv.org/pdf/2508.12292)|\u65e0|\u25c6 \u63d0\u51faHuBERT-VIC\u6a21\u578b\uff0c\u901a\u8fc7\u65b9\u5dee-\u4e0d\u53d8\u6027-\u534f\u65b9\u5dee\u6b63\u5219\u5316\uff08VICReg\uff09\u63d0\u5347\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u5728\u566a\u58f0\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u9996\u6b21\u5c06VICReg\u76ee\u6807\u5e94\u7528\u4e8e\u8bed\u97f3\u9886\u57df\uff0c\u8c03\u6574\u566a\u58f0\u8bed\u97f3\u8868\u5f81\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u589e\u5f3a\u6a21\u578b\u5bf9\u591a\u6837\u5316\u58f0\u5b66\u7279\u5f81\u7684\u6355\u6349\u80fd\u529b\u3002  \n\u25c6 \u901a\u8fc7\u8054\u5408\u4f18\u5316\u65b9\u5dee\u3001\u4e0d\u53d8\u6027\u548c\u534f\u65b9\u5dee\u7ea6\u675f\uff0c\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u4e0d\u540c\u566a\u58f0\u7c7b\u578b\u4e2d\u7684\u6cdb\u5316\u6027\u80fd\u3002  \n\u25c6 \u5728HuBERT\u6a21\u578b\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\uff0cLibriSpeech\u6d4b\u8bd5\u96c6\u4e0a\u76f8\u5bf9\u6027\u80fd\u63d0\u534723.3%\uff08clean\uff09\u548c13.2%\uff08other\uff09\u3002  \n\u25c6 \u4e3a\u89e3\u51b3\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u56e0\u4f9d\u8d56\u5e72\u51c0\u6570\u636e\u8bad\u7ec3\u5bfc\u81f4\u7684\u566a\u58f0\u573a\u666f\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2508.12255": "|2025-08-17|What do Speech Foundation Models Learn? Analysis and Applications|Ankita Pasad|[2508.12255](http://arxiv.org/pdf/2508.12255)|\u65e0|\u25c6 \u63d0\u51fa\u8f7b\u91cf\u7ea7\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408\u7edf\u8ba1\u5de5\u5177\u548c\u65e0\u8bad\u7ec3\u4efb\u52a1\uff0c\u7cfb\u7edf\u7814\u7a76\u8bed\u97f3\u57fa\u7840\u6a21\u578b\uff08SFMs\uff09\u5404\u5c42\u7f16\u7801\u7684\u58f0\u5b66\u548c\u8bed\u8a00\u5b66\u77e5\u8bc6\u3002  \n\u25c6 \u9996\u6b21\u5bf9\u591a\u79cdSFMs\u548c\u7edf\u8ba1\u5de5\u5177\u8fdb\u884c\u6a2a\u5411\u5bf9\u6bd4\u7814\u7a76\uff0c\u63ed\u793a\u6a21\u578b\u5185\u90e8\u77e5\u8bc6\u8868\u793a\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u5173\u8054\u6027\u3002  \n\u25c6 \u9488\u5bf9\u53e3\u8bed\u7406\u89e3\uff08SLU\uff09\u9886\u57df\u6570\u636e\u532e\u4e4f\u95ee\u9898\uff0c\u521b\u65b0\u6027\u5730\u8d21\u732e\u4e86\u53e3\u8bed\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff08NER\uff09\u548c\u5b9a\u4f4d\uff08NEL\uff09\u4efb\u52a1\uff0c\u6269\u5145SLU\u8bc4\u6d4b\u57fa\u51c6\u3002  \n\u25c6 \u9a8c\u8bc1\u7aef\u5230\u7aefSFM\u6a21\u578b\u5728SLU\u4efb\u52a1\u4e0a\u7684\u4f18\u8d8a\u6027\uff0c\u5176\u6027\u80fd\u8d85\u8d8a\u4f20\u7edf\u7ea7\u8054\u5f0f\uff08\u8bed\u97f3\u8bc6\u522b+\u6587\u672c\u6a21\u578b\uff09\u65b9\u6cd5\u3002  \n\u25c6 \u5168\u9762\u8bc4\u4f30\u4e0d\u540cSFMs\u53ca\u9002\u914d\u7b56\u7565\u5bf9SLU\u4efb\u52a1\u7684\u5f71\u54cd\uff0c\u4e3a\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002  \n\u25c6 \u901a\u8fc7\u5de5\u5177\u94fe\u548c\u6570\u636e\u96c6\u7684\u53cc\u91cd\u521b\u65b0\uff0c\u63a8\u52a8\u793e\u533a\u5bf9SFMs\u7684\u673a\u7406\u7406\u89e3\u4e0e\u5b9e\u7528\u5316\u5f00\u53d1\u3002|\n",
    "2508.13831": "|2025-08-19|Smooth Flow Matching|Jianbin Tan\u7b49|[2508.13831](http://arxiv.org/pdf/2508.13831)|\u65e0|\u672c\u6587\u63d0\u51faSmooth Flow Matching\uff08SFM\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u51fd\u6570\u578b\u6570\u636e\u7684\u751f\u6210\u5efa\u6a21\u95ee\u9898\u3002\u5176\u6838\u5fc3\u8d21\u732e\u4e0e\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u4e13\u4e3a\u51fd\u6570\u578b\u6570\u636e\u8bbe\u8ba1\uff0c\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u5bf9\u9ad8\u65af\u6027\u6216\u4f4e\u79e9\u5047\u8bbe\u7684\u9650\u5236\uff0c\u6784\u5efa\u534a\u53c2\u6570Copula\u6d41\u751f\u6210\u65e0\u9650\u7ef4\u975e\u9ad8\u65af\u51fd\u6570\u6570\u636e\u3002\n\u25c6 \u8ba1\u7b97\u6548\u7387\u9ad8\u4e14\u80fd\u5904\u7406\u4e0d\u89c4\u5219\u91c7\u6837\u89c2\u6d4b\uff0c\u76f4\u63a5\u4fdd\u8bc1\u751f\u6210\u51fd\u6570\u7684\u5e73\u6ed1\u6027\uff0c\u514b\u670d\u4e86\u73b0\u6709\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u5728\u51fd\u6570\u6570\u636e\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u5c40\u9650\u3002\n\u25c6 \u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u9a8c\u8bc1\u4e86SFM\u5728\u5408\u6210\u6570\u636e\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u5e76\u5728MIMIC-IV\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\u4e0a\u6210\u529f\u751f\u6210\u4e86\u9ad8\u8d28\u91cf\u4e34\u5e8a\u8f68\u8ff9\u66ff\u4ee3\u6570\u636e\u3002\n\u25c6 \u4e3a\u9690\u79c1\u654f\u611f\u573a\u666f\u4e0b\u7684\u7edf\u8ba1\u5206\u6790\u63d0\u4f9b\u4e86\u5b9e\u7528\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7b49\u51fd\u6570\u578b\u6570\u636e\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u6548\u7528\u4ef7\u503c\u3002|\n",
    "2508.14682": "|2025-08-20|GeMS: Efficient Gaussian Splatting for Extreme Motion Blur|Gopi Raju Matta\u7b49|[2508.14682](http://arxiv.org/pdf/2508.14682)|\u65e0|GeMS\u662f\u9996\u4e2a\u76f4\u63a5\u4ece\u6781\u7aef\u8fd0\u52a8\u6a21\u7cca\u56fe\u50cf\u4e2d\u8fdb\u884c3D\u9ad8\u65af\u6e85\u5c04\uff083DGS\uff09\u91cd\u5efa\u7684\u6846\u67b6\uff0c\u65e0\u9700\u4f9d\u8d56\u4efb\u4f55\u6e05\u6670\u56fe\u50cf\u3002\u5176\u6838\u5fc3\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u63d0\u51faVGGSfM\uff0c\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u65b9\u6cd5\uff0c\u76f4\u63a5\u4ece\u6a21\u7cca\u8f93\u5165\u4e2d\u4f30\u8ba1\u76f8\u673a\u4f4d\u59ff\u5e76\u751f\u6210\u70b9\u4e91\u3002\n\u25c6 \u5f15\u51653DGS-MCMC\u65b9\u6cd5\uff0c\u5c06\u9ad8\u65af\u5206\u5e03\u89c6\u4e3a\u6982\u7387\u5206\u5e03\u6837\u672c\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u53d6\u4ee3\u4e86\u4f9d\u8d56\u542f\u53d1\u5f0f densification \u548c pruning \u7684\u4f20\u7edf\u7b56\u7565\u3002\n\u25c6 \u8054\u5408\u4f18\u5316\u76f8\u673a\u8f68\u8ff9\u4e0e\u9ad8\u65af\u53c2\u6570\uff0c\u5b9e\u73b0\u66f4\u7a33\u5b9a\u7684\u4e09\u7ef4\u573a\u666f\u91cd\u5efa\u3002\n\u25c6 \u8fdb\u4e00\u6b65\u63d0\u51faGeMS-E\u53d8\u4f53\uff0c\u96c6\u6210\u4e8b\u4ef6\u76f8\u673a\u6570\u636e\uff0c\u901a\u8fc7\u4e8b\u4ef6\u53cc\u79ef\u5206\u53bb\u6a21\u7cca\uff08EDI\uff09\u751f\u6210\u66f4\u6e05\u6670\u56fe\u50cf\u4ee5\u4f18\u5316\u521d\u59cb\u4f30\u8ba1\u3002\n\u8be5\u6846\u67b6\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u4e25\u91cd\u6a21\u7cca\u4e0b3DGS\u91cd\u5efa\u7684\u6839\u672c\u6027\u6311\u6218\u3002|\n",
    "2508.15457": "|2025-08-21|Enhancing Novel View Synthesis from extremely sparse views with SfM-free 3D Gaussian Splatting Framework|Zongqi He\u7b49|[2508.15457](http://arxiv.org/pdf/2508.15457)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf93D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u5728\u6781\u7aef\u7a00\u758f\u89c6\u89d2\uff08\u5982\u4ec52\u4e2a\u8bad\u7ec3\u89c6\u56fe\uff09\u4e0b\u56e0\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u521d\u59cb\u5316\u5931\u8d25\u5bfc\u81f4\u7684\u6e32\u67d3\u8d28\u91cf\u4e0b\u964d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700SfM\u7684\u65b0\u578b\u6846\u67b6\u3002\u5176\u6838\u5fc3\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u63d0\u51fa\u5bc6\u96c6\u7acb\u4f53\u6a21\u5757\u66ff\u4ee3SfM\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u76f8\u673a\u59ff\u6001\u4f30\u8ba1\u548c\u5168\u5c40\u7a20\u5bc6\u70b9\u4e91\u91cd\u5efa\u5b9e\u73b0\u521d\u59cb\u5316\u3002\n\u25c6 \u8bbe\u8ba1\u8fde\u8d2f\u89c6\u56fe\u63d2\u503c\u6a21\u5757\uff0c\u901a\u8fc7\u63d2\u503c\u76f8\u673a\u59ff\u6001\u5e76\u751f\u6210\u89c6\u89d2\u4e00\u81f4\u7684\u5185\u5bb9\u4f5c\u4e3a\u989d\u5916\u76d1\u7763\u4fe1\u53f7\uff0c\u7f13\u89e3\u7a00\u758f\u8f93\u5165\u7684\u4fe1\u606f\u7a00\u7f3a\u95ee\u9898\u3002\n\u25c6 \u5f15\u5165\u591a\u5c3a\u5ea6\u62c9\u666e\u62c9\u65af\u4e00\u81f4\u6027\u6b63\u5219\u5316\u548c\u81ea\u9002\u5e94\u7a7a\u95f4\u611f\u77e5\u591a\u5c3a\u5ea6\u51e0\u4f55\u6b63\u5219\u5316\uff0c\u663e\u8457\u63d0\u5347\u51e0\u4f55\u7ed3\u6784\u548c\u6e32\u67d3\u5185\u5bb9\u7684\u8d28\u91cf\u3002\n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6781\u7aef\u7a00\u758f\u6761\u4ef6\u4e0bPSNR\u6307\u6807\u63d0\u53472.75dB\uff0c\u5408\u6210\u56fe\u50cf\u7578\u53d8\u5c0f\u4e14\u9ad8\u9891\u7ec6\u8282\u4e30\u5bcc\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002|\n",
    "2508.16465": "|2025-08-25|HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images|Anilkumar Swamy\u7b49|[2508.16465](http://arxiv.org/pdf/2508.16465)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHOSt3R\u7684\u3001\u65e0\u9700\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u624b-\u7269\u4e09\u7ef4\u91cd\u5efa\u65b9\u6cd5\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u6446\u8131\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u5173\u952e\u70b9\u68c0\u6d4b\u6280\u672f\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5173\u952e\u70b9\u68c0\u6d4b\u5668\uff08keypoint-free\uff09\u7684\u9c81\u68d2\u65b9\u6cd5\uff0c\u76f4\u63a5\u4ece\u5355\u76ee\u8fd0\u52a8\u89c6\u9891\u4e2d\u4f30\u8ba1\u624b\u548c\u7269\u4f53\u7684\u4e09\u7ef4\u53d8\u6362\u3002\n\u25c6 \u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8eSfM\u548c\u624b\u90e8\u5173\u952e\u70b9\u4f18\u5316\u7684\u65b9\u6cd5\u5728\u7269\u4f53\u51e0\u4f55\u591a\u6837\u3001\u7eb9\u7406\u5f31\u4ee5\u53ca\u624b\u7269\u4e25\u91cd\u906e\u6321\u60c5\u51b5\u4e0b\u7684\u5931\u6548\u95ee\u9898\u3002\n\u25c6 \u5c06\u6240\u63d0\u7684\u53d8\u6362\u4f30\u8ba1\u65b9\u6cd5\u4e0e\u4e00\u4e2a\u591a\u89c6\u56fe\u91cd\u5efa\u6d41\u7a0b\u96c6\u6210\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u624b-\u7269\u4e09\u7ef4\u5f62\u72b6\u6062\u590d\u3002\n\u25c6 \u8be5\u65b9\u6cd5\u4e0d\u53d7\u7ea6\u675f\uff0c\u4e0d\u4f9d\u8d56\u9884\u5148\u626b\u63cf\u7684\u7269\u4f53\u6a21\u677f\u6216\u76f8\u673a\u5185\u53c2\uff0c\u5177\u6709\u66f4\u5f3a\u7684\u901a\u7528\u6027\u548c\u975e\u4fb5\u5165\u5f0f\u5e94\u7528\u6f5c\u529b\u3002\n\u25c6 \u5728SHOWMe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5728HO3D\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5bf9\u672a\u89c1\u7269\u4f53\u7c7b\u522b\u7684\u6cdb\u5316\u80fd\u529b\u3002|\n",
    "2508.16026": "|2025-08-22|NeuralMeshing: Complete Object Mesh Extraction from Casual Captures|Floris Erich\u7b49|[2508.16026](http://arxiv.org/pdf/2508.16026)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86NeuralMeshing\u7cfb\u7edf\uff0c\u7528\u4e8e\u4ece\u65e5\u5e38\u62cd\u6444\u7684\u591a\u6bb5\u89c6\u9891\u4e2d\u81ea\u52a8\u91cd\u5efa\u7269\u4f53\u7684\u5b8c\u6574\u7f51\u683c\u6a21\u578b\u3002\u5176\u6838\u5fc3\u521b\u65b0\u5982\u4e0b\uff1a\n\u25c6 \u4ec5\u9700\u901a\u8fc7\u666e\u901a\u89c6\u9891\u800c\u975e\u4e13\u4e1a\u626b\u63cf\u8bbe\u5907\u5373\u53ef\u5b9e\u73b0\u5b8c\u6574\u7269\u4f53\u5efa\u6a21\uff0c\u5927\u5e45\u964d\u4f4e\u786c\u4ef6\u95e8\u69db\u3002\n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u591a\u89c6\u9891\u878d\u5408\u7684\u5b8c\u6574\u91cd\u5efa\u65b9\u6848\uff0c\u65e0\u9700\u4f9d\u8d56\u540e\u5904\u7406\u7684\u5b54\u6d1e\u586b\u5145\u6280\u672f\u3002\n\u25c6 \u91c7\u7528\u6700\u5c11\u4eba\u5de5\u5e72\u9884\u7684\u6807\u6ce8\u65b9\u5f0f\uff08\u4ec5\u9700\u5728\u6bcf\u6bb5\u89c6\u9891\u4e2d\u6307\u5b9a\u4e00\u4e2a\u5df2\u77e5\u70b9\uff09\uff0c\u652f\u6301\u901a\u8fc7\u6807\u5b9a\u677f\u6216AR\u6807\u8bb0\u5b9e\u73b0\u81ea\u52a8\u5316\u3002\n\u25c6 \u7ed3\u5408\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u6280\u672f\u5b9e\u73b0\u81ea\u52a8\u5e27\u5b9a\u4f4d\u4e0e\u4e09\u7ef4\u91cd\u5efa\u3002\n\u25c6 \u5f00\u6e90\u7cfb\u7edf\u4ee3\u7801\uff0c\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u548c\u5e94\u7528\u53d1\u5c55\u3002|\n",
    "2508.17972": "|2025-08-25|SAIL-Recon: Large SfM by Augmenting Scene Regression with Localization|Junyuan Deng\u7b49|[2508.17972](http://arxiv.org/pdf/2508.17972)|\u65e0|SAIL-Recon\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5927\u89c4\u6a21\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u7684\u524d\u9988Transformer\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u573a\u666f\u56de\u5f52\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5927\u91cf\u8f93\u5165\u56fe\u50cf\u7684\u95ee\u9898\u3002\n\n\u25c6 \u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u5c06\u89c6\u89c9\u5b9a\u4f4d\u80fd\u529b\u878d\u5165\u573a\u666f\u56de\u5f52\u7f51\u7edc\uff0c\u901a\u8fc7\u7ed3\u5408\u4e24\u79cd\u8303\u5f0f\u7684\u4f18\u52bf\u6765\u63d0\u5347\u5904\u7406\u5927\u89c4\u6a21\u573a\u666f\u7684\u80fd\u529b\u3002\n\u25c6 \u65b9\u6cd5\u9996\u5148\u4ece\u951a\u56fe\u50cf\u5b50\u96c6\u8ba1\u7b97\u51fa\u4e00\u4e2a\u795e\u7ecf\u573a\u666f\u8868\u793a\uff0c\u7136\u540e\u57fa\u4e8e\u6b64\u8868\u793a\u5bf9\u56de\u5f52\u7f51\u7edc\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u91cd\u5efa\u6240\u6709\u8f93\u5165\u56fe\u50cf\u3002\n\u25c6 \u8be5\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u9ad8\u6548\u6269\u5c55\u5230\u5927\u89c4\u6a21\u573a\u666f\uff0c\u8fd8\u5728\u76f8\u673a\u59ff\u6001\u4f30\u8ba1\u548c\u65b0\u89c6\u56fe\u5408\u6210\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\n\u25c6 \u5728\u591a\u4e2a\u6743\u5a01\u6570\u636e\u96c6\uff08\u5982TUM-RGBD\u3001CO3Dv2\u548cTanks & Temples\uff09\u4e0a\u7684\u7efc\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002|\n",
    "2509.01873": "|2025-09-02|Doctoral Thesis: Geometric Deep Learning For Camera Pose Prediction, Registration, Depth Estimation, and 3D Reconstruction|Xueyang Kang|[2509.01873](http://arxiv.org/pdf/2509.01873)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u5f00\u53d1\u4e86\u7ed3\u5408\u51e0\u4f55\u5148\u9a8c\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u51e0\u4f55\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u4e09\u7ef4\u89c6\u89c9\u4e2d\u7684\u5173\u952e\u4efb\u52a1\u3002  \n\u25c6 \u9488\u5bf9\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u3001\u70b9\u4e91\u914d\u51c6\u3001\u6df1\u5ea6\u9884\u6d4b\u53ca\u4e09\u7ef4\u91cd\u5efa\u7b49\u4efb\u52a1\uff0c\u63d0\u51fa\u4e86\u5b9a\u5236\u5316\u7684\u51e0\u4f55\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002  \n\u25c6 \u901a\u8fc7\u5f15\u5165\u6df1\u5ea6\u4fe1\u606f\u3001\u8868\u9762\u6cd5\u7ebf\u548c\u7b49\u53d8\u6027\u7ea6\u675f\u7b49\u51e0\u4f55\u5148\u9a8c\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u8868\u793a\u51c6\u786e\u6027\u4e0e\u9c81\u68d2\u6027\u3002  \n\u25c6 \u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\uff08\u5982SfM\u548cSLAM\uff09\u5728\u975e\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u7279\u5f81\u6a21\u7cca\u548c\u51e0\u4f55\u7ec6\u8282\u7f3a\u5931\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u5728\u6587\u5316\u9057\u4ea7\u4fdd\u62a4\u548cVR/AR\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u63a8\u52a8\u4e86\u4e09\u7ef4\u6620\u5c04\u4e0e\u573a\u666f\u91cd\u5efa\u6280\u672f\u7684\u53d1\u5c55\u3002|\n",
    "2509.06685": "|2025-09-10|VIM-GS: Visual-Inertial Monocular Gaussian Splatting via Object-level Guidance in Large Scenes|Shengkai Zhang\u7b49|[2509.06685](http://arxiv.org/pdf/2509.06685)|\u65e0|VIM-GS\u662f\u4e00\u79cd\u7528\u4e8e\u5927\u573a\u666f\u65b0\u9896\u89c6\u56fe\u5408\u6210\u7684\u89c6\u89c9-\u60ef\u6027\u5355\u76ee\u9ad8\u65af\u6cfc\u6e85\u6846\u67b6\u3002\u5176\u6838\u5fc3\u8d21\u732e\u662f\u89e3\u51b3\u4e86\u5355\u76ee\u56fe\u50cf\u56e0\u7f3a\u4e4f\u51c6\u786e\u6df1\u5ea6\u4fe1\u606f\u800c\u5bfc\u81f4\u6e32\u67d3\u8d28\u91cf\u5dee\u7684\u95ee\u9898\u3002\u5177\u4f53\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6df1\u5ea6\u751f\u6210\u6846\u67b6\uff0c\u5de7\u5999\u5730\u878d\u5408\u4e86\u6765\u81ea\u89c6\u89c9-\u60ef\u6027SLAM\u7684\u7a00\u758f\u4f46\u7cbe\u786e\u7684\u6df1\u5ea6\uff0c\u4e0e\u6765\u81ea\u5927\u57fa\u7840\u6a21\u578b\u7684\u7a20\u5bc6\u4f46\u7c97\u7cd9\u7684\u6df1\u5ea6\u3002\n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u8c61\u5206\u5272\u7684\u6df1\u5ea6\u4f20\u64ad\u7b97\u6cd5\uff0c\u901a\u8fc7\u6e32\u67d3\u7ed3\u6784\u5316\u7269\u4f53\u7684\u50cf\u7d20\u6df1\u5ea6\uff0c\u6709\u6548\u5f25\u5408\u4e86\u7a00\u758f\u8f93\u5165\u4e0e\u7a20\u5bc6\u8f93\u51fa\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002\n\u25c6 \u5f00\u53d1\u4e86\u4e00\u4e2a\u52a8\u6001\u6df1\u5ea6\u4f18\u5316\u6a21\u5757\uff0c\u4e13\u95e8\u5904\u7406\u52a8\u6001\u7269\u4f53\u4e0a\u4e0d\u5b8c\u6574\u7684SLAM\u6df1\u5ea6\uff0c\u5e76\u8fdb\u4e00\u6b65\u4f18\u5316\u7c97\u7cd9\u7684\u5927\u6a21\u578b\u6df1\u5ea6\u4f30\u8ba1\u3002\n\u6700\u7ec8\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u4e86\u9ad8\u8d28\u91cf\u4e14\u51c6\u786e\u7684\u5bc6\u96c6\u6df1\u5ea6\u56fe\uff0c\u4ece\u800c\u652f\u6301\u4e86\u9ad8\u65af\u6cfc\u6e85\u5728\u5927\u573a\u666f\u4e2d\u7684\u9ad8\u6e05\u6e32\u67d3\uff0c\u5728\u516c\u5f00\u548c\u5b9a\u5236\u6570\u636e\u96c6\u4e0a\u5747\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u6e32\u67d3\u8d28\u91cf\u3002|\n",
    "2509.09720": "|2025-09-09|Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision|Akansel Cosgun\u7b49|[2509.09720](http://arxiv.org/pdf/2509.09720)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63a8\u51fa\u4e86\u6fb3\u5927\u5229\u4e9a\u8d85\u5e02\u7269\u4f53\u6570\u636e\u96c6\uff08ASOS\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u4e3a\u673a\u5668\u4eba\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u8bbe\u8ba1\u7684\u5b9e\u7269\u4e0e3D\u6a21\u578b\u57fa\u51c6\u6570\u636e\u96c6\u3002\n\n\u25c6 \u63d0\u4f9b\u4e86\u5305\u542b50\u79cd\u5e38\u89c1\u8d85\u5e02\u5546\u54c1\u7684\u9ad8\u8d28\u91cf3D\u7eb9\u7406\u7f51\u683c\u6570\u636e\u96c6\uff0c\u6240\u6709\u7269\u54c1\u5747\u53ef\u4ece\u6fb3\u5927\u5229\u4e9a\u5927\u578b\u8fde\u9501\u8d85\u5e02\u8f7b\u677e\u8d2d\u5f97\uff0c\u6210\u672c\u4f4e\u5ec9\u4e14\u6613\u4e8e\u83b7\u53d6\u3002\n\u25c6 \u91c7\u7528\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u6280\u672f\u548c\u9ad8\u5206\u8fa8\u7387\u6210\u50cf\u6280\u672f\u751f\u6210\u6c34\u5bc6\u7684\u4e09\u7ef4\u7f51\u683c\uff0c\u6a21\u578b\u8d28\u91cf\u9ad8\u3002\n\u25c6 \u6570\u636e\u96c6\u8986\u76d610\u4e2a\u4e0d\u540c\u7c7b\u522b\uff0c\u7269\u54c1\u5728\u5f62\u72b6\u3001\u5c3a\u5bf8\u548c\u91cd\u91cf\u4e0a\u5177\u6709\u591a\u6837\u6027\uff0c\u589e\u5f3a\u4e86\u5176\u5b9e\u7528\u6027\u3002\n\u25c6 \u4e13\u6ce8\u4e8e\u73b0\u5b9e\u4e16\u754c\u7684\u9002\u7528\u6027\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u6570\u636e\u96c6\u4e2d\u5408\u6210\u6a21\u578b\u6216\u4e13\u7528\u7269\u4f53\u53ef\u53ca\u6027\u6709\u9650\u7684\u7f3a\u9677\u3002\n\u25c6 \u8be5\u6570\u636e\u96c6\u975e\u5e38\u9002\u5408\u7528\u4e8e\u7269\u4f53\u68c0\u6d4b\u3001\u4f4d\u59ff\u4f30\u8ba1\u548c\u673a\u5668\u4eba\u64cd\u4f5c\u7b49\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002|\n",
    "2509.11853": "|2025-09-15|Segmentation-Driven Initialization for Sparse-view 3D Gaussian Splatting|Yi-Hsin Li\u7b49|[2509.11853](http://arxiv.org/pdf/2509.11853)|\u65e0|\u672c\u6587\u9488\u5bf9\u7a00\u758f\u89c6\u56fe\u5408\u6210\u4e2d\u51e0\u4f55\u4e0e\u5916\u89c2\u6062\u590d\u56f0\u96be\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5272\u9a71\u52a8\u521d\u59cb\u5316\u76843D\u9ad8\u65af\u6e85\u5c04\u65b9\u6cd5\uff08SDI-GS\uff09\u3002  \n\u25c6 \u63d0\u51fa\u5229\u7528\u533a\u57df\u5206\u5272\u6280\u672f\u8bc6\u522b\u7ed3\u6784\u663e\u8457\u533a\u57df\uff0c\u66ff\u4ee3\u4f20\u7edf\u4f9d\u8d56\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u6216\u591a\u89c6\u56fe\u7acb\u4f53\uff08MVS\uff09\u7684\u65b9\u6cd5\u3002  \n\u25c6 \u901a\u8fc7\u9009\u62e9\u6027\u4e0b\u91c7\u6837\u7a20\u5bc6\u70b9\u4e91\uff0c\u5927\u5e45\u51cf\u5c113D\u9ad8\u65af\u6570\u91cf\uff0c\u964d\u4f4e\u5185\u5b58\u5360\u7528\u548c\u8ba1\u7b97\u6210\u672c\u3002  \n\u25c6 \u5728\u4fdd\u6301\u573a\u666f\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u9ad8\u8fbe50%\u7684\u9ad8\u65af\u6570\u91cf\u524a\u51cf\uff0c\u5e76\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u3002  \n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6e32\u67d3\u8d28\u91cf\uff08PSNR\u3001SSIM\uff09\uff0c\u4ec5LPIPS\u7565\u6709\u4e0b\u964d\uff0c\u6709\u6548\u63a8\u52a8\u4e863DGS\u5728\u53d7\u9650\u89c6\u89d2\u573a\u666f\u4e2d\u7684\u5b9e\u7528\u5316\u3002|\n",
    "2509.11829": "|2025-09-15|WAFER: A new method to retrieve sun-induced fluorescence based on spectral wavelet decompositions|Veronika Oehl\u7b49|[2509.11829](http://arxiv.org/pdf/2509.11829)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWAFER\u7684\u65b0\u578b\u65e5\u5149\u8bf1\u5bfc\u53f6\u7eff\u7d20\u8367\u5149\uff08SIF\uff09\u53cd\u6f14\u65b9\u6cd5\u3002  \n\u25c6 \u5229\u7528\u5c0f\u6ce2\u5206\u89e3\u6280\u672f\u5904\u7406\u53cd\u5c04\u8f90\u5c04\u548c\u53c2\u8003\u8f90\u5c04\u5149\u8c31\uff0c\u901a\u8fc7\u6bd4\u8f83\u5c0f\u6ce2\u7cfb\u6570\u6765\u72ec\u7acb\u83b7\u53d6\u76f8\u5bf9\u53cd\u5c04\u7387\uff0c\u907f\u514d\u4e86\u8367\u5149\u4e0e\u53cd\u5c04\u7387\u7684\u8026\u5408\u3002  \n\u25c6 \u53ef\u76f4\u63a5\u4ece\u5269\u4f59\u504f\u79fb\u91cf\u4e2d\u63a8\u5bfc\u51fa\u8367\u5149\u4fe1\u53f7\uff0c\u65e0\u9700\u5bf9\u8367\u5149\u5149\u8c31\u5f62\u72b6\u8fdb\u884c\u5148\u9a8c\u5047\u8bbe\uff0c\u51cf\u5c11\u4e86\u6a21\u578b\u504f\u5dee\u3002  \n\u25c6 \u65b9\u6cd5\u9002\u7528\u4e8e\u4efb\u610f\u6ce2\u957f\u7a97\u53e3\u548c\u5168\u5149\u8c31\u8303\u56f4\uff0c\u80fd\u5145\u5206\u5229\u7528\u6240\u6709\u53ef\u7528\u5149\u8c31\u6570\u636e\uff0c\u5e76\u53ef\u5206\u79bb\u4e0d\u540c\u9891\u7387\u7684\u5438\u6536\u7ebf\u7279\u5f81\u3002  \n\u25c6 \u65e0\u9700\u4f9d\u8d56\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u4e14\u5bf9\u53cd\u5c04\u7387\u5f62\u72b6\u7684\u5047\u8bbe\u8981\u6c42\u6781\u4f4e\uff0c\u589e\u5f3a\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u548c\u7075\u6d3b\u6027\u3002  \n\u25c6 \u901a\u8fc7\u5408\u6210\u6570\u636e\u548c\u5b9e\u5730\u6d4b\u91cf\u9a8c\u8bc1\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\uff08iFLD\u548cSFM\uff09\u7ed3\u679c\u4e00\u81f4\uff0c\u4f46\u989d\u5916\u63d0\u4f9b\u4e86\u63a2\u7d22\u771f\u5b9e\u8367\u5149\u5149\u8c31\u5f62\u72b6\u548c\u81ea\u7531\u9009\u62e9\u53cd\u6f14\u7a97\u53e3\u7684\u4f18\u52bf\u3002|\n",
    "2509.11097": "|2025-09-14|3DAeroRelief: The first 3D Benchmark UAV Dataset for Post-Disaster Assessment|Nhut Le\u7b49|[2509.11097](http://arxiv.org/pdf/2509.11097)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63a8\u51fa\u4e86\u9996\u4e2a\u4e13\u95e8\u7528\u4e8e\u707e\u540e\u8bc4\u4f30\u7684\u4e09\u7ef4\u65e0\u4eba\u673a\u57fa\u51c6\u6570\u636e\u96c63DAeroRelief\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u6570\u636e\u7a7a\u767d\u3002  \n\u25c6\u9996\u521b\u9762\u5411\u707e\u540e\u573a\u666f\u7684\u4e09\u7ef4\u8bed\u4e49\u5206\u5272\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u4e13\u6ce8\u4e8e\u771f\u5b9e\u707e\u5bb3\u73af\u5883\u4e2d\u7684\u7cbe\u7ec6\u7ed3\u6784\u635f\u4f24\u8bc6\u522b  \n\u25c6\u91c7\u7528\u4f4e\u6210\u672c\u65e0\u4eba\u673a\u91c7\u96c6\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u5728\u5371\u9669\u533a\u57df\u9ad8\u6548\u3001\u7075\u6d3b\u4e14\u5b89\u5168\u7684\u5927\u89c4\u6a21\u4e09\u7ef4\u6570\u636e\u83b7\u53d6  \n\u25c6\u901a\u8fc7\u8fd0\u52a8\u91cd\u5efa\u548c\u591a\u89c6\u89d2\u7acb\u4f53\u6280\u672f\u751f\u6210\u5bc6\u96c6\u4e09\u7ef4\u70b9\u4e91\uff0c\u5e76\u7ed3\u5408\u4eba\u5de5\u4e8c\u7ef4\u6807\u6ce8\u6295\u5f71\u81f3\u4e09\u7ef4\u7a7a\u95f4\uff0c\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8bed\u4e49\u6ce8\u91ca  \n\u25c6\u6570\u636e\u96c6\u5305\u542b\u771f\u5b9e\u98d3\u98ce\u53d7\u707e\u533a\u57df\u7684\u5927\u89c4\u6a21\u5ba4\u5916\u573a\u666f\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u6570\u636e\u96c6\u5c40\u9650\u4e8e\u57ce\u5e02\u6216\u5ba4\u5185\u73af\u5883\u7684\u4e0d\u8db3  \n\u8bba\u6587\u8fd8\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\u8bc4\u4f30\u4e86\u591a\u79cd\u5148\u8fdb\u4e09\u7ef4\u5206\u5272\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63a8\u52a8\u707e\u540e\u54cd\u5e94\u4e09\u7ef4\u89c6\u89c9\u7cfb\u7edf\u53d1\u5c55\u65b9\u9762\u7684\u5b9e\u7528\u4ef7\u503c\u3002|\n",
    "2509.12759": "|2025-09-18|A-TDOM: Active TDOM via On-the-Fly 3DGS|Yiwei Xu\u7b49|[2509.12759](http://arxiv.org/pdf/2509.12759)|\u65e0|\u25c6 True Digital Orthophoto Map (TDOM) serves as a crucial geospatial product in various fields such as urban management, city planning, land surveying, etc.\n\u25c6 However, traditional TDOM generation methods generally rely on a complex offline photogrammetric pipeline, resulting in delays that hinder real-time applications.\n\u25c6 Moreover, the quality of TDOM may degrade due to various challenges, such as inaccurate camera poses or Digital Surface Model (DSM) and scene occlusions.|\n",
    "2509.12458": "|2025-09-15|Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles|\u00c0lmos Veres-Vit\u00e0lyos\u7b49|[2509.12458](http://arxiv.org/pdf/2509.12458)|\u65e0|\u25c6 Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for navigating indoor and hard-to-reach areas, yet their significant constraints in payload and autonomy have largely prevented their use for complex tasks like high-quality 3-Dimensional (3D) reconstruction.\n\u25c6 To overcome this challenge, we introduce a novel system architecture that enables fully autonomous, high-fidelity 3D scanning of static objects using UAVs weighing under 100 grams.\n\u25c6 Our core innovation lies in a dual-reconstruction pipeline that creates a real-time feedback loop between data capture and flight control.|\n",
    "2509.13414": "|2025-09-18|MapAnything: Universal Feed-Forward Metric 3D Reconstruction|Nikhil Keetha\u7b49|[2509.13414](http://arxiv.org/pdf/2509.13414)|\u65e0|\u25c6 We introduce MapAnything, a unified transformer-based feed-forward model that ingests one or more images along with optional geometric inputs such as camera intrinsics, poses, depth, or partial reconstructions, and then directly regresses the metric 3D scene geometry and cameras.\n\u25c6 MapAnything leverages a factored representation of multi-view scene geometry, i.e., a collection of depth maps, local ray maps, camera poses, and a metric scale factor that effectively upgrades local reconstructions into a globally consistent metric frame.\n\u25c6 Standardizing the supervision and training across diverse datasets, along with flexible input augmentation, enables MapAnything to address a broad range of 3D vision tasks in a single feed-forward pass, including uncalibrated structure-from-motion, calibrated multi-view stereo, monocular depth estimation, camera localization, depth completion, and more.|\n",
    "2509.15548": "|2025-09-26|MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild|Deming Li\u7b49|[2509.15548](http://arxiv.org/pdf/2509.15548)|\u65e0|\u25c6 In-the-wild photo collections often contain limited volumes of imagery and exhibit multiple appearances, e.g., taken at different times of day or seasons, posing significant challenges to scene reconstruction and novel view synthesis.\n\u25c6 Although recent adaptations of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3DGS) have improved in these areas, they tend to oversmooth and are prone to overfitting.\n\u25c6 In this paper, we present MS-GS, a novel framework designed with Multi-appearance capabilities in Sparse-view scenarios using 3DGS.|\n",
    "2509.17270": "|2025-09-21|Reference-aware SFM layers for intrusive intelligibility prediction|Hanlin Yu\u7b49|[2509.17270](http://arxiv.org/pdf/2509.17270)|\u65e0|\u25c6 Intrusive speech-intelligibility predictors that exploit explicit reference signals are now widespread, yet they have not consistently surpassed non-intrusive systems.\n\u25c6 We argue that a primary cause is the limited exploitation of speech foundation models (SFMs).\n\u25c6 This work revisits intrusive prediction by combining reference conditioning with multi-layer SFM representations.|\n",
    "2509.16329": "|2025-09-19|Investigating Polyglot Speech Foundation Models for Learning Collective Emotion from Crowds|Orchid Chetia Phukan\u7b49|[2509.16329](http://arxiv.org/pdf/2509.16329)|\u65e0|\u25c6 This paper investigates the polyglot (multilingual) speech foundation models (SFMs) for Crowd Emotion Recognition (CER).\n\u25c6 We hypothesize that polyglot SFMs, pre-trained on diverse languages, accents, and speech patterns, are particularly adept at navigating the noisy and complex acoustic environments characteristic of crowd settings, thereby offering a significant advantage for CER.\n\u25c6 To substantiate this, we perform a comprehensive analysis, comparing polyglot, monolingual, and speaker recognition SFMs through extensive experiments on a benchmark CER dataset across varying audio durations (1 sec, 500 ms, and 250 ms).|\n",
    "2509.18898": "|2025-09-23|DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring|Pengteng Li\u7b49|[2509.18898](http://arxiv.org/pdf/2509.18898)|\u65e0|\u25c6 In this paper, we propose the first Structure-from-Motion (SfM)-free deblurring 3D Gaussian Splatting method via event camera, dubbed DeblurSplat.\n\u25c6 We address the motion-deblurring problem in two ways.\n\u25c6 First, we leverage the pretrained capability of the dense stereo module (DUSt3R) to directly obtain accurate initial point clouds from blurred images.|\n",
    "2509.19898": "|2025-09-24|Aerial-Ground Image Feature Matching via 3D Gaussian Splatting-based Intermediate View Rendering|Jiangxue Yu\u7b49|[2509.19898](http://arxiv.org/pdf/2509.19898)|\u65e0|\u25c6 The integration of aerial and ground images has been a promising solution in 3D modeling of complex scenes, which is seriously restricted by finding reliable correspondences.\n\u25c6 The primary contribution of this study is a feature matching algorithm for aerial and ground images, whose core idea is to generate intermediate views to alleviate perspective distortions caused by the extensive viewpoint changes.\n\u25c6 First, by using aerial images only, sparse models are reconstructed through an incremental SfM (Structure from Motion) engine due to their large scene coverage.|\n",
    "2509.24126": "|2025-09-28|BOSfM: A View Planning Framework for Optimal 3D Reconstruction of Agricultural Scenes|Athanasios Bacharis\u7b49|[2509.24126](http://arxiv.org/pdf/2509.24126)|\u65e0|\u25c6 Active vision (AV) has been in the spotlight of robotics research due to its emergence in numerous applications including agricultural tasks such as precision crop monitoring and autonomous harvesting to list a few.\n\u25c6 A major AV problem that gained popularity is the 3D reconstruction of targeted environments using 2D images from diverse viewpoints.\n\u25c6 While collecting and processing a large number of arbitrarily captured 2D images can be arduous in many practical scenarios, a more efficient solution involves optimizing the placement of available cameras in 3D space to capture fewer, yet more informative, images that provide sufficient visual information for effective reconstruction of the environment of interest.|\n",
    "2509.23991": "|2025-09-28|RPG360: Robust 360 Depth Estimation with Perspective Foundation Models and Graph Optimization|Dongki Jung\u7b49|[2509.23991](http://arxiv.org/pdf/2509.23991)|\u65e0|\u25c6 The increasing use of 360 images across various domains has emphasized the need for robust depth estimation techniques tailored for omnidirectional images.\n\u25c6 However, obtaining large-scale labeled datasets for 360 depth estimation remains a significant challenge.\n\u25c6 In this paper, we propose RPG360, a training-free robust 360 monocular depth estimation method that leverages perspective foundation models and graph optimization.|\n",
    "2509.23947": "|2025-09-28|CrashSplat: 2D to 3D Vehicle Damage Segmentation in Gaussian Splatting|Drago\u015f-Andrei Chileban\u7b49|[2509.23947](http://arxiv.org/pdf/2509.23947)|\u65e0|\u25c6 Automatic car damage detection has been a topic of significant interest for the auto insurance industry as it promises faster, accurate, and cost-effective damage assessments.\n\u25c6 However, few works have gone beyond 2D image analysis to leverage 3D reconstruction methods, which have the potential to provide a more comprehensive and geometrically accurate representation of the damage.\n\u25c6 Moreover, recent methods employing 3D representations for novel view synthesis, particularly 3D Gaussian Splatting (3D-GS), have demonstrated the ability to generate accurate and coherent 3D reconstructions from a limited number of views.|\n",
    "2509.25191": "|2025-09-29|VGGT-X: When VGGT Meets Dense Novel View Synthesis|Yang Liu\u7b49|[2509.25191](http://arxiv.org/pdf/2509.25191)|\u65e0|\u25c6 We study the problem of applying 3D Foundation Models (3DFMs) to dense Novel View Synthesis (NVS).\n\u25c6 Despite significant progress in Novel View Synthesis powered by NeRF and 3DGS, current approaches remain reliant on accurate 3D attributes (e.g., camera poses and point clouds) acquired from Structure-from-Motion (SfM), which is often slow and fragile in low-texture or low-overlap captures.\n\u25c6 Recent 3DFMs showcase orders of magnitude speedup over the traditional pipeline and great potential for online NVS.|\n",
    "2510.01665": "|2025-10-02|Non-Rigid Structure-from-Motion via Differential Geometry with Recoverable Conformal Scale|Yongbo Chen\u7b49|[2510.01665](http://arxiv.org/pdf/2510.01665)|\u65e0|\u25c6 Non-rigid structure-from-motion (NRSfM), a promising technique for addressing the mapping challenges in monocular visual deformable simultaneous localization and mapping (SLAM), has attracted growing attention.\n\u25c6 We introduce a novel method, called Con-NRSfM, for NRSfM under conformal deformations, encompassing isometric deformations as a subset.\n\u25c6 Our approach performs point-wise reconstruction using 2D selected image warps optimized through a graph-based framework.|\n"
  },
  "Visual Localization": {
    "2504.20379": "|**2025-05-01**|**GSFeatLoc: Visual Localization Using Feature Correspondence on 3D Gaussian Splatting**|Jongwon Lee et.al.|[2504.20379](http://arxiv.org/abs/2504.20379)|null|\n",
    "2505.01113": "|**2025-05-02**|**NeuroLoc: Encoding Navigation Cells for 6-DOF Camera Localization**|Xun Li et.al.|[2505.01113](http://arxiv.org/abs/2505.01113)|null|\n",
    "2505.03565": "|**2025-05-06**|**Thermal-LiDAR Fusion for Robust Tunnel Localization in GNSS-Denied and Low-Visibility Conditions**|Lukas Schichler et.al.|[2505.03565](http://arxiv.org/abs/2505.03565)|null|\n",
    "2505.03422": "|**2025-05-06**|**LiftFeat: 3D Geometry-Aware Local Feature Matching**|Yepeng Liu et.al.|[2505.03422](http://arxiv.org/abs/2505.03422)|**[link](https://github.com/lyp-deeplearning/liftfeat)**|\n",
    "2505.03242": "|**2025-05-06**|**Seeing the Abstract: Translating the Abstract Language for Vision Language Models**|Davide Talon et.al.|[2505.03242](http://arxiv.org/abs/2505.03242)|**[link](https://github.com/davidetalon/fashionact)**|\n",
    "2505.03836": "|**2025-05-04**|**OBD-Finder: Explainable Coarse-to-Fine Text-Centric Oracle Bone Duplicates Discovery**|Chongsheng Zhang et.al.|[2505.03836](http://arxiv.org/abs/2505.03836)|**[link](https://github.com/cszhanglmu/obd-finder)**|\n",
    "2505.01956": "|**2025-05-13**|**SafeNav: Safe Path Navigation using Landmark Based Localization in a GPS-denied Environment**|Ganesh Sapkota et.al.|[2505.01956](http://arxiv.org/abs/2505.01956)|null|\n",
    "2505.12254": "|**2025-05-18**|**MMS-VPR: Multimodal Street-Level Visual Place Recognition Dataset and Benchmark**|Yiwei Ou et.al.|[2505.12254](http://arxiv.org/abs/2505.12254)|null|\n",
    "2505.11620": "|**2025-05-16**|**Improved Bag-of-Words Image Retrieval with Geometric Constraints for Ground Texture Localization**|Aaron Wilhelm et.al.|[2505.11620](http://arxiv.org/abs/2505.11620)|null|\n",
    "2505.11121": "|**2025-05-16**|**Redundancy-Aware Pretraining of Vision-Language Foundation Models in Remote Sensing**|Mathis J\u00fcrgen Adler et.al.|[2505.11121](http://arxiv.org/abs/2505.11121)|null|\n",
    "2505.16447": "|**2025-05-22**|**TAT-VPR: Ternary Adaptive Transformer for Dynamic and Efficient Visual Place Recognition**|Oliver Grainge et.al.|[2505.16447](http://arxiv.org/abs/2505.16447)|null|\n",
    "2505.15877": "|**2025-05-21**|**Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval**|Siting Li et.al.|[2505.15877](http://arxiv.org/abs/2505.15877)|null|\n",
    "2505.15867": "|**2025-05-21**|**SCENIR: Visual Semantic Clarity through Unsupervised Scene Graph Retrieval**|Nikolaos Chaidos et.al.|[2505.15867](http://arxiv.org/abs/2505.15867)|**[link](https://github.com/nickhaidos/scenir-icml2025)**|\n",
    "2505.13828": "|**2025-05-20**|**Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models**|Kiarash Naghavi Khanghah et.al.|[2505.13828](http://arxiv.org/abs/2505.13828)|null|\n",
    "2505.23763": "|**2025-05-29**|**Sketch Down the FLOPs: Towards Efficient Networks for Human Sketch**|Aneeshan Sain et.al.|[2505.23763](http://arxiv.org/abs/2505.23763)|null|\n",
    "2505.22859": "|**2025-05-28**|**4DTAM: Non-Rigid Tracking and Mapping via Dynamic Surface Gaussians**|Hidenobu Matsuki et.al.|[2505.22859](http://arxiv.org/abs/2505.22859)|null|\n",
    "2505.22098": "|**2025-05-28**|**UAVPairs: A Challenging Benchmark for Match Pair Retrieval of Large-scale UAV Images**|Junhuan Liu et.al.|[2505.22098](http://arxiv.org/abs/2505.22098)|null|\n",
    "2505.22089": "|**2025-05-28**|**Fast Feature Matching of UAV Images via Matrix Band Reduction-based GPU Data Schedule**|San Jiang et.al.|[2505.22089](http://arxiv.org/abs/2505.22089)|null|\n",
    "2505.21754": "|**2025-05-27**|**Visual Loop Closure Detection Through Deep Graph Consensus**|Martin B\u00fcchner et.al.|[2505.21754](http://arxiv.org/abs/2505.21754)|null|\n",
    "2505.21647": "|**2025-05-27**|**QuARI: Query Adaptive Retrieval Improvement**|Eric Xing et.al.|[2505.21647](http://arxiv.org/abs/2505.21647)|null|\n",
    "2505.20764": "|**2025-05-27**|**ConText-CIR: Learning from Concepts in Text for Composed Image Retrieval**|Eric Xing et.al.|[2505.20764](http://arxiv.org/abs/2505.20764)|null|\n",
    "2505.20291": "|**2025-05-26**|**Visualized Text-to-Image Retrieval**|Di Wu et.al.|[2505.20291](http://arxiv.org/abs/2505.20291)|**[link](https://github.com/xiaowu0162/visualize-then-retrieve)**|\n",
    "2505.19952": "|**2025-05-26**|**Multimodal Reasoning Agent for Zero-Shot Composed Image Retrieval**|Rong-Cheng Tu et.al.|[2505.19952](http://arxiv.org/abs/2505.19952)|null|\n",
    "2505.19944": "|**2025-05-26**|**Can Visual Encoder Learn to See Arrows?**|Naoyuki Terashita et.al.|[2505.19944](http://arxiv.org/abs/2505.19944)|null|\n",
    "2506.02291": "|2025-06-02|Entity Image and Mixed-Modal Image Retrieval Datas...|Cristian-Ioan Blaga\u7b49|[2506.02291](http://arxiv.org/pdf/2506.02291)|\u65e0|\u25c6\u63d0\u51fa\u9996\u4e2a\u7ed3\u5408\u89c6\u89c9\u4e0e\u6587\u672c\u4fe1\u606f\u7684\u6df7\u5408\u6a21\u6001\u56fe\u50cf\u68c0\u7d22\u57fa\u51c6MMIR\uff0c\u5305\u542b\u5355\u5b9e\u4f53\u56fe\u50cf\u548c\u591a\u5b9e\u4f53\u56fe\u50cf\u4e24\u79cd\u590d\u6742\u67e5\u8be2\u7c7b\u578b\u3002  \n\u25c6\u53d1\u5e03Entity Image\u548cMMIR\u4e24\u4e2a\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4f17\u5305\u6807\u6ce8\u9a8c\u8bc1\u6570\u636e\u8d28\u91cf\uff0c...|\n",
    "2506.00976": "|2025-06-01|Quantization-based Bounds on the Wasserstein Metri...|Jonathan Bobrutsky\u7b49|[2506.00976](http://arxiv.org/pdf/2506.00976)|\u65e0|\u25c6\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u91cf\u5316\u7f51\u683c\u7684\u9ad8\u6548Wasserstein\u8ddd\u79bb\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u901a\u8fc7\u7c97\u7f51\u683c\u4e0a\u7684Kantorovich\u95ee\u9898\u7cbe\u786e\u6c42\u89e3\u7ed3\u5408\u5347\u5c3a\u5ea6\u6821\u6b63\u6b65\u9aa4\uff0c\u5728\u4fdd\u63012%\u8bef\u5dee\u5185\u5b9e\u73b010-100\u500d\u52a0\u901f\u3002\u25c6\u521b\u65b0\u6027\u5730\u5728\u539f\u59cb\u7a7a\u95f4...|\n",
    "2505.24441": "|2025-05-30|SORCE: Small Object Retrieval in Com...|Chunxu Liu\u7b49|[2505.24441](http://arxiv.org/pdf/2505.24441)|[\u4ee3\u7801](https://github.com/mcg-nju/sorce)|\u25c6\u63d0\u51fa\u65b0\u4efb\u52a1SORCE\uff08\u590d\u6742\u73af\u5883\u4e2d\u7684\u5c0f\u7269\u4f53\u68c0\u7d22\uff09\uff0c\u4e13\u6ce8\u4e8e\u901a\u8fc7\u6587\u672c\u67e5\u8be2\u68c0\u7d22\u590d\u6742\u56fe\u50cf\u4e2d\u7684\u4e0d\u663e\u773c\u5c0f\u7269\u4f53\u3002  \n\u25c6\u6784\u5efa\u65b0\u57fa\u51c6SORCE-1K\uff0c\u5305\u542b\u590d\u6742\u73af\u5883\u56fe\u50cf\u548c\u63cf\u8ff0\u5c0f\u7269\u4f53\u7684\u6587\u672c\u67e5\u8be2\uff0c\u63ed\u793a\u73b0\u6709T2IR\u65b9\u6cd5...|\n",
    "2506.07045": "|2025-06-08|Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs|Yikun Ji\u7b49|[2506.07045](http://arxiv.org/pdf/2506.07045)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u53ef\u89e3\u91caAI\u751f\u6210\u56fe\u50cf\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u5b9a\u4f4d\u548c\u6587\u672c\u63a8\u7406\u80fd\u529b\uff0c\u4e0d\u4ec5\u68c0\u6d4b\u51c6\u786e\u7387\u9ad8\uff0c\u8fd8\u80fd\u63d0\u4f9b\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u89e3\u91ca\u3002  \n\u25c6 \u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8fb9\u754c\u6846\u6807\u6ce8\u548c\u63cf\u8ff0\u6027\u6587\u672c\u7684\u6570\u636e\u96c6\uff0c\u7a81\u51faAI\u751f\u6210\u56fe\u50cf\u7684\u5408\u6210\u4f2a\u5f71\uff0c\u4e3a\u6a21\u578b\u63d0\u4f9b\u89c6\u89c9-\u6587\u672c\u5bf9\u9f50\u7684\u63a8\u7406\u57fa\u7840\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u591a\u9636\u6bb5\u4f18\u5316\u7b56\u7565\uff0c\u9010\u6b65\u5e73\u8861\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u89c6\u89c9\u5b9a\u4f4d\u80fd\u529b\u548c\u6587\u672c\u89e3\u91ca\u8fde\u8d2f\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709MLLMs\u5728\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7\u5fae\u8c03MLLMs\uff0c\u4f7f\u5176\u80fd\u591f\u540c\u65f6\u5b9a\u4f4d\u56fe\u50cf\u4e2d\u7684\u89c6\u89c9\u7f3a\u9677\u5e76\u751f\u6210\u5408\u7406\u7684\u89e3\u91ca\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002  \n\u25c6 \u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4bAI\u751f\u6210\u56fe\u50cf\u548c\u5b9a\u4f4d\u89c6\u89c9\u7455\u75b5\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e3a\u53ef\u89e3\u91ca\u7684\u4f2a\u9020\u68c0\u6d4b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2506.06602": "|2025-06-07|Zero Shot Composed Image Retrieval|Santhosh Kakarla\u7b49|[2506.06602](http://arxiv.org/pdf/2506.06602)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eBLIP-2\u7684\u8f7b\u91cf\u7ea7Q-Former\u6a21\u578b\uff0c\u901a\u8fc7\u878d\u5408\u89c6\u89c9\u548c\u6587\u672c\u7279\u5f81\u5230\u5355\u4e00\u5d4c\u5165\uff0c\u663e\u8457\u63d0\u5347\u4e86\u96f6\u6837\u672c\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\uff08Zero-shot CIR\uff09\u7684\u6027\u80fd\u3002  \n\u25c6 \u5728FashionIQ\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5c06Recall@10\u6307\u6807\u4ece\u539f\u5148\u768420-25%\u5927\u5e45\u63d0\u5347\u81f345.6%\uff08\u886c\u886b\uff09\u300140.1%\uff08\u88d9\u5b50\uff09\u548c50.4%\uff08T\u6064\uff09\uff0c\u5e73\u5747Recall@50\u8fbe\u523067.6%\u3002  \n\u25c6 \u63a2\u7d22\u4e86Retrieval-DPO\u65b9\u6cd5\uff0c\u5c1d\u8bd5\u901a\u8fc7\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u635f\u5931\u5fae\u8c03CLIP\u6587\u672c\u7f16\u7801\u5668\uff0c\u4f46\u53d1\u73b0\u5176\u6548\u679c\u8fdc\u4f4e\u4e8e\u57fa\u7ebf\uff08\u4ec50.02% Recall@10\uff09\u3002  \n\u25c6 \u5206\u6790\u4e86Retrieval-DPO\u5931\u8d25\u7684\u56db\u5927\u539f\u56e0\uff1a\u7f3a\u4e4f\u56fe\u50cf-\u6587\u672c\u8054\u5408\u878d\u5408\u3001\u76ee\u6807\u51fd\u6570\u4e0eTop-K\u6307\u6807\u4e0d\u5339\u914d\u3001\u8d1f\u6837\u672c\u8d28\u91cf\u4f4e\uff0c\u4ee5\u53ca\u89c6\u89c9\u548cTransformer\u5c42\u51bb\u7ed3\u3002  \n\u25c6 \u7814\u7a76\u8868\u660e\uff0c\u6709\u6548\u7684\u57fa\u4e8e\u504f\u597d\u7684CIR\u9700\u8981\u771f\u6b63\u7684\u591a\u6a21\u6001\u878d\u5408\u3001\u4e0e\u6392\u540d\u76f8\u5173\u7684\u76ee\u6807\u51fd\u6570\uff0c\u4ee5\u53ca\u7cbe\u5fc3\u7b5b\u9009\u7684\u8d1f\u6837\u672c\u3002|\n",
    "2506.06220": "|2025-06-06|GenIR: Generative Visual Feedback for Mental Image Retrieval|Diji Yang\u7b49|[2506.06220](http://arxiv.org/pdf/2506.06220)|\u65e0|\u25c6 \u63d0\u51faMental Image Retrieval (MIR)\u4efb\u52a1\uff0c\u7814\u7a76\u7528\u6237\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u4ece\u6a21\u7cca\u5fc3\u7406\u56fe\u50cf\u4e2d\u68c0\u7d22\u76ee\u6807\u56fe\u50cf\u7684\u771f\u5b9e\u573a\u666f\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6587\u672c-\u56fe\u50cf\u68c0\u7d22\u7814\u7a76\u7684\u7a7a\u767d\u3002  \n\u25c6 \u8bbe\u8ba1GenIR\u65b9\u6cd5\uff0c\u9996\u6b21\u5229\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u53ef\u89c6\u5316\u53cd\u9988\uff0c\u5c06AI\u7cfb\u7edf\u5bf9\u7528\u6237\u610f\u56fe\u7684\u7406\u89e3\u8f6c\u5316\u4e3a\u76f4\u89c2\u7684\u5408\u6210\u56fe\u50cf\uff0c\u514b\u670d\u4f20\u7edf\u62bd\u8c61\u8bed\u8a00\u53cd\u9988\u7684\u6a21\u7cca\u6027\u95ee\u9898\u3002  \n\u25c6 \u6784\u5efa\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u751f\u6210\u9ad8\u8d28\u91cf\u591a\u8f6eMIR\u6570\u636e\u96c6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u57fa\u51c6\u652f\u6301\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eGenIR\u5728\u591a\u8f6e\u4ea4\u4e92\u68c0\u7d22\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u751f\u6210\u5f0f\u89c6\u89c9\u53cd\u9988\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u5f00\u521b\u6027\u5730\u5c06\u751f\u6210\u6a21\u578b\u4e0e\u4ea4\u4e92\u5f0f\u68c0\u7d22\u7ed3\u5408\uff0c\u4e3a\u5fc3\u7406\u56fe\u50cf\u68c0\u7d22\u9886\u57df\u5960\u5b9a\u65b0\u8303\u5f0f\uff0c\u63a8\u52a8\u4eba\u673a\u534f\u540c\u641c\u7d22\u7cfb\u7edf\u7684\u53d1\u5c55\u3002|\n",
    "2506.06205": "|2025-06-06|Astra: Toward General-Purpose Mobile Robots via Hierarchical Multimodal Learning|Sheng Chen\u7b49|[2506.06205](http://arxiv.org/pdf/2506.06205)|\u65e0|\u25c6\u63d0\u51faAstra\u53cc\u6a21\u578b\u67b6\u6784\uff08Astra-Global\u548cAstra-Local\uff09\uff0c\u901a\u8fc7\u5206\u5c42\u591a\u6a21\u6001\u5b66\u4e60\u5b9e\u73b0\u901a\u7528\u79fb\u52a8\u673a\u5668\u4eba\u5bfc\u822a\uff0c\u7a81\u7834\u4f20\u7edf\u6a21\u5757\u5316\u7cfb\u7edf\u7684\u5c40\u9650\u6027\u3002  \n\u25c6Astra-Global\u9996\u6b21\u5c06\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u6df7\u5408\u62d3\u6251-\u8bed\u4e49\u56fe\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\u548c\u5168\u5c40\u5b9a\u4f4d\u80fd\u529b\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002  \n\u25c6Astra-Local\u91c7\u7528\u81ea\u76d1\u7763\u8bad\u7ec3\u76844D\u65f6\u7a7a\u7f16\u7801\u5668\u751f\u6210\u9c81\u68d2\u7279\u5f81\uff0c\u652f\u6301\u5c40\u90e8\u8def\u5f84\u89c4\u5212\u548c\u91cc\u7a0b\u8ba1\u4f30\u8ba1\u7b49\u591a\u4efb\u52a1\u5b66\u4e60\u3002  \n\u25c6\u521b\u65b0\u6027\u63d0\u51fa\u57fa\u4e8e\u6d41\u5339\u914d\u548c\u63a9\u7801ESDF\u635f\u5931\u7684\u89c4\u5212\u5934\uff0c\u6709\u6548\u964d\u4f4e\u78b0\u649e\u98ce\u9669\uff0c\u751f\u6210\u66f4\u5b89\u5168\u7684\u5c40\u90e8\u8f68\u8ff9\u3002  \n\u25c6\u91cc\u7a0b\u8ba1\u5934\u901a\u8fc7Transformer\u7f16\u7801\u5668\u878d\u5408\u591a\u4f20\u611f\u5668\u6570\u636e\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u76f8\u5bf9\u4f4d\u59ff\u9884\u6d4b\u3002  \n\u25c6\u5728\u771f\u5b9e\u5ba4\u5185\u573a\u666f\u7684\u79fb\u52a8\u673a\u5668\u4eba\u4e0a\u9a8c\u8bc1\uff0c\u7aef\u5230\u7aef\u4efb\u52a1\u6210\u529f\u7387\u663e\u8457\u63d0\u5347\uff0c\u5c55\u73b0\u5f3a\u6cdb\u5316\u80fd\u529b\u3002|\n",
    "2506.04764": "|2025-06-05|HypeVPR: Exploring Hyperbolic Space for Perspective to Equirectangular Visual Place Recognition|Suhan Woo\u7b49|[2506.04764](http://arxiv.org/pdf/2506.04764)|\u65e0|\u25c6 \u63d0\u51faHypeVPR\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u53cc\u66f2\u7a7a\u95f4\u5d4c\u5165\u5f15\u5165\u900f\u89c6\u5230\u73af\u89c6\uff08P2E\uff09\u89c6\u89c9\u4f4d\u7f6e\u8bc6\u522b\u4efb\u52a1\uff0c\u5229\u7528\u53cc\u66f2\u7a7a\u95f4\u66f4\u9002\u5408\u8868\u793a\u5c42\u6b21\u7ed3\u6784\u7684\u7279\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u5206\u5c42\u7279\u5f81\u805a\u5408\u673a\u5236\uff0c\u5728\u53cc\u66f2\u7a7a\u95f4\u4e2d\u7ec4\u7ec7\u5c40\u90e8\u5230\u5168\u5c40\u7684\u7279\u5f81\u8868\u793a\uff0c\u6709\u6548\u6355\u6349\u5168\u666f\u56fe\u50cf\u7684\u56fa\u6709\u5c42\u6b21\u5173\u7cfb\u3002  \n\u25c6 \u5f00\u53d1\u9ad8\u6548\u7684\u7c97\u5230\u7cbe\u641c\u7d22\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u5339\u914d\u901f\u5ea6\uff08\u6700\u9ad8\u8fbe5\u500d\uff09\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u89e3\u51b3\u8de8\u56fe\u50cf\u7c7b\u578b\u7684\u9c81\u68d2\u5339\u914d\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7\u53cc\u66f2\u7a7a\u95f4\u7684\u8ddd\u79bb\u4fdd\u6301\u7279\u6027\uff0c\u4f18\u5316\u7279\u5f81\u7a7a\u95f4\u4e2d\u7684\u8ddd\u79bb\u5ea6\u91cf\uff0c\u589e\u5f3a\u4e0d\u540c\u89c6\u89d2\u4e0b\u63cf\u8ff0\u7b26\u7684\u533a\u5206\u80fd\u529b\u3002  \n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u68c0\u7d22\u65f6\u95f4\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u548c\u6a21\u578b\uff0c\u63a8\u52a8\u76f8\u5173\u9886\u57df\u7814\u7a76\u3002|\n",
    "2506.04619": "|2025-06-05|Deep Learning Reforms Image Matching: A Survey and Outlook|Shihua Zhang\u7b49|[2506.04619](http://arxiv.org/pdf/2506.04619)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u6df1\u5ea6\u5b66\u4e60\u5982\u4f55\u9010\u6b65\u9769\u65b0\u4f20\u7edf\u56fe\u50cf\u5339\u914d\u6d41\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e86\u5206\u7c7b\u6846\u67b6\u3002  \n\u25c6\u521b\u65b0\u70b9\u4e00\uff1a\u9996\u6b21\u4ece\"\u9010\u6b65\u66ff\u4ee3\u4f20\u7edf\u6a21\u5757\"\u548c\"\u7aef\u5230\u7aef\u5408\u5e76\u591a\u6b65\u9aa4\"\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u5bf9\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u5206\u7c7b\uff08\u5305\u62ec\u53ef\u5b66\u4e60\u68c0\u6d4b-...|\n",
    "2506.08526": "|2025-06-10|Robust Visual Localization via Semantic-Guided Multi-Scale Transformer|Zhongtao Tian\u7b49|[2506.08526](http://arxiv.org/pdf/2506.08526)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u5c3a\u5ea6\u7279\u5f81\u5b66\u4e60\u4e0e\u8bed\u4e49\u573a\u666f\u7406\u89e3\u7684\u89c6\u89c9\u5b9a\u4f4d\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u6b21\u5316Transformer\u548c\u8de8\u5c3a\u5ea6\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u51e0\u4f55\u7ec6\u8282\u4e0e\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5728\u4fdd\u6301\u7a7a\u95f4\u7cbe\u5ea6\u7684\u540c\u65f6\u9002\u5e94\u73af\u5883\u53d8\u5316\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u795e\u7ecf\u573a\u666f\u8868\u5f81\u63d0\u4f9b\u7684\u8bed\u4e49\u76d1\u7763\u4fe1\u53f7\uff0c\u6307\u5bfc\u7f51\u7edc\u5b66\u4e60\u89c6\u89d2\u4e0d\u53d8\u7279\u5f81\uff0c\u6709\u6548\u7f16\u7801\u6301\u4e45\u7ed3\u6784\u4fe1\u606f\u5e76\u6291\u5236\u52a8\u6001\u73af\u5883\u5e72\u6270\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u591a\u5c3a\u5ea6Transformer\u67b6\u6784\uff0c\u5229\u7528\u8de8\u5c42\u7ea7\u6ce8\u610f\u529b\u673a\u5236\u6574\u5408\u4e0d\u540c\u5c3a\u5ea6\u7684\u89c6\u89c9\u7ebf\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u573a\u666f\u4e0b\u7684\u5b9a\u4f4d\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5728TartanAir\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u52a8\u6001\u7269\u4f53\u3001\u5149\u7167\u53d8\u5316\u548c\u906e\u6321\u7b49\u6311\u6218\u6027\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u4f4d\u59ff\u56de\u5f52\u65b9\u6cd5\u3002  \n\u25c6 \u9996\u6b21\u9a8c\u8bc1\u4e86\u8bed\u4e49\u5f15\u5bfc\u4e0e\u591a\u5c3a\u5ea6\u5904\u7406\u7684\u534f\u540c\u7b56\u7565\u5bf9\u73b0\u5b9e\u52a8\u6001\u73af\u5883\u4e2d\u89c6\u89c9\u5b9a\u4f4d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u9c81\u68d2\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2506.09748": "|2025-06-11|Hierarchical Image Matching for UAV Absolute Visual Localization via Semantic and Structural Constraints|Xiangkai Zhang\u7b49|[2506.09748](http://arxiv.org/pdf/2506.09748)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u8de8\u6e90\u56fe\u50cf\u5339\u914d\u65b9\u6cd5\uff0c\u7ed3\u5408\u8bed\u4e49\u611f\u77e5\u548c\u7ed3\u6784\u7ea6\u675f\u7684\u7c97\u5339\u914d\u6a21\u5757\u4e0e\u8f7b\u91cf\u7ea7\u7ec6\u7c92\u5ea6\u5339\u914d\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u7edd\u5bf9\u89c6\u89c9\u5b9a\u4f4d\u7684\u7cbe\u5ea6\u3002  \n\u25c6 \u5728\u7c97\u5339\u914d\u6a21\u5757\u4e2d\uff0c\u5229\u7528\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u63d0\u53d6\u7684\u8bed\u4e49\u7279\u5f81\uff0c\u5728\u8bed\u4e49\u548c\u7ed3\u6784\u7ea6\u675f\u4e0b\u5efa\u7acb\u533a\u57df\u7ea7\u5bf9\u5e94\u5173\u7cfb\uff0c\u6709\u6548\u514b\u670d\u4e86\u8de8\u6e90\u5dee\u5f02\u548c\u65f6\u53d8\u56e0\u7d20\u5e26\u6765\u7684\u6311\u6218\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u8f7b\u91cf\u7ea7\u7ec6\u7c92\u5ea6\u5339\u914d\u6a21\u5757\uff0c\u901a\u8fc7\u63d0\u53d6\u7cbe\u7ec6\u7279\u5f81\u5efa\u7acb\u50cf\u7d20\u7ea7\u5bf9\u5e94\u5173\u7cfb\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u3002  \n\u25c6 \u6784\u5efa\u4e86\u4e0d\u4f9d\u8d56\u76f8\u5bf9\u5b9a\u4f4d\u6280\u672f\u7684\u65e0\u4eba\u673a\u7edd\u5bf9\u89c6\u89c9\u5b9a\u4f4d\u6d41\u7a0b\uff0c\u901a\u8fc7\u56fe\u50cf\u68c0\u7d22\u6a21\u5757\u4e0e\u5206\u5c42\u5339\u914d\u6a21\u5757\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u5b8c\u5168\u57fa\u4e8e\u89c6\u89c9\u7684\u5168\u5c40\u5b9a\u4f4d\u3002  \n\u25c6 \u5728\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u548c\u65b0\u63d0\u51fa\u7684CS-UAV\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u7684\u9ad8\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002|\n",
    "2506.10182": "|2025-06-11|Improving Personalized Search with Regularized Low-Rank Parameter Updates|Fiona Ryan\u7b49|[2506.10182](http://arxiv.org/pdf/2506.10182)|[\u4ee3\u7801](https://github.com/adobe-research/polar-vl)|\u25c6 \u63d0\u51fa\u4e00\u79cd\u6b63\u5219\u5316\u4f4e\u79e9\u53c2\u6570\u66f4\u65b0\u65b9\u6cd5\uff0c\u4ec5\u9700\u5fae\u8c03\u8bed\u8a00\u7f16\u7801\u5668\u6700\u540e\u4e00\u5c42\u7684\u5c11\u91cf\u53c2\u6570\uff0c\u5373\u53ef\u6709\u6548\u9002\u5e94\u4e2a\u6027\u5316\u89c6\u89c9-\u8bed\u8a00\u68c0\u7d22\u4efb\u52a1\uff0c\u907f\u514d\u4f20\u7edf\u6587\u672c\u53cd\u8f6c\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u53d1\u73b0\u53c2\u6570\u76f8\u52a0\u7b56\u7565\u80fd\u6709\u6548\u6574\u5408\u591a\u4e2a\u5df2\u5b66\u4e60\u4e2a\u6027\u5316\u6982\u5ff5\u7684\u53c2\u6570\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u591a\u6982\u5ff5\u7ec4\u5408\u7684\u8bc6\u522b\u80fd\u529b\u3002  \n\u25c6 \u5f15\u5165\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u751f\u6210\u63cf\u8ff0\u7684\u56fe\u50cf\u68c0\u7d22\u8bc4\u4f30\u6307\u6807\uff0c\u91cf\u5316\u5fae\u8c03\u540e\u6a21\u578b\u5bf9\u901a\u7528\u77e5\u8bc6\u7684\u4fdd\u7559\u7a0b\u5ea6\u3002  \n\u25c6 \u5728DeepFashion2\u548cConCon-Chi\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u4e2a\u6027\u5316\u68c0\u7d22\u51c6\u786e\u7387\u8f83\u4e4b\u524d\u65b9\u6cd5\u63d0\u53474%-22%\u3002  \n\u25c6 \u901a\u8fc7\u53cc\u7f16\u7801\u5668\u6a21\u578b\u5185\u90e8\u8868\u5f81\u7684\u9488\u5bf9\u6027\u9002\u914d\uff0c\u89e3\u51b3\u4e86\u5c11\u6837\u672c\u573a\u666f\u4e0b\u4e2a\u6027\u5316\u6982\u5ff5\u4e0e\u901a\u7528\u77e5\u8bc6\u878d\u5408\u7684\u96be\u9898\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u4f4e\u79e9\u53c2\u6570\u66f4\u65b0\u5728\u4fdd\u7559\u901a\u7528\u77e5\u8bc6\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u5bf9\"\u6211\u7684\u72d7Fido\"\u7b49\u4e2a\u6027\u5316\u6982\u5ff5\u7684\u8de8\u4e0a\u4e0b\u6587\u8bc6\u522b\u80fd\u529b\u3002|\n",
    "2506.10030": "|2025-06-10|Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment|Tianyu Chen\u7b49|[2506.10030](http://arxiv.org/pdf/2506.10030)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u591a\u6a21\u6001RAG\u7cfb\u7edf\u4e2d\u56fe\u50cf\u77e5\u8bc6\u7248\u6743\u4fdd\u62a4\u7684\u6c34\u5370\u6846\u67b6AQUA\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7a7a\u767d\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e24\u79cd\u4e92\u8865\u7684\u6c34\u5370\u5d4c\u5165\u65b9\u6cd5\uff1a\u57fa\u4e8e\u9996\u5b57\u6bcd\u7f29\u5199\u7684\u89e6\u53d1\u5668\u548c\u7a7a\u95f4\u5173\u7cfb\u7ebf\u7d22\uff0c\u786e\u4fdd\u6c34\u5370\u4fe1\u53f7\u5728\u56fe\u50cf\u5230\u6587\u672c\u7684\u95f4\u63a5\u4f20\u64ad\u4e2d\u4fdd\u6301\u6709\u6548\u3002  \n\u25c6 \u5b9e\u73b0\u4e86\u6c34\u5370\u7684\u9ad8\u6548\u6027\u3001\u5f3a\u9c81\u68d2\u6027\u548c\u4e0d\u53ef\u611f\u77e5\u6027\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u7a33\u5b9a\u5de5\u4f5c\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u73b0\u6709RAG\u6c34\u5370\u6280\u672f\u4ec5\u5173\u6ce8\u6587\u672c\u77e5\u8bc6\u800c\u5ffd\u7565\u56fe\u50cf\u4fdd\u62a4\u7684\u5c40\u9650\u6027\uff0c\u6269\u5c55\u4e86\u7248\u6743\u4fdd\u62a4\u8303\u56f4\u3002  \n\u25c6 \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86AQUA\u5728\u8de8\u6a21\u6001\u573a\u666f\u4e0b\u7684\u53ef\u9760\u6027\uff0c\u652f\u6301\u5bf9\u8d21\u732e\u6570\u636e\u7684\u7cbe\u51c6\u7248\u6743\u8ffd\u8e2a\u3002  \n\u25c6 \u4e3aRAG-as-a-Service\u73af\u5883\u4e2d\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u5171\u4eab\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7248\u6743\u5b89\u5168\u4fdd\u969c\u65b9\u6848\u3002|\n",
    "2506.11167": "|2025-06-11|Towards a general-purpose foundation model for fMRI analysis|Cheng Wang\u7b49|[2506.11167](http://arxiv.org/pdf/2506.11167)|\u65e0|\u25c6 \u63d0\u51faNeuroSTORM\uff0c\u9996\u4e2a\u9762\u5411fMRI\u5206\u6790\u7684\u901a\u7528\u57fa\u7840\u6a21\u578b\uff0c\u76f4\u63a5\u4ece4D fMRI\u6570\u636e\u5b66\u4e60\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u56e0\u590d\u6742\u9884\u5904\u7406\u548c\u4efb\u52a1\u4e13\u7528\u6a21\u578b\u5bfc\u81f4\u7684\u590d\u73b0\u6027\u548c\u8fc1\u79fb\u6027\u4e0d\u8db3\u95ee\u9898\u3002  \n\u25c6 \u91c7\u7528Mamba\u67b6\u6784\u548c\u79fb\u4f4d\u626b\u63cf\u7b56\u7565\uff0c\u9ad8\u6548\u5904\u7406\u5b8c\u65744D fMRI\u4f53\u79ef\uff0c\u7a81\u7834\u4f20\u7edf\u65f6\u7a7a\u5efa\u6a21\u6548\u7387\u74f6\u9888\u3002  \n\u25c6 \u8bbe\u8ba1\u7a7a\u95f4-\u65f6\u95f4\u8054\u5408\u4f18\u5316\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7ed3\u5408\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\u5fae\u8c03\uff08prompt tuning\uff09\uff0c\u663e\u8457\u63d0\u5347\u8de8\u4efb\u52a1\u8fc1\u79fb\u80fd\u529b\u3002  \n\u25c6 \u57fa\u4e8e\u8d85\u5927\u89c4\u6a21\u6570\u636e\u96c6\u9884\u8bad\u7ec3\uff0828.65\u767e\u4e07\u5e27fMRI\uff0c50,000+\u53d7\u8bd5\u8005\uff0c\u8de8\u591a\u4e2d\u5fc3\u53ca5-100\u5c81\u5e74\u9f84\u8303\u56f4\uff09\uff0c\u5efa\u7acb\u8fc4\u4eca\u6700\u5168\u9762\u7684\u8111\u529f\u80fd\u8868\u5f81\u5e93\u3002  \n\u25c6 \u5728\u4e94\u9879\u4efb\u52a1\uff08\u5e74\u9f84/\u6027\u522b\u9884\u6d4b\u3001\u8868\u578b\u9884\u6d4b\u3001\u75be\u75c5\u8bca\u65ad\u3001fMRI-\u56fe\u50cf\u68c0\u7d22\u3001\u4efb\u52a1\u6001\u5206\u7c7b\uff09\u4e2d\u5168\u9762\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u7f8e\u3001\u97e9\u3001\u6fb3\u4e34\u5e8a\u6570\u636e\u9a8c\u8bc1\u4e2d\u5c55\u73b0\u5353\u8d8a\u8bca\u65ad\u6027\u80fd\u3002  \n\u25c6 \u5f00\u6e90\u6807\u51c6\u5316\u6a21\u578b\u6846\u67b6\uff0c\u4e3afMRI\u4e34\u5e8a\u7814\u7a76\u63d0\u4f9b\u53ef\u590d\u73b0\u3001\u53ef\u8fc1\u79fb\u7684\u57fa\u7840\u5de5\u5177\uff0c\u63a8\u52a8\u8111\u75be\u75c5\u8bca\u65ad\u7684\u8de8\u4e2d\u5fc3\u5e94\u7528\u3002|\n",
    "2506.13509": "|2025-06-16|A Semantically-Aware Relevance Measure for Content-Based Medical Image Retrieval Evaluation|Xiaoyang Wei\u7b49|[2506.13509](http://arxiv.org/pdf/2506.13509)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u8bed\u4e49\u611f\u77e5\u76f8\u5173\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u533b\u5b66\u56fe\u50cf\u68c0\u7d22\uff08CBIR\uff09\u7684\u6027\u80fd\u8bc4\u4f30\u96be\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u7528\u533b\u5b66\u6587\u672c\uff08\u5982\u653e\u5c04\u5b66\u62a5\u544a\u6216\u6587\u732e\u63cf\u8ff0\uff09\u4e2d\u9690\u542b\u7684\u533b\u5b66\u6982\u5ff5\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u5bf9\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002  \n\u25c6 \u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u91cf\u5316\u533b\u5b66\u6982\u5ff5\u95f4\u7684\u8bed\u4e49\u8ddd\u79bb\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u5c06\u533b\u5b66\u6982\u5ff5\u89c6\u4e3a\u72ec\u7acb\u6807\u7b7e\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u6355\u6349\u6982\u5ff5\u95f4\u7684\u7ec6\u5fae\u5173\u8054\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u57fa\u4e8e\u8fd1\u4f3c\u5339\u914d\u7684\u76f8\u5173\u6027\u8bc4\u5206\u673a\u5236\uff0c\u901a\u8fc7\u8ba1\u7b97\u4e24\u7ec4\u533b\u5b66\u6982\u5ff5\u7684\u76f8\u4f3c\u6027\u95f4\u63a5\u8861\u91cf\u533b\u5b66\u56fe\u50cf\u7684\u76f8\u4f3c\u5ea6\u3002  \n\u25c6 \u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u884c\u6027\uff0c\u4e3a\u533b\u5b66CBIR\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u7b26\u5408\u4e34\u5e8a\u8bed\u4e49\u7684\u65b0\u6807\u51c6\u3002|\n",
    "2506.13496": "|2025-06-19|Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval|Kshitij Kavimandan\u7b49|[2506.13496](http://arxiv.org/pdf/2506.13496)|\u65e0|\u25c6\u63d0\u51fa\u5206\u5c42\u591a\u6b63\u4f8b\u5bf9\u6bd4\u5b66\u4e60\u635f\u5931\u51fd\u6570\uff0c\u9996\u6b21\u5229\u7528Locarno\u56fd\u9645\u5206\u7c7b\u4f53\u7cfb\uff08LIC\uff09\u7684\u5c42\u7ea7\u5173\u7cfb\u6307\u5bfc\u4e13\u5229\u56fe\u50cf\u68c0\u7d22\u3002  \n\u25c6\u901a\u8fc7\u5c42\u7ea7\u5206\u7c7b\u6811\u52a8\u6001\u5206\u914d\u591a\u7ec4\u6b63\u6837\u672c\u5bf9\uff0c\u6839\u636e\u4e13\u5229\u56fe\u50cf\u5728LIC\u4e2d\u7684\u5c42\u7ea7\u8ddd\u79bb\u8d4b\u4e88\u4e0d\u540c\u76f8\u4f3c\u5ea6\u6743\u91cd\u3002  \n\u25c6\u7a81\u7834\u4f20\u7edf\u5bf9\u6bd4\u5b66\u4e60\u4ec5\u4f7f\u7528\u5355\u4e00\u6837\u672c\u5bf9\u7684\u9650\u5236\uff0c\u80fd\u540c\u65f6\u5b66\u4e60\u8de8\u5c42\u7ea7\u7684\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5173\u8054\u3002  \n\u25c6\u5728DeepPatent2\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u666e\u9002\u6027\uff0c\u53ef\u9002\u914d\u591a\u79cd\u89c6\u89c9\u548c\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u6a21\u578b\u3002  \n\u25c6\u7279\u522b\u4f18\u5316\u4e86\u5c0f\u53c2\u6570\u91cf\u6a21\u578b\u7684\u68c0\u7d22\u6027\u80fd\uff0c\u5728\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u5177\u6709\u663e\u8457\u90e8\u7f72\u4f18\u52bf\u3002  \n\u25c6\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6355\u6349\u4e13\u5229\u56fe\u50cf\u7684\u6280\u672f\u7ec6\u8282\u548c\u590d\u6742\u8bed\u4e49\uff0c\u63d0\u5347\u8de8\u7c7b\u522b\u68c0\u7d22\u51c6\u786e\u7387\u3002|\n",
    "2506.13133": "|2025-06-16|EmbodiedPlace: Learning Mixture-of-Features with Embodied Constraints for Visual Place Recognition|Bingxi Liu\u7b49|[2506.13133](http://arxiv.org/pdf/2506.13133)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7b80\u5355\u91cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408\u7279\u5f81\uff08MoF\uff09\u65b9\u6cd5\u5728\u5177\u8eab\u7ea6\u675f\u4e0b\u4f18\u5316\u5168\u5c40\u7279\u5f81\uff0c\u63d0\u5347\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u6027\u80fd\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u5177\u8eab\u7ea6\u675f\u5728VPR\u4e2d\u7684\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u5e76\u6839\u636e\u73b0\u6709\u6570\u636e\u96c6\u5c06\u5176\u5206\u7c7b\u4e3aGPS\u6807\u7b7e\u3001\u65f6\u5e8f\u6233\u3001\u5c40\u90e8\u7279\u5f81\u5339\u914d\u548c\u81ea\u76f8\u4f3c\u77e9\u9635\u7b49\u7c7b\u578b\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684MoF\u6743\u91cd\u8ba1\u7b97\u7b56\u7565\uff0c\u91c7\u7528\u591a\u5ea6\u91cf\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u878d\u5408\u591a\u79cd\u7279\u5f81\u4fe1\u606f\u3002  \n\u25c6 \u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u4ec5\u970025 KB\u989d\u5916\u53c2\u6570\u548c\u6bcf\u5e2710\u5fae\u79d2\u5904\u7406\u65f6\u95f4\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002  \n\u25c6 \u5728Pitts-30k\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u57fa\u4e8eDINOv2\u7684\u57fa\u7ebf\u6027\u80fd\u63d0\u53470.9%\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\uff0c\u9002\u5408\u5b9e\u9645\u673a\u5668\u4eba\u5e94\u7528\u3002|\n",
    "2506.13073": "|2025-06-16|SuperPlace: The Renaissance of Classical Feature Aggregation for Visual Place Recognition in the Era of Foundation Models|Bingxi Liu\u7b49|[2506.13073](http://arxiv.org/pdf/2506.13073)|\u65e0|\u25c6 \u63d0\u51faSuperPlace\u6846\u67b6\uff0c\u91cd\u65b0\u5229\u7528\u7ecf\u5178\u7279\u5f81\u805a\u5408\u65b9\u6cd5\uff08\u5982GeM\u548cNetVLAD\uff09\uff0c\u5728\u57fa\u7840\u6a21\u578b\u65f6\u4ee3\u4f18\u5316\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u6027\u80fd\u3002  \n\u25c6 \u5f00\u53d1\u76d1\u7763\u6807\u7b7e\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5b9e\u73b0\u8de8\u591a\u4e2aVPR\u6570\u636e\u96c6\u7684\u7edf\u4e00\u8bad\u7ec3\u6846\u67b6\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u63d0\u51faG\u00b2M\u7279\u5f81\u805a\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ccGeM\u7ed3\u6784\u5b66\u4e60\u7279\u5f81\u56fe\u7684\u4e3b\u6210\u5206\u5e76\u6821\u51c6\u8f93\u51fa\uff0c\u4ec5\u9700\u5341\u5206\u4e4b\u4e00\u7279\u5f81\u7ef4\u5ea6\u5373\u53ef\u8fbe\u5230\u4f18\u5f02\u6548\u679c\u3002  \n\u25c6 \u8bbe\u8ba1NetVLAD-Linear\uff08NVL\uff09\u7684\u4e8c\u6b21\u5fae\u8c03\u7b56\u7565\uff08FT\u00b2\uff09\uff0c\u5148\u5728\u9ad8\u7ef4\u7a7a\u95f4\u5b66\u4e60\u7279\u5f81\u5411\u91cf\uff0c\u518d\u901a\u8fc7\u5355\u7ebf\u6027\u5c42\u538b\u7f29\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eSuperPlace\u7684\u4f18\u8d8a\u6027\uff0cG\u00b2M\u5728\u4f4e\u7ef4\u5ea6\u4e0b\u8868\u73b0\u7a81\u51fa\uff0cNVL-FT\u00b2\u5728MSLS\u6392\u884c\u699c\u4e0a\u6392\u540d\u7b2c\u4e00\u3002|\n",
    "2506.12401": "|2025-06-14|Feature Complementation Architecture for Visual Place Recognition|Weiwei Wang\u7b49|[2506.12401](http://arxiv.org/pdf/2506.12401)|\u65e0|\u25c6 \u63d0\u51fa\u5c40\u90e8-\u5168\u5c40\u7279\u5f81\u4e92\u8865\u7f51\u7edc\uff08LGCN\uff09\uff0c\u901a\u8fc7\u5e76\u884cCNN-ViT\u6df7\u5408\u67b6\u6784\u89e3\u51b3\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u4e2d\u5c40\u90e8\u7ec6\u8282\u4e0e\u5168\u5c40\u4e0a\u4e0b\u6587\u96be\u4ee5\u517c\u987e\u7684\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u52a8\u6001\u7279\u5f81\u878d\u5408\u6a21\u5757\uff08DFM\uff09\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u7a7a\u95f4\u548c\u901a\u9053\u4f9d\u8d56\u5173\u7cfb\u5b9e\u73b0\u81ea\u9002\u5e94\u7279\u5f81\u878d\u5408\uff0c\u63d0\u5347\u7279\u5f81\u8868\u8fbe\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5728\u51bb\u7ed3\u7684ViT\u4e3b\u5e72\u4e2d\u5f15\u5165\u8f7b\u91cf\u7ea7\u9891\u57df-\u7a7a\u95f4\u878d\u5408\u9002\u914d\u5668\uff0c\u4ee5\u53ef\u63a7\u53c2\u6570\u91cf\u5b9e\u73b0\u4efb\u52a1\u7279\u5b9a\u9002\u914d\uff0c\u589e\u5f3aViT\u5206\u652f\u5bf9VPR\u4efb\u52a1\u7684\u9002\u5e94\u80fd\u529b\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eLGCN\u5728\u591a\u4e2aVPR\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u663e\u8457\u63d0\u5347\u3002  \n\u25c6 \u6574\u4f53\u67b6\u6784\u517c\u987e\u8ba1\u7b97\u6548\u7387\u4e0e\u6027\u80fd\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e0b\u7684\u673a\u5668\u4eba\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2506.14707": "|2025-06-17|HARMONY: A Scalable Distributed Vector Database for High-Throughput Approximate Nearest Neighbor Search|Qian Xu\u7b49|[2506.14707](http://arxiv.org/pdf/2506.14707)|\u65e0|\u25c6 \u63d0\u51faHarmony\u5206\u5e03\u5f0f\u5411\u91cf\u6570\u636e\u5e93\uff0c\u89e3\u51b3\u5355\u673a\u5904\u7406\u9ad8\u7ef4\u5411\u91cf\u65f6\u7684\u5185\u5b58\u548c\u6548\u7387\u74f6\u9888\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u591a\u7c92\u5ea6\u5206\u533a\u7b56\u7565\uff0c\u7ed3\u5408\u57fa\u4e8e\u7ef4\u5ea6\u548c\u57fa\u4e8e\u5411\u91cf\u7684\u5206\u533a\u65b9\u6cd5\uff0c\u5b9e\u73b0\u8ba1\u7b97\u8d1f\u8f7d\u5747\u8861\u3002  \n\u25c6 \u901a\u8fc7\u4f18\u5316\u5206\u533a\u7b56\u7565\u6709\u6548\u964d\u4f4e\u8282\u70b9\u95f4\u901a\u4fe1\u5f00\u9500\uff0c\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u541e\u5410\u91cf\u3002  \n\u25c6 \u5f15\u5165\u57fa\u4e8e\u8ddd\u79bb\u8ba1\u7b97\u5355\u8c03\u6027\u7684\u65e9\u671f\u505c\u6b62\u526a\u679d\u673a\u5236\uff0c\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u3002  \n\u25c6 \u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHarmony\u5728\u56db\u8282\u70b9\u914d\u7f6e\u4e0b\u5e73\u5747\u541e\u5410\u91cf\u8fbe\u5230\u73b0\u6709\u65b9\u6848\u76844.63\u500d\u3002  \n\u25c6 \u9488\u5bf9\u503e\u659c\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u6027\u80fd\u6bd4\u4f20\u7edf\u5206\u5e03\u5f0f\u65b9\u6848\u63d0\u534758%\uff0c\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u8d1f\u8f7d\u9002\u5e94\u80fd\u529b\u3002|\n",
    "2506.14178": "|2025-06-17|TACS-Graphs: Traversability-Aware Consistent Scene Graphs for Ground Robot Indoor Localization and Mapping|Jeewon Kim\u7b49|[2506.14178](http://arxiv.org/pdf/2506.14178)|\u65e0|\u25c6 \u63d0\u51faTACS-Graphs\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u5730\u9762\u673a\u5668\u4eba\u53ef\u901a\u884c\u6027\uff08traversability\uff09\u4e0e\u623f\u95f4\u5206\u5272\u76f8\u7ed3\u5408\uff0c\u89e3\u51b3\u4f20\u7edf3D\u573a\u666f\u56fe\u4e2d\u623f\u95f4\u5c42\u5206\u5272\u4e0d\u4e00\u81f4\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7\u53ef\u901a\u884c\u6027\u7ea6\u675f\u91cd\u65b0\u5b9a\u4e49\u623f\u95f4\u8fb9\u754c\uff0c\u514b\u670d\u4f53\u7d20\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u51e0\u4f55\u90bb\u8fd1\u6027\u5bfc\u81f4\u7684\u6b20\u5206\u5272\uff08\u5f00\u653e\u7a7a\u95f4\u8bef\u5224\uff09\u548c\u8fc7\u5206\u5272\uff08\u590d\u6742\u73af\u5883\u788e\u7247\u5316\uff09\u7f3a\u9677\u3002  \n\u25c6 \u6784\u5efa\u62d3\u6251\u4e0e\u8bed\u4e49\u66f4\u4e00\u81f4\u7684\u573a\u666f\u56fe\uff0c\u5728\u7ed3\u6784\u590d\u6742\u5ba4\u5185\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u623f\u95f4\u5c42\u8bed\u4e49\u5206\u5272\u3002  \n\u25c6 \u5f00\u53d1\u57fa\u4e8e\u4e00\u81f4\u6027\u573a\u666f\u56fe\u7684\u95ed\u73af\u68c0\u6d4b\u65b9\u6cd5\uff08CoSG-LCD\uff09\uff0c\u5229\u7528\u589e\u5f3a\u7684\u5206\u5272\u4e00\u81f4\u6027\u63d0\u5347\u95ed\u73af\u68c0\u6d4b\u6548\u7387\uff0c\u8fdb\u800c\u63d0\u9ad8\u4f4d\u59ff\u4f30\u8ba1\u7cbe\u5ea6\u3002  \n\u25c6 \u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u5728\u573a\u666f\u56fe\u4e00\u81f4\u6027\u548c\u4f4d\u59ff\u56fe\u4f18\u5316\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u6280\u672f\uff0c\u4e3a\u673a\u5668\u4eba\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u73af\u5883\u8868\u5f81\u3002|\n",
    "2506.15180": "|2025-06-18|ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections|Ziling Huang\u7b49|[2506.15180](http://arxiv.org/pdf/2506.15180)|\u65e0|\u25c6 \u63d0\u51faReSeDis\u4efb\u52a1\uff0c\u9996\u6b21\u5c06\u5927\u89c4\u6a21\u56fe\u50cf\u68c0\u7d22\u4e0e\u50cf\u7d20\u7ea7\u5b9a\u4f4d\u7ed3\u5408\uff0c\u8981\u6c42\u6a21\u578b\u6839\u636e\u6587\u672c\u63cf\u8ff0\u5728\u56fe\u50cf\u5e93\u4e2d\u68c0\u7d22\u76ee\u6807\u5e76\u7cbe\u786e\u5b9a\u4f4d\u5176\u4f4d\u7f6e\uff08\u8fb9\u754c\u6846\u6216\u5206\u5272\u63a9\u7801\uff09\u3002  \n\u25c6 \u6784\u5efa\u9996\u4e2a\u9488\u5bf9\u8be5\u4efb\u52a1\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u786e\u4fdd\u6bcf\u4e2a\u63cf\u8ff0\u552f\u4e00\u5bf9\u5e94\u5206\u6563\u5728\u5927\u89c4\u6a21\u591a\u6837\u5316\u56fe\u50cf\u5e93\u4e2d\u7684\u76ee\u6807\u5b9e\u4f8b\uff0c\u907f\u514d\u8bef\u5339\u914d\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u8054\u5408\u8bc4\u4f30\u6307\u6807\uff0c\u540c\u65f6\u8861\u91cf\u68c0\u7d22\u53ec\u56de\u7387\u4e0e\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u89e3\u51b3\u73b0\u6709\u6280\u672f\u53ea\u80fd\u5355\u72ec\u8bc4\u4f30\u67d0\u4e00\u65b9\u9762\u7684\u5c40\u9650\u3002  \n\u25c6 \u63d0\u4f9b\u57fa\u4e8e\u51bb\u7ed3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63ed\u793a\u8be5\u4efb\u52a1\u672a\u6765\u7814\u7a76\u7684\u5de8\u5927\u63d0\u5347\u7a7a\u95f4\u3002  \n\u25c6 \u4e3a\u6784\u5efa\u4e0b\u4e00\u4ee3\u9c81\u68d2\u3001\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u771f\u5b9e\u7aef\u5230\u7aef\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5f25\u8865\u73b0\u6709\u6280\u672f\uff08\u89c6\u89c9\u5b9a\u4f4d\u5047\u8bbe\u76ee\u6807\u5fc5\u7136\u5b58\u5728\uff0c\u6587\u672c\u68c0\u7d22\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u5b9a\u4f4d\uff09\u7684\u4e0d\u8db3\u3002|\n",
    "2506.16745": "|2025-06-20|Class Agnostic Instance-level Descriptor for Visual Instance Search|Qi-Ying Sun\u7b49|[2506.16745](http://arxiv.org/pdf/2506.16745)|\u65e0|\u25c6\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u76d1\u7763ViT\u7684\u7c7b\u65e0\u5173\u5b9e\u4f8b\u7ea7\u63cf\u8ff0\u7b26\uff0c\u89e3\u51b3\u4e86\u89c6\u89c9\u5b9e\u4f8b\u641c\u7d22\u4e2d\u7f3a\u4e4f\u6709\u6548\u5b9e\u4f8b\u7ea7\u7279\u5f81\u8868\u793a\u7684\u95ee\u9898\u3002  \n\u25c6\u901a\u8fc7\u5c42\u6b21\u5316\u5206\u89e3\u7279\u5f81\u96c6\uff0c\u5c06\u5b9e\u4f8b\u533a\u57df\u53d1\u73b0\u5efa\u6a21\u4e3a\u68c0\u6d4b\u7d27\u51d1\u7279\u5f81\u5b50\u96c6\u7684\u8fc7\u7a0b\uff0c\u751f\u6210\u591a\u5c42\u6b21\u7684\u8bed\u4e49\u7279\u5f81\u5b50\u96c6\u3002  \n\u25c6\u6784\u5efa\u7684\u7279\u5f81\u5c42\u6b21\u7ed3\u6784\u4e2d\uff0c\u975e\u53f6\u8282\u70b9\u548c\u53f6\u8282\u70b9\u5bf9\u5e94\u56fe\u50cf\u4e2d\u4e0d\u540c\u8bed\u4e49\u5c3a\u5ea6\u7684\u5b9e\u4f8b\u533a\u57df\uff0c\u6709\u6548\u5904\u7406\u4e86\u7269\u4f53\u5d4c\u5165\u548c\u906e\u6321\u95ee\u9898\u3002  \n\u25c6\u751f\u6210\u7684\u8282\u70b9\u7279\u5f81\u6784\u6210\u56fe\u50cf\u7684\u5168\u9762\u5b9e\u4f8b\u8868\u793a\uff0c\u9002\u7528\u4e8e\u5df2\u77e5\u548c\u672a\u77e5\u7269\u4f53\u7c7b\u522b\uff0c\u5177\u6709\u5f3a\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6\u5728\u4e09\u4e2a\u5b9e\u4f8b\u641c\u7d22\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002|\n",
    "2506.16353": "|2025-06-19|MambaHash: Visual State Space Deep Hashing Model for Large-Scale Image Retrieval|Chao He\u7b49|[2506.16353](http://arxiv.org/pdf/2506.16353)|[\u4ee3\u7801](https://github.com/shuaichaochao/mambahash)|\u25c6 \u9996\u6b21\u5c06\u89c6\u89c9\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08Mamba\uff09\u5f15\u5165\u5927\u89c4\u6a21\u56fe\u50cf\u54c8\u5e0c\u68c0\u7d22\u4efb\u52a1\uff0c\u63a2\u7d22\u5176\u5728\u8be5\u9886\u57df\u7684\u9002\u7528\u6027\u548c\u4f18\u52bf\u3002  \n\u25c6 \u63d0\u51fa\u5206\u9636\u6bb5\u7684\u4e3b\u5e72\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u7ec4Mamba\u64cd\u4f5c\u5b9e\u73b0\u591a\u65b9\u5411\u626b\u63cf\uff0c\u6709\u6548\u5efa\u6a21\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u606f\u3002  \n\u25c6 \u8bbe\u8ba1\u901a\u9053\u4ea4\u4e92\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u589e\u5f3a\u8de8\u901a\u9053\u4fe1\u606f\u4ea4\u6d41\uff0c\u63d0\u5347\u7279\u5f81\u8868\u8fbe\u80fd\u529b\u3002  \n\u25c6 \u5f00\u53d1\u81ea\u9002\u5e94\u7279\u5f81\u589e\u5f3a\u6a21\u5757\uff0c\u589e\u52a0\u7279\u5f81\u591a\u6837\u6027\u5e76\u5f3a\u5316\u6a21\u578b\u7684\u89c6\u89c9\u8868\u793a\u80fd\u529b\u3002  \n\u25c6 \u5728CIFAR-10\u3001NUS-WIDE\u548cIMAGENET\u7b49\u4e3b\u6d41\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u76f8\u6bd4\u73b0\u6709\u6df1\u5ea6\u54c8\u5e0c\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u6548\u7387\u548c\u68c0\u7d22\u6027\u80fd\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\uff0c\u4e3a\u7ebf\u6027\u590d\u6742\u5ea6\u6a21\u578b\u5728\u56fe\u50cf\u68c0\u7d22\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u65b0\u601d\u8def\u3002|\n",
    "2506.16273": "|2025-06-19|Fine-grained Image Retrieval via Dual-Vision Adaptation|Xin Jiang\u7b49|[2506.16273](http://arxiv.org/pdf/2506.16273)|\u65e0|\u25c6\u63d0\u51fa\u53cc\u89c6\u89c9\u9002\u5e94\uff08DVA\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6837\u672c\u548c\u7279\u5f81\u534f\u540c\u9002\u914d\u89e3\u51b3\u7ec6\u7c92\u5ea6\u56fe\u50cf\u68c0\u7d22\uff08FGIR\uff09\u4e2d\u9884\u8bad\u7ec3\u6a21\u578b\u6613\u8fc7\u62df\u5408\u7684\u95ee\u9898\uff0c\u4fdd\u7559\u9884\u8bad\u7ec3\u77e5\u8bc6\u7684\u540c\u65f6\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6\u8bbe\u8ba1\u5bf9\u8c61\u611f\u77e5\u9002\u914d\uff08Object-Perceptual Adaptation\uff09\uff0c\u901a\u8fc7\u4fee\u6539\u8f93\u5165\u6837\u672c\u5f15\u5bfc\u51bb\u7ed3\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u805a\u7126\u5bf9\u7c7b\u522b\u9884\u6d4b\u5173\u952e\u7684\u7269\u4f53\u53ca\u5c40\u90e8\u7279\u5f81\u3002  \n\u25c6\u63d0\u51fa\u4e0a\u4e0b\u6587\u5185\u9002\u914d\uff08In-Context Adaptation\uff09\uff0c\u4ec5\u5f15\u5165\u5c11\u91cf\u53ef\u8c03\u53c2\u6570\u8fdb\u884c\u7279\u5f81\u9002\u914d\uff0c\u4f7f\u8c03\u6574\u540e\u7684\u7279\u5f81\u66f4\u8d34\u8fd1\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u907f\u514d\u4fee\u6539\u539f\u59cb\u9884\u8bad\u7ec3\u53c2\u6570\u3002  \n\u25c6\u7ed3\u5408\u77e5\u8bc6\u84b8\u998f\u673a\u5236\u63d0\u51fa\u5224\u522b\u611f\u77e5\u8fc1\u79fb\uff08Discrimination Perception Transfer\uff09\uff0c\u5c06\u5bf9\u8c61\u611f\u77e5\u9002\u914d\u4e2d\u7684\u5224\u522b\u77e5\u8bc6\u9ad8\u6548\u8fc1\u79fb\u81f3\u56fe\u50cf\u7f16\u7801\u5668\uff0c\u5e73\u8861\u68c0\u7d22\u6548\u7387\u4e0e\u6027\u80fd\u3002  \n\u25c6\u5b9e\u9a8c\u8868\u660eDVA\u57283\u4e2a\u5206\u5e03\u5185\u548c3\u4e2a\u5206\u5e03\u5916\u7ec6\u7c92\u5ea6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u53ef\u5b66\u4e60\u53c2\u6570\u91cf\u663e\u8457\u5c11\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002|\n",
    "2506.15988": "|2025-06-19|Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation|Connor Malone\u7b49|[2506.15988](http://arxiv.org/pdf/2506.15988)|[\u4ee3\u7801](https://github.com/QVPR/aarapsiproject)|\u25c6 \u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u56db\u79cd\u5e38\u89c1\u5bf9\u6297\u653b\u51fb\u548c\u56db\u79cdVPR\u4e13\u7528\u653b\u51fb\u5bf9\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u5b9a\u4f4d\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u7cfb\u7edf\u7684\u8106\u5f31\u6027\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u95ed\u73af\u7cfb\u7edf\u6846\u67b6\uff0c\u5c06VPR\u3001\u5bf9\u6297\u653b\u51fb\u68c0\u6d4b\u5668\uff08AAD\uff09\u548c\u4e3b\u52a8\u5bfc\u822a\u51b3\u7b56\u76f8\u7ed3\u5408\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6027\u80fd\u4f18\u52bf\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u65b0\u9896\u7684\u5b9e\u9a8c\u8303\u5f0f\uff0c\u8bc1\u660e\u5373\u4f7fAAD\u7684\u68c0\u6d4b\u51c6\u786e\u7387\u6709\u9650\uff08\u5982\u771f\u9633\u6027\u738775%\u3001\u5047\u9633\u6027\u738725%\uff09\uff0c\u4e5f\u80fd\u663e\u8457\u964d\u4f4e\u5e73\u5747\u6cbf\u8f68\u5b9a\u4f4d\u8bef\u5dee\u7ea650%\u3002  \n\u25c6 \u9996\u6b21\u7814\u7a76\u4e86\u5feb\u901f\u68af\u5ea6\u7b26\u53f7\u6cd5\uff08FGSM\uff09\u5bf9\u6297\u653b\u51fb\u5728VPR\u4e2d\u7684\u6709\u6548\u6027\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u591a\u9879\u5173\u952e\u8bc4\u4f30\u6307\u6807\uff08\u5982\u6cbf\u8f68\u8bef\u5dee\u3001\u53d7\u653b\u51fb\u65f6\u95f4\u6bd4\u4f8b\u3001\u4e0d\u5b89\u5168\u72b6\u6001\u65f6\u95f4\u6bd4\u4f8b\u7b49\uff09\uff0c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cf\u5316\u4f9d\u636e\u3002  \n\u25c6 \u5f3a\u8c03\u4e86AAD\u5728\u5b9e\u9645\u673a\u5668\u4eba\u5bfc\u822a\u7cfb\u7edf\u4e2d\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u8d56\u7684\u5bfc\u822a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002|\n",
    "2506.15851": "|2025-06-18|Semantic and Feature Guided Uncertainty Quantification of Visual Localization for Autonomous Vehicles|Qiyuan Wu\u7b49|[2506.15851](http://arxiv.org/pdf/2506.15851)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56fe\u50cf\u7279\u5f81\u548c\u8bed\u4e49\u4fe1\u606f\u7684\u8f7b\u91cf\u7ea7\u4f20\u611f\u5668\u8bef\u5dee\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u89c6\u89c9\u5b9a\u4f4d\u4e2d\u7684\u4e8c\u7ef4\u8bef\u5dee\u5206\u5e03\u3002  \n\u25c6 \u901a\u8fc7\u6761\u4ef6\u5316\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u9690\u542b\u5730\u6355\u6349\u4e86\u672a\u6807\u6ce8\u7684\u5173\u952e\u73af\u5883\u56e0\u7d20\uff08\u5982\u57ce\u5e02/\u9ad8\u901f\u3001\u52a8\u6001/\u9759\u6001\u573a\u666f\u3001\u5b63\u8282\u53d8\u5316\uff09\u3002  \n\u25c6 \u91c7\u7528\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u66ff\u4ee3\u4f20\u7edf\u9ad8\u65af\u5206\u5e03\uff0c\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u6076\u52a3\u5929\u6c14\u548c\u5149\u7167\u6761\u4ef6\u4e0b\u7684\u6d4b\u91cf\u8bef\u5dee\u7279\u6027\u3002  \n\u25c6 \u5728Ithaca365\u591a\u5929\u6c14/\u5149\u7167\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u51c6\u786e\u6027\uff0c\u6db5\u76d6\u6674\u5929\u3001\u591c\u95f4\u548c\u96ea\u5929\u7b49\u590d\u6742\u573a\u666f\u3002  \n\u25c6 \u63d0\u51fa\u72ec\u7279\u7684\u4f20\u611f\u5668\u95e8\u63a7\u65b9\u6cd5\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u5b9a\u4f4d\u6ee4\u6ce2\u5668\u8bc4\u4f30\u4f20\u611f\u5668\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u8054\u5408\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6027\u80fd\u3002  \n\u25c6 \u4e3a\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u5de5\u5177\u3002|\n",
    "2506.18902": "|2025-06-24|jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval|Michael G\u00fcnther\u7b49|[2506.18902](http://arxiv.org/pdf/2506.18902)|\u65e0|\u25c6 \u63d0\u51fajina-embeddings-v4\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u4e2a38\u4ebf\u53c2\u6570\u7684\u591a\u6a21\u6001\u5d4c\u5165\u6a21\u578b\uff0c\u7edf\u4e00\u4e86\u6587\u672c\u548c\u56fe\u50cf\u7684\u8868\u793a\u3002  \n\u25c6 \u91c7\u7528\u65b0\u9896\u7684\u67b6\u6784\uff0c\u652f\u6301\u5355\u5411\u91cf\u548c\u591a\u5411\u91cf\u5d4c\u5165\uff0c\u5e76\u91c7\u7528\u540e\u671f\u4ea4\u4e92\u98ce\u683c\u3002  \n\u25c6 \u5f15\u5165\u4efb\u52a1\u7279\u5b9a\u7684\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u9002\u914d\u5668\uff0c\u4f18\u5316\u4e86\u591a\u79cd\u68c0\u7d22\u573a\u666f\u7684\u6027\u80fd\uff0c\u5305\u62ec\u57fa\u4e8e\u67e5\u8be2\u7684\u4fe1\u606f\u68c0\u7d22\u3001\u8de8\u6a21\u6001\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u7f16\u7a0b\u4ee3\u7801\u641c\u7d22\u3002  \n\u25c6 \u5728\u5355\u6a21\u6001\u548c\u8de8\u6a21\u6001\u68c0\u7d22\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u5904\u7406\u89c6\u89c9\u4e30\u5bcc\u5185\u5bb9\uff08\u5982\u8868\u683c\u3001\u56fe\u8868\u3001\u56fe\u8868\u548c\u6df7\u5408\u5a92\u4f53\u683c\u5f0f\uff09\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u3002  \n\u25c6 \u63d0\u51faJina-VDR\u57fa\u51c6\uff0c\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u4e30\u5bcc\u56fe\u50cf\u68c0\u7d22\u80fd\u529b\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7a7a\u767d\u3002|\n",
    "2506.18246": "|2025-06-26|Referring Expression Instance Retrieval and A Strong End-to-End Baseline|Xiangzhao Hao\u7b49|[2506.18246](http://arxiv.org/pdf/2506.18246)|\u65e0|\u25c6 \u63d0\u51fa\u65b0\u4efb\u52a1REIR\uff08Referring Expression Instance Retrieval\uff09\uff0c\u586b\u8865\u4e86\u4f20\u7edf\u6587\u672c-\u56fe\u50cf\u68c0\u7d22\uff08TIR\uff09\u7cbe\u5ea6\u4e0d\u8db3\u548c\u6307\u4ee3\u8868\u8fbe\u7406\u89e3\uff08REC\uff09\u6269\u5c55\u6027\u5dee\u7684\u7a7a\u767d\uff0c\u652f\u6301\u8de8\u5927\u89c4\u6a21\u56fe\u5e93\u7684\u5b9e\u4f8b\u7ea7\u68c0\u7d22\u4e0e\u5b9a\u4f4d\u3002  \n\u25c6 \u6784\u5efa\u9996\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6REIRCOCO\uff0c\u901a\u8fc7\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7ec6\u7c92\u5ea6\u6307\u4ee3\u8868\u8fbe\uff0c\u57fa\u4e8eMSCOCO\u548cRefCOCO\u5b9e\u4f8b\u589e\u5f3a\u6570\u636e\u591a\u6837\u6027\u3002  \n\u25c6 \u63d0\u51fa\u7aef\u5230\u7aef\u57fa\u7ebf\u65b9\u6cd5CLARE\uff0c\u91c7\u7528\u53cc\u6d41\u67b6\u6784\u8bbe\u8ba1\uff0c\u7ed3\u5408\u76ee\u6807\u68c0\u6d4b\u4e0eREC\u9884\u8bad\u7ec3\uff0c\u5b9e\u73b0\u8de8\u6a21\u6001\u7279\u5f81\u5bf9\u9f50\u3002  \n\u25c6 \u521b\u65b0\u6027\u5f15\u5165Mix of Relation Experts\uff08MORE\uff09\u6a21\u5757\uff0c\u663e\u5f0f\u5efa\u6a21\u5b9e\u4f8b\u95f4\u5173\u7cfb\uff0c\u63d0\u5347\u590d\u6742\u573a\u666f\u4e0b\u7684\u68c0\u7d22\u7cbe\u5ea6\u3002  \n\u25c6 \u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6CLIA\uff08Contrastive Language-Instance Alignment\uff09\u4f18\u5316\u8bed\u8a00-\u5b9e\u4f8b\u5bf9\u9f50\uff0c\u4f7f\u6a21\u578b\u5728REIR\u3001TIR\u548cREC\u4efb\u52a1\u4e0a\u5747\u8fbe\u5230SOTA\u6027\u80fd\u3002  \n\u25c6 \u9a8c\u8bc1\u4e86CLARE\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u9996\u6b21\u5b9e\u73b0\u5355\u4e00\u6a21\u578b\u540c\u65f6\u652f\u6301\u5b9e\u4f8b\u68c0\u7d22\u3001\u7c97\u7c92\u5ea6\u68c0\u7d22\u548c\u7ec6\u7c92\u5ea6\u5b9a\u4f4d\u4e09\u7c7b\u4efb\u52a1\u3002|\n",
    "2506.20467": "|2025-06-25|Visualizing intercalation effects in 2D materials using AFM based techniques|Karmen Kapusti\u0107\u7b49|[2506.20467](http://arxiv.org/pdf/2506.20467)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u539f\u5b50\u529b\u663e\u5fae\u955c\uff08AFM\uff09\u7684\u975e\u4fb5\u5165\u6027\u65b9\u6cd5\uff0c\u7528\u4e8e\u53ef\u89c6\u5316\u4e8c\u7ef4\u6750\u6599\uff08\u5982MoS2/\u77f3\u58a8\u70ef/Ir(111)\uff09\u4e2d\u786b\u63d2\u5c42\u5f15\u8d77\u7684\u5c40\u90e8\u7ed3\u6784\u548c\u7535\u5b50\u6027\u8d28\u53d8\u5316\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u8d85\u9ad8\u771f\u7a7a\u6280\u672f\u7684\u8017\u65f6\u3001\u9ad8\u6210\u672c\u548c\u7a7a\u95f4\u9650\u5236\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7AFM\u5f62\u8c8c\u6210\u50cf\u76f4\u63a5\u89c2\u5bdf\u5230\u63d2\u5c42\u5bfc\u81f4\u7684\u7ed3\u6784\u53d8\u5316\uff0c\u5e76\u7ed3\u5408\u76f8\u4f4d\u6210\u50cf\u4e0e\u529b\u5b66\u6d4b\u91cf\uff0c\u9996\u6b21\u53d1\u73b0\u63d2\u5c42\u533a\u57df\u6768\u6c0f\u6a21\u91cf\u548c\u7c98\u9644\u529b\u7684\u964d\u4f4e\u3002  \n\u25c6 \u5229\u7528\u5f00\u5c14\u6587\u63a2\u9488\u529b\u663e\u5fae\u955c\uff08KPFM\uff09\u63ed\u793a\u4e86\u63d2\u5c42\u533a\u57df\u7684\u8868\u9762\u7535\u52bf\u548c\u529f\u51fd\u6570\u53d8\u5316\uff0c\u4e3a\u63d2\u5c42\u6548\u5e94\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u7535\u5b50\u5b66\u7279\u5f81\u8bc1\u636e\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u5149\u8bf1\u5bfc\u529b\u663e\u5fae\u955c\uff08PiFM\uff09\u68c0\u6d4b\u63d2\u5c42\u533a\u57df\u7684\u5149\u5b66\u54cd\u5e94\u589e\u5f3a\uff0c\u62d3\u5c55\u4e86AFM\u6280\u672f\u5728\u5149\u5b66\u6027\u8d28\u8868\u5f81\u4e2d\u7684\u5e94\u7528\u3002  \n\u25c6 \u7efc\u5408\u591a\u79cdAFM\u6280\u672f\u5b9e\u73b0\u4e86\u63d2\u5c42\u6548\u5e94\u7684\u591a\u7ef4\u5ea6\u6620\u5c04\uff08\u7ed3\u6784\u3001\u529b\u5b66\u3001\u7535\u5b50\u3001\u5149\u5b66\uff09\uff0c\u4e3a\u4e8c\u7ef4\u6750\u6599\u6027\u80fd\u8c03\u63a7\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u548c\u7406\u8bba\u4f9d\u636e\u3002  \n\u25c6 \u8bc1\u660e\u4e86AFM\u6280\u672f\u5728\u4e8c\u7ef4\u6750\u6599\u63d2\u5c42\u7814\u7a76\u4e2d\u7684\u9ad8\u6548\u6027\u548c\u666e\u9002\u6027\uff0c\u4e3a\u672a\u6765\u6750\u6599\u8bbe\u8ba1\u548c\u5668\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u9ad8\u5206\u8fa8\u7387\u7684\u8868\u5f81\u65b9\u6848\u3002|\n",
    "2506.20312": "|2025-06-25|On the Burstiness of Faces in Set|Jiong Wang|[2506.20312](http://arxiv.org/pdf/2506.20312)|\u65e0|\u25c6 \u9996\u6b21\u63ed\u793a\u4e86\u96c6\u5408\u4eba\u8138\u8bc6\u522b(SFR)\u4e2d\u666e\u904d\u5b58\u5728\u7684\"\u7a81\u53d1\u6027\"\u73b0\u8c61\uff0c\u5373\u7279\u5b9a\u5c5e\u6027\u4eba\u8138\u5728\u96c6\u5408\u4e2d\u9ad8\u9891\u51fa\u73b0\uff0c\u5bfc\u81f4\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0b\u964d\u548c\u8bc4\u4f30\u5e72\u6270\u3002  \n\u25c6 \u63d0\u51fa\u4e09\u79cd\u7a81\u53d1\u6027\u4eba\u8138\u68c0\u6d4b\u7b56\u7565\uff1a\u57fa\u4e8eQuickshift++\u7684\u805a\u7c7b\u65b9\u6cd5\u3001\u7279\u5f81\u81ea\u76f8\u4f3c\u6027\u5206\u6790\u548c\u5e7f\u4e49\u6700\u5927\u6c60\u5316(GMP)\u6280\u672f\uff0c\u6709\u6548\u8bc6\u522b\u96c6\u5408\u4e2d\u7684\u9ad8\u9891\u4eba\u8138\u3002  \n\u25c6 \u5728\u8bad\u7ec3\u9636\u6bb5\u901a\u8fc7\u8c03\u6574\u91c7\u6837\u6bd4\u4f8b\u6291\u5236\u7a81\u53d1\u6027\u5f71\u54cd\uff0c\u5728\u8bc4\u4f30\u9636\u6bb5\u589e\u5f3a\u4f4e\u9891\u4eba\u8138\u7684\u8d21\u732e\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u65e0\u7ea6\u675f\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002  \n\u25c6 \u521b\u65b0\u6027\u63d0\u51fa\u8d28\u91cf\u611f\u77e5GMP\u65b9\u6cd5\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u611f\u77e5\u4eba\u8138\u8d28\u91cf\u5e76\u5bf9\u4f4e\u8d28\u91cf\u56fe\u50cf\u4fdd\u6301\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u539f\u59cbGMP\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7a81\u53d1\u6027\u73b0\u8c61\u7684\u5e7f\u6cdb\u5b58\u5728\uff0c\u8bc1\u660e\u6291\u5236\u7a81\u53d1\u6027\u80fd\u663e\u8457\u63d0\u5347\u73b0\u6709SFR\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bc6\u522b\u6027\u80fd\uff0c\u4e3a\u96c6\u5408\u4eba\u8138\u8bc6\u522b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2506.21101": "|2025-06-26|OracleFusion: Assisting the Decipherment of Oracle Bone Script with Structurally Constrained Semantic Typography|Caoshuo Li\u7b49|[2506.21101](http://arxiv.org/pdf/2506.21101)|\u65e0|\u25c6 \u63d0\u51faOracleFusion\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u8bed\u4e49\u6392\u7248\u6280\u672f\u5e94\u7528\u4e8e\u7532\u9aa8\u6587\u7834\u8bd1\uff0c\u901a\u8fc7\u7ed3\u6784\u7ea6\u675f\u751f\u6210\u8bed\u4e49\u589e\u5f3a\u7684\u77e2\u91cf\u5b57\u4f53\u3002  \n\u25c6 \u7b2c\u4e00\u9636\u6bb5\u91c7\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u7ed3\u5408\u7a7a\u95f4\u611f\u77e5\u63a8\u7406\uff08SAR\uff09\uff0c\u5b9e\u73b0\u5bf9\u7532\u9aa8\u6587\u5b57\u5f62\u7684\u7ed3\u6784\u5206\u6790\u4e0e\u5173\u952e\u90e8\u4ef6\u89c6\u89c9\u5b9a\u4f4d\u3002  \n\u25c6 \u7b2c\u4e8c\u9636\u6bb5\u521b\u65b0\u6027\u5f15\u5165\u7532\u9aa8\u6587\u7ed3\u6784\u5411\u91cf\u878d\u5408\uff08OSVF\uff09\u6280\u672f\uff0c\u901a\u8fc7\u5b57\u5f62\u7ed3\u6784\u7ea6\u675f\u548c\u5b57\u5f62\u4fdd\u6301\u7ea6\u675f\uff0c\u786e\u4fdd\u751f\u6210\u7ed3\u679c\u7684\u7ed3\u6784\u5b8c\u6574\u6027\u4e0e\u8bed\u4e49\u51c6\u786e\u6027\u3002  \n\u25c6 \u5728\u89c6\u89c9\u5448\u73b0\u4e0a\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\uff0c\u751f\u6210\u517c\u5177\u7f8e\u5b66\u8d28\u91cf\u4e0e\u53ef\u8bfb\u6027\u7684\u5b57\u5f62\u8868\u8fbe\uff0c\u4e3a\u4e13\u5bb6\u7834\u8bd1\u63d0\u4f9b\u76f4\u89c2\u8f85\u52a9\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eOracleFusion\u5728\u8bed\u4e49\u76f8\u5173\u6027\u3001\u89c6\u89c9\u5438\u5f15\u529b\u548c\u5b57\u5f62\u4fdd\u6301\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u7834\u8bd1\u6548\u7387\u3002  \n\u25c6 \u6846\u67b6\u53ef\u5bf9\u672a\u89e3\u8bfb\u7532\u9aa8\u6587\u5b57\u7b26\u63d0\u4f9b\u4e13\u5bb6\u7ea7\u89c1\u89e3\uff0c\u6210\u4e3a\u63a8\u52a8\u7532\u9aa8\u6587\u7814\u7a76\u7684\u5b9e\u7528\u5de5\u5177\u3002|\n",
    "2506.22336": "|2025-06-27|MatChA: Cross-Algorithm Matching with Feature Augmentation|Paula Carb\u00f3 Cubero\u7b49|[2506.22336](http://arxiv.org/pdf/2506.22336)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u89e3\u51b3\u8de8\u7279\u5f81\u68c0\u6d4b\u5668\u89c6\u89c9\u5b9a\u4f4d\u95ee\u9898\u7684\u65b9\u6cd5MatChA\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u5fc5\u987b\u4f7f\u7528\u76f8\u540c\u68c0\u6d4b\u5668\u7684\u9650\u5236\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u901a\u8fc7\u7279\u5f81\u63cf\u8ff0\u7b26\u589e\u5f3a\u6280\u672f\u63d0\u5347\u8de8\u68c0\u6d4b\u5668\u7279\u5f81\u5339\u914d\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u5173\u952e\u70b9\u91cd\u590d\u7387\u4f4e\u548c\u63cf\u8ff0\u7b26\u533a\u5206\u5ea6\u4e0d\u8db3\u7684\u96be\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u5c06\u7279\u5f81\u8f6c\u6362\u5230\u6f5c\u5728\u7a7a\u95f4\u7684\u65b9\u6848\uff0c\u6709\u6548\u5b9e\u73b0\u4e86\u4e0d\u540c\u7b97\u6cd5\u751f\u6210\u63cf\u8ff0\u7b26\u7684\u517c\u5bb9\u5339\u914d\u3002  \n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8de8\u7279\u5f81\u573a\u666f\u4e0b\u7684\u56fe\u50cf\u5339\u914d\u548c\u89c6\u89c9\u5b9a\u4f4d\u7cbe\u5ea6\u3002  \n\u25c6 \u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6848\u4f9d\u8d56\u5171\u540c\u5173\u952e\u70b9\u7684\u5047\u8bbe\uff0c\u66f4\u8d34\u5408\u5b9e\u9645\u5e94\u7528\u4e2d\u4e0d\u540c\u8bbe\u5907\u4f7f\u7528\u4e0d\u540c\u7279\u5f81\u63d0\u53d6\u7b97\u6cd5\u7684\u590d\u6742\u573a\u666f\u3002|\n",
    "2506.22939": "|2025-06-28|Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data|Ghufran A. Omran\u7b49|[2506.22939](http://arxiv.org/pdf/2506.22939)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u548c\u521b\u65b0\u70b9\u5982\u4e0b\uff1a  \n\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cCuttlefish Optimized Bidirectional Recurrent Neural Network (CO-BRNN)\u201d\u7684\u65b0\u578b\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u9065\u611f\u6570\u636e\u7684\u573a\u666f\u5206\u7c7b\u3002  \n\u25c6 \u901a\u8fc7\u7ed3\u5408\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u548c\u4f18\u5316\u7b97\u6cd5\uff08Cuttlefish\u4f18\u5316\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u590d\u6742\u9065\u611f\u6570\u636e\u4e2d\u7684\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3002  \n\u25c6 \u5728\u5b9e\u9a8c\u4e2d\uff0cCO-BRNN\u7684\u51c6\u786e\u7387\u8fbe\u523097%\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u591a\u79cd\u65b9\u6cd5\uff08\u5982MLP-CNN\u3001CNN-LSTM\u3001LSTM-CRF\u7b49\uff09\uff0c\u5c55\u73b0\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5bf9\u5927\u89c4\u6a21\u3001\u9ad8\u566a\u58f0\u6570\u636e\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5f3a\u8c03\u4e86\u7269\u7406\u9a8c\u8bc1\u5728\u536b\u661f\u6570\u636e\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u786e\u4fdd\u6a21\u578b\u7ed3\u679c\u7684\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\u3002  \n\u25c6 \u4e3a\u9065\u611f\u573a\u666f\u5206\u7c7b\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u601d\u8def\uff0c\u53ef\u5e94\u7528\u4e8e\u707e\u5bb3\u63a7\u5236\u3001\u751f\u6001\u76d1\u6d4b\u3001\u57ce\u5e02\u89c4\u5212\u7b49\u591a\u4e2a\u9886\u57df\u3002|\n",
    "2506.22864": "|2025-06-28|Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval|Li-Cheng Shen\u7b49|[2506.22864](http://arxiv.org/pdf/2506.22864)|\u65e0|\u25c6 \u63d0\u51faMask-aware TIR\uff08MaTIR\uff09\u65b0\u4efb\u52a1\uff0c\u9996\u6b21\u5c06\u6587\u672c\u5230\u56fe\u50cf\u68c0\u7d22\uff08TIR\uff09\u4e0e\u6307\u4ee3\u8868\u8fbe\u5206\u5272\uff08RES\uff09\u7edf\u4e00\uff0c\u8981\u6c42\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u56fe\u50cf\u641c\u7d22\u548c\u7cbe\u786e\u76ee\u6807\u5206\u5272\u3002  \n\u25c6 \u8bbe\u8ba1\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u5229\u7528SAM 2\u548cAlpha-CLIP\u79bb\u7ebf\u751f\u6210\u5bf9\u8c61\u63a9\u7801\u548c\u533a\u57df\u7ea7\u5d4c\u5165\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5206\u5272\u611f\u77e5\u68c0\u7d22\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u91cd\u65b0\u6392\u5e8f\u5e76\u751f\u6210\u76ee\u6807\u6846\uff0c\u4e0e\u63a9\u7801\u5339\u914d\u63d0\u5347\u7cbe\u5ea6\u3002  \n\u25c6 \u521b\u65b0\u6027\u7ed3\u5408\u5206\u5272\u6a21\u578b\uff08SAM 2\uff09\u4e0e\u8de8\u6a21\u6001\u68c0\u7d22\u6280\u672f\uff08Alpha-CLIP\uff09\uff0c\u5728\u79bb\u7ebf\u9636\u6bb5\u9884\u8ba1\u7b97\u63a9\u7801\u548c\u5d4c\u5165\uff0c\u663e\u8457\u964d\u4f4e\u5728\u7ebf\u68c0\u7d22\u8ba1\u7b97\u6210\u672c\u3002  \n\u25c6 \u5f15\u5165MLLM\u8fdb\u884c\u7ed3\u679c\u91cd\u6392\u548c\u5b9a\u4f4d\u4f18\u5316\uff0c\u5229\u7528\u5176\u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\u63d0\u5347\u68c0\u7d22\u51c6\u786e\u7387\u4e0e\u5206\u5272\u8d28\u91cf\u3002  \n\u25c6 \u5728COCO\u548cD$^3$\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u68c0\u7d22\u7cbe\u5ea6\u548c\u5206\u5272\u6548\u679c\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u8de8\u6a21\u6001\u4efb\u52a1\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002|\n",
    "2507.00659": "|2025-07-01|LoD-Loc v2: Aerial Visual Localization over Low Level-of-Detail City Models using Explicit Silhouette Alignment|Juelin Zhu\u7b49|[2507.00659](http://arxiv.org/pdf/2507.00659)|\u65e0|\u25c6 \u63d0\u51faLoD-Loc v2\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u57fa\u4e8e\u4f4e\u7ec6\u8282\u5c42\u6b21\uff08LoD1\uff09\u57ce\u5e02\u6a21\u578b\u7684\u65e0\u4eba\u673a\u7a7a\u4e2d\u89c6\u89c9\u5b9a\u4f4d\uff0c\u7a81\u7834\u4ee5\u5f80\u4f9d\u8d56\u9ad8\u7ec6\u8282\u6a21\u578b\uff08LoD2/LoD3\uff09\u7684\u9650\u5236\u3002  \n\u25c6 \u91c7\u7528\u7c97\u5230\u7cbe\u7684\u53cc\u9636\u6bb5\u7b56\u7565\uff1a\u901a\u8fc7\u663e\u5f0f\u8f6e\u5ed3\u5bf9\u9f50\u6784\u5efa\u59ff\u6001\u4ee3\u4ef7\u4f53\u79ef\u7b5b\u9009\u7c97\u59ff\u6001\uff0c\u518d\u7ed3\u5408\u7c92\u5b50\u6ee4\u6ce2\u4e0e\u591a\u5149\u675f\u8ddf\u8e2a\u8fdb\u884c\u7cbe\u7ec6\u4f18\u5316\u3002  \n\u25c6 \u521b\u65b0\u6027\u8bbe\u8ba1\u59ff\u6001\u4ee3\u4ef7\u4f53\u79ef\uff0c\u901a\u8fc7\u5747\u5300\u91c7\u6837\u59ff\u6001\u5047\u8bbe\u5e76\u91cf\u5316\u6295\u5f71\u8f6e\u5ed3\u4e0e\u9884\u6d4b\u8f6e\u5ed3\u7684\u5bf9\u9f50\u5ea6\uff0c\u5b9e\u73b0\u9ad8\u6548\u6982\u7387\u5206\u5e03\u5efa\u6a21\u3002  \n\u25c6 \u63d0\u51fa\u591a\u5149\u675f\u8ddf\u8e2a\u7684\u7c92\u5b50\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u663e\u8457\u6269\u5927\u6536\u655b\u57df\u5bb9\u9519\u8303\u56f4\uff0c\u53ef\u9002\u5e94\u66f4\u5927\u521d\u59cb\u59ff\u6001\u8bef\u5dee\u3002  \n\u25c6 \u53d1\u5e03\u9996\u4e2a\u8986\u76d610.7\u5e73\u65b9\u516c\u91cc\u7684LoD1\u57ce\u5e02\u6a21\u578b\u6570\u636e\u96c6\uff0c\u5305\u542b\u771f\u5b9eRGB\u67e5\u8be2\u56fe\u50cf\u4e0e\u59ff\u6001\u771f\u503c\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7814\u7a76\u3002  \n\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u9ad8/\u4f4eLoD\u6a21\u578b\u4e0b\u5747\u5b9e\u73b0\u6700\u4f18\u7cbe\u5ea6\uff0c\u751a\u81f3\u8d85\u8d8a\u57fa\u4e8e\u7eb9\u7406\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4e3a\u5168\u7403\u57ce\u5e02\u5b9a\u4f4d\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002|\n",
    "2507.04735": "|2025-07-07|An analysis of vision-language models for fabric retrieval|Francesco Giuliari\u7b49|[2507.04735](http://arxiv.org/pdf/2507.04735)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6807\u6ce8\u6d41\u7a0b\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u751f\u6210\u4e24\u79cd\u6587\u672c\u63cf\u8ff0\uff08\u81ea\u7531\u81ea\u7136\u8bed\u8a00\u548c\u7ed3\u6784\u5316\u5c5e\u6027\u63cf\u8ff0\uff09\uff0c\u89e3\u51b3\u4e86\u7ec7\u7269\u9886\u57df\u516c\u5f00\u6570\u636e\u96c6\u7684\u7f3a\u5931\u95ee\u9898\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e09\u79cd\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08CLIP\u3001LAION-CLIP\u548cMeta Perception Encoder\uff09\u5728\u96f6\u6837\u672c\u7ec7\u7269\u56fe\u50cf\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002  \n\u25c6 \u53d1\u73b0\u7ed3\u6784\u5316\u5c5e\u6027\u63cf\u8ff0\u80fd\u663e\u8457\u63d0\u5347\u68c0\u7d22\u7cbe\u5ea6\uff0c\u5c24\u5176\u5728\u89c6\u89c9\u590d\u6742\u7684\u7ec7\u7269\u7c7b\u522b\u4e2d\uff0c\u63ed\u793a\u4e86\u6587\u672c\u63cf\u8ff0\u5f62\u5f0f\u5bf9\u8de8\u6a21\u6001\u68c0\u7d22\u7684\u5173\u952e\u5f71\u54cd\u3002  \n\u25c6 \u9a8c\u8bc1\u4e86Meta Perception Encoder\u51ed\u501f\u66f4\u5f3a\u7684\u7279\u5f81\u5bf9\u9f50\u80fd\u529b\uff0c\u5728\u7ec7\u7269\u68c0\u7d22\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u4e3a\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u6a21\u578b\u9009\u62e9\u4f9d\u636e\u3002  \n\u25c6 \u6307\u51fa\u96f6\u6837\u672c\u68c0\u7d22\u5728\u7ec6\u7c92\u5ea6\u7ec7\u7269\u9886\u57df\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002  \n\u25c6 \u7ed3\u5408\u6280\u672f\u6027\u6587\u672c\u63cf\u8ff0\u4e0e\u5148\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7b56\u7565\uff0c\u4e3a\u5236\u9020\u4e1a\u7b49\u4e13\u4e1a\u9886\u57df\u7684\u8de8\u6a21\u6001\u68c0\u7d22\u4f18\u5316\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6307\u5bfc\u3002|\n",
    "2507.04667": "|2025-07-08|What's Making That Sound Right Now? Video-centric Audio-Visual Localization|Hahyeon Choi\u7b49|[2507.04667](http://arxiv.org/pdf/2507.04667)|\u65e0|\u25c6 \u63d0\u51faAVATAR\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9996\u6b21\u5f15\u5165\u89c6\u9891\u4e2d\u5fc3\u5316\u89c6\u89d2\uff0c\u89e3\u51b3\u73b0\u6709\u97f3\u9891-\u89c6\u89c9\u5b9a\u4f4d\uff08AVL\uff09\u7814\u7a76\u4ec5\u5173\u6ce8\u9759\u6001\u56fe\u50cf\u7684\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u56db\u79cd\u590d\u6742\u573a\u666f\uff08\u5355\u58f0\u6e90\u3001\u6df7\u5408\u58f0\u6e90\u3001\u591a\u5b9e\u4f53\u3001\u5c4f\u5e55\u5916\u58f0\u6e90\uff09\uff0c\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u5047\u8bbe\u58f0\u6e90\u53ef\u89c1\u4e14\u5355\u4e00\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u5f00\u53d1TAVLO\u6a21\u578b\uff0c\u9996\u521b\u9ad8\u5206\u8fa8\u7387\u65f6\u5e8f\u5efa\u6a21\u673a\u5236\uff0c\u6709\u6548\u6355\u6349\u58f0\u97f3\u4e0e\u89c6\u89c9\u5bf9\u8c61\u7684\u52a8\u6001\u5173\u8054\u3002  \n\u25c6 \u5b9e\u8bc1\u53d1\u73b0\u4f20\u7edf\u65b9\u6cd5\u56e0\u4f9d\u8d56\u5168\u5c40\u97f3\u9891\u7279\u5f81\u548c\u9010\u5e27\u6620\u5c04\uff0c\u96be\u4ee5\u8ffd\u8e2a\u65f6\u5e8f\u53d8\u5316\uff0c\u800cTAVLO\u901a\u8fc7\u65f6\u5e8f\u5efa\u6a21\u5b9e\u73b0\u7cbe\u51c6\u5bf9\u9f50\u3002  \n\u25c6 \u5efa\u7acb\u89c6\u9891\u4e2d\u5fc3\u5316AVL\u65b0\u6807\u51c6\uff0c\u9996\u6b21\u7cfb\u7edf\u8bba\u8bc1\u65f6\u5e8f\u52a8\u6001\u5bf9\u97f3\u9891-\u89c6\u89c9\u5b9a\u4f4d\u7684\u5173\u952e\u5f71\u54cd\u3002|\n",
    "2507.04662": "|2025-07-07|Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR|Tao Du\u7b49|[2507.04662](http://arxiv.org/pdf/2507.04662)|\u65e0|\u25c6 \u63d0\u51fa\u5229\u7528\u6beb\u7c73\u6ce25G NR\u7cfb\u7edf\u8fdb\u884c\u4e3b\u52a8\u611f\u77e5\uff0c\u5b9e\u73b0\u7c7b\u4f3c\u6fc0\u5149\u96f7\u8fbe\u7684\u70b9\u4e91\u751f\u6210\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u88ab\u52a8SLAM\u6280\u672f\u4f9d\u8d56\u955c\u9762\u53cd\u5c04\u5047\u8bbe\u7684\u5c40\u9650\u3002  \n\u25c6 \u91c7\u7528\u4e8c\u8fdb\u5236\u641c\u7d22\u65b9\u6cd5\u4ece\u6bcf\u4e2a\u6ce2\u675f\u65b9\u5411\u7684\u529f\u7387\u5ef6\u8fdf\u5256\u9762\u4e2d\u63d0\u53d6\u70b9\u4e91\uff0c\u63d0\u9ad8\u4e86\u73af\u5883\u611f\u77e5\u7684\u7cbe\u5ea6\u548c\u7ec6\u8282\u3002  \n\u25c6 \u901a\u8fc7\u591a\u76ee\u6807\u70b9\u6821\u51c6\u786c\u4ef6\u5ef6\u8fdf\uff0c\u786e\u4fdd\u70b9\u4e91\u6570\u636e\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u540e\u7eed\u5b9a\u4f4d\u548c\u5efa\u56fe\u63d0\u4f9b\u53ef\u9760\u8f93\u5165\u3002  \n\u25c6 \u5229\u7528\u70b9\u4e91\u914d\u51c6\u7b97\u6cd5\u4ece\u8fde\u7eed\u8f68\u8ff9\u89c6\u89d2\u4f30\u8ba1\u7ec8\u7aef\u4f4d\u59ff\u53d8\u5316\uff0c\u5b9e\u73b0\u52a8\u6001\u73af\u5883\u4e0b\u7684\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u3002  \n\u25c6 \u7ed3\u5408\u95ed\u73af\u68c0\u6d4b\u4e0e\u4f4d\u59ff\u56fe\u4f18\u5316\u6280\u672f\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u611f\u77e5\u7ed3\u679c\uff0c\u5b8c\u6210\u7cbe\u786e\u7684\u7ec8\u7aef\u5b9a\u4f4d\u548c\u65e0\u7ebf\u7535\u5730\u56fe\u91cd\u5efa\u3002  \n\u25c6 \u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6709\u6548\u6027\uff0c\u4e3a5G NR\u5728SLAM\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8df5\u4f9d\u636e\u3002|\n",
    "2507.04503": "|2025-07-06|U-ViLAR: Uncertainty-Aware Visual Localization for Autonomous Driving via Differentiable Association and Registration|Xiaofan Li\u7b49|[2507.04503](http://arxiv.org/pdf/2507.04503)|\u65e0|\u25c6 \u63d0\u51faU-ViLAR\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u5b9a\u4f4d\u4e0d\u786e\u5b9a\u6027\u540c\u65f6\u7eb3\u5165\u89c6\u89c9\u5b9a\u4f4d\u7cfb\u7edf\uff0c\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u5728\u590d\u6742\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u89c6\u89c9\u7279\u5f81\u6620\u5c04\u5230\u9e1f\u77b0\u56fe\uff08BEV\uff09\u7a7a\u95f4\uff0c\u589e\u5f3a\u4e0e\u9ad8\u7cbe\u5730\u56fe\u7684\u7a7a\u95f4\u4e00\u81f4\u6027\uff0c\u89e3\u51b3\u89c6\u89d2\u5dee\u5f02\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u7279\u5f81\u5173\u8054\u6a21\u5757\uff08Perceptual Uncertainty-guided Association\uff09\uff0c\u6709\u6548\u964d\u4f4e\u611f\u77e5\u8bef\u5dee\u5bf9\u5339\u914d\u7684\u5f71\u54cd\u3002  \n\u25c6 \u5f00\u53d1\u5b9a\u4f4d\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u914d\u51c6\u6a21\u5757\uff08Localization Uncertainty-guided Registration\uff09\uff0c\u901a\u8fc7\u91cf\u5316\u5b9a\u4f4d\u7f6e\u4fe1\u5ea6\u4f18\u5316\u4f4d\u59ff\u4f30\u8ba1\u7cbe\u5ea6\u3002  \n\u25c6 \u5b9e\u73b0\u5173\u8054\uff08\u5927\u8303\u56f4\u7c97\u5b9a\u4f4d\uff09\u4e0e\u914d\u51c6\uff08\u7cbe\u7ec6\u5b9a\u4f4d\uff09\u7684\u534f\u540c\u4f18\u5316\uff0c\u5728\u4fdd\u6301\u5927\u573a\u666f\u8986\u76d6\u80fd\u529b\u7684\u540c\u65f6\u63d0\u5347\u5398\u7c73\u7ea7\u5b9a\u4f4d\u51c6\u786e\u6027\u3002  \n\u25c6 \u901a\u8fc7\u5927\u89c4\u6a21\u81ea\u52a8\u9a7e\u9a76\u8f66\u961f\u5b9e\u6d4b\u9a8c\u8bc1\uff0c\u5728GNSS\u5931\u6548\u3001\u52a8\u6001\u969c\u788d\u7269\u7b49\u590d\u6742\u573a\u666f\u4e0b\u4fdd\u6301\u7a33\u5b9a\u6027\u80fd\uff0c\u7efc\u5408\u7cbe\u5ea6\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002|\n",
    "2507.03831": "|2025-07-04|Query-Based Adaptive Aggregation for Multi-Dataset Joint Training Toward Universal Visual Place Recognition|Jiuhong Xiao\u7b49|[2507.03831](http://arxiv.org/pdf/2507.03831)|\u65e0|\u25c6\u63d0\u51fa\u57fa\u4e8e\u67e5\u8be2\u7684\u81ea\u9002\u5e94\u805a\u5408\uff08QAA\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u67e5\u8be2\u5411\u91cf\u4f5c\u4e3a\u53c2\u8003\u7801\u672c\uff0c\u6709\u6548\u63d0\u5347\u591a\u6570\u636e\u96c6\u8054\u5408\u8bad\u7ec3\u4e2d\u7684\u4fe1\u606f\u5bb9\u91cf\uff0c\u907f\u514d\u4f20\u7edf\u7279\u5f81\u805a\u5408\u5c42\u7684\u4fe1\u606f\u9971\u548c\u95ee\u9898\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u5f15\u5165\u8de8\u67e5\u8be2\u76f8\u4f3c\u5ea6\uff08CS\uff09\u8ba1\u7b97\u673a\u5236\uff0c\u5229\u7528\u67e5\u8be2\u7ea7\u56fe\u50cf\u7279\u5f81\u4e0e\u53c2\u8003\u7801\u672c\u7684\u76f8\u4f3c\u6027\u751f\u6210\u9c81\u68d2\u63cf\u8ff0\u7b26\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6\u9996\u6b21\u5b9e\u73b0\u591a\u6570\u636e\u96c6\u8054\u5408\u8bad\u7ec3\u7684\u901a\u7528\u89c6\u89c9\u4f4d\u7f6e\u8bc6\u522b\uff08VPR\uff09\u6a21\u578b\uff0c\u5728\u4fdd\u6301\u5355\u6570\u636e\u96c6\u5cf0\u503c\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u8de8\u6570\u636e\u96c6\u7684\u5e73\u8861\u6cdb\u5316\u8868\u73b0\u3002  \n\u25c6\u901a\u8fc7\u53ef\u89c6\u5316\u5206\u6790\u63ed\u793a\u5b66\u4e60\u5230\u7684\u67e5\u8be2\u5411\u91cf\u5177\u6709\u8de8\u6570\u636e\u96c6\u7684\u591a\u6837\u5316\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u4e3a\u591a\u6e90\u6570\u636e\u878d\u5408\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u4f9d\u636e\u3002  \n\u25c6\u5728\u8ba1\u7b97\u6548\u7387\u548c\u53c2\u6570\u91cf\u63a7\u5236\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u672a\u663e\u8457\u589e\u52a0\u6a21\u578b\u590d\u6742\u5ea6\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6027\u80fd\u7a81\u7834\u3002  \n\u25c6\u5f00\u6e90\u4ee3\u7801\u5e76\u8f85\u4ee5\u8be6\u5c3d\u7684\u6d88\u878d\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86QAA\u673a\u5236\u7684\u53ef\u6269\u5c55\u6027\u548c\u6838\u5fc3\u7ec4\u4ef6\u6709\u6548\u6027\u3002|\n",
    "2507.05970": "|2025-07-08|Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval|Haiwen Li\u7b49|[2507.05970](http://arxiv.org/pdf/2507.05970)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u4e09\u5143\u7ec4\u751f\u6210\u6d41\u7a0b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfCIR\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u5bfc\u81f4\u7684\u6269\u5c55\u6027\u548c\u96f6\u6837\u672c\u80fd\u529b\u53d7\u9650\u95ee\u9898\u3002  \n\u25c6 \u6784\u5efa\u4e86\u9996\u4e2a\u5168\u5408\u6210\u6570\u636e\u96c6CIRHS\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u63d0\u793a\u8bcd\uff0c\u5e76\u901a\u8fc7\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u63a7\u5236\u751f\u6210\u5177\u6709\u76f8\u540c\u5143\u7d20\u7684\u56fe\u50cf\u5bf9\uff0c\u7ecf\u7b5b\u9009\u91cd\u7ec4\u5f62\u6210\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u63d0\u51fa\u6df7\u5408\u4e0a\u4e0b\u6587\u5bf9\u9f50\u6846\u67b6\uff08CoAlign\uff09\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u5bf9\u9f50\u4e0e\u5c40\u90e8\u63a8\u7406\u7684\u534f\u540c\u4f18\u5316\uff0c\u80fd\u591f\u5b66\u4e60\u66f4\u9c81\u68d2\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u8868\u5f81\u3002  \n\u25c6 \u9996\u6b21\u9a8c\u8bc1\u4e86\u5728\u5168\u5408\u6210\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3CIR\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0cCoAlign\u5728\u4e09\u4e2a\u5e38\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u5353\u8d8a\u7684\u96f6\u6837\u672c\u6027\u80fd\u3002  \n\u25c6 \u5728\u76d1\u7763\u8bad\u7ec3\u573a\u666f\u4e0b\uff0c\u8be5\u65b9\u6cd5\u8d85\u8d8a\u6240\u6709\u73b0\u6709\u5148\u8fdbCIR\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u68c0\u7d22\u6846\u67b6\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u548cCIRHS\u6570\u636e\u96c6\u5c06\u4fc3\u8fdbCIR\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002|\n",
    "2507.05631": "|2025-07-08|OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval|Zhiwei Chen\u7b49|[2507.05631](http://arxiv.org/pdf/2507.05631)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u5206\u5272\u7684\u7126\u70b9\u6620\u5c04\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u901a\u8fc7\u4e3b\u5bfc\u533a\u57df\u5206\u5272\u548c\u53cc\u91cd\u7126\u70b9\u6620\u5c04\u6a21\u5757\uff0c\u6709\u6548\u533a\u5206\u56fe\u50cf\u4e2d\u7684\u5173\u952e\u533a\u57df\u4e0e\u566a\u58f0\uff0c\u63d0\u5347\u67e5\u8be2\u7279\u5f81\u8d28\u91cf\u3002  \n\u25c6 \u8bbe\u8ba1\u6587\u672c\u5f15\u5bfc\u7684\u7126\u70b9\u4fee\u6b63\u6a21\u5757\uff0c\u5229\u7528\u4fee\u6539\u6587\u672c\u7684\u8bed\u4e49\u4fe1\u606f\u81ea\u9002\u5e94\u8c03\u6574\u53c2\u8003\u56fe\u50cf\u7684\u89c6\u89c9\u7126\u70b9\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u6587\u672c\u4f18\u5148\u7ea7\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\u3002  \n\u25c6 \u9996\u6b21\u5728\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\uff08CIR\uff09\u4e2d\u5f15\u5165\u89c6\u89c9\u4e3b\u5bfc\u533a\u57df\u5206\u5272\u6280\u672f\uff0c\u51cf\u5c11\u566a\u58f0\u5e72\u6270\u5bf9\u591a\u6a21\u6001\u7279\u5f81\u878d\u5408\u7684\u8d1f\u9762\u5f71\u54cd\u3002  \n\u25c6 \u901a\u8fc7\u53cc\u7126\u70b9\u6620\u5c04\u673a\u5236\u540c\u6b65\u4f18\u5316\u89c6\u89c9\u4e0e\u6587\u672c\u7279\u5f81\u63d0\u53d6\uff0c\u589e\u5f3a\u6a21\u578b\u5bf9\u7528\u6237\u590d\u6742\u4fee\u6539\u610f\u56fe\u7684\u7406\u89e3\u80fd\u529b\u3002  \n\u25c6 \u6784\u5efa\u5b8c\u6574\u7f51\u7edcOFFSET\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\uff0c\u4e3aCIR\u9886\u57df\u63d0\u4f9b\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u516c\u5f00\u4ee3\u7801\u4e0e\u6570\u636e\uff0c\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u53d1\u5c55\u3002|\n",
    "2507.05513": "|2025-07-07|Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model|Mengyao Xu\u7b49|[2507.05513](http://arxiv.org/pdf/2507.05513)|\u65e0|\u25c6 \u63d0\u51fallama-nemoretriever-colembed\u6a21\u578b\uff0c\u5b9e\u73b0\u6587\u672c-\u56fe\u50cf\u8de8\u6a21\u6001\u68c0\u7d22\u7684\u9876\u5c16\u6027\u80fd\uff0c\u5728ViDoRe V1/V2\u57fa\u51c6\u4e0aNDCG@5\u5206\u522b\u8fbe\u523091.0\u548c63.5\uff0c\u5237\u65b0\u699c\u5355\u8bb0\u5f55\u3002  \n\u25c6 \u57fa\u4e8eNVIDIA Eagle2\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u67b6\u6784\u6539\u9020\uff0c\u5c06\u56e0\u679c\u6ce8\u610f\u529b\u66ff\u6362\u4e3a\u53cc\u5411\u6ce8\u610f\u529b\u673a\u5236\uff0c\u589e\u5f3a\u591a\u6a21\u6001\u7279\u5f81\u4ea4\u4e92\u80fd\u529b\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165ColBERT\u98ce\u683c\u7684\u5ef6\u8fdf\u4ea4\u4e92\u673a\u5236\uff0c\u5728\u5171\u4eab\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u8de8\u6a21\u6001\u68c0\u7d22\uff0c\u663e\u8457\u63d0\u5347\u5339\u914d\u7cbe\u5ea6\u3002  \n\u25c6 \u8bbe\u8ba1\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5148\u9884\u8bad\u7ec3\u518d\u5fae\u8c03\uff0c\u6709\u6548\u589e\u5f3a\u6a21\u578b\u68c0\u7d22\u80fd\u529b\u3002  \n\u25c6 \u5168\u9762\u5206\u6790\u6a21\u578b\u5728\u5b58\u50a8\u6548\u7387\u4e0e\u68c0\u7d22\u7cbe\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4f18\u5316\u4f9d\u636e\u3002  \n\u25c6 \u53d1\u5e031B\u548c3B\u4e24\u79cd\u53c2\u6570\u91cf\u53d8\u4f53\uff0c\u5176\u4e2d3B\u7248\u672c\u6210\u4e3a\u5f53\u524d\u6027\u80fd\u6700\u4f18\u7684\u8de8\u6a21\u6001\u68c0\u7d22\u6a21\u578b\u3002|\n",
    "2507.07079": "|2025-07-09|Evaluating Attribute Confusion in Fashion Text-to-Image Generation|Ziyue Liu\u7b49|[2507.07079](http://arxiv.org/pdf/2507.07079)|\u65e0|\u25c6 \u9488\u5bf9\u65f6\u5c1a\u9886\u57df\u6587\u672c\u751f\u6210\u56fe\u50cf\uff08T2I\uff09\u4efb\u52a1\u4e2d\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u7ec6\u7c92\u5ea6\u5c5e\u6027\u5173\u8054\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9\u5b9a\u4f4d\u548c\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u7684\u65b0\u578b\u8bc4\u4f30\u6846\u67b6\u3002  \n\u25c6 \u901a\u8fc7\u5355\u5b9e\u4f53\u5b9a\u4f4d\u7b56\u7565\uff0c\u5728\u89c6\u89c9\u548c\u6587\u672c\u6a21\u6001\u4e0a\u540c\u6b65\u5206\u6790\u5c5e\u6027\u6df7\u6dc6\u73b0\u8c61\uff08\u5982\u5c5e\u6027\u6b63\u786e\u751f\u6210\u4f46\u5f52\u5c5e\u9519\u8bef\u5b9e\u4f53\uff09\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bf9\u590d\u6742\u7ec4\u5408\u8bed\u4e49\u8bc4\u4f30\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u5c40\u90e8\u5316\u4eba\u5de5\u8bc4\u4f30\u534f\u8bae\uff0c\u5e76\u521b\u65b0\u6027\u5730\u63d0\u51fa\u81ea\u52a8\u6307\u6807L-VQAScore\uff0c\u7ed3\u5408\u89c6\u89c9\u5b9a\u4f4d\u4e0eVQA\u6280\u672f\uff0c\u540c\u65f6\u68c0\u6d4b\u5c5e\u6027\u6b63\u786e\u53cd\u6620\uff08reflection\uff09\u548c\u9519\u8bef\u6cc4\u6f0f\uff08leakage\uff09\u60c5\u51b5\u3002  \n\u25c6 \u6784\u5efa\u4e86\u5305\u542b\u6311\u6218\u6027\u7ec4\u5408\u5bf9\u9f50\u573a\u666f\u7684\u65b0\u6570\u636e\u96c6\uff0c\u9a8c\u8bc1\u4e86L-VQAScore\u5728\u7ec6\u7c92\u5ea6\u5b9e\u4f53-\u5c5e\u6027\u5173\u8054\u8bc4\u4f30\u4e0a\u7684\u4f18\u8d8a\u6027\uff0c\u5176\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u76f8\u5173\u6027\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002  \n\u25c6 \u8be5\u5de5\u4f5c\u4e3a\u65f6\u5c1a\u9886\u57dfT2I\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u5ba2\u89c2\u8bc4\u4f30\u65b9\u6848\uff0c\u663e\u8457\u51cf\u5c11\u5bf9\u4e3b\u89c2\u8bc4\u4ef7\u7684\u4f9d\u8d56\uff0c\u63a8\u52a8\u751f\u6210\u6a21\u578b\u5728\u590d\u6742\u8bed\u4e49\u573a\u666f\u4e0b\u7684\u7cbe\u51c6\u4f18\u5316\u3002|\n",
    "2507.06654": "|2025-07-09|MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval|Naoya Sogi\u7b49|[2507.06654](http://arxiv.org/pdf/2507.06654)|\u65e0|\u25c6 \u63d0\u51fa\u65b0\u4efb\u52a1CDR-CA\uff08\u590d\u5408\u5c5e\u6027\u4e0a\u4e0b\u6587\u591a\u6837\u6027\u4f18\u5316\uff09\uff0c\u9488\u5bf9\u6587\u672c\u5230\u56fe\u50cf\u68c0\u7d22\u4e2d\u4e0d\u540c\u5e94\u7528\u573a\u666f\u5bf9\u591a\u6837\u6027\u9700\u6c42\u7684\u5dee\u5f02\uff0c\u5b9e\u73b0\u591a\u5c5e\u6027\u591a\u6837\u6027\u6309\u9700\u8c03\u6574\u3002  \n\u25c6 \u63d0\u51fa\u591a\u6e90\u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\uff08MS-DPPs\uff09\uff0c\u5c06\u4f20\u7edfDPP\u6269\u5c55\u4e3a\u591a\u6e90\u5f62\u5f0f\uff0c\u901a\u8fc7\u6d41\u5f62\u8868\u793a\u6784\u5efa\u7edf\u4e00\u76f8\u4f3c\u6027\u77e9\u9635\uff0c\u652f\u6301\u591a\u5c5e\u6027\u8054\u5408\u4f18\u5316\u3002  \n\u25c6 \u5f15\u5165\u5207\u7ebf\u5f52\u4e00\u5316\uff08Tangent Normalization\uff09\u6280\u672f\uff0c\u6709\u6548\u878d\u5408\u4e0d\u540c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u52a8\u6001\u9002\u5e94\u591a\u6837\u5316\u5e94\u7528\u573a\u666f\u7684\u9700\u6c42\u3002  \n\u25c6 \u5b9e\u9a8c\u9a8c\u8bc1\u4e86MS-DPPs\u5728\u591a\u6837\u6027\u4f18\u5316\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u5c24\u5176\u5728\u590d\u5408\u5c5e\u6027\u63a7\u5236\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002  \n\u25c6 \u516c\u5f00\u4ee3\u7801\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\uff0c\u4e3a\u6587\u672c\u5230\u56fe\u50cf\u68c0\u7d22\u7684\u5b9e\u7528\u5316\u591a\u6837\u6027\u4f18\u5316\u63d0\u4f9b\u65b0\u57fa\u7ebf\u3002|\n",
    "2507.07467": "|2025-07-10|SCREP: Scene Coordinate Regression and Evidential Learning-based Perception-Aware Trajectory Generation|Juyeop Han\u7b49|[2507.07467](http://arxiv.org/pdf/2507.07467)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u573a\u666f\u5750\u6807\u56de\u5f52\uff08SCR\uff09\u548c\u8bc1\u636e\u5b66\u4e60\u7684\u65b0\u578b\u611f\u77e5\u611f\u77e5\u8f68\u8ff9\u751f\u6210\u6846\u67b6SCREP\uff0c\u7528\u4e8eGPS\u62d2\u6b62\u73af\u5883\u4e0b\u7684\u81ea\u4e3b\u98de\u884c\u3002  \n\u25c6 \u901a\u8fc7\u8bc1\u636e\u5b66\u4e60\u65b9\u6cd5\u4f18\u5316SCR\u4f4d\u59ff\u4f30\u8ba1\u5668\uff0c\u80fd\u591f\u9884\u6d4b\u50cf\u7d20\u4e0d\u786e\u5b9a\u6027\u5e76\u5f15\u5bfc\u76f8\u673a\u671d\u5411\u53ef\u9760\u6027\u9ad8\u7684\u573a\u666f\u5750\u6807\u533a\u57df\u3002  \n\u25c6 \u91c7\u7528\u6eda\u52a8\u65f6\u57df\u8f68\u8ff9\u4f18\u5316\u5668\uff0c\u5b9e\u65f6\u8c03\u6574\u98de\u884c\u8f68\u8ff9\u4ee5\u6700\u5927\u5316\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u540c\u65f6\u7ed3\u5408\u56fa\u5b9a\u6ede\u540e\u5e73\u6ed1\u5668\u878d\u5408\u4f4e\u9891SCR\u6570\u636e\u4e0e\u9ad8\u9891IMU\u6570\u636e\u3002  \n\u25c6 \u5728\u4eff\u771f\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u56fa\u5b9a\u504f\u822a\u548c\u524d\u89c6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u5c06\u5e73\u79fb\uff08\u65cb\u8f6c\uff09\u5e73\u5747\u8bef\u5dee\u964d\u4f4e\u4e8654%/15%\uff0840%/31%\uff09\u3002  \n\u25c6 \u901a\u8fc7\u786c\u4ef6\u5728\u73af\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u5b9e\u65f6\u6027\u548c\u53ef\u884c\u6027\uff0c\u5b9e\u73b0\u4e86\u611f\u77e5-\u63a7\u5236\u95ed\u73af\u7684\u9ad8\u6548\u8fd0\u884c\u3002|\n",
    "2507.07384": "|2025-07-10|VP-SelDoA: Visual-prompted Selective DoA Estimation of Target Sound via Semantic-Spatial Matching|Yu Chen\u7b49|[2507.07384](http://arxiv.org/pdf/2507.07384)|\u65e0|\u25c6 \u63d0\u51fa\u8de8\u5b9e\u4f8b\u97f3\u9891-\u89c6\u89c9\u5b9a\u4f4d\uff08CI-AVL\uff09\u65b0\u4efb\u52a1\uff0c\u5229\u7528\u540c\u7c7b\u58f0\u97f3\u4e8b\u4ef6\u7684\u4e0d\u540c\u5b9e\u4f8b\u56fe\u50cf\u5b9a\u4f4d\u76ee\u6807\u58f0\u6e90\uff0c\u51cf\u5c11\u5bf9\u914d\u5bf9\u6570\u636e\u7684\u4f9d\u8d56\u5e76\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u8bbe\u8ba1VP-SelDoA\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u7ea7\u6a21\u6001\u878d\u5408\u548cFrequency-Temporal ConMamba\u67b6\u6784\u751f\u6210\u76ee\u6807\u9009\u62e9\u6027\u63a9\u7801\uff0c\u5b9e\u73b0\u591a\u58f0\u6e90\u573a\u666f\u4e0b\u7684\u76ee\u6807\u58f0\u6e90\u9694\u79bb\u3002  \n\u25c6 \u63d0\u51fa\u8bed\u4e49-\u7a7a\u95f4\u5339\u914d\u673a\u5236\uff0c\u7ed3\u5408\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u81ea\u6ce8\u610f\u529b\u5bf9\u9f50\u5f02\u6784\u7684\u8bed\u4e49\u4e0e\u7a7a\u95f4\u7279\u5f81\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u89c6\u89c9\u8bed\u4e49\u4e0e\u58f0\u5b66\u7a7a\u95f4\u7279\u5f81\u9519\u4f4d\u95ee\u9898\u3002  \n\u25c6 \u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6VGG-SSL\uff0c\u5305\u542b296\u7c7b\u58f0\u97f3\u4e8b\u4ef6\u768413,981\u6761\u7a7a\u95f4\u97f3\u9891\u7247\u6bb5\uff0c\u4e3aCI-AVL\u7814\u7a76\u63d0\u4f9b\u6570\u636e\u652f\u6301\u3002  \n\u25c6 \u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08MAE\uff09\u548c\u51c6\u786e\u7387\uff08ACC\uff09\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u97f3\u9891-\u89c6\u89c9\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5206\u522b\u8fbe\u523012.04\u548c78.23%\u3002|\n",
    "2507.07135": "|2025-07-08|FACap: A Large-scale Fashion Dataset for Fine-grained Composed Image Retrieval|Fran\u00e7ois Gard\u00e8res\u7b49|[2507.07135](http://arxiv.org/pdf/2507.07135)|\u65e0|\u25c6 \u63d0\u51fa\u4e86FACap\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u81ea\u52a8\u6784\u5efa\u7684\u65f6\u5c1a\u9886\u57df\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u4e13\u4e1a\u7ec6\u7c92\u5ea6\u6807\u6ce8\u7684\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e24\u9636\u6bb5\u81ea\u52a8\u6807\u6ce8\u6d41\u7a0b\uff0c\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u4fee\u6539\u6587\u672c\uff0c\u964d\u4f4e\u4e86\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u3002  \n\u25c6 \u63d0\u51fa\u4e86FashionBLIP-2\u6a21\u578b\uff0c\u901a\u8fc7\u5728FACap\u4e0a\u5fae\u8c03\u901a\u7528BLIP-2\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u548c\u591a\u5934\u67e5\u8be2-\u5019\u9009\u5339\u914d\u673a\u5236\uff0c\u63d0\u5347\u4e86\u65f6\u5c1a\u7ec6\u7c92\u5ea6\u4fe1\u606f\u7684\u5904\u7406\u80fd\u529b\u3002  \n\u25c6 \u5728Fashion IQ\u57fa\u51c6\u548c\u589e\u5f3a\u7248enhFashionIQ\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6a21\u578b\u6548\u679c\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u65f6\u5c1a\u9886\u57df\u7ec4\u5408\u68c0\u7d22\u6027\u80fd\uff0c\u5c24\u5176\u5728\u7ec6\u7c92\u5ea6\u6587\u672c\u4fee\u6539\u573a\u666f\u3002  \n\u25c6 \u4e3a\u7535\u5546\u7b49\u5b9e\u9645\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u65f6\u5c1a\u56fe\u50cf\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u81ea\u52a8\u6784\u5efa\u9886\u57df\u4e13\u7528\u6570\u636e\u96c6\u4e0e\u6a21\u578b\u9002\u914d\u76f8\u7ed3\u5408\u7684\u6709\u6548\u6027\u3002|\n",
    "2507.08546": "|2025-07-11|RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features|Inye Na\u7b49|[2507.08546](http://arxiv.org/pdf/2507.08546)|\u65e0|\u25c6 \u63d0\u51faRadiomicsRetrieval\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u624b\u5de5\u8bbe\u8ba1\u7684\u653e\u5c04\u7ec4\u5b66\u7279\u5f81\u4e0e\u6df1\u5ea6\u5b66\u4e60\u5d4c\u5165\u7ed3\u5408\uff0c\u5b9e\u73b0\u80bf\u7624\u7ea7\u522b\u76843D\u533b\u5b66\u56fe\u50cf\u68c0\u7d22\uff0c\u7a81\u7834\u73b0\u67092D\u65b9\u6cd5\u7684\u5c40\u9650\u3002  \n\u25c6 \u91c7\u7528\u53ef\u63d0\u793a\u5206\u5272\u6a21\u578b\uff08\u5982SAM\uff09\u751f\u6210\u80bf\u7624\u7279\u5f02\u6027\u56fe\u50cf\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u653e\u5c04\u7ec4\u5b66\u7279\u5f81\u5bf9\u9f50\uff0c\u589e\u5f3a\u7279\u5f81\u8868\u8fbe\u80fd\u529b\u3002  \n\u25c6 \u5f15\u5165\u89e3\u5256\u4f4d\u7f6e\u5d4c\u5165\uff08APE\uff09\uff0c\u4e3a\u68c0\u7d22\u7cfb\u7edf\u63d0\u4f9b\u5168\u5c40\u89e3\u5256\u4e0a\u4e0b\u6587\uff0c\u652f\u6301\u57fa\u4e8e\u4f4d\u7f6e\u7684\u7075\u6d3b\u67e5\u8be2\u3002  \n\u25c6 \u6846\u67b6\u4ec5\u9700\u6700\u5c0f\u7528\u6237\u4ea4\u4e92\uff08\u5982\u5355\u70b9\u6807\u6ce8\uff09\uff0c\u663e\u8457\u964d\u4f4e\u5206\u5272\u5f00\u9500\uff0c\u9002\u5e94\u591a\u6837\u4e34\u5e8a\u573a\u666f\u3002  \n\u25c6 \u652f\u6301\u6df7\u5408\u67e5\u8be2\u6a21\u5f0f\uff08\u56fe\u50cf\u5d4c\u5165\u6216\u9009\u5b9a\u653e\u5c04\u7ec4\u5b66\u5c5e\u6027\uff09\uff0c\u63d0\u5347\u8bca\u65ad\u3001\u6cbb\u7597\u89c4\u5212\u53ca\u533b\u5b66\u7814\u7a76\u7684\u5b9e\u7528\u6027\u3002  \n\u25c6 \u5728\u80ba\u90e8CT\u548c\u8111\u90e8MRI\u516c\u5f00\u6570\u636e\u96c6\u9a8c\u8bc1\u4e2d\uff0c\u653e\u5c04\u7ec4\u5b66\u7279\u5f81\u663e\u8457\u63d0\u9ad8\u68c0\u7d22\u7279\u5f02\u6027\uff0cAPE\u5bf9\u57fa\u4e8e\u4f4d\u7f6e\u7684\u641c\u7d22\u81f3\u5173\u91cd\u8981\u3002|\n",
    "2507.08420": "|2025-07-11|LiDAR, GNSS and IMU Sensor Alignment through Dynamic Time Warping to Construct 3D City Maps|Haitian Wang\u7b49|[2507.08420](http://arxiv.org/pdf/2507.08420)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408LiDAR\u3001GNSS\u548cIMU\u6570\u636e\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u65f6\u95f4\u89c4\u6574\uff08DTW\uff09\u8fdb\u884c\u901f\u5ea6\u5bf9\u9f50\uff0c\u89e3\u51b3\u57ce\u5e02\u89c4\u6a213D\u5efa\u56fe\u65f6\u7684\u7d2f\u79ef\u6f02\u79fb\u95ee\u9898\u3002  \n\u25c6 \u91c7\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u4f18\u5316GNSS\u548cIMU\u4fe1\u53f7\uff0c\u7ed3\u5408\u57fa\u4e8e\u6b63\u6001\u5206\u5e03\u53d8\u6362\uff08NDT\uff09\u7684\u5c40\u90e8\u5efa\u56fe\u4e0e\u4f4d\u59ff\u56fe\u4f18\u5316\uff0c\u63d0\u5347\u5c40\u90e8\u7cbe\u5ea6\u3002  \n\u25c6 \u5f15\u5165GNSS\u7ea6\u675f\u951a\u70b9\u548c\u91cd\u53e0\u6bb5\u7cbe\u7ec6\u914d\u51c6\u6280\u672f\uff0c\u663e\u8457\u6539\u5584\u5168\u5c40\u4e00\u81f4\u6027\uff0c\u5c06\u5e73\u5747\u5168\u5c40\u5bf9\u9f50\u8bef\u5dee\u4ece3.32\u7c73\u964d\u4f4e\u81f31.24\u7c73\uff08\u63d0\u534761.4%\uff09\u3002  \n\u25c6 \u53d1\u5e03\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5305\u542b21\u6761\u57ce\u5e02\u73af\u7ebf\u768412.8\u4e07\u5e27128\u7ebfLiDAR\u6570\u636e\u3001\u540c\u6b65RTK-GNSS\u8f68\u8ff9\u53caMEMS-IMU\u6d4b\u91cf\u503c\uff0c\u586b\u8865\u7814\u7a76\u7a7a\u767d\u3002  \n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u9053\u8def\u4e2d\u5fc3\u7ebf\u548c\u4ea4\u53c9\u53e3\u7684\u51e0\u4f55\u4e00\u81f4\u6027\u8bc4\u4f30\u6307\u6807\uff0c\u91cf\u5316\u5168\u5c40\u4e0e\u5c40\u90e8\u7cbe\u5ea6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u5efa\u7acb\u65b0\u57fa\u51c6\u3002  \n\u25c6 \u6240\u6784\u5efa\u7684\u9ad8\u7cbe\u5ea6\u5730\u56fe\u652f\u6301\u667a\u6167\u57ce\u5e02\u89c4\u5212\u3001\u57fa\u7840\u8bbe\u65bd\u76d1\u6d4b\u7b49\u5e94\u7528\uff0c\u540c\u65f6\u516c\u5f00\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002|\n",
    "2507.08404": "|2025-07-11|Deep Hashing with Semantic Hash Centers for Image Retrieval|Li Chen\u7b49|[2507.08404](http://arxiv.org/pdf/2507.08404)|\u65e0|\u25c6 \u63d0\u51fa\u8bed\u4e49\u54c8\u5e0c\u4e2d\u5fc3\u6982\u5ff5\uff0c\u901a\u8fc7\u6570\u636e\u4f9d\u8d56\u7684\u76f8\u4f3c\u6027\u8ba1\u7b97\u6355\u6349\u7c7b\u522b\u95f4\u7684\u8bed\u4e49\u5173\u7cfb\uff0c\u53d6\u4ee3\u4f20\u7edf\u6570\u636e\u65e0\u5173\u7684\u54c8\u5e0c\u4e2d\u5fc3\u751f\u6210\u65b9\u6cd5\u3002  \n\u25c6 \u8bbe\u8ba1\u4e09\u9636\u6bb5\u6846\u67b6SHC\uff1a\u5148\u8bad\u7ec3\u5206\u7c7b\u7f51\u7edc\u8bc6\u522b\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u518d\u4f18\u5316\u751f\u6210\u4fdd\u7559\u8bed\u4e49\u7ed3\u6784\u7684\u54c8\u5e0c\u4e2d\u5fc3\uff0c\u6700\u540e\u8bad\u7ec3\u6df1\u5ea6\u54c8\u5e0c\u7f51\u7edc\u751f\u6210\u4e8c\u8fdb\u5236\u7801\u3002  \n\u25c6 \u5f00\u53d1\u65b0\u578b\u4f18\u5316\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u8bed\u4e49\u76f8\u5173\u6027\u7684\u540c\u65f6\u5f3a\u5236\u6700\u5c0f\u4e2d\u5fc3\u95f4\u8ddd\uff0c\u907f\u514d\u54c8\u5e0c\u7801\u8fc7\u5ea6\u76f8\u4f3c\u7684\u95ee\u9898\u3002  \n\u25c6 \u9996\u6b21\u5c06\u7c7b\u522b\u8bed\u4e49\u5173\u7cfb\u5efa\u6a21\u4e3a\u6c49\u660e\u7a7a\u95f4\u7684\u8ddd\u79bb\u7ea6\u675f\uff0c\u4f7f\u76f8\u4f3c\u7c7b\u522b\u7684\u54c8\u5e0c\u4e2d\u5fc3\u8ddd\u79bb\u66f4\u8fd1\uff0c\u4e0d\u76f8\u4f3c\u7c7b\u522b\u66f4\u8fdc\u3002  \n\u25c6 \u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6027\u80fd\uff0cMAP@100/1000/ALL\u6307\u6807\u5e73\u5747\u63d0\u53477.26%/7.62%/11.71%\uff0c\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002  \n\u25c6 \u63d0\u51fa\u7684\u6570\u636e\u4f9d\u8d56\u76f8\u4f3c\u6027\u8ba1\u7b97\u65b9\u6cd5\u80fd\u81ea\u9002\u5e94\u4e0d\u540c\u6570\u636e\u5206\u5e03\uff0c\u589e\u5f3a\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002|\n",
    "2507.08021": "|2025-07-08|Unveiling Effective In-Context Configurations for Image Captioning: An External & Internal Analysis|Li Li\u7b49|[2507.08021](http://arxiv.org/pdf/2507.08021)|\u65e0|\u25c6 \u9996\u6b21\u5bf9\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u5728\u56fe\u50cf\u63cf\u8ff0\u4efb\u52a1\u4e2d\u7684\u6f14\u793a\u914d\u7f6e\u8fdb\u884c\u7cfb\u7edf\u6027\u5916\u90e8\u7814\u7a76\uff0c\u63a2\u7d22\u4e86\u793a\u4f8b\u6570\u91cf\u3001\u56fe\u50cf\u68c0\u7d22\u548c\u63cf\u8ff0\u5206\u914d\u4e09\u4e2a\u7ef4\u5ea6\u7684\u7b56\u7565\u3002  \n\u25c6 \u901a\u8fc7\u5185\u90e8\u6ce8\u610f\u529b\u673a\u5236\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5178\u578b\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMM\uff09\u7684\u6ce8\u610f\u529b\u7279\u5f81\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u91cf\u5316\u6307\u6807\u4ee5\u8bc4\u4f30\u6a21\u578b\u884c\u4e3a\u3002  \n\u25c6 \u7ed3\u5408\u5916\u90e8\u5b9e\u9a8c\u4e0e\u5185\u90e8\u673a\u5236\u5206\u6790\u7684\u53cc\u91cd\u89c6\u89d2\uff0c\u63d0\u4f9b\u4e86\u7406\u89e3\u591a\u6a21\u6001ICL\u7684\u65b0\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u793a\u4f8b\u914d\u7f6e\u5982\u4f55\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5f71\u54cd\u6a21\u578b\u8868\u73b0\u3002  \n\u25c6 \u63d0\u51fa\u6ce8\u610f\u529b\u9a71\u52a8\u7684\u6a21\u578b\u52a0\u901f\u4e0e\u538b\u7f29\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u5206\u6790\u7684\u6a21\u578b\u4f18\u5316\u53ef\u884c\u6027\u3002  \n\u25c6 \u5bf9\u6bd4\u4e86\u76f8\u540c\u67b6\u6784\u4e0e\u9884\u8bad\u7ec3\u7b56\u7565\u7684LMM\u6027\u80fd\u5dee\u5f02\uff0c\u4ece\u9884\u8bad\u7ec3\u6570\u636e\u7279\u5f81\u89d2\u5ea6\u89e3\u91ca\u4e86\u6a21\u578b\u8868\u73b0\u5dee\u5f02\u7684\u539f\u56e0\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u7ed3\u5408\u5916\u90e8\u8bc4\u4f30\u4e0e\u5185\u90e8\u6307\u6807\u7684\u65b0\u65b9\u6cd5\u8bba\uff0c\u53ef\u6269\u5c55\u81f3\u5176\u4ed6\u5927\u6a21\u578b\u7814\u7a76\u9886\u57df\u3002|\n",
    "2507.10473": "|2025-07-14|GT-Loc: Unifying When and Where in Images Through a Joint Embedding Space|David G. Shatwell\u7b49|[2507.10473](http://arxiv.org/pdf/2507.10473)|\u65e0|\u25c6 GT-Loc\u9996\u6b21\u63d0\u51fa\u8054\u5408\u5b66\u4e60\u56fe\u50cf\u62cd\u6444\u65f6\u95f4\u548c\u5730\u7406\u4f4d\u7f6e\u7684\u7edf\u4e00\u5d4c\u5165\u7a7a\u95f4\uff0c\u901a\u8fc7\u591a\u7f16\u7801\u5668\uff08\u56fe\u50cf\u3001\u65f6\u95f4\u3001\u5730\u70b9\uff09\u5728\u5171\u4eab\u7279\u5f81\u7a7a\u95f4\u4e2d\u5bf9\u9f50\u4e09\u8005\u8868\u5f81\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u4e2d\u65f6\u95f4\u9884\u6d4b\u4f9d\u8d56\u5730\u7406\u4fe1\u606f\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u73af\u5f62\u65f6\u5e8f\u5ea6\u91cf\u5b66\u4e60\u76ee\u6807\uff0c\u5c06\u65f6\u95f4\u5dee\u5f02\u5efa\u6a21\u4e3a\u73af\u9762\uff08toroidal\uff09\u4e0a\u7684\u8f6f\u76ee\u6807\uff0c\u66ff\u4ee3\u4f20\u7edf\u5bf9\u6bd4\u5b66\u4e60\u7684\u786c\u6b63\u8d1f\u6837\u672c\uff0c\u66f4\u8d34\u5408\u65f6\u95f4\u5468\u671f\u6027\u7684\u672c\u8d28\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8054\u5408\u4f18\u5316\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65f6\u95f4\u9884\u6d4b\u65b9\u6cd5\uff0c\u5373\u4f7f\u5bf9\u6bd4\u90a3\u4e9b\u5728\u63a8\u7406\u9636\u6bb5\u4f7f\u7528\u771f\u5b9e\u5730\u7406\u4f4d\u7f6e\u4f5c\u4e3a\u8f93\u5165\u7684\u65b9\u6cd5\uff0c\u4ecd\u5c55\u73b0\u51fa\u66f4\u9ad8\u7cbe\u5ea6\u3002  \n\u25c6 \u5728\u6807\u51c6\u5730\u7406\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u8fbe\u5230\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u540c\u65f6\u7edf\u4e00\u5d4c\u5165\u7a7a\u95f4\u652f\u6301\u7ec4\u5408\u68c0\u7d22\uff08\u5982\"\u590f\u5b63\u9ec4\u660f\u7684\u5df4\u9ece\"\uff09\u548c\u6587\u672c\u5f15\u5bfc\u7684\u56fe\u50cf\u68c0\u7d22\uff0c\u6269\u5c55\u4e86\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u63d0\u51fa\u65b0\u57fa\u51c6\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u63ed\u793a\u4e86\u65f6\u95f4\u4e0e\u5730\u7406\u7ebf\u7d22\u7684\u6df1\u5c42\u5173\u8054\uff0c\u4e3a\u8de8\u6a21\u6001\u68c0\u7d22\u7814\u7a76\u63d0\u4f9b\u65b0\u65b9\u5411\u3002|\n",
    "2507.10403": "|2025-07-14|Text-to-Remote-Sensing-Image Retrieval beyond RGB Sources|Daniele Rege Cambrin\u7b49|[2507.10403](http://arxiv.org/pdf/2507.10403)|\u65e0|\u25c6 \u63d0\u51faCrisisLandMark\u6570\u636e\u96c6\uff0c\u5305\u542b64.7\u4e07\u5f20Sentinel-1 SAR\u548cSentinel-2\u591a\u5149\u8c31\u56fe\u50cf\uff0c\u5e76\u914d\u5bf9\u4e86\u7ed3\u6784\u5316\u6587\u672c\u6807\u6ce8\uff0c\u8986\u76d6\u571f\u5730\u8986\u76d6\u3001\u571f\u5730\u5229\u7528\u548c\u5371\u673a\u4e8b\u4ef6\uff0c\u6570\u636e\u6765\u6e90\u6743\u5a01\u3002  \n\u25c6 \u5f00\u53d1CLOSP\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u672c\u4f5c\u4e3a\u6865\u6881\uff0c\u5c06\u672a\u914d\u5bf9\u7684\u5149\u5b66\u548cSAR\u56fe\u50cf\u5bf9\u9f50\u5230\u7edf\u4e00\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u5b9e\u73b0\u8de8\u6a21\u6001\u68c0\u7d22\u3002  \n\u25c6 CLOSP\u5728\u68c0\u7d22\u6027\u80fd\u4e0a\u53d6\u5f97\u7a81\u7834\uff0cnDGC\u6307\u6807\u6bd4\u73b0\u6709\u6a21\u578b\u63d0\u534754%\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u6548\u679c\u3002  \n\u25c6 \u63d0\u51fa\u7edf\u4e00\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7\u5149\u5b66\u56fe\u50cf\u7684\u4e30\u5bcc\u8bed\u4e49\u77e5\u8bc6\u95f4\u63a5\u8f85\u52a9SAR\u56fe\u50cf\u89e3\u8bd1\uff0c\u514b\u670dSAR\u56fe\u50cf\u89e3\u8bd1\u7684\u56fa\u6709\u56f0\u96be\u3002  \n\u25c6 \u6269\u5c55GeoCLOSP\u6a21\u578b\uff0c\u6574\u5408\u5730\u7406\u5750\u6807\u4fe1\u606f\uff0c\u5728\u901a\u7528\u8bed\u4e49\u4efb\u52a1\u548c\u5730\u7406\u4f4d\u7f6e\u76f8\u5173\u7684\u5371\u673a\u4e8b\u4ef6\u68c0\u7d22\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u6210\u4e3a\u7279\u5b9a\u9886\u57df\u7684\u4e13\u5bb6\u3002  \n\u25c6 \u5f3a\u8c03\u591a\u4f20\u611f\u5668\u6570\u636e\u548c\u5730\u7406\u4e0a\u4e0b\u6587\u6574\u5408\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u9065\u611f\u6863\u6848\u7684\u5168\u9762\u5229\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2507.10265": "|2025-07-14|Kaleidoscopic Background Attack: Disrupting Pose Estimation with Multi-Fold Radial Symmetry Textures|Xinlong Ding\u7b49|[2507.10265](http://arxiv.org/pdf/2507.10265)|\u65e0|\u25c6\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u2014\u2014\u4e07\u82b1\u7b52\u80cc\u666f\u653b\u51fb\uff08KBA\uff09\uff0c\u901a\u8fc7\u591a\u91cd\u590d\u5236\u5bf9\u79f0\u7eb9\u7406\u6784\u9020\u5706\u5f62\u80cc\u666f\u56fe\u6848\uff0c\u6709\u6548\u5e72\u6270\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u6a21\u578b\u3002  \n\u25c6\u9996\u6b21\u5229\u7528\u81ea\u7136\u7eb9\u7406\u7247\u6bb5\u6784\u5efa\u5177\u6709\u591a\u91cd\u590d\u5236\u5bf9\u79f0\u6027\u7684\u5706\u76d8\u7ed3\u6784\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u5728\u4e0d\u540c\u89c6\u89d2\u4e0b\u4fdd\u6301\u9ad8\u5ea6\u76f8\u4f3c\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u7684\u8de8\u89c6\u89d2\u4e00\u81f4\u6027\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u63d0\u51fa\u4e86\u6295\u5f71\u65b9\u5411\u4e00\u81f4\u6027\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u4f18\u5316\u4e07\u82b1\u7b52\u7eb9\u7406\u7247\u6bb5\u7684\u7a7a\u95f4\u5206\u5e03\uff0c\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u653b\u51fb\u6548\u679c\u3002  \n\u25c6\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u653b\u51fb\u591a\u79cd\u4e3b\u6d41\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u7a00\u758f\u8f93\u5165\u573a\u666f\u4e0b\u80cc\u666f\u7eb9\u7406\u5bf9\u4f4d\u59ff\u4f30\u8ba1\u7684\u5173\u952e\u5f71\u54cd\u3002  \n\u25c6\u4e3a\u5bf9\u6297\u653b\u51fb\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u5c06\u51e0\u4f55\u5bf9\u79f0\u6027\u4e0e\u81ea\u7136\u7eb9\u7406\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u590d\u6742\u5bf9\u6297\u6837\u672c\u751f\u6210\u7684\u9ad8\u6548\u653b\u51fb\u3002|\n",
    "2507.10571": "|2025-07-09|Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning|Konstantinos I. Roumeliotis\u7b49|[2507.10571](http://arxiv.org/pdf/2507.10571)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u6a21\u5757\u5316Agentic AI\u89c6\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u5c06\u901a\u7528\u591a\u6a21\u6001\u667a\u80fd\u4f53\u4e0e\u975e\u89c6\u89c9\u63a8\u7406\u534f\u8c03\u5668\u3001RAG\u6a21\u5757\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u611f\u77e5\u4e0e\u5143\u63a8\u7406\u7684\u5206\u79bb\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u4fe1\u4efb\u611f\u77e5\u534f\u8c03\u673a\u5236\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u6821\u51c6\u6307\u6807\uff08ECE/OCR/CCC\uff09\u52a8\u6001\u8c03\u8282\u5bf9\u591a\u667a\u80fd\u4f53\u7684\u4fe1\u4efb\u5ea6\uff0c\u5728\u96f6\u6837\u672c\u573a\u666f\u4e0b\u51c6\u786e\u7387\u63d0\u534777.94%\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u57fa\u4e8eCLIP\u56fe\u50cf\u68c0\u7d22\u548c\u91cd\u8bc4\u4f30\u5faa\u73af\u7684\u4fe1\u4efb\u6821\u51c6\u65b9\u6cd5\uff0c\u5229\u7528\u89c6\u89c9\u76f8\u4f3c\u6848\u4f8b\u4fee\u6b63\u667a\u80fd\u4f53\u7684\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u589e\u5f3a\u9884\u6d4b\u53ef\u89e3\u91ca\u6027\u3002  \n\u25c6 \u5728\u82f9\u679c\u53f6\u75c5\u5bb3\u8bca\u65ad\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e09\u79cd\u914d\u7f6e\uff1a\u96f6\u6837\u672c\u7f6e\u4fe1\u534f\u8c03\u3001\u5fae\u8c03\u667a\u80fd\u4f53\u4f18\u5316\u3001\u4ee5\u53caRAG\u589e\u5f3a\u7684\u4fe1\u4efb\u6821\u51c6\u534f\u8c03\uff0c\u6700\u9ad8\u8fbe85.63%\u51c6\u786e\u7387\u3002  \n\u25c6 \u53d1\u73b0GPT-4o\u5177\u6709\u66f4\u4f18\u6821\u51c6\u6027\uff0c\u800cQwen-2.5-VL\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u73b0\u8c61\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u5206\u6790\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002  \n\u25c6 \u5f00\u6e90\u5168\u90e8\u6a21\u578b\u3001\u63d0\u793a\u8bcd\u3001\u8f6f\u4ef6\u4ee3\u7801\u53ca\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4e3a\u53ef\u4fe1\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5efa\u7acb\u53ef\u590d\u73b0\u57fa\u51c6\uff0c\u9002\u7528\u4e8e\u751f\u7269\u8bca\u65ad\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u3002|\n",
    "2507.12416": "|2025-07-16|QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval|Jaehyun Kwak\u7b49|[2507.12416](http://arxiv.org/pdf/2507.12416)|\u65e0|\u25c6 \u63d0\u51faQuRe\u65b9\u6cd5\uff0c\u901a\u8fc7\u786c\u8d1f\u6837\u672c\u91c7\u6837\u89e3\u51b3\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\uff08CIR\uff09\u4e2d\u5047\u9634\u6027\u95ee\u9898\uff0c\u4f18\u5316\u5956\u52b1\u6a21\u578b\u76ee\u6807\u4ee5\u63d0\u5347\u68c0\u7d22\u76f8\u5173\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u65b0\u9896\u7684\u786c\u8d1f\u6837\u672c\u91c7\u6837\u7b56\u7565\uff0c\u9009\u62e9\u76ee\u6807\u56fe\u50cf\u540e\u76f8\u5173\u6027\u5206\u6570\u4e24\u6b21\u9661\u964d\u4e4b\u95f4\u7684\u56fe\u50cf\uff0c\u6709\u6548\u8fc7\u6ee4\u5047\u9634\u6027\u6837\u672c\u3002  \n\u25c6 \u521b\u5efaHP-FashionIQ\u6570\u636e\u96c6\uff0c\u9996\u6b21\u5728CIR\u4efb\u52a1\u4e2d\u660e\u786e\u6355\u83b7\u7528\u6237\u504f\u597d\uff0c\u8d85\u8d8a\u4f20\u7edf\u4ec5\u5173\u6ce8\u76ee\u6807\u56fe\u50cf\u68c0\u7d22\u7684\u8bc4\u4f30\u65b9\u5f0f\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eQuRe\u5728FashionIQ\u548cCIRR\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u5e76\u5728HP-FashionIQ\u4e0a\u5c55\u73b0\u51fa\u4e0e\u4eba\u7c7b\u504f\u597d\u6700\u5f3a\u7684\u5bf9\u9f50\u6027\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\uff0c\u4e3aCIR\u9886\u57df\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u65b9\u6cd5\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u5bfc\u5411\u7684\u8bc4\u4f30\u6846\u67b6\u3002|\n",
    "2507.11834": "|2025-07-16|CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning|Peiwen Xia\u7b49|[2507.11834](http://arxiv.org/pdf/2507.11834)|\u65e0|\u25c6 \u63d0\u51faCorrMoE\u6846\u67b6\uff0c\u9996\u6b21\u9488\u5bf9\u8de8\u573a\u666f\u548c\u8de8\u57df\u5bf9\u5e94\u70b9\u4fee\u526a\u4efb\u52a1\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u89c6\u89c9\u57df\u4e0d\u4e00\u81f4\u548c\u573a\u666f\u7ed3\u6784\u591a\u6837\u65f6\u7684\u6027\u80fd\u74f6\u9888\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u53bb\u98ce\u683c\u5316\u53cc\u5206\u652f\u7ed3\u6784\uff0c\u901a\u8fc7\u9690\u5f0f\u548c\u663e\u5f0f\u56fe\u7279\u5f81\u7684\u98ce\u683c\u6df7\u5408\uff0c\u6709\u6548\u51cf\u5c11\u57df\u7279\u5f02\u6027\u8868\u5f81\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u63d0\u5347\u8de8\u57df\u9c81\u68d2\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u53cc\u878d\u5408\u4e13\u5bb6\u6df7\u5408\u6a21\u5757\uff08Bi-Fusion MoE\uff09\uff0c\u7ed3\u5408\u7ebf\u6027\u590d\u6742\u5ea6\u6ce8\u610f\u529b\u673a\u5236\u548c\u52a8\u6001\u4e13\u5bb6\u8def\u7531\uff0c\u81ea\u9002\u5e94\u6574\u5408\u591a\u89c6\u89d2\u7279\u5f81\u4ee5\u5e94\u5bf9\u573a\u666f\u591a\u6837\u6027\u3002  \n\u25c6 \u5728\u7279\u5f81\u878d\u5408\u4e2d\u5b9e\u73b0\u8ba1\u7b97\u6548\u7387\u4f18\u5316\uff0c\u901a\u8fc7\u7ebf\u6027\u6ce8\u610f\u529b\u964d\u4f4e\u4f20\u7edfTransformer\u7684\u4e8c\u6b21\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u591a\u4e13\u5bb6\u6a21\u578b\u7684\u52a8\u6001\u9002\u5e94\u6027\u3002  \n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709SOTA\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u8de8\u57df\u548c\u8de8\u573a\u666f\u4efb\u52a1\u4e2d\u5c55\u73b0\u5f3a\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u53ef\u590d\u73b0\u7684\u57fa\u7840\u3002|\n",
    "2507.12823": "|2025-07-17|FAR-Net: Multi-Stage Fusion Network with Enhanced Semantic Alignment and Adaptive Reconciliation for Composed Image Retrieval|Jeong-Woo Park\u7b49|[2507.12823](http://arxiv.org/pdf/2507.12823)|\u65e0|\u25c6 \u63d0\u51faFAR-Net\u591a\u9636\u6bb5\u878d\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u65e9\u671f\u548c\u665a\u671f\u878d\u5408\u4f18\u52bf\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u89c6\u89c9-\u6587\u672c\u6a21\u6001\u878d\u5408\u4e2d\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u589e\u5f3a\u8bed\u4e49\u5bf9\u9f50\u6a21\u5757\uff08ESAM\uff09\uff0c\u901a\u8fc7\u8de8\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5173\u8054\uff0c\u5f25\u8865\u665a\u671f\u878d\u5408\u5bf9\u5c40\u90e8\u5bf9\u9f50\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u5f15\u5165\u81ea\u9002\u5e94\u534f\u8c03\u6a21\u5757\uff08ARM\uff09\uff0c\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u5d4c\u5165\u7684\u65e9\u671f\u878d\u5408\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u5e73\u8861\u6587\u672c\u663e\u5f0f\u63cf\u8ff0\u4e0e\u89c6\u89c9\u4e0a\u4e0b\u6587\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u6574\u5408ESAM\u4e0eARM\uff0c\u5f62\u6210\u4e92\u8865\u673a\u5236\uff0c\u540c\u65f6\u6355\u6349\u5168\u5c40\u8bed\u4e49\u548c\u5c40\u90e8\u7ec6\u8282\uff0c\u63d0\u5347\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u7cbe\u5ea6\u3002  \n\u25c6 \u5728CIRR\u548cFashionIQ\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0cRecall@1\u6700\u9ad8\u63d0\u53472.4%\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002|\n",
    "2507.12819": "|2025-07-17|MCoT-RE: Multi-Faceted Chain-of-Thought and Re-Ranking for Training-Free Zero-Shot Composed Image Retrieval|Jeong-Woo Park\u7b49|[2507.12819](http://arxiv.org/pdf/2507.12819)|\u65e0|\u25c6 \u63d0\u51faMCoT-RE\u6846\u67b6\uff0c\u9996\u6b21\u5728\u96f6\u6837\u672c\u8bad\u7ec3\u81ea\u7531\u7684\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u4efb\u52a1\u4e2d\u5f15\u5165\u591a\u89d2\u5ea6\u601d\u7ef4\u94fe\uff08Chain-of-Thought\uff09\u6280\u672f\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u6a21\u6001\u4ea4\u4e92\u4e0d\u8db3\u7684\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7\u53cc\u8def\u5f84\u751f\u6210\u7b56\u7565\uff0c\u5206\u522b\u751f\u6210\u4fa7\u91cd\u6587\u672c\u4fee\u6539\u7684 caption \u548c\u878d\u5408\u89c6\u89c9\u4e0a\u4e0b\u6587\u7684 caption\uff0c\u5e73\u8861\u663e\u5f0f\u4fee\u6539\u4e0e\u9690\u5f0f\u89c6\u89c9\u7ebf\u7d22\u7684\u5229\u7528\u3002  \n\u25c6 \u8bbe\u8ba1\u4e24\u9636\u6bb5\u68c0\u7d22\u6d41\u7a0b\uff1a\u9996\u9636\u6bb5\u7528\u4fee\u6539\u5bfc\u5411 caption \u7c97\u7b5b\u5019\u9009\u56fe\u50cf\uff0c\u7b2c\u4e8c\u9636\u6bb5\u7ed3\u5408\u53cc caption \u548c\u53c2\u8003\u56fe\u50cf\u8fdb\u884c\u591a\u7c92\u5ea6\u91cd\u6392\u5e8f\uff0c\u63d0\u5347\u7cbe\u5ea6\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u601d\u7ef4\u94fe\u6269\u5c55\u81f3\u591a\u6a21\u6001\u573a\u666f\uff0c\u6307\u5bfc MLLM \u540c\u65f6\u5904\u7406\u6587\u672c\u6307\u4ee4\u4e0e\u89c6\u89c9\u4e0a\u4e0b\u6587\uff0c\u907f\u514d\u4fe1\u606f\u4e22\u5931\u3002  \n\u25c6 \u5728\u4e3b\u6d41\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u663e\u8457\u63d0\u5347\uff0cFashionIQ \u7684 Recall@10 \u63d0\u9ad8 6.24%\uff0cCIRR \u7684 Recall@1 \u63d0\u5347 8.58%\uff0c\u8fbe\u5230\u96f6\u6837\u672c\u65b9\u6cd5\u6700\u4f18\u6027\u80fd\u3002  \n\u25c6 \u6574\u4e2a\u6846\u67b6\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u4ec5\u4f9d\u8d56\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u4fdd\u6301\u9ad8\u6548\u4f4e\u6210\u672c\u4f18\u52bf\u7684\u540c\u65f6\u7a81\u7834\u73b0\u6709\u6280\u672f\u74f6\u9888\u3002|\n",
    "2507.15109": "|2025-07-20|LoopNet: A Multitasking Few-Shot Learning Approach for Loop Closure in Large Scale SLAM|Mohammad-Maher Nakshbandi\u7b49|[2507.15109](http://arxiv.org/pdf/2507.15109)|\u65e0|\u25c6 \u63d0\u51faLoopNet\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u5c11\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u5927\u89c4\u6a21SLAM\u4e2d\u7684\u95ed\u73af\u68c0\u6d4b\u95ee\u9898\uff0c\u517c\u987e\u7cbe\u5ea6\u4e0e\u5b9e\u65f6\u6027\u9700\u6c42\u3002  \n\u25c6 \u91c7\u7528\u6539\u8fdb\u7684ResNet\u67b6\u6784\uff0c\u652f\u6301\u52a8\u6001\u89c6\u89c9\u6570\u636e\u96c6\u7684\u5728\u7ebf\u91cd\u8bad\u7ec3\uff0c\u5e76\u9488\u5bf9\u5d4c\u5165\u5f0f\u8bbe\u5907\u8fdb\u884c\u4f18\u5316\uff0c\u9002\u5e94\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u3002  \n\u25c6 \u521b\u65b0\u6027\u7ed3\u5408\u5c11\u6837\u672c\u5b66\u4e60\u7b56\u7565\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u5feb\u901f\u9002\u5e94\u65b0\u73af\u5883\uff0c\u540c\u65f6\u8f93\u51fa\u67e5\u8be2\u7d22\u5f15\u548c\u9884\u6d4b\u8d28\u91cf\u8bc4\u4f30\uff0c\u589e\u5f3a\u7cfb\u7edf\u53ef\u9760\u6027\u3002  \n\u25c6 \u5229\u7528DISK\u63cf\u8ff0\u7b26\u66ff\u4ee3\u4f20\u7edf\u624b\u5de5\u7279\u5f81\u6216\u5e38\u89c4\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5149\u7167\u3001\u89c6\u89d2\u7b49\u53d8\u5316\u6761\u4ef6\u4e0b\u7684\u95ed\u73af\u68c0\u6d4b\u6027\u80fd\u3002  \n\u25c6 \u5f00\u6e90\u4e86\u65b0\u578b\u95ed\u73af\u68c0\u6d4b\u57fa\u51c6\u6570\u636e\u96c6LoopDB\uff0c\u586b\u8865\u73b0\u6709\u6570\u636e\u5728\u52a8\u6001\u573a\u666f\u548c\u5d4c\u5165\u5f0f\u786c\u4ef6\u8bc4\u4f30\u65b9\u9762\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u6574\u4f53\u65b9\u6848\u5728\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u5747\u5df2\u516c\u5f00\uff0c\u63a8\u52a8SLAM\u9886\u57df\u7814\u7a76\u53ef\u590d\u73b0\u6027\u3002|\n",
    "2507.15089": "|2025-07-20|Visual Place Recognition for Large-Scale UAV Applications|Ioannis Tsampikos Papapetros\u7b49|[2507.15089](http://arxiv.org/pdf/2507.15089)|\u65e0|\u25c6 \u63d0\u51fa\u4e86LASED\u5927\u89c4\u6a21\u65e0\u4eba\u673a\u89c6\u89c9\u5b9a\u4f4d\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ea6100\u4e07\u5f20\u56fe\u7247\uff0c\u8986\u76d6\u7231\u6c99\u5c3c\u4e9a17\u4e07\u4e2a\u72ec\u7279\u5730\u70b9\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5730\u7406\u548c\u65f6\u95f4\u591a\u6837\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u822a\u7a7a\u573a\u666f\u4e2d\u7684\u8bad\u7ec3\u6548\u679c\u3002  \n\u25c6 \u6570\u636e\u96c6\u91c7\u7528\u7ed3\u6784\u5316\u8bbe\u8ba1\uff0c\u786e\u4fdd\u5730\u70b9\u5206\u79bb\u6e05\u6670\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u89c4\u6a21\u5c0f\u3001\u591a\u6837\u6027\u4e0d\u8db3\u5bfc\u81f4\u7684\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\u3002  \n\u25c6 \u63d0\u51fa\u4f7f\u7528\u53ef\u8f6c\u5411\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08steerable CNNs\uff09\u5904\u7406\u65e0\u4eba\u673a\u56fe\u50cf\u4e2d\u7684\u65cb\u8f6c\u6a21\u7cca\u95ee\u9898\uff0c\u5229\u7528\u5176\u65cb\u8f6c\u7b49\u53d8\u6027\u751f\u6210\u65b9\u5411\u4e0d\u53d8\u7684\u7279\u5f81\u8868\u793a\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\uff0c\u57fa\u4e8eLASED\u8bad\u7ec3\u7684\u6a21\u578b\u53ec\u56de\u7387\u663e\u8457\u9ad8\u4e8e\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u51f8\u663e\u4e86\u5730\u7406\u8986\u76d6\u548c\u65f6\u95f4\u591a\u6837\u6027\u7684\u91cd\u8981\u6027\u3002  \n\u25c6 \u53ef\u8f6c\u5411CNN\u5728\u65cb\u8f6c\u6a21\u7cca\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e73\u5747\u53ec\u56de\u7387\u6bd4\u6700\u4f73\u975e\u53ef\u8f6c\u5411\u7f51\u7edc\u63d0\u9ad812%\uff0c\u6709\u6548\u63d0\u5347\u4e86\u822a\u7a7a\u89c6\u89c9\u5b9a\u4f4d\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u7ed3\u5408\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u96c6\u548c\u65cb\u8f6c\u7b49\u53d8\u7f51\u7edc\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u589e\u5f3a\u4e86\u822a\u7a7a\u89c6\u89c9\u5b9a\u4f4d\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002|\n",
    "2507.14902": "|2025-07-20|U-MARVEL: Unveiling Key Factors for Universal Multimodal Retrieval via Embedding Learning with MLLMs|Xiaojie Li\u7b49|[2507.14902](http://arxiv.org/pdf/2507.14902)|\u65e0|\u25c6 \u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u57fa\u4e8eMLLMs\u7684\u901a\u7528\u591a\u6a21\u6001\u68c0\u7d22\uff08UMR\uff09\u4e2d\u5f71\u54cd\u5d4c\u5165\u5b66\u4e60\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u63ed\u793a\u4e86\u5e38\u88ab\u5ffd\u89c6\u7684\u8bad\u7ec3\u7ec6\u8282\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u91cd\u8981\u5f71\u54cd\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684MLLM\u5d4c\u5165\u5b66\u4e60\u6846\u67b6U-MARVEL\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u8fc7\u6e21\u3001\u56f0\u96be\u8d1f\u6837\u672c\u6316\u6398\u548c\u91cd\u6392\u5e8f\u84b8\u998f\u7b49\u7b56\u7565\u4f18\u5316\u5d4c\u5165\u751f\u6210\u548c\u8bad\u7ec3\u8fc7\u7a0b\u3002  \n\u25c6 \u5728\u76d1\u7763\u5b66\u4e60\u573a\u666f\u4e0b\uff0cU-MARVEL\u5728M-BEIR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u663e\u8457\u7684\u6027\u80fd\u4f18\u52bf\u3002  \n\u25c6 \u6846\u67b6\u5728\u96f6\u6837\u672c\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\u3001\u6587\u672c-\u89c6\u9891\u68c0\u7d22\u7b49\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u7814\u7a76\u4e3a\u591a\u6a21\u6001\u68c0\u7d22\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u4ee3\u7801\u5b9e\u73b0\u548c\u7cfb\u7edf\u5316\u7684\u8bad\u7ec3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\u53d1\u5c55\u3002|\n",
    "2507.14477": "|2025-07-19|OptiCorNet: Optimizing Sequence-Based Context Correlation for Visual Place Recognition|Zhenyu Li\u7b49|[2507.14477](http://arxiv.org/pdf/2507.14477)|\u65e0|\u25c6 OptiCorNet\u63d0\u51fa\u9996\u4e2a\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u7684\u5e8f\u5217\u5efa\u6a21\u6846\u67b6\uff0c\u5c06\u7a7a\u95f4\u7279\u5f81\u63d0\u53d6\u4e0e\u65f6\u5e8f\u5dee\u5206\u7edf\u4e00\u5230\u5355\u4e00\u6a21\u5757\u4e2d\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u5355\u5e27\u5d4c\u5165\u65b9\u6cd5\u7684\u5c40\u9650\u3002  \n\u25c6 \u521b\u65b0\u8bbe\u8ba1\u53ef\u5fae\u5206\u65f6\u5e8f\u5dee\u5206\u7b97\u5b50\uff08DSD\uff09\uff0c\u901a\u8fc7\u56fa\u5b9a\u6743\u91cd\u5dee\u5206\u6838\u6355\u6349\u65b9\u5411\u6027\u5e8f\u5217\u5dee\u5f02\uff0c\u7ed3\u5408LSTM\u7cbe\u4fee\u6a21\u5757\uff0c\u6709\u6548\u5efa\u6a21\u77ed\u65f6\u7a7a\u95f4\u4e0a\u4e0b\u6587\u548c\u957f\u7a0b\u65f6\u5e8f\u5173\u8054\u3002  \n\u25c6 \u5f15\u5165\u6b8b\u5dee\u6295\u5f71\u673a\u5236\u589e\u5f3a\u63cf\u8ff0\u7b26\u5224\u522b\u529b\uff0c\u751f\u6210\u7684\u7d27\u51d1\u5e8f\u5217\u63cf\u8ff0\u7b26\u5bf9\u89c6\u89d2\u53d8\u5316\u548c\u5916\u89c2\u5dee\u5f02\u5177\u6709\u663e\u8457\u9c81\u68d2\u6027\u3002  \n\u25c6 \u91c7\u7528\u56db\u5143\u7ec4\u635f\u5931\u51fd\u6570\u540c\u6b65\u4f18\u5316\u6279\u6b21\u5185\u6b63\u6837\u672c\u5bf9\u9f50\u4e0e\u591a\u8d1f\u6837\u672c\u5206\u79bb\uff0c\u663e\u8457\u63d0\u5347\u8de8\u573a\u666f\u7c7b\u95f4\u53ef\u5206\u6027\u3002  \n\u25c6 \u9996\u6b21\u5b9e\u73b0\u65f6\u5e8f\u805a\u5408\u7684\u7aef\u5230\u7aef\u8054\u5408\u5b66\u4e60\uff0c\u76f8\u6bd4\u540e\u5904\u7406\u65b9\u6cd5\u76f4\u63a5\u4f18\u5316\u5e8f\u5217\u7ea7\u5d4c\u5165\uff0c\u5728\u5b63\u8282\u548c\u89c6\u89d2\u53d8\u5316\u573a\u666f\u4e0b\u53d6\u5f97\u7a81\u7834\u6027\u6027\u80fd\u63d0\u5347\u3002  \n\u25c6 \u8f7b\u91cf\u7ea71D\u5377\u79ef\u7f16\u7801\u5668\u8bbe\u8ba1\u786e\u4fdd\u8ba1\u7b97\u6548\u7387\uff0c\u5728\u591a\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5168\u9762\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002|\n",
    "2507.14215": "|2025-07-16|Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired|Jiayu\u7b49|[2507.14215](http://arxiv.org/pdf/2507.14215)|\u65e0|\u25c6 \u5f00\u53d1\u4e86JerryNet\uff0c\u4e00\u79cd\u5b9a\u5236CNN\u67b6\u6784\uff0c\u53ef\u5b9e\u65f6\u7cbe\u786e\u5b9a\u4f4d9\u4e2a\u65b9\u5411\u7684\u58f0\u6e90\uff0c\u65b9\u5411\u8bc6\u522b\u51c6\u786e\u7387\u8fbe91.1%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002  \n\u25c6 \u57fa\u4e8eCLAP\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5b9e\u73b0\u7eaf\u97f3\u9891\u5206\u7c7b\uff0c\u5728\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u548cAudioSet\u4e0a\u5206\u522b\u8fbe\u523098.5%\u548c95%\u7684\u51c6\u786e\u7387\u3002  \n\u25c6 \u63d0\u51fa\u591a\u6a21\u6001\u878d\u5408\u6a21\u578b\uff0c\u7ed3\u5408\u97f3\u9891\u3001\u89c6\u89c9\u548c\u6587\u672c\u6570\u636e\u7cbe\u786e\u5b9a\u4f4d\u56fe\u50cf\u4e2d\u7684\u58f0\u6e90\uff0c\u91c7\u7528Yolov9\u76ee\u6807\u68c0\u6d4b\u548c\u97f3\u9891-\u89c6\u89c9\u5b9a\u4f4d\u6a21\u5757\uff0ccIoU\u8fbe0.892\uff0cAUC\u4e3a0.658\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u786c\u4ef6\u7cfb\u7edf\uff0c\u5305\u62ec\u56db\u9ea6\u514b\u98ce\u77e9\u5f62\u9635\u5217\u548c\u773c\u955c\u5f0f\u6444\u50cf\u5934\uff0c\u901a\u8fc7\u8155\u5e26\u663e\u793a\u65b9\u5411\u7b49\u5173\u952e\u4fe1\u606f\uff0c\u63d0\u5347\u804b\u54d1\u4eba\u7fa4\u7684\u5b9e\u65f6\u4ea4\u4e92\u4f53\u9a8c\u3002  \n\u25c6 \u586b\u8865\u4e86\u5f53\u524d\u7814\u7a76\u4e2d\u9488\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7684\u6280\u672f\u7a7a\u767d\uff0c\u4e3a\u65b0\u4e00\u4ee3\u65e0\u969c\u788d\u8bbe\u5907\u5f00\u53d1\u5960\u5b9a\u57fa\u7840\u3002  \n\u25c6 \u5728\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\u5168\u9762\u9a8c\u8bc1\u7cfb\u7edf\u6027\u80fd\uff0c\u5404\u9879\u6307\u6807\u5747\u8d85\u8d8a\u540c\u7c7b\u6a21\u578b\uff0c\u5c55\u73b0\u51fa\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002|\n",
    "2507.17455": "|2025-07-23|VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization|Sania Waheed\u7b49|[2507.17455](http://arxiv.org/pdf/2507.17455)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u6df7\u5408\u5730\u7406\u5b9a\u4f4d\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u548c\u68c0\u7d22\u5f0f\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u65b9\u6cd5\u7684\u4f18\u52bf\u3002  \n\u25c6 \u5229\u7528VLM\u751f\u6210\u5730\u7406\u5148\u9a8c\u4fe1\u606f\uff0c\u6709\u6548\u7f29\u5c0f\u68c0\u7d22\u641c\u7d22\u7a7a\u95f4\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u68c0\u7d22\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u611f\u77e5\u6df7\u6dc6\u4e0a\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u91cd\u6392\u5e8f\u673a\u5236\uff0c\u7ed3\u5408\u7279\u5f81\u76f8\u4f3c\u5ea6\u548c\u521d\u59cb\u5750\u6807\u90bb\u8fd1\u6027\uff0c\u7b5b\u9009\u5730\u7406\u5408\u7406\u6027\u6700\u9ad8\u7684\u5339\u914d\u7ed3\u679c\u3002  \n\u25c6 \u5728\u591a\u4e2a\u5730\u7406\u5b9a\u4f4d\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u8857\u9053\u7ea7\uff08\u63d0\u53474.51%\uff09\u548c\u57ce\u5e02\u7ea7\uff08\u63d0\u534713.52%\uff09\u5b9a\u4f4d\u7cbe\u5ea6\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002  \n\u25c6 \u901a\u8fc7VLM\u4e0eVPR\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u4e14\u9ad8\u7cbe\u5ea6\u7684\u884c\u661f\u7ea7\u5730\u7406\u5b9a\u4f4d\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u5355\u4e00\u65b9\u6cd5\u5b58\u5728\u7684\u5e7b\u89c9\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3002|\n",
    "2507.17412": "|2025-07-23|Content-based 3D Image Retrieval and a ColBERT-inspired Re-ranking for Tumor Flagging and Staging|Farnaz Khun Jush\u7b49|[2507.17412](http://arxiv.org/pdf/2507.17412)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u4e0d\u4f9d\u8d56\u9884\u5206\u5272\u6570\u636e\u548c\u5668\u5b98\u7279\u5f02\u6027\u6570\u636e\u96c6\u7684CBIR\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u4e34\u5e8a\u4e2d\u5927\u578b\u975e\u7ed3\u6784\u5316\u56fe\u50cf\u5f52\u6863\u7cfb\u7edf\uff08\u5982PACS\uff09\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165C-MIR\u65b9\u6cd5\uff0c\u5c06ColBERT\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u5ef6\u8fdf\u4ea4\u4e92\u673a\u5236\u9002\u914d\u4e8e3D\u533b\u5b66\u5f71\u50cf\u91cd\u6392\u5e8f\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e0a\u4e0b\u6587\u611f\u77e5\u68c0\u7d22\u3002  \n\u25c6 \u5728\u56db\u79cd\u80bf\u7624\u90e8\u4f4d\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u7ed3\u5408\u4e09\u79cd\u7279\u5f81\u63d0\u53d6\u5668\u548c\u4e09\u79cd\u6570\u636e\u5e93\u914d\u7f6e\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u666e\u9002\u6027\u3002  \n\u25c6 \u7814\u7a76\u53d1\u73b0C-MIR\u80fd\u81ea\u52a8\u5b9a\u4f4d\u611f\u5174\u8da3\u533a\u57df\uff0c\u65e0\u9700\u6570\u636e\u9884\u5206\u5272\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u6570\u636e\u589e\u5f3a\u7684\u8ba1\u7b97\u6210\u672c\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eC-MIR\u5728\u80bf\u7624\u6807\u8bb0\uff08\u5c24\u5176\u7ed3\u80a0\u548c\u80ba\u764c\uff09\u4e2d\u6027\u80fd\u663e\u8457\u63d0\u5347\uff08p<0.05\uff09\uff0c\u5e76\u5728\u80bf\u7624\u5206\u671f\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002  \n\u25c6 \u8be5\u7814\u7a76\u4e3a\u5148\u8fdb\u68c0\u7d22\u6280\u672f\u5728\u533b\u7597\u5b9e\u8df5\u4e2d\u7684\u843d\u5730\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u6709\u671b\u4f18\u5316\u4e34\u5e8a\u8bca\u65ad\u6d41\u7a0b\u3002|\n",
    "2507.18444": "|2025-07-24|DSFormer: A Dual-Scale Cross-Learning Transformer for Visual Place Recognition|Haiyang Jiang\u7b49|[2507.18444](http://arxiv.org/pdf/2507.18444)|\u65e0|\u25c6 \u63d0\u51faDSFormer\u53cc\u5c3a\u5ea6\u4ea4\u53c9\u5b66\u4e60Transformer\u6a21\u5757\uff0c\u901a\u8fc7\u53cc\u5411\u4fe1\u606f\u4f20\u9012\u6574\u5408CNN\u6700\u540e\u4e24\u5c42\u7684\u53cc\u5c3a\u5ea6\u7279\u5f81\uff0c\u540c\u65f6\u6355\u6349\u8bed\u4e49\u4e30\u5bcc\u6027\u548c\u7a7a\u95f4\u7ec6\u8282\u3002  \n\u25c6 \u8bbe\u8ba1\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5904\u7406\u5355\u5c3a\u5ea6\u5185\u7684\u957f\u7a0b\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5f15\u5165\u5171\u4eab\u4ea4\u53c9\u6ce8\u610f\u529b\u5b9e\u73b0\u8de8\u5c3a\u5ea6\u5b66\u4e60\uff0c\u589e\u5f3a\u7279\u5f81\u8868\u793a\u80fd\u529b\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u63d0\u51fa\u591a\u89c6\u89d2\u5757\u805a\u7c7b\u7b56\u7565\uff0c\u91cd\u6784SF-XL\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u5206\u533a\u65b9\u5f0f\uff0c\u4f18\u5316\u6570\u636e\u7ec4\u7ec7\u4ee5\u63d0\u5347\u5bf9\u89c6\u89d2\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u7ed3\u5408\u4e0a\u8ff0\u6280\u672f\uff0c\u751f\u6210\u9002\u5e94\u73af\u5883\u53d8\u5316\u7684\u9c81\u68d2\u5168\u5c40\u5d4c\u5165\u8868\u5f81\uff0c\u76f8\u6bd4\u5148\u524d\u5206\u533a\u65b9\u6cd5\u51cf\u5c11\u7ea630%\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u3002  \n\u25c6 \u4ec5\u4f7f\u7528512\u7ef4\u5168\u5c40\u63cf\u8ff0\u7b26\u5373\u5b9e\u73b0\u5168\u5c40\u68c0\u7d22\uff0c\u5728\u591a\u6570\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8d85\u8d8aDELG\u3001Patch-NetVLAD\u7b49\u5148\u8fdb\u65b9\u6cd5\uff0c\u8fbe\u5230SOTA\u6027\u80fd\u3002  \n\u25c6 \u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\u4efb\u52a1\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.20934": "|2025-07-28|Exploring text-to-image generation for historical document image retrieval|Melissa Cote\u7b49|[2507.20934](http://arxiv.org/pdf/2507.20934)|\u65e0|\u25c6 \u63d0\u51faT2I-QBE\u65b0\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u6587\u672c\u751f\u6210\u56fe\u50cf\uff08T2I\uff09\u6280\u672f\u5e94\u7528\u4e8e\u6587\u6863\u56fe\u50cf\u68c0\u7d22\uff08DIR\uff09\u9886\u57df\uff0c\u586b\u8865\u4e86\u57fa\u4e8e\u5c5e\u6027\u68c0\u7d22\uff08ABDIR\uff09\u4e0e\u57fa\u4e8e\u793a\u4f8b\u68c0\u7d22\uff08QBE\uff09\u4e4b\u95f4\u7684\u6280\u672f\u9e3f\u6c9f\u3002  \n\u25c6 \u5229\u7528\u751f\u6210\u5f0fAI\uff08Leonardo.Ai\uff09\u5c06\u6587\u672c\u63d0\u793a\uff08\u5305\u542b\u6587\u6863\u7c7b\u578b\u63cf\u8ff0\u548cABDIR\u98ce\u683c\u5c5e\u6027\u5217\u8868\uff09\u8f6c\u5316\u4e3a\u67e5\u8be2\u56fe\u50cf\uff0c\u65e0\u9700\u7528\u6237\u63d0\u4f9b\u771f\u5b9e\u67e5\u8be2\u6837\u672c\uff0c\u89e3\u51b3\u4e86QBE\u4f9d\u8d56\u73b0\u6709\u6837\u672c\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u9488\u5bf9\u5386\u53f2\u6587\u6863\u7684\u89c6\u89c9\u591a\u6837\u6027\u548c\u72ec\u7279\u6027\u8bbe\u8ba1\u68c0\u7d22\u65b9\u6848\uff0c\u901a\u8fc7CNN\u63d0\u53d6\u751f\u6210\u56fe\u50cf\u4e0e\u6570\u636e\u96c6\u4e2d\u6587\u6863\u7684\u7279\u5f81\u8fdb\u884c\u76f8\u4f3c\u5ea6\u5339\u914d\uff0c\u9a8c\u8bc1\u4e86\u751f\u6210\u56fe\u50cf\u4f5c\u4e3a\u67e5\u8be2\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u5728HisIR19\u5386\u53f2\u6587\u6863\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6210\u529f\u68c0\u7d22\u76f8\u5173\u6587\u6863\uff0c\u4e3a\u65e0\u6837\u672c\u573a\u666f\u4e0b\u7684\u6587\u6863\u68c0\u7d22\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u9996\u6b21\u63a2\u7d22\u4e86T2I\u751f\u6210\u6280\u672f\u4e0e\u4f20\u7edfQBE\u8303\u5f0f\u7684\u7ed3\u5408\uff0c\u4e3aDIR\u9886\u57df\u5f00\u8f9f\u4e86\u57fa\u4e8e\u751f\u6210\u6a21\u578b\u7684\u65b0\u7814\u7a76\u65b9\u5411\u3002|\n",
    "2507.20892": "|2025-07-28|PixelNav: Towards Model-based Vision-Only Navigation with Topological Graphs|Sergey Bakulin\u7b49|[2507.20892](http://arxiv.org/pdf/2507.20892)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7ecf\u5178\u6a21\u578b\u89c4\u5212\u7b97\u6cd5\u7684\u6df7\u5408\u89c6\u89c9\u5bfc\u822a\u65b9\u6cd5\uff0c\u7a81\u7834\u4e86\u7eaf\u7aef\u5230\u7aef\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u91c7\u7528\u5206\u5c42\u7cfb\u7edf\u67b6\u6784\uff0c\u6574\u5408\u4e86\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u3001\u53ef\u901a\u884c\u6027\u4f30\u8ba1\u3001\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\u548c\u4f4d\u59ff\u4f30\u8ba1\u7b49\u591a\u9879\u524d\u6cbf\u6280\u672f\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u4f7f\u7528\u62d3\u6251\u56fe\u4f5c\u4e3a\u73af\u5883\u8868\u5f81\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u73af\u5883\u9002\u5e94\u80fd\u529b\u3002  \n\u25c6 \u76f8\u6bd4\u7aef\u5230\u7aef\u65b9\u6848\uff0c\u8be5\u7cfb\u7edf\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u89e3\u51b3\u4e86\u9ed1\u7bb1\u6a21\u578b\u5728\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u7684\u5173\u952e\u74f6\u9888\u3002  \n\u25c6 \u901a\u8fc7\u5927\u91cf\u771f\u5b9e\u573a\u666f\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u89c6\u89c9\u5bfc\u822a\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002  \n\u25c6 \u5728\u51cf\u5c11\u8bad\u7ec3\u6570\u636e\u4f9d\u8d56\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\u4f18\u52bf\u3002|\n",
    "2507.20564": "|2025-07-28|ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided Captioning|Duc-Tai Dinh\u7b49|[2507.20564](http://arxiv.org/pdf/2507.20564)|\u65e0|\u25c6 \u63d0\u51faZSE-Cap\u7cfb\u7edf\uff0c\u5728EVENTA\u7ade\u8d5b\u4e2d\u65e0\u9700\u5fae\u8c03\u5373\u83b7\u5f97\u7b2c\u56db\u540d\uff0c\u5c55\u793a\u4e86\u96f6\u6837\u672c\u5b66\u4e60\u7684\u5f3a\u5927\u80fd\u529b\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u96c6\u6210CLIP\u3001SigLIP\u548cDINOv2\u4e09\u79cd\u6a21\u578b\u7684\u76f8\u4f3c\u5ea6\u5206\u6570\uff0c\u63d0\u5347\u56fe\u50cf\u68c0\u7d22\u6027\u80fd\u3002  \n\u25c6 \u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\u5f15\u5bfcGemma 3\u6a21\u578b\uff0c\u5b9e\u73b0\u6587\u7ae0\u9ad8\u5c42\u4e8b\u4ef6\u4e0e\u56fe\u50cf\u89c6\u89c9\u5185\u5bb9\u7684\u5173\u8054\u751f\u6210\u63cf\u8ff0\u3002  \n\u25c6 \u7ed3\u5408\u57fa\u7840\u6a21\u578b\u7684\u96c6\u6210\u548c\u63d0\u793a\u6280\u672f\uff0c\u5728\u79c1\u6709\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f970.42002\u7684\u9ad8\u5206\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u63d0\u4f9b\u5f00\u6e90\u4ee3\u7801\uff0c\u4fc3\u8fdb\u96f6\u6837\u672c\u56fe\u50cf\u68c0\u7d22\u4e0e\u63cf\u8ff0\u751f\u6210\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002|\n",
    "2507.20538": "|2025-07-28|Uni-Mapper: Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments|Gilhwan Kang\u7b49|[2507.20538](http://arxiv.org/pdf/2507.20538)|\u65e0|\u25c6 Uni-Mapper\u63d0\u51fa\u9996\u4e2a\u52a8\u6001\u611f\u77e5\u7684\u591a\u6a21\u6001LiDAR\u5730\u56fe\u7edf\u4e00\u6846\u67b6\uff0c\u89e3\u51b3\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u591a\u4f20\u611f\u5668\u5730\u56fe\u878d\u5408\u7684\u96be\u9898\u3002  \n\u25c6 \u91c7\u7528\u57fa\u4e8e\u4f53\u7d20\u81ea\u7531\u7a7a\u95f4\u54c8\u5e0c\u7684\u7c97\u5230\u7ec6\u52a8\u6001\u7269\u4f53\u5254\u9664\u65b9\u6cd5\uff0c\u901a\u8fc7\u65f6\u5e8f\u5360\u7528\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u5e76\u79fb\u9664\u52a8\u6001\u5bf9\u8c61\uff0c\u63d0\u5347\u573a\u666f\u4e00\u81f4\u6027\u3002  \n\u25c6 \u521b\u65b0\u8bbe\u8ba1\u52a8\u6001\u611f\u77e5\u7684\u95ed\u73af\u68c0\u6d4b\u6a21\u5757\uff0c\u7ed3\u5408\u4fdd\u7559\u7684\u9759\u6001\u5c40\u90e8\u7279\u5f81\u751f\u6210\u5168\u5c40\u63cf\u8ff0\u7b26\uff0c\u589e\u5f3a\u52a8\u6001\u73af\u5883\u4e0b\u7684\u5730\u70b9\u8bc6\u522b\u9c81\u68d2\u6027\u3002  \n\u25c6 \u63d0\u51fa\u96c6\u4e2d\u5f0f\u951a\u8282\u70b9\u7b56\u7565\u4f18\u5316\u4f4d\u59ff\u56fe\uff0c\u6709\u6548\u89e3\u51b3\u5730\u56fe\u5408\u5e76\u65f6\u7684\u4f1a\u8bdd\u5185\u6f02\u79fb\u8bef\u5dee\u548c\u8de8\u5730\u56fe\u95ed\u73af\u95ee\u9898\u3002  \n\u25c6 \u6846\u67b6\u652f\u6301\u5f02\u6784LiDAR\uff08\u5982\u673a\u68b0\u5f0f\u4e0e\u56fa\u6001\u96f7\u8fbe\uff09\u7684\u8de8\u6a21\u6001\u5339\u914d\uff0c\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002  \n\u25c6 \u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u591a\u5730\u56fe\u5bf9\u9f50\u6d41\u7a0b\uff0c\u5305\u542b\u52a8\u6001\u5904\u7406\u3001\u95ed\u73af\u68c0\u6d4b\u4e0e\u591a\u9636\u6bb5\u4f4d\u59ff\u56fe\u4f18\u5316\uff0c\u9002\u7528\u4e8e\u591a\u673a\u5668\u4eba\u534f\u4f5c\u573a\u666f\u3002|\n",
    "2507.21742": "|2025-07-29|Adversarial Reconstruction Feedback for Robust Fine-grained Generalization|Shijie Wang\u7b49|[2507.21742](http://arxiv.org/pdf/2507.21742)|\u65e0|\u25c6 \u63d0\u51faAdvRF\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u6027\u91cd\u5efa\u53cd\u9988\u673a\u5236\u5b66\u4e60\u4e0e\u7c7b\u522b\u65e0\u5173\u7684\u5dee\u5f02\u8868\u5f81\uff0c\u89e3\u51b3\u73b0\u6709\u7ec6\u7c92\u5ea6\u56fe\u50cf\u68c0\u7d22\u65b9\u6cd5\u5bf9\u9884\u5b9a\u4e49\u7c7b\u522b\u7684\u8bed\u4e49\u4f9d\u8d56\u95ee\u9898\u3002  \n\u25c6 \u5c06\u7ec6\u7c92\u5ea6\u56fe\u50cf\u68c0\u7d22\u91cd\u65b0\u5b9a\u4e49\u4e3a\u89c6\u89c9\u5dee\u5f02\u91cd\u5efa\u4efb\u52a1\uff0c\u7ed3\u5408\u68c0\u7d22\u6a21\u578b\u7684\u7c7b\u522b\u611f\u77e5\u5dee\u5f02\u5b9a\u4f4d\u4e0e\u91cd\u5efa\u6a21\u578b\u7684\u7c7b\u522b\u65e0\u5173\u7279\u5f81\u5b66\u4e60\uff0c\u5b9e\u73b0\u53cc\u5411\u4f18\u5316\u3002  \n\u25c6 \u901a\u8fc7\u91cd\u5efa\u6a21\u578b\u63ed\u793a\u68c0\u7d22\u6a21\u578b\u5ffd\u7565\u7684\u6b8b\u5dee\u5f02\uff0c\u8feb\u4f7f\u68c0\u7d22\u6a21\u578b\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u540c\u65f6\u68c0\u7d22\u6a21\u578b\u7684\u4f18\u5316\u4fe1\u53f7\u6307\u5bfc\u91cd\u5efa\u6a21\u578b\u6539\u8fdb\u91cd\u5efa\u80fd\u529b\u3002  \n\u25c6 \u91c7\u7528\u77e5\u8bc6\u84b8\u998f\u5c06\u91cd\u5efa\u6a21\u578b\u751f\u6210\u7684\u7c7b\u522b\u65e0\u5173\u5dee\u5f02\u8868\u5f81\u8fc1\u79fb\u5230\u68c0\u7d22\u6a21\u578b\uff0c\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\u3002  \n\u25c6 \u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u7ec6\u7c92\u5ea6\u548c\u7c97\u7c92\u5ea6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86AdvRF\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\u5747\u663e\u793a\u5176\u663e\u8457\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002|\n",
    "2507.22791": "|2025-07-30|Modality-Aware Feature Matching: A Comprehensive Review of Single- and Cross-Modality Techniques|Weide Liu\u7b49|[2507.22791](http://arxiv.org/pdf/2507.22791)|\u65e0|\u25c6 \u5168\u9762\u7efc\u8ff0\u4e86\u5355\u6a21\u6001\u4e0e\u8de8\u6a21\u6001\u7279\u5f81\u5339\u914d\u6280\u672f\uff0c\u6db5\u76d6RGB\u56fe\u50cf\u3001\u6df1\u5ea6\u56fe\u50cf\u30013D\u70b9\u4e91\u3001LiDAR\u626b\u63cf\u3001\u533b\u5b66\u56fe\u50cf\u53ca\u89c6\u89c9-\u8bed\u8a00\u4ea4\u4e92\u7b49\u591a\u79cd\u6a21\u6001\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7cfb\u7edf\u6027\u603b\u7ed3\u7684\u7a7a\u767d\u3002  \n\u25c6 \u5bf9\u6bd4\u5206\u6790\u4e86\u4f20\u7edf\u624b\u5de5\u65b9\u6cd5\uff08\u5982Harris\u89d2\u70b9\u3001SIFT\u548cORB\u63cf\u8ff0\u7b26\uff09\u4e0e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08\u5982SuperPoint\u548cLoFTR\uff09\u7684\u4f18\u52a3\uff0c\u6307\u51fa\u540e\u8005\u5728\u8de8\u6a21\u6001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u4e0a\u7684\u663e\u8457\u63d0\u5347\u3002  \n\u25c6 \u91cd\u70b9\u4ecb\u7ecd\u4e86\u6a21\u6001\u611f\u77e5\u6280\u672f\u8fdb\u5c55\uff0c\u5305\u62ec\u9488\u5bf9\u6df1\u5ea6\u56fe\u50cf\u7684\u51e0\u4f55\u4e0e\u6df1\u5ea6\u4e13\u7528\u63cf\u8ff0\u7b26\u30013D\u70b9\u4e91\u7684\u7a00\u758f\u4e0e\u7a20\u5bc6\u5b66\u4e60\u65b9\u6cd5\u3001LiDAR\u626b\u63cf\u7684\u6ce8\u610f\u529b\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u53ca\u533b\u5b66\u56fe\u50cf\u5339\u914d\u7684MIND\u63cf\u8ff0\u7b26\u7b49\u521b\u65b0\u65b9\u6848\u3002  \n\u25c6 \u6df1\u5165\u63a2\u8ba8\u8de8\u6a21\u6001\u5e94\u7528\u573a\u666f\uff0c\u5982\u533b\u5b66\u56fe\u50cf\u914d\u51c6\u548c\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\uff0c\u63ed\u793a\u4e86\u7279\u5f81\u5339\u914d\u6280\u672f\u5728\u5904\u7406\u591a\u6837\u5316\u6570\u636e\u4ea4\u4e92\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u4e0e\u53d1\u5c55\u8d8b\u52bf\u3002  \n\u25c6 \u7cfb\u7edf\u603b\u7ed3\u4e86\u5f53\u524d\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411\uff0c\u4e3a\u8de8\u6a21\u6001\u7279\u5f81\u5339\u914d\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u8def\u7ebf\u56fe\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u5411\u66f4\u590d\u6742\u3001\u66f4\u5b9e\u7528\u7684\u573a\u666f\u62d3\u5c55\u3002|\n",
    "2507.23629": "|2025-07-31|DRACo-SLAM2: Distributed Robust Acoustic Communication-efficient SLAM for Imaging Sonar EquippedUnderwater Robot Teams with Object Graph Matching|Yewei Huang\u7b49|[2507.23629](http://arxiv.org/pdf/2507.23629)|\u65e0|\u25c6 \u63d0\u51faDRACo-SLAM2\u6846\u67b6\uff0c\u6539\u8fdb\u539f\u6709\u7cfb\u7edf\uff0c\u4e13\u4e3a\u914d\u5907\u591a\u6ce2\u675f\u6210\u50cf\u58f0\u7eb3\u7684\u6c34\u4e0b\u673a\u5668\u4eba\u56e2\u961f\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u5206\u5e03\u5f0fSLAM\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u58f0\u7eb3\u5730\u56fe\u8868\u793a\u4e3a\u5bf9\u8c61\u56fe\uff0c\u901a\u8fc7\u5bf9\u8c61\u56fe\u5339\u914d\u5b9e\u73b0\u9ad8\u6548\u8de8\u673a\u5668\u4eba\u95ed\u73af\u68c0\u6d4b\uff0c\u65e0\u9700\u4f9d\u8d56\u5148\u9a8c\u51e0\u4f55\u4fe1\u606f\u3002  \n\u25c6 \u9488\u5bf9\u6c34\u4e0b\u626b\u63cf\u5339\u914d\u7279\u70b9\uff0c\u63d0\u51fa\u589e\u91cf\u5f0f\u7fa4\u7ec4\u4e00\u81f4\u6d4b\u91cf\u96c6\u6700\u5927\u5316\uff08GCM\uff09\u65b9\u6cd5\uff0c\u6539\u8fdb\u539f\u6709PCM\u7b97\u6cd5\uff0c\u6709\u6548\u5904\u7406\u76f8\u90bb\u8de8\u673a\u5668\u4eba\u95ed\u73af\u5171\u4eab\u76f8\u4f3c\u914d\u51c6\u8bef\u5dee\u7684\u573a\u666f\u3002  \n\u25c6 \u901a\u8fc7\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u8fdb\u884c\u5e7f\u6cdb\u5bf9\u6bd4\u5206\u6790\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u548c\u5b9e\u7528\u6027\u3002  \n\u25c6 \u6846\u67b6\u5728\u901a\u4fe1\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u7279\u522b\u9002\u5408\u6c34\u4e0b\u673a\u5668\u4eba\u56e2\u961f\u534f\u4f5c\u5efa\u56fe\u4e0e\u5b9a\u4f4d\u9700\u6c42\u3002|\n",
    "2507.23569": "|2025-07-31|Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization|Maxime Pietrantoni\u7b49|[2507.23569](http://arxiv.org/pdf/2507.23569)|\u65e0|\u25c6 \u63d0\u51fa\u9ad8\u65af\u6cfc\u6e85\u7279\u5f81\u573a\uff08GSFFs\uff09\uff0c\u5c06\u663e\u5f0f\u51e0\u4f55\u6a21\u578b\uff083DGS\uff09\u4e0e\u9690\u5f0f\u7279\u5f81\u573a\u7ed3\u5408\uff0c\u7528\u4e8e\u89c6\u89c9\u5b9a\u4f4d\u4efb\u52a1\u3002  \n\u25c6 \u5229\u75283DGS\u7684\u5bc6\u96c6\u51e0\u4f55\u4fe1\u606f\u548c\u53ef\u5fae\u5206\u5149\u6805\u5316\u7b97\u6cd5\uff0c\u5b66\u4e60\u57fa\u4e8e3D\u7a7a\u95f4\u7684\u9c81\u68d2\u7279\u5f81\u8868\u793a\u3002  \n\u25c6 \u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u5c063D\u5c3a\u5ea6\u611f\u77e5\u7279\u5f81\u573a\u4e0e2D\u7279\u5f81\u7f16\u7801\u5668\u5bf9\u9f50\u5230\u540c\u4e00\u5d4c\u5165\u7a7a\u95f4\uff0c\u63d0\u5347\u7279\u5f81\u4e00\u81f4\u6027\u3002  \n\u25c6 \u5f15\u51653D\u7ed3\u6784\u611f\u77e5\u7684\u805a\u7c7b\u65b9\u6cd5\uff0c\u6b63\u5219\u5316\u8868\u5f81\u5b66\u4e60\u5e76\u751f\u6210\u53ef\u7528\u4e8e\u9690\u79c1\u4fdd\u62a4\u7684\u573a\u666f\u5206\u5272\u7ed3\u679c\u3002  \n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u7279\u5f81\u56fe\u6216\u5206\u5272\u56fe\u5bf9\u9f50\u7684\u4f4d\u59ff\u4f18\u5316\u65b9\u6cd5\uff0c\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u548c\u975e\u9690\u79c1\u4fdd\u62a4\u4e24\u79cd\u5b9a\u4f4d\u6d41\u7a0b\u3002  \n\u25c6 \u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u5148\u8fdb\u6027\uff0c\u5b9e\u73b0\u4e86\u5f53\u524d\u6700\u4f18\u7684\u5b9a\u4f4d\u6027\u80fd\u3002|\n",
    "2507.22938": "|2025-07-25|A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents|Sumit Soman\u7b49|[2507.22938](http://arxiv.org/pdf/2507.22938)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u5c06\u6d41\u7a0b\u56fe\u8f6c\u5316\u4e3a\u56fe\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6587\u672c\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u56fe\u50cf\u95ee\u7b54\u7684\u75db\u70b9\u3002  \n\u25c6 \u9996\u6b21\u5c06\u89c6\u89c9\u5927\u8bed\u8a00\u6a21\u578b(VLM)\u751f\u6210\u7684\u6d41\u7a0b\u56fe\u56fe\u8868\u793a\u4e0e\u6587\u672c\u5d4c\u5165\u7ba1\u9053\u7ed3\u5408\uff0c\u5b9e\u73b0\u7535\u4fe1\u9886\u57df\u591a\u6a21\u6001\u95ee\u7b54\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u5b8c\u6574\u7684\u5904\u7406\u6d41\u7a0b\uff0c\u5305\u62ec\u6280\u672f\u6587\u6863\u5904\u7406\u3001\u56fe\u50cf\u7c7b\u578b\u5206\u7c7b\u3001\u56fe\u8868\u793a\u6784\u5efa\u7b49\u5173\u952e\u6b65\u9aa4\uff0c\u5f62\u6210\u53ef\u843d\u5730\u7684\u7cfb\u7edf\u67b6\u6784\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u5fae\u8c03\u540e\u7684VLM\u751f\u6210\u7684\u56fe\u8868\u793a\u4e0e\u771f\u5b9e\u503c\u7f16\u8f91\u8ddd\u79bb\u66f4\u5c0f\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5bf9\u6d41\u7a0b\u56fe\u8868\u793a\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5728\u63a8\u7406\u9636\u6bb5\u65e0\u9700\u4f7f\u7528VLM\uff0c\u4ec5\u9700\u6587\u672c\u5d4c\u5165\u6a21\u578b\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\uff0c\u663e\u8457\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u3002  \n\u25c6 \u5728\u7535\u4fe1\u4ea7\u54c1\u6587\u6863\u6784\u5efa\u7684QA\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u7535\u4fe1\u9886\u57df\u9002\u914d\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u8868\u73b0\u4f18\u5f02\u3002|\n",
    "2508.02034": "|2025-08-04|Protego: User-Centric Pose-Invariant Privacy Protection Against Face Recognition-Induced Digital Footprint Exposure|Ziling Wang\u7b49|[2508.02034](http://arxiv.org/pdf/2508.02034)|\u65e0|\u25c6\u63d0\u51faProtego\uff0c\u4e00\u79cd\u7528\u6237\u4e2d\u5fc3\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u901a\u8fc73D\u9762\u90e8\u7b7e\u540d\u751f\u6210\u59ff\u6001\u4e0d\u53d8\u76842D\u8868\u793a\uff0c\u52a8\u6001\u53d8\u5f62\u4e3a\u81ea\u71363D\u9762\u5177\uff0c\u9002\u914d\u7528\u6237\u4efb\u610f\u59ff\u6001\u8868\u60c5\u7684\u56fe\u50cf\uff0c\u5728\u5206\u4eab\u524d\u8fdb\u884c\u4fdd\u62a4\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u589e\u5f3aFR\u6a21\u578b\u654f\u611f\u6027\uff0c\u4f7f\u53d7\u4fdd\u62a4\u56fe\u50cf\u65e0\u6cd5\u76f8\u4e92\u5339\u914d\uff0c\u7a81\u7834\u73b0\u6709\u65b9\u6cd5\u4ec5\u9632\u5fa1\u5916\u90e8\u67e5\u8be2\u7684\u5c40\u9650\u3002  \n\u25c6\u5b9e\u9a8c\u8bc1\u660e\u5728\u591a\u79cd\u9ed1\u76d2FR\u6a21\u578b\u4e0b\u663e\u8457\u964d\u4f4e\u68c0\u7d22\u51c6\u786e\u7387\uff0c\u6027\u80fd\u81f3\u5c11\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd52\u500d\u3002  \n\u25c6\u9996\u6b21\u5b9e\u73b0\u89c6\u9891\u573a\u666f\u4e0b\u7684\u89c6\u89c9\u8fde\u8d2f\u6027\u4fdd\u62a4\uff0c\u6ee1\u8db3\u52a8\u6001\u5185\u5bb9\u5bf9\u4e00\u81f4\u6027\u548c\u81ea\u7136\u5916\u89c2\u7684\u9ad8\u8981\u6c42\u3002  \n\u25c6\u4e3a\u5bf9\u6297FR\u6280\u672f\u6ee5\u7528\uff08\u5982\u5927\u89c4\u6a21\u76d1\u63a7\u4e0e\u975e\u81ea\u613f\u8eab\u4efd\u8ffd\u8e2a\uff09\u63d0\u4f9b\u5b9e\u7528\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u586b\u8865\u7528\u6237\u4e3b\u52a8\u9632\u62a4\u7684\u6280\u672f\u7a7a\u767d\u3002  \n\u25c6\u901a\u8fc73D\u52302D\u7684\u5c01\u88c5\u4e0e\u52a8\u6001\u9002\u914d\u673a\u5236\uff0c\u517c\u987e\u5f3a\u9690\u79c1\u4fdd\u62a4\u4e0e\u89c6\u89c9\u81ea\u7136\u5ea6\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u6613\u88ab\u68c0\u6d4b\u6216\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u7684\u75db\u70b9\u3002|\n",
    "2508.03494": "|2025-08-05|Prototype-Enhanced Confidence Modeling for Cross-Modal Medical Image-Report Retrieval|Shreyank N Gowda\u7b49|[2508.03494](http://arxiv.org/pdf/2508.03494)|\u65e0|\u25c6 \u63d0\u51faPrototype-Enhanced Confidence Modeling (PECM)\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ea7\u539f\u578b\u5efa\u6a21\u89e3\u51b3\u533b\u5b66\u8de8\u6a21\u6001\u68c0\u7d22\u4e2d\u8bed\u4e49\u6a21\u7cca\u6027\u95ee\u9898\u3002  \n\u25c6 \u9996\u6b21\u5728\u533b\u5b66\u56fe\u50cf-\u62a5\u544a\u68c0\u7d22\u4e2d\u5f15\u5165\u53cc\u6d41\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u673a\u5236\uff0c\u7ed3\u5408\u539f\u578b\u76f8\u4f3c\u5ea6\u5206\u5e03\u81ea\u9002\u5e94\u8c03\u6574\u9ad8\u4e0d\u786e\u5b9a\u6027\u6570\u636e\u7684\u5f71\u54cd\u6743\u91cd\u3002  \n\u25c6 \u8bbe\u8ba1\u591a\u6a21\u6001\u539f\u578b\u5b66\u4e60\u6a21\u5757\uff0c\u5206\u522b\u6355\u6349\u56fe\u50cf\u548c\u6587\u672c\u7684\u5c42\u6b21\u5316\u8bed\u4e49\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u8de8\u6a21\u6001\u5bf9\u9f50\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5f00\u53d1\u81ea\u9002\u5e94\u52a0\u6743\u7b56\u7565\uff0c\u52a8\u6001\u5e73\u8861\u4e0d\u540c\u7f6e\u4fe1\u5ea6\u6837\u672c\u5728\u68c0\u7d22\u6392\u5e8f\u4e2d\u7684\u8d21\u732e\uff0c\u6539\u5584\u4e34\u5e8a\u590d\u6742\u573a\u666f\u4e0b\u7684\u7ed3\u679c\u53ef\u9760\u6027\u3002  \n\u25c6 \u5728\u5b8c\u5168\u76d1\u7763\u548c\u96f6\u6837\u672c\u68c0\u7d22\u4efb\u52a1\u4e0a\u5b9e\u73b0\u6700\u9ad810.17%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u591a\u4e2a\u653e\u5c04\u5b66\u6570\u636e\u96c6\u4e0a\u5237\u65b0\u5f53\u524d\u6700\u4f18\u6c34\u5e73\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u9a8c\u8bc1\u539f\u578b\u589e\u5f3a\u65b9\u6cd5\u5bf9\u533b\u5b66\u6570\u636e\u56fa\u6709\u6b67\u4e49\u6027\u7684\u5904\u7406\u80fd\u529b\uff0c\u4e3a\u4e34\u5e8a\u8de8\u6a21\u6001\u68c0\u7d22\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002|\n",
    "2508.04801": "|2025-08-06|ACM Multimedia Grand Challenge on ENT Endoscopy Analysis|Trong-Thuan Nguyen\u7b49|[2508.04801](http://arxiv.org/pdf/2508.04801)|\u65e0|\u25c6 \u63d0\u51fa\u4e86ENTRep\u6311\u6218\u8d5b\uff0c\u9996\u6b21\u5c06\u8033\u9f3b\u5589\u5185\u7aa5\u955c\u5206\u6790\u7684\u7ec6\u7c92\u5ea6\u89e3\u5256\u5206\u7c7b\u4e0e\u8de8\u6a21\u6001\u68c0\u7d22\uff08\u56fe\u50cf\u5230\u56fe\u50cf\u3001\u6587\u672c\u5230\u56fe\u50cf\uff09\u7ed3\u5408\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u516c\u5171\u57fa\u51c6\u7684\u7a7a\u767d\u3002  \n\u25c6 \u6784\u5efa\u4e86\u9996\u4e2a\u652f\u6301\u53cc\u8bed\uff08\u8d8a\u5357\u8bed\u548c\u82f1\u8bed\uff09\u4e34\u5e8a\u63cf\u8ff0\u7684\u4e13\u4e1a\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e13\u5bb6\u6807\u6ce8\u7684\u89e3\u5256\u533a\u57df\u3001\u6b63\u5e38/\u5f02\u5e38\u72b6\u6001\u53ca\u53cc\u8bed\u8a00\u53d9\u4e8b\u6587\u672c\uff0c\u589e\u5f3a\u4e86\u6570\u636e\u591a\u6837\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e09\u4e2a\u6807\u51c6\u5316\u8bc4\u6d4b\u4efb\u52a1\uff08\u5206\u7c7b\u3001\u56fe\u50cf\u68c0\u7d22\u3001\u6587\u672c\u68c0\u7d22\uff09\uff0c\u5e76\u5efa\u7acb\u670d\u52a1\u5668\u7aef\u8bc4\u5206\u673a\u5236\uff0c\u786e\u4fdd\u8bc4\u4f30\u7684\u516c\u5e73\u6027\u4e0e\u53ef\u590d\u73b0\u6027\u3002  \n\u25c6 \u5f15\u5165\u516c\u5f00\u548c\u79c1\u6709\u6d4b\u8bd5\u96c6\u7684\u53cc\u8f68\u8bc4\u4f30\u7b56\u7565\uff0c\u517c\u987e\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4e0e\u4e34\u5e8a\u5b9e\u9645\u9700\u6c42\u3002  \n\u25c6 \u901a\u8fc7\u5206\u6790\u4f18\u80dc\u56e2\u961f\u65b9\u6848\uff0c\u63ed\u793a\u4e86\u591a\u6a21\u6001\u878d\u5408\u548c\u8de8\u8bed\u8a00\u5bf9\u9f50\u5728\u533b\u7597\u5f71\u50cf\u5206\u6790\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002|\n",
    "2508.04790": "|2025-08-06|Advanced Multi-Architecture Deep Learning Framework for BIRADS-Based Mammographic Image Retrieval: Comprehensive Performance Analysis with Super-Ensemble Optimization|MD Shaikh Rahman\u7b49|[2508.04790](http://arxiv.org/pdf/2508.04790)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u9488\u5bf9BIRADS\u4e94\u5206\u7c7b\u4e73\u817a\u56fe\u50cf\u68c0\u7d22\u7684\u7efc\u5408\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u533b\u5b66\u56fe\u50cf\u68c0\u7d22\u4e2d\u6837\u672c\u4e0d\u8db3\u3001\u6570\u636e\u5212\u5206\u4e0d\u5f53\u548c\u7edf\u8ba1\u9a8c\u8bc1\u4e0d\u8db3\u7684\u65b9\u6cd5\u5b66\u5c40\u9650\u3002  \n\u25c6 \u7cfb\u7edf\u6bd4\u8f83\u4e86DenseNet121\u3001ResNet50\u548cVGG16\u67b6\u6784\uff0c\u7ed3\u5408\u5dee\u5f02\u5316\u5fae\u8c03\u3001\u5ea6\u91cf\u5b66\u4e60\u548c\u8d85\u96c6\u6210\u4f18\u5316\u7b49\u5148\u8fdb\u8bad\u7ec3\u7b56\u7565\uff0c\u5176\u4e2d\u5dee\u5f02\u5316\u5fae\u8c03\u4f7fDenseNet121\u548cResNet50\u7684precision@10\u63d0\u534719.6%\u3002  \n\u25c6 \u91c7\u7528\u4e25\u683c\u5206\u5c42\u6570\u636e\u5212\u5206\uff0850%/20%/30%\u8bad\u7ec3/\u9a8c\u8bc1/\u6d4b\u8bd5\uff09\u548c1000\u6b21bootstrap\u7f6e\u4fe1\u533a\u95f4\u9a8c\u8bc1\uff0c\u6d4b\u8bd5\u96c6\u5305\u542b602\u4f8b\u67e5\u8be2\uff0c\u786e\u4fdd\u7ed3\u679c\u4e34\u5e8a\u53ef\u9760\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u63d0\u51fa\u8d85\u96c6\u6210\u4f18\u5316\u65b9\u6cd5\uff0c\u6574\u5408\u4e92\u8865\u67b6\u6784\u5b9e\u73b036.33%\u7684precision@10\uff0895% CI: 34.78%-37.88%\uff09\uff0c\u6bd4\u57fa\u7ebf\u63d0\u534724.93%\uff0c\u6bcf\u67e5\u8be2\u8fd4\u56de3.6\u4e2a\u76f8\u5173\u75c5\u4f8b\u3002  \n\u25c6 \u901a\u8fc7\u7edf\u8ba1\u9a8c\u8bc1\u663e\u793a\u4e0d\u540c\u4f18\u5316\u7b56\u7565\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff08p<0.001\uff0cCohen's d>0.8\uff09\uff0c\u540c\u65f6\u4fdd\u63012.8\u6beb\u79d2\u7684\u5b9e\u65f6\u68c0\u7d22\u6548\u7387\uff0c\u8fdc\u8d85\u6587\u732e\u4e2d5\u7c7b\u533b\u5b66\u68c0\u7d2220-25%\u7684\u6027\u80fd\u9884\u671f\u3002  \n\u25c6 \u5efa\u7acb\u4e34\u5e8a\u90e8\u7f72\u7684\u5faa\u8bc1\u67b6\u6784\u9009\u62e9\u6307\u5357\uff0c\u4e3a\u8bca\u65ad\u652f\u6301\u548c\u8d28\u91cf\u63a7\u5236\u5e94\u7528\u63d0\u4f9b\u65b0\u6027\u80fd\u57fa\u51c6\u3002|\n",
    "2508.04476": "|2025-08-06|Metric Learning in an RKHS|Gokcan Tatli\u7b49|[2508.04476](http://arxiv.org/pdf/2508.04476)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff08RKHS\uff09\u4e2d\u8fdb\u884c\u5ea6\u91cf\u5b66\u4e60\u7684\u901a\u7528\u6846\u67b6\uff0c\u7a81\u7834\u4e86\u4ee5\u5f80\u4ec5\u9650\u4e8e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff08\u211d\u1d48\uff09\u7684\u7406\u8bba\u5c40\u9650\u3002  \n\u25c6 \u9996\u6b21\u4e3a\u57fa\u4e8e\u6838\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u7684\u975e\u7ebf\u6027\u5ea6\u91cf\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7f3a\u4e4f\u7406\u8bba\u652f\u6491\u7684\u7a7a\u767d\u3002  \n\u25c6 \u63a8\u5bfc\u4e86\u65b0\u7684\u6cdb\u5316\u8bef\u5dee\u754c\u548c\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u754c\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u6240\u9700\u7684\u6570\u636e\u91cf\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002  \n\u25c6 \u901a\u8fc7\u4eff\u771f\u5b9e\u9a8c\u548c\u771f\u5b9e\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002  \n\u25c6 \u5c06\u4e09\u5143\u7ec4\u6bd4\u8f83\uff08\u5982\u201ch\u66f4\u63a5\u8fd1i\u8fd8\u662fj\uff1f\u201d\uff09\u7684\u5f31\u76d1\u7763\u4fe1\u53f7\u4e0eRKHS\u7ed3\u5408\uff0c\u6269\u5c55\u4e86\u5ea6\u91cf\u5b66\u4e60\u5728\u56fe\u50cf\u68c0\u7d22\u3001\u63a8\u8350\u7cfb\u7edf\u7b49\u573a\u666f\u7684\u5e94\u7528\u6f5c\u529b\u3002|\n",
    "2508.04424": "|2025-08-06|Composed Object Retrieval: Object-level Retrieval via Composed Expressions|Tong Wang\u7b49|[2508.04424](http://arxiv.org/pdf/2508.04424)|\u65e0|\u25c6 \u63d0\u51fa\u5168\u65b0\u4efb\u52a1Composed Object Retrieval (COR)\uff0c\u7a81\u7834\u73b0\u6709\u56fe\u50cf\u7ea7\u7ec4\u5408\u68c0\u7d22\u5c40\u9650\uff0c\u5b9e\u73b0\u57fa\u4e8e\u53c2\u8003\u5bf9\u8c61+\u6587\u672c\u63cf\u8ff0\u7684\u5bf9\u8c61\u7ea7\u7cbe\u786e\u68c0\u7d22\u4e0e\u5206\u5272\u3002  \n\u25c6 \u63ed\u793aCOR\u4efb\u52a1\u7684\u6838\u5fc3\u6311\u6218\uff1a\u9700\u5728\u590d\u6742\u573a\u666f\u4e2d\u7cbe\u51c6\u5b9a\u4f4d\u7b26\u5408\u7ec4\u5408\u8bed\u4e49\u7684\u4efb\u610f\u5bf9\u8c61\uff0c\u540c\u65f6\u6392\u9664\u8bed\u4e49\u76f8\u4f3c\u4f46\u65e0\u5173\u7684\u5e72\u6270\u5bf9\u8c61\u3002  \n\u25c6 \u6784\u5efa\u9996\u4e2a\u5927\u89c4\u6a21COR\u57fa\u51c6\u6570\u636e\u96c6COR127K\uff0c\u5305\u542b408\u4e2a\u7c7b\u522b\u300112.7\u4e07\u7ec4\u68c0\u7d22\u4e09\u5143\u7ec4\uff0c\u8986\u76d6\u591a\u6837\u5316\u8bed\u4e49\u53d8\u6362\u573a\u666f\u3002  \n\u25c6 \u8bbe\u8ba1\u7edf\u4e00\u7aef\u5230\u7aef\u6a21\u578bCORE\uff0c\u521b\u65b0\u6027\u6574\u5408\u53c2\u8003\u533a\u57df\u7f16\u7801\u3001\u81ea\u9002\u5e94\u89c6\u89c9-\u6587\u672c\u4ea4\u4e92\u548c\u533a\u57df\u7ea7\u5bf9\u6bd4\u5b66\u4e60\u4e09\u5927\u5173\u952e\u6280\u672f\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eCORE\u5728\u57fa\u7c7b\u548c\u65b0\u7c7b\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u4e3a\u7ec6\u7c92\u5ea6\u591a\u6a21\u6001\u68c0\u7d22\u7814\u7a76\u5f00\u8f9f\u65b0\u65b9\u5411\u3002  \n\u25c6 \u9996\u6b21\u5b9e\u73b0\u4ece\"\u56fe\u50cf\u7ea7\u5339\u914d\"\u5230\"\u5bf9\u8c61\u7ea7\u5b9a\u4f4d\"\u7684\u8de8\u8d8a\uff0c\u63a8\u52a8\u591a\u6a21\u6001\u7cfb\u7edf\u5bf9\u7528\u6237\u610f\u56fe\u7684\u7cbe\u7ec6\u5316\u7406\u89e3\u3002|\n",
    "2508.04335": "|2025-08-06|RiemanLine: Riemannian Manifold Representation of 3D Lines for Factor Graph Optimization|Yanyan Li\u7b49|[2508.04335](http://arxiv.org/pdf/2508.04335)|\u65e0|\u25c6 \u63d0\u51faRiemanLine\uff0c\u4e00\u79cd\u57fa\u4e8e\u9ece\u66fc\u6d41\u5f62\u76843D\u76f4\u7ebf\u7edf\u4e00\u6700\u5c0f\u8868\u793a\u6cd5\uff0c\u53ef\u540c\u65f6\u5904\u7406\u72ec\u7acb\u76f4\u7ebf\u548c\u5e73\u884c\u7ebf\u7ec4\uff0c\u89e3\u51b3\u4e86\u4eba\u9020\u73af\u5883\u4e2d\u666e\u904d\u5b58\u5728\u7684\u7ed3\u6784\u89c4\u5f8b\u6027\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u76f4\u7ebf\u5730\u6807\u89e3\u8026\u4e3a\u5168\u5c40\u548c\u5c40\u90e8\u7ec4\u4ef6\uff1a\u5728\u5355\u4f4d\u7403\u9762S\u00b2\u4e0a\u4f18\u5316\u7684\u5171\u4eab\u6d88\u5931\u65b9\u5411\uff0c\u4ee5\u53ca\u5728\u6b63\u4ea4\u5b50\u7a7a\u95f4\u4e0a\u7ea6\u675f\u7684\u7f29\u653e\u6cd5\u5411\u91cf\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u89c4\u5f8b\u7684\u7d27\u51d1\u7f16\u7801\u3002  \n\u25c6 \u5bf9\u4e8en\u6761\u5e73\u884c\u7ebf\uff0c\u5c06\u53c2\u6570\u7a7a\u95f4\u4ece4n\uff08\u6b63\u4ea4\u5f62\u5f0f\uff09\u51cf\u5c11\u52302n+2\uff0c\u65e0\u9700\u663e\u5f0f\u7ea6\u675f\u5373\u53ef\u81ea\u7136\u5d4c\u5165\u5e73\u884c\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u53c2\u6570\u7ef4\u5ea6\u3002  \n\u25c6 \u5c06\u8be5\u53c2\u6570\u5316\u65b9\u6cd5\u96c6\u6210\u5230\u56e0\u5b50\u56fe\u6846\u67b6\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u65b9\u5411\u5bf9\u9f50\u548c\u5c40\u90e8\u91cd\u6295\u5f71\u4f18\u5316\u7684\u7edf\u4e00\u57fa\u4e8e\u6d41\u5f62\u7684\u675f\u8c03\u6574\u3002  \n\u25c6 \u5728ICL-NUIM\u3001TartanAir\u548c\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u59ff\u6001\u4f30\u8ba1\u548c\u76f4\u7ebf\u91cd\u5efa\u65b9\u9762\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u540c\u65f6\u6539\u5584\u4e86\u6536\u655b\u7a33\u5b9a\u6027\u3002|\n",
    "2508.05661": "|2025-07-31|Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace|Andre Rusli\u7b49|[2508.05661](http://arxiv.org/pdf/2508.05661)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96f6\u6837\u672c\u68c0\u7d22\u7684\u53ef\u6269\u5c55\u89c6\u89c9\u641c\u7d22\u7cfb\u7edf\uff0c\u9002\u7528\u4e8eC2C\u7535\u5546\u5e73\u53f0\uff0c\u89e3\u51b3\u4e86\u975e\u7ed3\u6784\u5316\u5546\u54c1\u5217\u8868\u7684\u641c\u7d22\u96be\u9898\u3002  \n\u25c6 \u9996\u6b21\u5728Mercari\u5e73\u53f0\u4e2d\u5bf9\u6bd4\u4e86\u591a\u79cd\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u68c0\u7d22\u6027\u80fd\uff0c\u53d1\u73b0\u591a\u8bed\u8a00SigLIP\u6a21\u578b\u8868\u73b0\u6700\u4f18\uff0cnDCG@5\u6307\u6807\u6bd4\u539f\u6709\u5fae\u8c03\u57fa\u7ebf\u63d0\u534713.3%\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u5b9e\u65f6\u63a8\u7406\u4e0e\u540e\u53f0\u7d22\u5f15\u76f8\u7ed3\u5408\u7684\u5de5\u4f5c\u6d41\uff0c\u5e76\u901a\u8fc7\u964d\u7ef4\u4f18\u5316\u7edf\u4e00\u5d4c\u5165\u7ba1\u9053\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u90e8\u7f72\u3002  \n\u25c6 \u901a\u8fc7\u7ebf\u4e0aA/B\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5b9e\u9645\u6548\u679c\uff0c\u5b9e\u9a8c\u7ec4\u7528\u6237\u901a\u8fc7\u56fe\u50cf\u641c\u7d22\u7684\u6210\u4ea4\u7387\u63d0\u5347\u9ad8\u8fbe40.9%\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7528\u6237\u53c2\u4e0e\u5ea6\u548c\u8f6c\u5316\u7387\u3002  \n\u25c6 \u8bc1\u660e\u4e86\u96f6\u6837\u672c\u6a21\u578b\u53ef\u4f5c\u4e3a\u751f\u4ea7\u73af\u5883\u7684\u5f3a\u57fa\u7ebf\u65b9\u6848\uff0c\u65e2\u80fd\u5feb\u901f\u90e8\u7f72\uff0c\u53c8\u4fdd\u7559\u4e86\u672a\u6765\u5fae\u8c03\u7684\u7075\u6d3b\u6027\uff0c\u5927\u5e45\u964d\u4f4e\u5f00\u53d1\u6210\u672c\u3002|\n",
    "2508.09105": "|2025-08-13|SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling|Shixuan Sun\u7b49|[2508.09105](http://arxiv.org/pdf/2508.09105)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u9762\u5411\u534a\u9ed1\u76d2\u68c0\u7d22\u63a7\u5236\u73af\u5883\u7684\u6765\u6e90\u611f\u77e5\u6210\u5458\u5ba1\u8ba1\u6846\u67b6(SMA)\uff0c\u5b9e\u73b0\u751f\u6210\u5185\u5bb9\u7ec6\u7c92\u5ea6\u6765\u6e90\u8ffd\u8e2a\uff08\u9884\u8bad\u7ec3/\u5916\u90e8\u68c0\u7d22/\u7528\u6237\u8f93\u5165\uff09\uff0c\u89e3\u51b3\u4f20\u7edf\u6210\u5458\u63a8\u7406\u65b9\u6cd5\u5728RAG\u7cfb\u7edf\u4e2d\u5931\u6548\u7684\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u57fa\u4e8e\u96f6\u9636\u4f18\u5316\u7684\u5f52\u56e0\u4f30\u8ba1\u673a\u5236\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u6270\u52a8\u91c7\u6837\u548c\u5cad\u56de\u5f52\u5efa\u6a21\uff0c\u5728\u534a\u9ed1\u76d2\u7ea6\u675f\u4e0b\u9c81\u68d2\u8fd1\u4f3c\u8f93\u5165\u4ee4\u724c\u5bf9\u8f93\u51fa\u7684\u771f\u5b9e\u5f71\u54cd\u3002  \n\u25c6 \u9996\u521b\u8de8\u6a21\u6001\u5f52\u56e0\u6280\u672f\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u6a21\u578b\u5c06\u56fe\u50cf\u8f93\u5165\u6295\u5f71\u4e3a\u6587\u672c\u63cf\u8ff0\uff0c\u5b9e\u73b0\u6587\u672c\u6a21\u6001\u7684\u4ee4\u724c\u7ea7\u5f52\u56e0\uff0c\u9996\u6b21\u652f\u6301MRAG\u7cfb\u7edf\u4e2d\u56fe\u50cf\u68c0\u7d22\u75d5\u8ff9\u7684\u6210\u5458\u63a8\u7406\u3002  \n\u25c6 \u5c06\u6210\u5458\u63a8\u7406\u7684\u7814\u7a76\u7126\u70b9\u4ece\"\u6570\u636e\u662f\u5426\u88ab\u8bb0\u5fc6\"\u8f6c\u5411\"\u5185\u5bb9\u6765\u6e90\u4f55\u5904\"\uff0c\u4e3a\u590d\u6742\u751f\u6210\u7cfb\u7edf\u7684\u6570\u636e\u6eaf\u6e90\u5ba1\u8ba1\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002  \n\u25c6 \u7a81\u7834\u73b0\u6709\u65b9\u6cd5\u5728\u68c0\u7d22\u4e0e\u591a\u6a21\u6001\u878d\u5408\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u63a7\u5236\u68c0\u7d22\u8fc7\u7a0b\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u9690\u79c1\u6cc4\u9732\u8d23\u4efb\u8ba4\u5b9a\u3002|\n",
    "2508.08917": "|2025-08-12|A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition|Jintao Cheng\u7b49|[2508.08917](http://arxiv.org/pdf/2508.08917)|\u65e0|\u25c6\u63d0\u51fa\u57fa\u4e8e\u4f2a\u5168\u5c40\u878d\u5408\u8303\u5f0f\u7684\u8de8\u89c6\u89d2\u7f51\u7edc\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u5206\u652f\u534f\u540c\u5b66\u4e60\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\u7279\u5f81\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5ffd\u7565\u7279\u5f81\u7a7a\u95f4\u5185\u5728\u7ed3\u6784\u7684\u95ee\u9898\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u5f15\u5165\u4f2a\u5168\u5c40\u4fe1\u606f\u5f15\u5bfc\u673a\u5236\uff0c\u6709\u6548\u534f\u8c03\u4e0d\u540c\u6a21\u6001\u5206\u652f\u7684\u7279\u5f81\u8868\u8fbe\uff0c\u589e\u5f3a\u590d\u6742\u73af\u5883\u4e0b\u7684\u573a\u666f\u8bc6\u522b\u80fd\u529b\u3002  \n\u25c6\u63d0\u51fa\u6d41\u5f62\u9002\u5e94\u4e0e\u6210\u5bf9\u65b9\u5dee-\u5c40\u90e8\u6027\u5b66\u4e60\u5ea6\u91cf\u65b9\u6cd5\uff0c\u6784\u5efa\u5bf9\u79f0\u6b63\u5b9a(SPD)\u77e9\u9635\u8ba1\u7b97\u9a6c\u6c0f\u8ddd\u79bb\uff0c\u53d6\u4ee3\u4f20\u7edf\u6b27\u6c0f\u8ddd\u79bb\u5ea6\u91cf\u3002  \n\u25c6\u901a\u8fc7\u51e0\u4f55\u5316\u5efa\u6a21\u51c6\u786e\u523b\u753b\u7279\u5f81\u7a7a\u95f4\u5185\u6570\u636e\u672c\u8d28\u5206\u5e03\uff0c\u6355\u6349\u590d\u6742\u7684\u7c7b\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u5347\u65f6\u53d8\u573a\u666f\u4e0b\u7684\u8bc6\u522b\u9c81\u68d2\u6027\u3002  \n\u25c6\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u590d\u6742\u73af\u5883\u6761\u4ef6\u4e0b\u5177\u6709\u7ade\u4e89\u4f18\u52bf\uff0c\u5c24\u5176\u5728GPS\u62d2\u6b62\u73af\u5883\u4e2d\u7684\u5b9a\u4f4d\u548c\u95ed\u73af\u68c0\u6d4b\u4efb\u52a1\u8868\u73b0\u7a81\u51fa\u3002  \n\u25c6\u6574\u4f53\u6846\u67b6\u7a81\u7834\u4e86\u6b27\u5f0f\u7a7a\u95f4\u7ebf\u6027\u5047\u8bbe\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6fc0\u5149\u96f7\u8fbe\u5730\u70b9\u8bc6\u522b\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u975e\u7ebf\u6027\u7279\u5f81\u5b66\u4e60\u8303\u5f0f\u3002|\n",
    "2508.09241": "|2025-08-12|FineState-Bench: A Comprehensive Benchmark for Fine-Grained State Control in GUI Agents|Fengxian Ji\u7b49|[2508.09241](http://arxiv.org/pdf/2508.09241)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u7ec6\u7c92\u5ea6GUI\u4ee3\u7406\u63a7\u5236\u8bc4\u4f30\u6807\u51c6FineState-Bench\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u4ec5\u5173\u6ce8\u7c97\u7c92\u5ea6\u4efb\u52a1\u5b8c\u6210\u7684\u7a7a\u767d  \n\u25c6 \u6784\u5efa\u4e86\u8de8\u5e73\u53f0\uff08\u684c\u9762/\u7f51\u9875/\u79fb\u52a8\u7aef\uff09\u76842257\u9879\u4efb\u52a1\u6d4b\u8bd5\u96c6\uff0c\u5305\u542b\u56db\u4e2a\u7ec4\u4ef6\u6a21\u5757\u548c\u56db\u9636\u6bb5\u8bc4\u4f30\u6307\u6807  \n\u25c6 \u521b\u65b0\u5f00\u53d1\u4e86\u5373\u63d2\u5373\u7528\u7684\u89c6\u89c9\u8bca\u65ad\u52a9\u624bVDA\uff0c\u9996\u6b21\u5b9e\u73b0\u611f\u77e5\u4e0e\u5b9a\u4f4d\u80fd\u529b\u7684\u91cf\u5316\u89e3\u8026\u5206\u6790  \n\u25c6 \u901a\u8fc7\u5b9e\u9a8c\u63ed\u793a\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u4ea4\u4e92\u4e2d\u4ec5\u8fbe32.8%\u51c6\u786e\u7387\uff0c\u9a8c\u8bc1\u4e86\u57fa\u51c6\u7684\u6709\u6548\u6027  \n\u25c6 \u9996\u6b21\u8bc1\u5b9e\u89c6\u89c9\u5b9a\u4f4d\u80fd\u529b\u662f\u5f53\u524dGUI\u4ee3\u7406\u7684\u4e3b\u8981\u74f6\u9888\uff08\u7406\u60f3\u89c6\u89c9\u53ef\u4f7fGemini\u6a21\u578b\u6210\u529f\u7387\u63d0\u534714.9%\uff09  \n\u25c6 \u5b8c\u6574\u5f00\u6e90\u8bc4\u4f30\u6846\u67b6\u4e0e\u6570\u636e\u96c6\uff0c\u4e3aGUI\u4ee3\u7406\u7814\u7a76\u63d0\u4f9b\u6807\u51c6\u5316\u6d4b\u8bd5\u73af\u5883\u4e0e\u8bca\u65ad\u5de5\u5177|\n",
    "2508.11272": "|2025-08-15|Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering|Jun Li\u7b49|[2508.11272](http://arxiv.org/pdf/2508.11272)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPMTFR\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u91d1\u5b57\u5854\u5339\u914d\u6a21\u578b\u4e0e\u65e0\u8bad\u7ec3\u7cbe\u70bc\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u76d1\u7763\u5f0f\u7ec4\u5408\u56fe\u50cf\u68c0\u7d22\uff08CIR\uff09\u7684\u6027\u80fd\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u7b80\u5355\u9ad8\u6548\u7684\u91d1\u5b57\u5854\u4fee\u8865\u6a21\u5757\uff08Pyramid Patcher\uff09\uff0c\u901a\u8fc7\u591a\u7c92\u5ea6\u89c6\u89c9\u4fe1\u606f\u7406\u89e3\u589e\u5f3a\u6a21\u578b\u5bf9\u53c2\u8003\u56fe\u50cf\u548c\u4fee\u6539\u6307\u4ee4\u7684\u8054\u5408\u89e3\u6790\u80fd\u529b\u3002  \n\u25c6 \u9996\u6b21\u5c06\u8868\u793a\u5de5\u7a0b\uff08Representation Engineering\uff09\u5f15\u5165CIR\u4efb\u52a1\uff0c\u5229\u7528\u601d\u7ef4\u94fe\uff08CoT\uff09\u6570\u636e\u63d0\u53d6\u8868\u5f81\u5e76\u6ce8\u5165\u591a\u6a21\u6001\u5927\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6392\u5e8f\u6a21\u578b\u5373\u53ef\u4f18\u5316\u68c0\u7d22\u7ed3\u679c\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5728\u76d1\u7763\u5f0fCIR\u4e2d\u5b9e\u73b0\u65e0\u8bad\u7ec3\u7cbe\u70bc\u8303\u5f0f\uff0c\u6446\u8131\u4f20\u7edf\u65b9\u6cd5\u5bf9\u663e\u5f0f\u6587\u672c\u63a8\u7406\u6216\u590d\u6742\u63d0\u793a\u8bbe\u8ba1\u7684\u4f9d\u8d56\uff0c\u4ec5\u901a\u8fc7\u8868\u5f81\u6ce8\u5165\u5373\u53ef\u63d0\u5347\u5206\u6570\u3002  \n\u25c6 \u5728\u4e3b\u6d41CIR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8f7b\u91cf\u5316\u4e0e\u53ef\u6269\u5c55\u6027\u3002|\n",
    "2508.10933": "|2025-08-12|Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications|Yoli Shavit\u7b49|[2508.10933](http://arxiv.org/pdf/2508.10933)|\u65e0|\u25c6 \u5c06\u76f8\u673a\u4f4d\u59ff\u81ea\u7f16\u7801\u5668\uff08PAE\uff09\u4ece\u7edd\u5bf9\u4f4d\u59ff\u56de\u5f52\uff08APR\uff09\u6269\u5c55\u5230\u76f8\u5bf9\u4f4d\u59ff\u56de\u5f52\uff08RPR\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8ePAE\u7684RPR\u65b9\u6cd5\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u5b58\u50a8\u56fe\u50cf\u6216\u4f4d\u59ff\u6570\u636e\u7684\u91cd\u5b9a\u4f4d\u65b9\u6848\uff0c\u901a\u8fc7PAE-based RPR\u5bf9APR\u9884\u6d4b\u7ed3\u679c\u8fdb\u884c\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u3002  \n\u25c6 \u5728\u540c\u7b49\u67b6\u6784\u4e0b\uff0c\u9a8c\u8bc1\u4e86PAE-based RPR\u76f8\u6bd4\u4f20\u7edf\u56fe\u50cf\u57faRPR\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u6027\u80fd\u4f18\u52bf\u3002  \n\u25c6 \u5728\u5ba4\u5185\u573a\u666f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5bf9APR\u5b9a\u4f4d\u7cbe\u5ea6\u7684\u663e\u8457\u63d0\u5347\uff0c\u5c24\u5176\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u7a81\u51fa\u3002  \n\u25c6 \u4ec5\u970030%\u7684\u8bad\u7ec3\u6570\u636e\u5373\u53ef\u8fbe\u5230\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u96f6\u552e\u573a\u666f\u90e8\u7f72\u4e2d\u7684\u6570\u636e\u6536\u96c6\u8d1f\u62c5\uff0c\u63d0\u5347\u4e86\u6570\u636e\u6548\u7387\u3002  \n\u25c6 \u5f00\u6e90\u4e86\u4ee3\u7801\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u4e0e\u5e94\u7528\u63d0\u4f9b\u4e86\u4fbf\u5229\u3002|\n",
    "2508.12290": "|2025-08-17|CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval|Chor Boon Tan\u7b49|[2508.12290](http://arxiv.org/pdf/2508.12290)|\u65e0|\u25c6 \u63d0\u51faCLAIR\u65b9\u6cd5\uff0c\u5229\u7528CLIP\u751f\u6210\u7684\u566a\u58f0\u4f2a\u6807\u7b7e\u8fdb\u884c\u5f31\u76d1\u7763\u96f6\u6837\u672c\u8de8\u57df\u56fe\u50cf\u68c0\u7d22\uff08WSZS-CDIR\uff09\uff0c\u66ff\u4ee3\u4f20\u7edf\u65e0\u76d1\u7763\u65b9\u6cd5\u3002  \n\u25c6 \u901a\u8fc7CLIP\u6587\u672c\u4e0e\u56fe\u50cf\u7279\u5f81\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7f6e\u4fe1\u5206\u6570\uff0c\u6709\u6548\u4f18\u5316\u566a\u58f0\u4f2a\u6807\u7b7e\u7684\u8d28\u91cf\u3002  \n\u25c6 \u8bbe\u8ba1\u7c7b\u611f\u77e5\u6f5c\u5728\u7a7a\u95f4\u7f16\u7801\u673a\u5236\uff0c\u7ed3\u5408\u5b9e\u4f8b\u95f4\u548c\u7c07\u95f4\u5bf9\u6bd4\u635f\u5931\uff0c\u63d0\u5347\u7279\u5f81\u533a\u5206\u5ea6\u3002  \n\u25c6 \u63d0\u51fa\u8de8\u57df\u5bf9\u6bd4\u635f\u5931\u51cf\u5c11\u57df\u5dee\u5f02\uff0c\u5e76\u521b\u65b0\u6027\u5730\u901a\u8fc7\u95ed\u5f0f\u89e3\u5b66\u4e60\u8de8\u57df\u6620\u5c04\u51fd\u6570\uff0c\u4ec5\u7528CLIP\u6587\u672c\u5d4c\u5165\u5b9e\u73b0\u7279\u5f81\u5bf9\u9f50\u3002  \n\u25c6 \u5f15\u5165\u53ef\u5b66\u4e60\u63d0\u793a\u8bcd\u589e\u5f3a\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u652f\u6301\u65b0\u7c7b\u522b\u68c0\u7d22\u3002  \n\u25c6 \u5728TUBerlin\u3001Sketchy\u7b49\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86CLAIR\u7684\u4f18\u8d8a\u6027\uff0c\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002|\n",
    "2508.13843": "|2025-08-19|UniECS: Unified Multimodal E-Commerce Search Framework with Gated Cross-modal Fusion|Zihan Liang\u7b49|[2508.13843](http://arxiv.org/pdf/2508.13843)|\u65e0|\u25c6 \u63d0\u51fa\u4e86UniECS\u7edf\u4e00\u591a\u6a21\u6001\u7535\u5546\u641c\u7d22\u6846\u67b6\uff0c\u80fd\u7075\u6d3b\u5904\u7406\u56fe\u50cf\u3001\u6587\u672c\u53ca\u5176\u4efb\u610f\u7ec4\u5408\u7684\u68c0\u7d22\u573a\u666f\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u5c40\u9650\u4e8e\u56fa\u5b9a\u6a21\u6001\u914d\u5bf9\u7684\u9650\u5236\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u65b0\u578b\u95e8\u63a7\u591a\u6a21\u6001\u7f16\u7801\u5668\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u878d\u5408\u673a\u5236\uff0c\u6709\u6548\u6574\u5408\u4e0d\u540c\u6a21\u6001\u8868\u5f81\u5e76\u5904\u7406\u6a21\u6001\u7f3a\u5931\u95ee\u9898\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u7efc\u5408\u8bad\u7ec3\u7b56\u7565\uff0c\u7ed3\u5408\u8de8\u6a21\u6001\u5bf9\u9f50\u635f\u5931\u3001\u5c40\u90e8\u5bf9\u9f50\u635f\u5931\u3001\u6a21\u6001\u5185\u5bf9\u6bd4\u635f\u5931\u548c\u81ea\u9002\u5e94\u635f\u5931\u52a0\u6743\uff0c\u4f18\u5316\u6a21\u578b\u5b66\u4e60\u6548\u679c\u3002  \n\u25c6 \u6784\u5efa\u4e86M-BEER\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b5\u4e07\u5546\u54c1\u5bf9\uff0c\u4e3a\u591a\u6a21\u6001\u7535\u5546\u68c0\u7d22\u63d0\u4f9b\u5168\u9762\u8bc4\u4f30\u6807\u51c6\u3002  \n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff08\u5982\u6587\u672c\u641c\u56fe\u4efb\u52a1R@10\u63d0\u534728%\uff09\uff0c\u53c2\u6570\u91cf\u4ec50.2B\uff0c\u6548\u7387\u8fdc\u8d85\u66f4\u5927\u89c4\u6a21\u6a21\u578b\u3002  \n\u25c6 \u6210\u529f\u90e8\u7f72\u4e8e\u5feb\u624b\u7535\u5546\u641c\u7d22\u5e73\u53f0\uff0c\u70b9\u51fb\u7387\u63d0\u53472.74%\u3001\u6536\u5165\u589e\u957f8.33%\uff0c\u9a8c\u8bc1\u4e86\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002|\n",
    "2508.13488": "|2025-08-19|ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments|Jingwen Yu\u7b49|[2508.13488](http://arxiv.org/pdf/2508.13488)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u91cd\u590d\u73af\u5883\u4e2d\u8fdb\u884c\u9c81\u68d2\u56de\u73af\u95ed\u5408\u9a8c\u8bc1\u7684\u65b9\u6cd5ROVER\uff0c\u5176\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u5229\u7528\u5386\u53f2\u8f68\u8ff9\u4f5c\u4e3a\u5148\u9a8c\u7ea6\u675f\u6765\u63d0\u5347\u9a8c\u8bc1\u53ef\u9760\u6027\u3002  \n\u25c6 \u9996\u6b21\u5c06\u673a\u5668\u4eba\u7684\u65f6\u7a7a\u8fd0\u52a8\u8f68\u8ff9\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\u5f15\u5165\u56de\u73af\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u4ec5\u4f9d\u8d56\u5916\u89c2\u7279\u5f81\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u63d0\u51fa\u901a\u8fc7\u4f4d\u59ff\u56fe\u4f18\u5316\u751f\u6210\u5019\u9009\u56de\u73af\u5bf9\u5e94\u7684\u8f68\u8ff9\uff0c\u5e76\u8bbe\u8ba1\u8bc4\u5206\u673a\u5236\u8bc4\u4f30\u8be5\u8f68\u8ff9\u4e0e\u65e0\u56de\u73af\u5148\u9a8c\u8f68\u8ff9\u7684\u4e00\u81f4\u6027\u3002  \n\u25c6 \u5728\u5b58\u5728\u9ad8\u5ea6\u76f8\u4f3c\u7ed3\u6784\u7684\u91cd\u590d\u73af\u5883\u4e2d\u80fd\u6709\u6548\u62d2\u7edd\u9519\u8bef\u56de\u73af\uff0c\u663e\u8457\u964d\u4f4eSLAM\u7cfb\u7edf\u7684\u8bef\u68c0\u98ce\u9669\u3002  \n\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u516c\u5f00\u6570\u636e\u96c6\u548c\u771f\u5b9e\u573a\u666f\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u53ef\u65e0\u7f1d\u96c6\u6210\u81f3\u73b0\u6709\u5148\u8fdbSLAM\u7cfb\u7edf\u4e2d\u3002|\n",
    "2508.15297": "|2025-08-21|DesignCLIP: Multimodal Learning with CLIP for Design Patent Understanding|Zhu Wang\u7b49|[2508.15297](http://arxiv.org/pdf/2508.15297)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86DesignCLIP\uff0c\u4e00\u4e2a\u57fa\u4e8eCLIP\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u8bbe\u8ba1\u4e13\u5229\u7684\u7406\u89e3\u4e0e\u5206\u6790\u3002\u5176\u6838\u5fc3\u8d21\u732e\u4e0e\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u6784\u5efa\u4e86\u9996\u4e2a\u9488\u5bf9\u7f8e\u56fd\u8bbe\u8ba1\u4e13\u5229\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u4e3a\u591a\u6a21\u6001\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002\n\u25c6 \u63d0\u51fa\u7c7b\u611f\u77e5\u5206\u7c7b\u4e0e\u5bf9\u6bd4\u5b66\u4e60\u7b56\u7565\uff0c\u6709\u6548\u9002\u5e94\u4e13\u5229\u6570\u636e\u7684\u62bd\u8c61\u548c\u7ed3\u6784\u6027\u7279\u70b9\u3002\n\u25c6 \u5229\u7528\u751f\u6210\u5f0f\u8be6\u7ec6\u6807\u6ce8\u548c\u4e13\u5229\u56fe\u50cf\u7684\u591a\u89c6\u89d2\u5b66\u4e60\uff0c\u589e\u5f3a\u4e86\u56fe\u50cf\u4e0e\u6587\u672c\u7684\u8bed\u4e49\u5bf9\u9f50\u3002\n\u25c6 \u9a8c\u8bc1\u4e86\u6846\u67b6\u5728\u4e13\u5229\u5206\u7c7b\u548c\u68c0\u7d22\u4efb\u52a1\u4e0a\u7684\u4f18\u8d8a\u6027\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u53caSOTA\u6a21\u578b\u3002\n\u25c6 \u63a2\u7d22\u4e86\u591a\u6a21\u6001\u4e13\u5229\u68c0\u7d22\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u8bbe\u8ba1\u521b\u65b0\u63d0\u4f9b\u66f4\u591a\u6837\u5316\u7684\u7075\u611f\u6765\u6e90\u3002|\n",
    "2508.18242": "|2025-08-25|GSVisLoc: Generalizable Visual Localization for Gaussian Splatting Scene Representations|Fadi Khatib\u7b49|[2508.18242](http://arxiv.org/pdf/2508.18242)|\u65e0|GSVisLoc\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u573a\u666f\u8868\u793a\u8bbe\u8ba1\u7684\u901a\u7528\u89c6\u89c9\u5b9a\u4f4d\u65b9\u6cd5\u3002  \n\u25c6 \u9996\u6b21\u5b9e\u73b0\u4e86\u65e0\u9700\u4efb\u4f55\u4fee\u6539\u6216\u91cd\u8bad\u7ec3\uff0c\u76f4\u63a5\u5229\u7528\u539f\u59cb3DGS\u6a21\u578b\u8fdb\u884c\u89c6\u89c9\u5b9a\u4f4d\u3002  \n\u25c6 \u901a\u8fc7\u4e0b\u91c7\u6837\u548c\u7f16\u78013D\u9ad8\u65af\u6765\u63d0\u53d6\u573a\u666f\u7279\u5f81\uff0c\u5e76\u4e0e\u67e5\u8be2\u56fe\u50cf\u7279\u5f81\u8fdb\u884c\u9c81\u68d2\u5339\u914d\u3002  \n\u25c6 \u91c7\u7528\u7531\u7c97\u5230\u7cbe\u7684\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u7c97\u5339\u914d\u3001\u7cbe\u7ec6\u5339\u914d\u548c\u59ff\u6001\u4f18\u5316\uff0c\u786e\u4fdd\u9ad8\u7cbe\u5ea6\u4f4d\u59ff\u4f30\u8ba1\u3002  \n\u25c6 \u5728\u5ba4\u5185\u5916\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e3DGS\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002  \n\u25c6 \u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u5168\u65b0\u573a\u666f\u3002|\n",
    "2508.17972": "|2025-08-25|SAIL-Recon: Large SfM by Augmenting Scene Regression with Localization|Junyuan Deng\u7b49|[2508.17972](http://arxiv.org/pdf/2508.17972)|\u65e0|SAIL-Recon\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5927\u89c4\u6a21\u8fd0\u52a8\u6062\u590d\u7ed3\u6784\uff08SfM\uff09\u7684\u524d\u9988Transformer\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u573a\u666f\u56de\u5f52\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5927\u91cf\u8f93\u5165\u56fe\u50cf\u7684\u95ee\u9898\u3002\n\n\u25c6 \u6838\u5fc3\u521b\u65b0\u662f\u5c06\u89c6\u89c9\u5b9a\u4f4d\u80fd\u529b\u878d\u5165\u573a\u666f\u56de\u5f52\u7f51\u7edc\uff0c\u901a\u8fc7\u5f15\u5165\u951a\u70b9\u56fe\u50cf\u5b50\u96c6\u6765\u6784\u5efa\u795e\u7ecf\u573a\u666f\u8868\u793a\u3002\n\u25c6 \u8be5\u65b9\u6cd5\u9996\u5148\u4ece\u951a\u70b9\u56fe\u50cf\u8ba1\u7b97\u51fa\u4e00\u4e2a\u7d27\u51d1\u7684\u795e\u7ecf\u573a\u666f\u8868\u793a\uff0c\u4f5c\u4e3a\u5168\u5c40\u573a\u666f\u5148\u9a8c\u3002\n\u25c6 \u56de\u5f52\u7f51\u7edc\u968f\u540e\u4ee5\u8be5\u795e\u7ecf\u8868\u793a\u4e3a\u6761\u4ef6\u8fdb\u884c\u5fae\u8c03\uff0c\u4ece\u800c\u80fd\u591f\u9ad8\u6548\u5730\u91cd\u5efa\u6240\u6709\u8f93\u5165\u56fe\u50cf\u7684\u76f8\u673a\u4f4d\u59ff\u548c3D\u7ed3\u6784\u3002\n\u25c6 \u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u573a\u666f\u56de\u5f52\u65b9\u6cd5\u5e94\u5bf9\u6781\u7aef\u89c6\u89d2\u53d8\u5316\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u6210\u529f\u5c06\u5176\u6269\u5c55\u81f3\u5927\u89c4\u6a21\u573a\u666f\u3002\n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728TUM-RGBD\u3001CO3Dv2\u548cTanks & Temples\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u548c\u65b0\u89c6\u89d2\u5408\u6210\u4efb\u52a1\u4e0a\u5747\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002|\n",
    "2508.17416": "|2025-08-24|Data Leakage in Visual Datasets|Patrick Ramos\u7b49|[2508.17416](http://arxiv.org/pdf/2508.17416)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u7cfb\u7edf\u6027\u5730\u5206\u6790\u4e86\u89c6\u89c9\u6570\u636e\u96c6\u4e2d\u7684\u6570\u636e\u6cc4\u6f0f\u95ee\u9898\u53ca\u5176\u5bf9\u6a21\u578b\u8bc4\u4f30\u53ef\u9760\u6027\u7684\u5f71\u54cd\u3002  \n\u25c6\u9996\u6b21\u5bf9\u89c6\u89c9\u6570\u636e\u6cc4\u6f0f\u8fdb\u884c\u4e86\u591a\u7ef4\u5ea6\u5206\u7c7b\uff0c\u4f9d\u636e\u6a21\u6001\u3001\u8986\u76d6\u8303\u56f4\u548c\u7a0b\u5ea6\u5212\u5206\u6cc4\u6f0f\u7c7b\u578b\u3002  \n\u25c6\u91c7\u7528\u56fe\u50cf\u68c0\u7d22\u6280\u672f\u5b9e\u8bc1\u68c0\u9a8c\u4e86\u591a\u4e2a\u4e3b\u6d41\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u6240\u6709\u88ab\u5206\u6790\u6570\u636e\u96c6\u5747\u5b58\u5728\u4e0d\u540c\u5f62\u5f0f\u7684\u6cc4\u6f0f\u3002  \n\u25c6\u8bc1\u660e\u4e86\u5404\u7c7b\u6cc4\u6f0f\uff08\u4ece\u4e25\u91cd\u5230\u8f7b\u5fae\uff09\u5747\u4f1a\u635f\u5bb3\u4e0b\u6e38\u4efb\u52a1\u4e2d\u6a21\u578b\u8bc4\u4f30\u7684\u516c\u6b63\u6027\u3002  \n\u25c6\u63ed\u793a\u4e86\u4e92\u8054\u7f51\u6570\u636e\u6e90\u4e0e\u516c\u5f00\u57fa\u51c6\u5e76\u5b58\u5bfc\u81f4\u7684\u6cc4\u6f0f\u5fc5\u7136\u6027\uff0c\u547c\u5401\u5b66\u754c\u5173\u6ce8\u6570\u636e\u6784\u5efa\u89c4\u8303\u3002  \n\u7814\u7a76\u7ed3\u679c\u5bf9\u89c6\u89c9\u9886\u57df\u57fa\u51c6\u6784\u5efa\u548c\u6a21\u578b\u8bc4\u4f30\u5b9e\u8df5\u5177\u6709\u91cd\u8981\u8b66\u793a\u610f\u4e49\u3002|\n",
    "2508.16707": "|2025-08-22|Sparse and Dense Retrievers Learn Better Together: Joint Sparse-Dense Optimization for Text-Image Retrieval|Jonghyun Song\u7b49|[2508.16707](http://arxiv.org/pdf/2508.16707)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u7a00\u758f-\u5bc6\u96c6\u68c0\u7d22\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u591a\u6a21\u6001\u6587\u672c-\u56fe\u50cf\u68c0\u7d22\u6027\u80fd\u3002  \n\u25c6 \u901a\u8fc7\u81ea\u77e5\u8bc6\u84b8\u998f\u5b9e\u73b0\u7a00\u758f\u4e0e\u5bc6\u96c6\u8868\u793a\u7684\u53cc\u5411\u534f\u540c\u5b66\u4e60\uff0c\u7a81\u7834\u4ee5\u5f80\u5355\u5411\u84b8\u998f\u6216\u72ec\u7acb\u8bad\u7ec3\u7684\u9650\u5236\u3002  \n\u25c6 \u63d0\u51fa\u878d\u5408\u76f8\u4f3c\u5ea6\u5206\u6570\uff08\u7a00\u758f\u4e0e\u5bc6\u96c6\u5f97\u5206\u7684\u52a0\u6743\u548c\uff09\u4f5c\u4e3a\u5171\u4eab\u6559\u5e08\u4fe1\u53f7\uff0c\u540c\u6b65\u4f18\u5316\u4e24\u79cd\u8868\u793a\u3002  \n\u25c6 \u4ec5\u5fae\u8c03\u5bc6\u96c6\u7f16\u7801\u5668\u6700\u540e\u4e00\u5c42\u548c\u7a00\u758f\u6295\u5f71\u5934\uff0c\u65e0\u9700\u5168\u6a21\u578b\u91cd\u8bad\u7ec3\uff0c\u9ad8\u6548\u517c\u5bb9\u73b0\u6709\u89c6\u89c9-\u8bed\u8a00\u9884\u8bad\u7ec3\u6a21\u578b\u3002  \n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u4f7f\u7a00\u758f\u68c0\u7d22\u5668\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7a00\u758f\u57fa\u7ebf\uff0c\u751a\u81f3\u8fbe\u5230\u6216\u8d85\u8d8a\u5bc6\u96c6\u6a21\u578b\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u7a00\u758f\u6a21\u578b\u7684\u9ad8\u6548\u4e0e\u53ef\u89e3\u91ca\u6027\u4f18\u52bf\u3002|\n",
    "2508.18971": "|2025-08-26|Can we make NeRF-based visual localization privacy-preserving?|Maxime Pietrantoni\u7b49|[2508.18971](http://arxiv.org/pdf/2508.18971)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u57fa\u4e8eNeRF\u7684\u89c6\u89c9\u5b9a\u4f4d\u65b9\u6cd5\u5b58\u5728\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u9996\u5148\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u7528\u4e8e\u7cfb\u7edf\u68c0\u9a8cNeRF\u8868\u793a\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u6027\uff0c\u53d1\u73b0\u5373\u4f7f\u79fb\u9664\u989c\u8272\u9884\u6d4b\u5934\uff0c\u5176\u51e0\u4f55\u8868\u793a\u4ecd\u4f1a\u5b58\u50a8\u654f\u611f\u7ec6\u8282\u3002  \n\u25c6 \u63d0\u51fa\u4e00\u79cd\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\uff0c\u5c06RGB\u56fe\u50cf\u8f6c\u6362\u4e3a\u5206\u5272\u6807\u7b7e\u4f5c\u4e3a\u8bad\u7ec3\u76d1\u7763\uff0c\u907f\u514d\u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u56fe\u50cf\u6570\u636e\u3002  \n\u25c6 \u6784\u5efa\u4e86ppNeSF\uff08\u9690\u79c1\u4fdd\u62a4\u795e\u7ecf\u5206\u5272\u573a\uff09\uff0c\u4ee5\u5206\u5272\u6807\u7b7e\u66ff\u4ee3RGB\u8fdb\u884c\u8bad\u7ec3\uff0c\u786e\u4fdd\u573a\u666f\u8868\u793a\u65e2\u7c97\u7cd9\u65e0\u6cd5\u8fd8\u539f\u7ec6\u8282\uff0c\u53c8\u4fdd\u7559\u8db3\u591f\u7684\u5224\u522b\u6027\u7528\u4e8e\u5b9a\u4f4d\u3002  \n\u25c6 \u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5148\u8fdb\u7684\u89c6\u89c9\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5e73\u8861\u4e86\u9690\u79c1\u4e0e\u5b9e\u7528\u6027\u3002  \n\u25c6 \u6574\u4f53\u5de5\u4f5c\u9996\u6b21\u7cfb\u7edf\u63ed\u793a\u4e86NeRF\u7684\u9690\u79c1\u6f0f\u6d1e\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u66ff\u4ee3\u7684\u9690\u79c1\u4fdd\u62a4\u8303\u5f0f\u3002|\n",
    "2508.18904": "|2025-08-26|Event-Enriched Image Analysis Grand Challenge at ACM Multimedia 2025|Thien-Phuc Tran\u7b49|[2508.18904](http://arxiv.org/pdf/2508.18904)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63a8\u51fa\u4e86\u9996\u4e2a\u4e13\u6ce8\u4e8e\u4e8b\u4ef6\u7ea7\u591a\u6a21\u6001\u7406\u89e3\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6311\u6218EVENTA\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u56fe\u50cf\u5206\u6790\u4e2d\u5ffd\u89c6\u4e0a\u4e0b\u6587\u548c\u8bed\u4e49\u6df1\u5ea6\u7684\u95ee\u9898\u3002\n\n\u25c6 \u9996\u521b\u5927\u89c4\u6a21\u4e8b\u4ef6\u7ea7\u591a\u6a21\u6001\u7406\u89e3\u57fa\u51c6\uff0c\u7a81\u7834\u4f20\u7edf\u56fe\u50cf\u63cf\u8ff0\u4e0e\u68c0\u7d22\u7684\u8868\u5c42\u8bc6\u522b\u5c40\u9650\u3002\n\u25c6 \u901a\u8fc7\u6574\u5408\u4e0a\u4e0b\u6587\u3001\u65f6\u5e8f\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u6784\u5efa\u201c\u4eba\u7269\u3001\u65f6\u95f4\u3001\u5730\u70b9\u3001\u4e8b\u4ef6\u3001\u539f\u56e0\u201d\u4e94\u7ef4\u4e8b\u4ef6\u7406\u89e3\u6846\u67b6\u3002\n\u25c6 \u57fa\u4e8eOpenEvents V1\u6570\u636e\u96c6\u8bbe\u8ba1\u53cc\u8d5b\u9053\uff1a\u4e8b\u4ef6\u589e\u5f3a\u56fe\u50cf\u68c0\u7d22\u4e0e\u63cf\u8ff0\uff0c\u4ee5\u53ca\u4e8b\u4ef6\u9a71\u52a8\u56fe\u50cf\u68c0\u7d22\u3002\n\u25c6 \u5efa\u7acb\u5305\u542b45\u652f\u56fd\u9645\u56e2\u961f\u53c2\u4e0e\u7684\u516c\u5e73\u8bc4\u4f30\u4f53\u7cfb\uff0c\u901a\u8fc7\u516c\u5f00\u548c\u79c1\u6709\u6d4b\u8bd5\u9636\u6bb5\u786e\u4fdd\u7ed3\u679c\u53ef\u590d\u73b0\u6027\u3002\n\u25c6 \u4e3a\u53d9\u4e8b\u9a71\u52a8\u591a\u5a92\u4f53AI\u5960\u5b9a\u57fa\u7840\uff0c\u63a8\u52a8\u65b0\u95fb\u3001\u5a92\u4f53\u5206\u6790\u3001\u6587\u5316\u5b58\u6863\u7b49\u9886\u57df\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u5e94\u7528\u53d1\u5c55\u3002|\n",
    "2508.19714": "|2025-08-27|Addressing Deepfake Issue in Selfie banking through camera based authentication|Subhrojyoti Mukherjee\u7b49|[2508.19714](http://arxiv.org/pdf/2508.19714)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u76f8\u673a\u6210\u50cf\u7279\u5f81\u6765\u9632\u5fa1\u81ea\u62cd\u94f6\u884c\u4e2d\u6df1\u5ea6\u4f2a\u9020\u653b\u51fb\u7684\u65b0\u578b\u8ba4\u8bc1\u65b9\u6cd5\u3002\n\n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u539f\u672c\u7528\u4e8e\u56fe\u50cf\u6eaf\u6e90\uff08\u5982\u56fe\u7247\u76f8\u673a\u5b9a\u4f4d\uff09\u7684\u53d6\u8bc1\u8bc6\u522b\u7cfb\u7edf\uff0c\u5e94\u7528\u4e8e\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u9886\u57df\uff0c\u5b9e\u73b0\u4e86\u6280\u672f\u5e94\u7528\u7684\u8de8\u754c\u8fc1\u79fb\u3002\n\u25c6 \u8be5\u65b9\u6cd5\u4e13\u6ce8\u4e8e\u5229\u7528\u76f8\u673a\u672c\u8eab\u7684\u786c\u4ef6\u7f3a\u9677\uff08\u5982\u955c\u5934\u5149\u5b66\u7279\u6027\u3001\u4f20\u611f\u5668\u566a\u58f0\u6a21\u5f0f\uff09\u4f5c\u4e3a\u751f\u7269\u7279\u5f81\u4e4b\u5916\u7684\u8f85\u52a9\u8ba4\u8bc1\u56e0\u7d20\uff0c\u56e0\u4e3a\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u96be\u4ee5\u5b8c\u7f8e\u590d\u5236\u8fd9\u4e9b\u7269\u7406\u5c42\u9762\u7684\u7ec6\u5fae\u7279\u5f81\u3002\n\u25c6 \u901a\u8fc7\u5206\u6790\u56fe\u50cf\u4e2d\u5d4c\u5165\u7684\u76f8\u673a\u56fa\u6709\u201c\u6307\u7eb9\u201d\u6765\u533a\u5206\u771f\u5b9e\u62cd\u6444\u7684\u7167\u7247\u4e0eAI\u751f\u6210\u7684\u4f2a\u9020\u56fe\u50cf\uff0c\u4e3a\u73b0\u6709\u7684\u9762\u90e8\u8bc6\u522b\u751f\u7269\u7cfb\u7edf\u589e\u52a0\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5b89\u5168\u5c42\u3002\n\u25c6 \u4e3a\u89e3\u51b3\u81ea\u62cd\u94f6\u884c\u7b49\u91d1\u878d\u573a\u666f\u4e0b\u9762\u4e34\u7684\u65e5\u76ca\u4e25\u5cfb\u7684\u6df1\u5ea6\u4f2a\u9020\u5a01\u80c1\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u80fd\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2508.20322": "|2025-08-27|Disentangling Latent Embeddings with Sparse Linear Concept Subspaces (SLiCS)|Zhi Li\u7b49|[2508.20322](http://arxiv.org/pdf/2508.20322)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSLiCS\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u8026\u89c6\u89c9-\u8bed\u8a00\u5171\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u4fe1\u606f\u3002\u5176\u6838\u5fc3\u8d21\u732e\u662f\u901a\u8fc7\u7a00\u758f\u7ebf\u6027\u6982\u5ff5\u5b50\u7a7a\u95f4\u5b9e\u73b0\u5d4c\u5165\u5411\u91cf\u7684\u7ed3\u6784\u5316\u5206\u89e3\u3002  \n\u25c6 \u63d0\u51fa\u4e00\u79cd\u76d1\u7763\u5f0f\u5b57\u5178\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u5d4c\u5165\u5411\u91cf\u5206\u89e3\u4e3a\u591a\u4e2a\u6982\u5ff5\u7279\u5b9a\u7684\u6210\u5206\uff0c\u6bcf\u4e2a\u6210\u5206\u7531\u5b57\u5178\u4e2d\u4e00\u7ec4\u7a00\u758f\u975e\u8d1f\u7684\u539f\u5b50\u5411\u91cf\u7ebf\u6027\u7ec4\u5408\u800c\u6210\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\uff0c\u4fdd\u8bc1\u6536\u655b\u6027\uff0c\u5e76\u80fd\u5b66\u4e60\u5177\u6709\u5206\u7ec4\u7ed3\u6784\u7684\u5b57\u5178\uff0c\u5176\u7ec4\u6d3b\u52a8\u4e0e\u591a\u6807\u7b7e\u4fe1\u606f\u5339\u914d\u3002  \n\u25c6 \u5229\u7528\u6587\u672c\u5171\u5d4c\u5165\u7279\u6027\uff0c\u5b9e\u73b0\u65e0\u76d1\u7763\u5b57\u5178\u5b66\u4e60\uff1a\u901a\u8fc7\u6982\u5ff5\u6807\u7b7e\u7684\u6587\u672c\u5d4c\u5165\u8fdb\u884c\u96f6\u6837\u672c\u5206\u7c7b\uff0c\u81ea\u52a8\u751f\u6210\u5b9e\u4f8b\u7ea7\u591a\u6807\u7b7e\u3002  \n\u25c6 \u80fd\u591f\u4e3a\u6bcf\u4e2a\u6982\u5ff5\u5b50\u7a7a\u95f4\u627e\u5230\u8bed\u4e49\u660e\u786e\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002  \n\u8be5\u65b9\u6cd5\u5728\u6982\u5ff5\u8fc7\u6ee4\u56fe\u50cf\u68c0\u7d22\u548c\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8eCLIP\u3001TiTok\u548cDINOv2\u7b49\u591a\u79cd\u5d4c\u5165\u7a7a\u95f4\u3002|\n",
    "2508.20209": "|2025-08-27|Low-exposure, high-quality multimodal speckle X-ray imaging via an intrinsic gradient-flow approach|Jayvan Liu\u7b49|[2508.20209](http://arxiv.org/pdf/2508.20209)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u6d41\u65b9\u6cd5\u7684\u65b0\u578b\u591a\u6a21\u6001\u6563\u6591X\u5c04\u7ebf\u6210\u50cf\u6280\u672f\u3002\u5176\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u5f00\u53d1\u4e86\u68af\u5ea6\u6d41MIST\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6210\u50cf\u6027\u80fd\u548c\u6570\u636e\u6548\u7387\u3002  \n\u25c6 \u9996\u6b21\u5c06\u68af\u5ea6\u6d41\u65b9\u6cd5\u5f15\u5165\u6563\u6591\u6210\u50cf\u9886\u57df\uff0c\u901a\u8fc7\u6c42\u89e3\u798f\u514b-\u666e\u6717\u514b\u65b9\u7a0b\u540c\u6b65\u83b7\u53d6\u8870\u51cf\u3001\u76f8\u79fb\u548c\u6697\u573a\u4e09\u79cd\u4e92\u8865\u6210\u50cf\u6a21\u5f0f  \n\u25c6 \u5927\u5e45\u51cf\u5c11\u6210\u50cf\u6240\u9700\u6570\u636e\u91cf\uff0c\u964d\u4f4e\u5b9e\u9a8c\u4e2d\u5bf9\u66dd\u5149\u91cf\u548c\u91c7\u6837\u6570\u91cf\u7684\u8981\u6c42  \n\u25c6 \u5728\u4fdd\u6301X\u5c04\u7ebf\u798f\u514b-\u666e\u6717\u514b\u65b9\u7a0b\u5b8c\u6574\u901a\u7528\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u7a81\u7834\u4f20\u7edf\u7b97\u6cd5\u7684\u5c40\u9650\u6027  \n\u25c6 \u663e\u8457\u63d0\u5347\u6697\u573a\u56fe\u50cf\u8d28\u91cf\uff0c\u80fd\u6709\u6548\u663e\u793a\u4f4e\u4e8e\u7a7a\u95f4\u5206\u8fa8\u7387\u7684\u4e9a\u50cf\u7d20\u7ed3\u6784\u4fe1\u606f  \n\u25c6 \u901a\u8fc7\u6fb3\u5927\u5229\u4e9a\u540c\u6b65\u8f90\u5c04\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u76f8\u4f4d\u886c\u5ea6\u548c\u6697\u573a\u6210\u50cf\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u7b80\u5316\u5b9e\u9a8c\u6d41\u7a0b\u7684\u573a\u666f\u3002|\n",
    "2508.20188": "|2025-08-27|Grounding Multimodal Large Language Models with Quantitative Skin Attributes: A Retrieval Study|Max Torop\u7b49|[2508.20188](http://arxiv.org/pdf/2508.20188)|\u65e0|\u8be5\u8bba\u6587\u63a2\u7d22\u4e86\u5982\u4f55\u5229\u7528\u5b9a\u91cf\u76ae\u80a4\u5c5e\u6027\u63d0\u5347\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u76ae\u80a4\u75be\u75c5\u8bca\u65ad\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u4e0e\u5b9a\u91cf\u76ae\u80a4\u5c5e\u6027\uff08\u5982\u75c5\u7076\u9762\u79ef\uff09\u76f8\u7ed3\u5408\uff0c\u4ee5\u589e\u5f3a\u8bca\u65ad\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\u3002  \n\u25c6 \u63d0\u51fa\u901a\u8fc7\u5fae\u8c03MLLMs\uff0c\u4f7f\u5176\u80fd\u591f\u4ece\u76ae\u80a4\u56fe\u50cf\u4e2d\u9884\u6d4b\u8fd9\u4e9b\u5b9a\u91cf\u5c5e\u6027\u503c\uff0c\u4ece\u800c\u5b9e\u73b0\u6a21\u578b\u5d4c\u5165\u7a7a\u95f4\u4e0e\u4e34\u5e8a\u5c5e\u6027\u7684\u5bf9\u9f50\u3002  \n\u25c6 \u91c7\u7528\u57fa\u4e8e\u5185\u5bb9\u7684\u56fe\u50cf\u68c0\u7d22\u65b9\u6cd5\uff0c\u5728SLICE-3D\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5d4c\u5165\u7a7a\u95f4\u4e0e\u5c5e\u6027\u4e4b\u95f4\u7684\u5173\u8054\u6027\u3002  \n\u25c6 \u4e3a\u6a21\u578b\u8bca\u65ad\u7ed3\u679c\u63d0\u4f9b\u4e86\u53ef\u91cf\u5316\u7684\u89c6\u89c9\u4f9d\u636e\uff0c\u4f7f\u6a21\u578b\u8f93\u51fa\u66f4\u5177\u53ef\u4fe1\u5ea6\u548c\u4ea4\u4e92\u6027\u3002  \n\u8fd9\u4e00\u7814\u7a76\u4e3a\u6784\u5efa\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u533b\u7597\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u548c\u65b9\u6cd5\u57fa\u7840\u3002|\n",
    "2508.21539": "|2025-08-29|HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones|Hao Ruan\u7b49|[2508.21539](http://arxiv.org/pdf/2508.21539)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u81ea\u7136\u8bed\u8a00\u5f15\u5bfc\u65e0\u4eba\u673a\u4efb\u52a1\u4e2d\u7684\u590d\u6742\u89c6\u89c9-\u8bed\u8a00\u7406\u89e3\u6311\u6218\uff0c\u63d0\u51fa\u4e86HCCM\u5206\u5c42\u8de8\u7c92\u5ea6\u5bf9\u6bd4\u4e0e\u5339\u914d\u5b66\u4e60\u6846\u67b6\u3002\u5176\u6838\u5fc3\u521b\u65b0\u5982\u4e0b\uff1a\n\u25c6 \u63d0\u51fa\u533a\u57df-\u5168\u5c40\u56fe\u50cf\u6587\u672c\u5bf9\u6bd4\u5b66\u4e60\uff08RG-ITC\uff09\uff0c\u65e0\u9700\u7cbe\u786e\u573a\u666f\u5212\u5206\u5373\u53ef\u6355\u83b7\u4ece\u5c40\u90e8\u5230\u5168\u5c40\u7684\u5206\u5c42\u8bed\u4e49\u5bf9\u9f50\uff1b\n\u25c6 \u8bbe\u8ba1\u533a\u57df-\u5168\u5c40\u56fe\u50cf\u6587\u672c\u5339\u914d\uff08RG-ITM\uff09\uff0c\u901a\u8fc7\u8bc4\u4f30\u5168\u5c40\u8de8\u6a21\u6001\u8868\u5f81\u4e2d\u7684\u5c40\u90e8\u8bed\u4e49\u4e00\u81f4\u6027\u6765\u589e\u5f3a\u7ec4\u5408\u63a8\u7406\u80fd\u529b\uff1b\n\u25c6 \u5f15\u5165\u52a8\u91cf\u5bf9\u6bd4\u4e0e\u84b8\u998f\u673a\u5236\uff08MCD\uff09\uff0c\u6709\u6548\u7f13\u89e3\u65e0\u4eba\u673a\u6587\u672c\u63cf\u8ff0\u4e0d\u5b8c\u6574\u6216\u6a21\u7cca\u5e26\u6765\u7684\u5bf9\u9f50\u4e0d\u7a33\u5b9a\u95ee\u9898\uff1b\n\u25c6 \u5728GeoText-1652\u548cERA\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u68c0\u7d22\u7cbe\u5ea6\u7a81\u7834\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u5c55\u73b0\u5f3a\u5927\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002|\n",
    "2509.02129": "|2025-09-02|Scale, Don't Fine-tune: Guiding Multimodal LLMs for Efficient Visual Place Recognition at Test-Time|Jintao Cheng\u7b49|[2509.02129](http://arxiv.org/pdf/2509.02129)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u7684\u96f6\u6837\u672c\u65b0\u6846\u67b6\uff0c\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u4e14\u5f3a\u5927\u7684\u8de8\u57df\u8bc6\u522b\u3002\u5176\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u63d0\u51fa\u6d4b\u8bd5\u65f6\u7f29\u653e\uff08TTS\uff09\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLM\uff09\u7684\u89c6\u89c9-\u8bed\u8a00\u5bf9\u9f50\u80fd\u529b\uff0c\u901a\u8fc7\u57fa\u4e8e\u5f15\u5bfc\u7684\u65b9\u6cd5\u76f4\u63a5\u8fdb\u884c\u76f8\u4f3c\u6027\u8bc4\u5206\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u5fae\u8c03\u7684\u9ad8\u8ba1\u7b97\u5f00\u9500\u3002\n\u25c6 \u91c7\u7528\u7ed3\u6784\u5316\u63d0\u793a\u751f\u6210\u957f\u5ea6\u53ef\u63a7\u7684JSON\u8f93\u51fa\uff0c\u6d88\u9664\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u590d\u6742\u7684\u591a\u9636\u6bb5\u5904\u7406\u6d41\u7a0b\uff0c\u7b80\u5316\u4e86\u6d41\u7a0b\u3002\n\u25c6 \u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u81ea\u4e00\u81f4\u6027\uff08UASC\uff09\u673a\u5236\uff0c\u4f7f\u6a21\u578b\u80fd\u5728\u6d4b\u8bd5\u65f6\u8fdb\u884c\u5b9e\u65f6\u81ea\u9002\u5e94\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6210\u672c\uff0c\u63d0\u5347\u4e86\u5b9e\u65f6\u6027\u3002\n\u25c6 \u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u8de8\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u591a\u79cd\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u4e86\u9ad8\u8fbe210\u500d\u3002\n\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6781\u5927\u63d0\u5347\u4e86\u6548\u7387\u4e0e\u9002\u5e94\u6027\u3002|\n",
    "2509.01968": "|2025-09-02|Ensemble-Based Event Camera Place Recognition Under Varying Illumination|Therese Joseph\u7b49|[2509.01968](http://arxiv.org/pdf/2509.01968)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u5f0f\u4e8b\u4ef6\u76f8\u673a\u5730\u70b9\u8bc6\u522b\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u5267\u70c8\u5149\u7167\u53d8\u5316\u4e0b\u7684\u73af\u5883\u9c81\u68d2\u6027\u3002  \n\u25c6 \u91c7\u7528\u591a\u4e8b\u4ef6\u91cd\u5efa\u3001\u591a\u7279\u5f81\u63d0\u53d6\u4e0e\u591a\u65f6\u5e8f\u5206\u8fa8\u7387\u7684\u96c6\u6210\u878d\u5408\u7b56\u7565\uff0c\u7a81\u7834\u4e86\u4ee5\u5f80\u4ec5\u878d\u5408\u65f6\u5e8f\u4fe1\u606f\u7684\u5c40\u9650\u3002  \n\u25c6 \u5728\u8de8\u65e5-\u591c\u5149\u7167\u53d8\u5316\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86Recall@1\u6307\u680757%\u7684\u76f8\u5bf9\u63d0\u5347\uff0c\u8868\u73b0\u51fa\u6781\u5f3a\u7684\u5149\u7167\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5728\u957f\u8fbe8\u516c\u91cc\u7684\u5b9e\u9645\u9a7e\u9a76\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\uff0c\u672a\u8fdb\u884c\u964d\u91c7\u6837\uff0c\u4fdd\u7559\u4e86\u771f\u5b9e\u4e8b\u4ef6\u5bc6\u5ea6\u53d8\u5316\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u5bf9\u5e8f\u5217\u5339\u914d\u6846\u67b6\u7684\u6539\u8fdb\uff0c\u6709\u6548\u63d0\u5347\u4e86\u957f\u5e8f\u5217\u4e0b\u7684\u8bc6\u522b\u6027\u80fd\u3002  \n\u25c6 \u7cfb\u7edf\u5206\u6790\u4e86\u4e8b\u4ef6\u8868\u5f81\u3001\u91cd\u5efa\u65b9\u6cd5\u548c\u7279\u5f81\u63d0\u53d6\u7b49\u5173\u952e\u8bbe\u8ba1\u9009\u9879\u7684\u5f71\u54cd\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002|\n",
    "2509.01360": "|2025-09-01|M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision|Che Liu\u7b49|[2509.01360](http://arxiv.org/pdf/2509.01360)|\u65e0|M3Ret\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u81ea\u76d1\u7763\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u533b\u5b66\u56fe\u50cf\u68c0\u7d22\u7684\u788e\u7247\u5316\u95ee\u9898\u3002\u5176\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u6df7\u5408\u6a21\u6001\u533b\u5b66\u6570\u636e\u96c6\uff0c\u5305\u542b86\u4e07\u4f59\u6837\u672c\uff0c\u6db5\u76d62D\u30013D\u53ca\u89c6\u9891\u6570\u636e\n\u25c6\u9996\u6b21\u5728\u4e0d\u4f7f\u7528\u4efb\u4f55\u6a21\u6001\u5b9a\u5236\u5316\u8bbe\u8ba1\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u7edf\u4e00\u7684\u591a\u6a21\u6001\u89c6\u89c9\u7f16\u7801\u5668\n\u25c6\u878d\u5408\u751f\u6210\u5f0f(MAE)\u4e0e\u5bf9\u6bd4\u5f0f(SimDINO)\u81ea\u76d1\u7763\u5b66\u4e60\u8303\u5f0f\uff0c\u5b66\u4e60\u53ef\u8fc1\u79fb\u7684\u89c6\u89c9\u8868\u793a\n\u25c6\u5728\u96f6\u6837\u672c\u68c0\u7d22\u4efb\u52a1\u4e0a\u5168\u9762\u8d85\u8d8aDINOv3\u548cBMC-CLIP\u7b49\u5f3a\u57fa\u7ebf\u6a21\u578b\n\u25c6\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u6a21\u6001\u5bf9\u9f50\u80fd\u529b\uff0c\u65e0\u9700\u914d\u5bf9\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u8de8\u6a21\u6001\u68c0\u7d22\n\u25c6\u9996\u6b21\u8bc1\u660e\u7eaf\u89c6\u89c9\u81ea\u76d1\u7763\u5b66\u4e60\u53ef\u6cdb\u5316\u81f3\u672a\u89c1\u6a21\u6001\uff08\u5982\u672a\u8bad\u7ec3\u7684MRI\u6570\u636e\uff09\uff0c\u4e3a\u533b\u5b66\u57fa\u7840\u6a21\u578b\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411|\n",
    "2509.01259": "|2025-09-01|ReCap: Event-Aware Image Captioning with Article Retrieval and Semantic Gaussian Normalization|Thinh-Phuc Nguyen\u7b49|[2509.01259](http://arxiv.org/pdf/2509.01259)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86ReCap\u7cfb\u7edf\uff0c\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u56fe\u50cf\u63cf\u8ff0\u751f\u6210\u65e0\u6cd5\u6355\u6349\u4e8b\u4ef6\u7ea7\u8bed\u4e49\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6574\u5408\u76f8\u5173\u6587\u7ae0\u4e2d\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u751f\u6210\u53d9\u4e8b\u4e30\u5bcc\u4e14\u4e8b\u5b9e\u51c6\u786e\u7684\u63cf\u8ff0\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u6587\u7ae0\u68c0\u7d22\u7cfb\u7edf\uff0c\u7ed3\u5408DINOv2\u5168\u5c40\u7279\u5f81\u76f8\u4f3c\u5ea6\u521d\u9009\u548c\u5c40\u90e8\u5757\u4e92\u8fd1\u90bb\u76f8\u4f3c\u5ea6\u91cd\u6392\u5e8f\uff0c\u63d0\u5347\u4e8b\u4ef6\u76f8\u5173\u6587\u7ae0\u7684\u68c0\u7d22\u7cbe\u5ea6\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u4e0a\u4e0b\u6587\u63d0\u53d6\u6846\u67b6\uff0c\u7efc\u5408\u6587\u7ae0\u6458\u8981\u3001\u901a\u7528\u63cf\u8ff0\u548c\u6e90\u6570\u636e\u4fe1\u606f\uff0c\u4e3a\u751f\u6210\u63cf\u8ff0\u63d0\u4f9b\u591a\u7ef4\u5ea6\u8bed\u4e49\u652f\u6301\u3002  \n\u25c6 \u5f15\u5165\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63cf\u8ff0\u751f\u6210\u673a\u5236\uff0c\u5e76\u91c7\u7528\u8bed\u4e49\u9ad8\u65af\u5f52\u4e00\u5316\u6280\u672f\uff0c\u589e\u5f3a\u751f\u6210\u6587\u672c\u7684\u6d41\u7545\u6027\u548c\u76f8\u5173\u6027\u3002  \n\u5728EVENTA 2025\u6311\u6218\u8d5b\u4e2d\uff0cReCap\u5728OpenEvents V1\u6570\u636e\u96c6\u4e0a\u53d6\u5f970.54666\u7684\u7efc\u5408\u8bc4\u5206\uff0c\u6392\u540d\u7b2c\u4e8c\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002  \n\u8be5\u7cfb\u7edf\u4e3a\u65b0\u95fb\u5b58\u6863\u7b49\u9ad8\u8981\u6c42\u9886\u57df\u63d0\u4f9b\u4e86\u89c6\u89c9\u611f\u77e5\u4e0e\u771f\u5b9e\u4e16\u754c\u77e5\u8bc6\u878d\u5408\u7684\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2509.00798": "|2025-09-03|Multimodal Iterative RAG for Knowledge Visual Question Answering|Changin Choi\u7b49|[2509.00798](http://arxiv.org/pdf/2509.00798)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86MI-RAG\uff0c\u4e00\u4e2a\u591a\u6a21\u6001\u8fed\u4ee3\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u77e5\u8bc6\u5bc6\u96c6\u578b\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u3002\u5176\u6838\u5fc3\u521b\u65b0\u70b9\u5728\u4e8e\uff1a\n\n\u25c6 \u91c7\u7528\u8fed\u4ee3\u5f0f\u68c0\u7d22-\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8f6e\u8fed\u4ee3\u9010\u6b65\u5b8c\u5584\u5916\u90e8\u77e5\u8bc6\u7684\u83b7\u53d6\u4e0e\u7406\u89e3\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5355\u6b21\u68c0\u7d22\u77e5\u8bc6\u4e0d\u8db3\u7684\u5c40\u9650\u3002\n\n\u25c6 \u5229\u7528\u7d2f\u79ef\u7684\u63a8\u7406\u8bb0\u5f55\u52a8\u6001\u751f\u6210\u591a\u67e5\u8be2\uff0c\u9a71\u52a8\u5bf9\u5305\u542b\u89c6\u89c9\u548c\u6587\u672c\u4fe1\u606f\u7684\u5f02\u6784\u77e5\u8bc6\u5e93\u8fdb\u884c\u8054\u5408\u641c\u7d22\u3002\n\n\u25c6 \u5b9e\u73b0\u4e86\u8de8\u6a21\u6001\u7684\u77e5\u8bc6\u878d\u5408\u4e0e\u63a8\u7406\u66f4\u65b0\uff0c\u5c06\u65b0\u68c0\u7d22\u5230\u7684\u77e5\u8bc6\u5408\u6210\u5230\u63a8\u7406\u8bb0\u5f55\u4e2d\uff0c\u8fdb\u884c\u6e10\u8fdb\u5f0f\u7684\u7cbe\u5316\u7406\u89e3\u3002\n\n\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6311\u6218\u6027\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u53ec\u56de\u7387\u548c\u7b54\u6848\u51c6\u786e\u7387\uff0c\u4e3a\u77e5\u8bc6\u5bc6\u96c6\u578b\u89c6\u89c9\u95ee\u7b54\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u7ec4\u5408\u63a8\u7406\u65b9\u6848\u3002|\n",
    "2509.00752": "|2025-08-31|Multi-Level CLS Token Fusion for Contrastive Learning in Endoscopy Image Classification|Y Hop Nguyen\u7b49|[2509.00752](http://arxiv.org/pdf/2509.00752)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u5185\u7aa5\u955c\u56fe\u50cf\u5206\u6790\u7684\u7edf\u4e00\u89c6\u89c9-\u8bed\u8a00\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u73b0\u4e09\u7c7b\u4e34\u5e8a\u4efb\u52a1\u7684\u9ad8\u6548\u534f\u540c\u5904\u7406\u3002  \n\u25c6 \u91c7\u7528CLIP ViT-B/16\u4e3b\u5e72\u7f51\u7edc\u5e76\u5f15\u5165\u4f4e\u79e9\u81ea\u9002\u5e94\uff08LoRA\uff09\u6280\u672f\uff0c\u5b9e\u73b0\u6709\u9650\u533b\u7597\u6570\u636e\u4e0b\u7684\u9ad8\u6548\u5fae\u8c03\u3002  \n\u25c6 \u63d0\u51fa\u591a\u7ea7CLS\u4ee4\u724c\u805a\u5408\u673a\u5236\uff0c\u589e\u5f3a\u89c6\u89c9\u7279\u5f81\u7684\u591a\u6837\u6027\u548c\u8868\u5f81\u80fd\u529b\u3002  \n\u25c6 \u8bbe\u8ba1\u7403\u9762\u7279\u5f81\u63d2\u503c\u65b9\u6cd5\uff0c\u4f18\u5316\u8de8\u6a21\u6001\u8bed\u4e49\u5bf9\u9f50\u6548\u679c\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u7c7b\u522b\u7279\u5b9a\u7684\u81ea\u7136\u8bed\u8a00\u63d0\u793a\uff0c\u5c06\u8bca\u65ad\u6587\u672c\u4e0a\u4e0b\u6587\u4e0e\u89c6\u89c9\u7279\u5f81\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u76d1\u7763\u5206\u7c7b\u8054\u5408\u8bad\u7ec3\u76ee\u6807\u8fdb\u884c\u878d\u5408\u3002  \n\u8be5\u6846\u67b6\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8fbe\u5230S\u6027\u80fd\uff08\u5206\u7c7b\u51c6\u786e\u738795%\uff0c\u68c0\u7d22Recall@1\u8d850.92\uff09\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5404\u6a21\u5757\u7684\u6709\u6548\u6027\uff0c\u4e3a\u4f4e\u8d44\u6e90\u533b\u7597\u573a\u666f\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u591a\u6a21\u6001\u7406\u89e3\u65b9\u6848\u3002|\n",
    "2509.00751": "|2025-08-31|EVENT-Retriever: Event-Aware Multimodal Image Retrieval for Realistic Captions|Dinh-Khoi Vo\u7b49|[2509.00751](http://arxiv.org/pdf/2509.00751)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9762\u5411\u590d\u6742\u4e8b\u4ef6\u63cf\u8ff0\u7684\u591a\u6a21\u6001\u56fe\u50cf\u68c0\u7d22\u7cfb\u7edfEVENT-Retriever\uff0c\u5176\u6838\u5fc3\u521b\u65b0\u5728\u4e8e\u901a\u8fc7\u591a\u9636\u6bb5\u6846\u67b6\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5bf9\u9690\u542b\u4e8b\u4ef6\u8bed\u4e49\u548c\u957f\u6587\u672c\u63cf\u8ff0\u7684\u68c0\u7d22\u74f6\u9888\u3002  \n\u25c6 \u7ed3\u5408\u5bc6\u96c6\u6587\u6863\u68c0\u7d22\u3001\u4e8b\u4ef6\u611f\u77e5\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\u548c\u9ad8\u6548\u56fe\u50cf\u6536\u96c6\u7684\u591a\u9636\u6bb5\u68c0\u7d22\u67b6\u6784  \n\u25c6 \u5229\u7528Qwen3\u7cfb\u5217\u6a21\u578b\u5b9e\u73b0\u6587\u7ae0\u641c\u7d22\u3001\u4e0a\u4e0b\u6587\u5bf9\u9f50\u548c\u7cbe\u51c6\u56fe\u50cf\u8bc4\u5206\u7684\u5206\u5c42\u5904\u7406  \n\u25c6 \u5f15\u5165\u57fa\u4e8e\u6807\u9898\u7684\u8bed\u4e49\u5339\u914d\u4e0e\u6392\u5e8f\u611f\u77e5\u9009\u62e9\u673a\u5236\u589e\u5f3a\u4e8b\u4ef6\u5173\u8054\u6027  \n\u25c6 \u91c7\u7528 Reciprocal Rank Fusion \u878d\u5408\u591a\u914d\u7f6e\u8f93\u51fa\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027  \n\u8be5\u7cfb\u7edf\u5728EVENTA 2025\u6311\u6218\u8d5bTrack 2\u79c1\u6709\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97\u7b2c\u4e00\u540d\uff0c\u8bc1\u660e\u4e86\u8bed\u8a00\u63a8\u7406\u4e0e\u591a\u6a21\u6001\u68c0\u7d22\u7ed3\u5408\u5bf9\u590d\u6742\u73b0\u5b9e\u56fe\u50cf\u7406\u89e3\u7684\u6709\u6548\u6027\u3002|\n",
    "2509.00177": "|2025-08-29|Category-level Text-to-Image Retrieval Improved: Bridging the Domain Gap with Diffusion Models and Vision Encoders|Faizan Farooq Khan\u7b49|[2509.00177](http://arxiv.org/pdf/2509.00177)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u7c7b\u522b\u7ea7\u6587\u672c-\u56fe\u50cf\u68c0\u7d22\u4efb\u52a1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u6a21\u6001\u5dee\u5f02\u7684\u521b\u65b0\u65b9\u6cd5\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u878d\u5408\u751f\u6210\u6a21\u578b\u4e0e\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8de8\u6a21\u6001\u68c0\u7d22\u6027\u80fd\u3002\n\n\u25c6 \u63d0\u51fa\u4e24\u9636\u6bb5\u68c0\u7d22\u6846\u67b6\uff1a\u9996\u5148\u751f\u6210\u6a21\u578b\u5c06\u6587\u672c\u67e5\u8be2\u8f6c\u6362\u4e3a\u89c6\u89c9\u67e5\u8be2\uff0c\u518d\u7528\u89c6\u89c9\u6a21\u578b\u8ba1\u7b97\u56fe\u50cf\u95f4\u76f8\u4f3c\u5ea6\u3002\n\u25c6 \u5229\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u9ad8\u8d28\u91cf\u56fe\u50cf\uff0c\u5c06\u6587\u672c\u6a21\u6001\u8f6c\u5316\u4e3a\u89c6\u89c9\u6a21\u6001\uff0c\u6709\u6548\u7f29\u5c0f\u6587\u672c\u4e0e\u56fe\u50cf\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u5dee\u8ddd\u3002\n\u25c6 \u8bbe\u8ba1\u805a\u5408\u7f51\u7edc\u6574\u5408\u591a\u4e2a\u751f\u6210\u56fe\u50cf\u7684\u5411\u91cf\u8868\u793a\uff0c\u5f62\u6210\u5355\u4e00\u4e14\u9c81\u68d2\u7684\u67e5\u8be2\u8868\u5f81\u3002\n\u25c6 \u521b\u65b0\u6027\u5730\u878d\u5408\u6587\u672c\u548c\u751f\u6210\u56fe\u50cf\u53cc\u6a21\u6001\u7684\u76f8\u4f3c\u5ea6\u8bc4\u5206\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u68c0\u7d22\u7cbe\u5ea6\u3002\n\u8be5\u65b9\u6cd5\u7efc\u5408\u8fd0\u7528\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u3001\u6269\u6563\u751f\u6210\u6a21\u578b\u548c\u89c6\u89c9\u7f16\u7801\u5668\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u4e2d\u663e\u8457\u4f18\u4e8e\u4ec5\u4f9d\u8d56\u6587\u672c\u67e5\u8be2\u7684\u68c0\u7d22\u65b9\u6cd5\u3002|\n",
    "2509.04351": "|2025-09-05|Global-to-Local or Local-to-Global? Enhancing Image Retrieval with Efficient Local Search and Effective Global Re-ranking|Dror Aiger\u7b49|[2509.04351](http://arxiv.org/pdf/2509.04351)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e0e\u4e3b\u6d41\u76f8\u53cd\u7684\u201c\u5c40\u90e8\u5230\u5168\u5c40\u201d\u56fe\u50cf\u68c0\u7d22\u65b0\u8303\u5f0f\uff0c\u53d6\u4ee3\u4e86\u4f20\u7edf\u7684\u201c\u5168\u5c40\u5230\u5c40\u90e8\u201d\u65b9\u6cd5\u3002  \n\u25c6 \u5229\u7528\u65b0\u5174\u7684\u9ad8\u6548\u5c40\u90e8\u7279\u5f81\u641c\u7d22\u6280\u672f\uff0c\u9996\u5148\u8fdb\u884c\u5927\u89c4\u6a21\u7cbe\u7ec6\u7684\u5c40\u90e8\u5339\u914d\uff0c\u4ee5\u627e\u5230\u5168\u5c40\u7279\u5f81\u5bb9\u6613\u9057\u6f0f\u7684\u5c40\u90e8\u76f8\u4f3c\u56fe\u50cf\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u68c0\u7d22\u76f8\u4f3c\u6027\u7684\u5168\u5c40\u7279\u5f81\u5373\u65f6\u91cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u5728\u91cd\u6392\u5e8f\u9636\u6bb5\u624d\u52a8\u6001\u751f\u6210\u5168\u5c40\u7279\u5f81\u3002  \n\u25c6 \u91c7\u7528\u591a\u7ef4\u7f29\u653e\u6280\u672f\uff0c\u5c06\u5c40\u90e8\u7279\u5f81\u68c0\u7d22\u83b7\u5f97\u7684\u76f8\u4f3c\u6027\u5173\u7cfb\u5d4c\u5165\u5230\u5168\u5c40\u7279\u5f81\u8868\u793a\u4e2d\uff0c\u4f7f\u5168\u5c40\u7279\u5f81\u80fd\u591f\u5c0a\u91cd\u5c40\u90e8\u5339\u914d\u7684\u7ed3\u679c\u3002  \n\u8fd9\u79cd\u7ed3\u5408\u4f7f\u5f97\u91cd\u6392\u5e8f\u8fc7\u7a0b\u65e2\u4fdd\u6301\u4e86\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u53c8\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u7cbe\u5ea6\u3002  \n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Revisited Oxford\u548cParis\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002|\n",
    "2509.04193": "|2025-09-04|DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval|Ruohong Yang\u7b49|[2509.04193](http://arxiv.org/pdf/2509.04193)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u65e0\u76d1\u7763\u8de8\u57df\u56fe\u50cf\u68c0\u7d22\u65b9\u6cd5DUDE\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u7279\u5f81\u89e3\u8026\u89e3\u51b3\u8de8\u57df\u68c0\u7d22\u4e2d\u5bf9\u8c61\u7279\u5f81\u4e0e\u57df\u98ce\u683c\u7ea0\u7f20\u7684\u96be\u9898\u3002  \n\u25c6 \u5229\u7528\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6a21\u578b\u5b9e\u73b0\u5bf9\u8c61\u7279\u5f81\u4e0e\u57df\u7279\u5b9a\u98ce\u683c\u7684\u89e3\u8026\uff0c\u589e\u5f3a\u8bed\u4e49\u8868\u793a\u7684\u7eaf\u51c0\u6027\u3002  \n\u25c6 \u63d0\u51fa\u6e10\u8fdb\u5f0f\u8de8\u57df\u4e92\u8fd1\u90bb\u5bf9\u9f50\u673a\u5236\uff0c\u901a\u8fc7\u57df\u5185\u5230\u57df\u95f4\u7684\u9010\u6b65\u5bf9\u9f50\u63d0\u5347\u7279\u5f81\u5339\u914d\u53ef\u9760\u6027\u3002  \n\u25c6 \u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08\u6db5\u76d613\u4e2a\u57df\uff09\u4e0a\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\u3002  \n\u8be5\u65b9\u6cd5\u65e0\u9700\u6807\u6ce8\u5373\u53ef\u5b9e\u73b0\u8de8\u57df\u7cbe\u51c6\u68c0\u7d22\uff0c\u4e3a\u65e0\u76d1\u7763\u57df\u9002\u5e94\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2509.04948": "|2025-09-05|Towards an Accurate and Effective Robot Vision (The Problem of Topological Localization for Mobile Robots)|Emanuela Boros|[2509.04948](http://arxiv.org/pdf/2509.04948)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u79fb\u52a8\u673a\u5668\u4eba\u5728\u529e\u516c\u5ba4\u73af\u5883\u4e2d\u7684\u62d3\u6251\u5b9a\u4f4d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u4f9d\u9760\u5355\u76ee\u5f69\u8272\u76f8\u673a\u56fe\u50cf\u3001\u4e0d\u4f9d\u8d56\u65f6\u5e8f\u8fde\u7eed\u6027\u7684\u89c6\u89c9\u5b9a\u4f4d\u65b9\u6cd5\u3002  \n\u25c6 \u7cfb\u7edf\u6027\u5730\u5b9a\u91cf\u6bd4\u8f83\u4e86\u591a\u79cd\u5148\u8fdb\u89c6\u89c9\u63cf\u8ff0\u7b26\uff08\u5982\u989c\u8272\u76f4\u65b9\u56fe\u3001SIFT\u3001ASIFT\u3001RGB-SIFT\u53ca\u8bcd\u888b\u6a21\u578b\uff09\u7684\u6027\u80fd\u3002  \n\u25c6 \u6df1\u5165\u5206\u6790\u4e86\u4e0d\u540c\u7279\u5f81\u63cf\u8ff0\u7b26\u3001\u8ddd\u79bb\u5ea6\u91cf\u65b9\u6cd5\u548c\u5206\u7c7b\u5668\u7684\u7ec4\u5408\u6548\u679c\uff0c\u5e76\u901a\u8fc7\u6807\u51c6\u8bc4\u4f30\u6307\u6807\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\u6269\u5c55\u4e86\u5df2\u6709\u5b9e\u9a8c\u3002  \n\u25c6 \u5728ImageCLEF\u8bc4\u6d4b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6240\u63d0\u914d\u7f6e\u7684\u6709\u6548\u6027\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u65b0\u56fe\u50cf\u5e8f\u5217\u7684\u6700\u53ef\u80fd\u4f4d\u7f6e\u8bc6\u522b\u3002  \n\u8bba\u6587\u4e3a\u5916\u89c2\u63cf\u8ff0\u7b26\u3001\u76f8\u4f3c\u6027\u5ea6\u91cf\u4e0e\u5206\u7c7b\u5668\u7684\u5408\u7406\u914d\u7f6e\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\uff0c\u4e3a\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u5b9e\u65f6\u5b9a\u4f4d\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002|\n",
    "2509.04772": "|2025-09-05|FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph|Zhangding Liu\u7b49|[2509.04772](http://arxiv.org/pdf/2509.04772)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86FloodVision\uff0c\u4e00\u79cd\u7ed3\u5408\u57fa\u7840\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u9886\u57df\u77e5\u8bc6\u56fe\u7684\u96f6\u6837\u672c\u6d2a\u6c34\u6df1\u5ea6\u4f30\u8ba1\u6846\u67b6\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u663e\u8457\u63d0\u5347\u4e86\u57ce\u5e02\u6d2a\u6c34\u6df1\u5ea6\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u5f3a\u5927\u7684\u57fa\u7840\u89c6\u89c9\u8bed\u8a00\u6a21\u578bGPT-4o\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u4e0e\u7ed3\u6784\u5316\u7684\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u6df1\u5ea6\u4f30\u8ba1\u3002\n\u25c6 \u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8f66\u8f86\u3001\u884c\u4eba\u7b49\u5e38\u89c1\u57ce\u5e02\u7269\u4f53\u771f\u5b9e\u5c3a\u5bf8\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u4e3a\u6a21\u578b\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7269\u7406\u73b0\u5b9e\u4f9d\u636e\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5e7b\u89c9\u95ee\u9898\u3002\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u5957\u52a8\u6001\u5904\u7406\u6d41\u7a0b\uff0c\u5305\u62ec\u53c2\u8003\u7269\u4f53\u8bc6\u522b\u3001\u6df9\u6ca1\u6bd4\u4f8b\u4f30\u7b97\u548c\u7edf\u8ba1\u79bb\u7fa4\u503c\u8fc7\u6ee4\uff0c\u4ee5\u8ba1\u7b97\u51fa\u7cbe\u786e\u7684\u6df1\u5ea6\u503c\u3002\n\u25c6 \u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u5176\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u4f4e\u81f38.17\u5398\u7c73\uff0c\u8f83GPT-4o\u57fa\u7ebf\u63d0\u5347\u4e8620.5%\uff0c\u5e76\u8d85\u8d8a\u4e86\u4ee5\u5f80\u7684CNN\u65b9\u6cd5\uff0c\u4e14\u5177\u5907\u8fd1\u5b9e\u65f6\u5904\u7406\u80fd\u529b\u3002|\n",
    "2509.06566": "|2025-09-08|Back To The Drawing Board: Rethinking Scene-Level Sketch-Based Image Retrieval|Emil Demi\u0107\u7b49|[2509.06566](http://arxiv.org/pdf/2509.06566)|\u65e0|\u672c\u6587\u9488\u5bf9\u573a\u666f\u7ea7\u8349\u56fe\u68c0\u7d22\u4efb\u52a1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5f3a\u8c03\u8349\u56fe\u56fa\u6709\u6a21\u7cca\u6027\u548c\u566a\u58f0\u7684\u9c81\u68d2\u6027\u8bad\u7ec3\u65b9\u6848\u3002\u5176\u6838\u5fc3\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u91cd\u65b0\u5ba1\u89c6\u4e86\u573a\u666f\u7ea7\u8349\u56fe\u68c0\u7d22\u95ee\u9898\uff0c\u5f3a\u8c03\u771f\u5b9e\u624b\u7ed8\u8349\u56fe\u7684\u6a21\u7cca\u6027\u548c\u566a\u58f0\u7279\u6027\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u6a21\u578b\u7ed3\u6784\u6539\u8fdb\u3002\n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u663e\u5f0f\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u4e13\u95e8\u9488\u5bf9\u8349\u56fe\u7684\u9ad8\u53d8\u5f02\u6027\u8fdb\u884c\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002\n\u25c6 \u901a\u8fc7\u7ed3\u5408\u9002\u5f53\u7684\u9884\u8bad\u7ec3\u7b56\u7565\u3001\u7f16\u7801\u5668\u67b6\u6784\u548c\u635f\u5931\u51fd\u6570\uff0c\u5728\u4e0d\u589e\u52a0\u6a21\u578b\u590d\u6742\u5ea6\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\n\u25c6 \u5728FS-COCO\u548cSketchyCOCO\u7b49\u6311\u6218\u6027\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u8bad\u7ec3\u8bbe\u8ba1\u5728\u8de8\u6a21\u6001\u68c0\u7d22\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002\n\u25c6 \u6307\u51fa\u4e86\u6539\u8fdb\u573a\u666f\u7ea7\u8349\u56fe\u68c0\u7d22\u8bc4\u4f30\u573a\u666f\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002|\n",
    "2509.07362": "|2025-09-09|Aerial-ground Cross-modal Localization: Dataset, Ground-truth, and Benchmark|Yandi Yang\u7b49|[2509.07362](http://arxiv.org/pdf/2509.07362)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u6784\u5efa\u4e86\u4e00\u4e2a\u89e3\u51b3\u7a7a\u5730\u8de8\u6a21\u6001\u5b9a\u4f4d\u6311\u6218\u7684\u7efc\u5408\u57fa\u51c6\u3002\u5176\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u521b\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u5927\u89c4\u6a21\u7a7a\u5730\u8de8\u6a21\u6001\u6570\u636e\u96c6\uff0c\u96c6\u6210\u4e86\u6765\u81ea\u79fb\u52a8\u6d4b\u91cf\u7cfb\u7edf\u7684\u5730\u9762\u56fe\u50cf\u548c\u4e09\u4e2a\u57ce\u5e02\uff08\u6b66\u6c49\u3001\u9999\u6e2f\u3001\u65e7\u91d1\u5c71\uff09\u7684\u673a\u8f7d\u6fc0\u5149\u626b\u63cf\u70b9\u4e91\u3002\n\u25c6 \u89e3\u51b3\u4e86\u8be5\u9886\u57df\u5e73\u53f0\u591a\u6837\u5316\u6570\u636e\u7f3a\u4e4f\u7684\u95ee\u9898\uff0c\u4e3a\u7b97\u6cd5\u5f00\u53d1\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6570\u636e\u57fa\u7840\u3002\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u57ce\u5e02\u573a\u666f\u7684\u53ef\u9760\u5730\u9762\u771f\u503c\u751f\u6210\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4ee5\u5f80\u8be5\u73af\u8282\u7684\u7f3a\u5931\u95ee\u9898\u3002\n\u25c6 \u9996\u6b21\u5728\u7a7a\u5730\u8de8\u5e73\u53f0\u8bbe\u7f6e\u4e0b\u5bf9\u73b0\u6709\u7684\u56fe\u50cf\u5230\u70b9\u4e91\u914d\u51c6\u7b97\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u5176\u6027\u80fd\u3002\n\u25c6 \u4e3a\u63d0\u5347\u5728\u7eb9\u7406\u7f3a\u5931\u3001\u5927\u89c6\u89d2\u53d8\u5316\u7b49\u6311\u6218\u4e0b\u7684\u89c6\u89c9\u5b9a\u4f4d\u7cbe\u5ea6\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\uff0c\u63a8\u52a8\u4e86\u76f8\u5173\u9886\u57df\u7684\u53d1\u5c55\u3002|\n",
    "2509.09306": "|2025-09-11|Listening for \"You\": Enhancing Speech Image Retrieval via Target Speaker Extraction|Wenhao Yang\u7b49|[2509.09306](http://arxiv.org/pdf/2509.09306)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u76ee\u6807\u8bf4\u8bdd\u4eba\u8bed\u97f3-\u56fe\u50cf\u68c0\u7d22\u4efb\u52a1\u53ca\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u8bf4\u8bdd\u4eba\u573a\u666f\u4e0b\u8bed\u97f3\u56fe\u50cf\u68c0\u7d22\u7684\u96be\u9898\u3002  \n\u25c6 \u9996\u6b21\u5f15\u5165\u76ee\u6807\u8bf4\u8bdd\u4eba\u63d0\u53d6\u6280\u672f\uff0c\u4ece\u6df7\u5408\u8bed\u97f3\u4e2d\u5206\u79bb\u5e76\u8bc6\u522b\u76ee\u6807\u8bf4\u8bdd\u4eba\u7684\u6307\u4ee4\u3002  \n\u25c6 \u7ed3\u5408\u81ea\u76d1\u7763\u97f3\u9891\u7f16\u7801\u5668\u548c\u89c6\u89c9\u6a21\u578b\uff0c\u901a\u8fc7\u76ee\u6807\u8bf4\u8bdd\u4eba\u611f\u77e5\u7684\u5bf9\u6bd4\u5b66\u4e60\u8fdb\u884c\u8de8\u6a21\u6001\u5bf9\u9f50\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u7aef\u5230\u7aef\u7684\u8054\u5408\u8bad\u7ec3\u6846\u67b6\uff0c\u5c06\u8bf4\u8bdd\u4eba\u63d0\u53d6\u4e0e\u68c0\u7d22\u4efb\u52a1\u7edf\u4e00\u4f18\u5316\uff0c\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u3002  \n\u5728\u4e8c\u8bf4\u8bdd\u4eba\u548c\u4e09\u8bf4\u8bdd\u4eba\u6df7\u5408\u8bed\u97f3\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u68c0\u7d22\u51c6\u786e\u7387\u63d0\u5347\u660e\u663e\u3002  \n\u8be5\u6280\u672f\u4e3a\u8f85\u52a9\u673a\u5668\u4eba\u548c\u591a\u6a21\u6001\u4ea4\u4e92\u7cfb\u7edf\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2509.11862": "|2025-09-15|Bridging Vision Language Models and Symbolic Grounding for Video Question Answering|Haodi Ma\u7b49|[2509.11862](http://arxiv.org/pdf/2509.11862)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSG-VLM\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u7b26\u53f7\u5316\u573a\u666f\u56fe\u589e\u5f3a\u89c6\u9891\u95ee\u7b54\u4e2d\u7684\u65f6\u7a7a\u4e0e\u56e0\u679c\u63a8\u7406\u80fd\u529b\u3002\n\n\u25c6 \u5f15\u5165\u7b26\u53f7\u5316\u573a\u666f\u56fe\uff08SGs\uff09\u4f5c\u4e3a\u89c6\u9891\u95ee\u7b54\u7684\u4e2d\u95f4 grounding \u4fe1\u53f7\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u5bf9\u8c61-\u5173\u7cfb\u8868\u793a\u4ee5\u8865\u5145\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u6574\u4f53\u63a8\u7406\u3002\n\u25c6 \u63d0\u51faSG-VLM\u6846\u67b6\uff0c\u5c06\u51bb\u7ed3\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u4e0e\u573a\u666f\u56fe grounding \u673a\u5236\u901a\u8fc7\u63d0\u793a\u548c\u89c6\u89c9\u5b9a\u4f4d\u8fdb\u884c\u96c6\u6210\u3002\n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08NExT-QA\u3001iVQA\u3001ActivityNet-QA\uff09\u548c\u4e0d\u540cVLMs\uff08QwenVL\u3001InternVL\uff09\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\n\u25c6 \u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u56e0\u679c\u63a8\u7406\u548c\u65f6\u95f4\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5c24\u5176\u5728\u9700\u8981\u7ec6\u7c92\u5ea6\u65f6\u7a7a\u5173\u7cfb\u7684\u89c6\u9891\u95ee\u7b54\u4e2d\u8868\u73b0\u7a81\u51fa\u3002\n\u25c6 \u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u7b26\u53f7 grounding \u65b9\u6cd5\u7684\u6f5c\u529b\u548c\u5f53\u524d\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u878d\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u7b26\u53f7\u63a8\u7406\u7684\u6df7\u5408\u65b9\u6cd5\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002|\n",
    "2509.11301": "|2025-09-14|UnLoc: Leveraging Depth Uncertainties for Floorplan Localization|Matthias W\u00fcest\u7b49|[2509.11301](http://arxiv.org/pdf/2509.11301)|\u65e0|UnLoc\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u5e8f\u5217\u5316\u76f8\u673a\u5e73\u9762\u56fe\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u6df1\u5ea6\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u4e0e\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u5f15\u5165\u6982\u7387\u5316\u6df1\u5ea6\u9884\u6d4b\u6a21\u578b\uff0c\u5c06\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u7ed3\u679c\u8868\u793a\u4e3a\u663e\u5f0f\u6982\u7387\u5206\u5e03\uff0c\u4ece\u800c\u6709\u6548\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002  \n\u25c6 \u6446\u8131\u5bf9\u6bcf\u573a\u666f\u5b9a\u5236\u6df1\u5ea6\u7f51\u7edc\u7684\u4f9d\u8d56\uff0c\u76f4\u63a5\u5229\u7528\u9884\u8bad\u7ec3\u5355\u76ee\u6df1\u5ea6\u6a21\u578b\uff0c\u5927\u5e45\u63d0\u5347\u65b9\u6cd5\u5728\u672a\u77e5\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u6027\u80fd\u3002  \n\u25c6 \u5728\u957f\u5e8f\u5217\u4e0e\u77ed\u5e8f\u5217\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u5747\u5b9e\u73b0\u7a81\u7834\uff0c\u5728LaMAR HGE\u6570\u636e\u96c6\u4e0a\u957f\u5e8f\u5217\u5b9a\u4f4d\u53ec\u56de\u7387\u63d0\u53472.7\u500d\uff0c\u77ed\u5e8f\u5217\u63d0\u534716.7\u500d\u3002  \n\u25c6 \u901a\u8fc7\u878d\u5408\u6613\u4e8e\u83b7\u53d6\u4e14\u957f\u671f\u7a33\u5b9a\u7684\u5e73\u9762\u56fe\u6570\u636e\uff0c\u514b\u670d\u89c6\u89c9\u5916\u89c2\u53d8\u5316\u5e26\u6765\u7684\u6311\u6218\uff0c\u589e\u5f3a\u7cfb\u7edf\u9c81\u68d2\u6027\u3002  \n\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\uff0c\u4e3a\u89c6\u89c9\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2509.12824": "|2025-09-17|DiffHash: Text-Guided Targeted Attack via Diffusion Models against Deep Hashing Image Retrieval|Zechao Liu\u7b49|[2509.12824](http://arxiv.org/pdf/2509.12824)|\u65e0|\u25c6 Deep hashing models have been widely adopted to tackle the challenges of large-scale image retrieval.\n\u25c6 However, these approaches face serious security risks due to their vulnerability to adversarial examples.\n\u25c6 Despite the increasing exploration of targeted attacks on deep hashing models, existing approaches still suffer from a lack of multimodal guidance, reliance on labeling information and dependence on pixel-level operations for attacks.|\n",
    "2509.14104": "|2025-09-17|CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts|Leonard Hackel\u7b49|[2509.14104](http://arxiv.org/pdf/2509.14104)|\u65e0|\u25c6 Self-supervised learning through masked autoencoders has attracted great attention for remote sensing (RS) foundation model (FM) development, enabling improved representation learning across diverse sensors and downstream tasks.\n\u25c6 However, existing RS FMs often either suffer from substantial computational complexity during both training and inference or exhibit limited representational capacity.\n\u25c6 These issues restrict their practical applicability in RS.|\n",
    "2509.13474": "|2025-09-16|Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization|Yujia Lin\u7b49|[2509.13474](http://arxiv.org/pdf/2509.13474)|\u65e0|\u25c6 Ensuring accurate localization of robots in environments without GPS capability is a challenging task.\n\u25c6 Visual Place Recognition (VPR) techniques can potentially achieve this goal, but existing RGB-based methods are sensitive to changes in illumination, weather, and other seasonal changes.\n\u25c6 Existing cross-modal localization methods leverage the geometric properties of RGB images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.|\n",
    "2509.13414": "|2025-09-18|MapAnything: Universal Feed-Forward Metric 3D Reconstruction|Nikhil Keetha\u7b49|[2509.13414](http://arxiv.org/pdf/2509.13414)|\u65e0|\u25c6 We introduce MapAnything, a unified transformer-based feed-forward model that ingests one or more images along with optional geometric inputs such as camera intrinsics, poses, depth, or partial reconstructions, and then directly regresses the metric 3D scene geometry and cameras.\n\u25c6 MapAnything leverages a factored representation of multi-view scene geometry, i.e., a collection of depth maps, local ray maps, camera poses, and a metric scale factor that effectively upgrades local reconstructions into a globally consistent metric frame.\n\u25c6 Standardizing the supervision and training across diverse datasets, along with flexible input augmentation, enables MapAnything to address a broad range of 3D vision tasks in a single feed-forward pass, including uncalibrated structure-from-motion, calibrated multi-view stereo, monocular depth estimation, camera localization, depth completion, and more.|\n",
    "2509.14985": "|2025-09-18|PRISM: Product Retrieval In Shopping Carts using Hybrid Matching|Arda Kabadayi\u7b49|[2509.14985](http://arxiv.org/pdf/2509.14985)|\u65e0|\u25c6 Compared to traditional image retrieval tasks, product retrieval in retail settings is even more challenging.\n\u25c6 Products of the same type from different brands may have highly similar visual appearances, and the query image may be taken from an angle that differs significantly from view angles of the stored catalog images.\n\u25c6 Foundational models, such as CLIP and SigLIP, often struggle to distinguish these subtle but important local differences.|\n",
    "2509.14746": "|2025-09-18|Chain-of-Thought Re-ranking for Image Retrieval Tasks|Shangrong Wu\u7b49|[2509.14746](http://arxiv.org/pdf/2509.14746)|\u65e0|\u25c6 Image retrieval remains a fundamental yet challenging problem in computer vision.\n\u25c6 While recent advances in Multimodal Large Language Models (MLLMs) have demonstrated strong reasoning capabilities, existing methods typically employ them only for evaluation, without involving them directly in the ranking process.\n\u25c6 As a result, their rich multimodal reasoning abilities remain underutilized, leading to suboptimal performance.|\n",
    "2509.14565": "|2025-09-18|DiffVL: Diffusion-Based Visual Localization on 2D Maps via BEV-Conditioned GPS Denoising|Li Gao\u7b49|[2509.14565](http://arxiv.org/pdf/2509.14565)|\u65e0|\u25c6 Accurate visual localization is crucial for autonomous driving, yet existing methods face a fundamental dilemma: While high-definition (HD) maps provide high-precision localization references, their costly construction and maintenance hinder scalability, which drives research toward standard-definition (SD) maps like OpenStreetMap.\n\u25c6 Current SD-map-based approaches primarily focus on Bird's-Eye View (BEV) matching between images and maps, overlooking a ubiquitous signal-noisy GPS.\n\u25c6 Although GPS is readily available, it suffers from multipath errors in urban environments.|\n",
    "2509.14516": "|2025-09-18|Event-LAB: Towards Standardized Evaluation of Neuromorphic Localization Methods|Adam D. Hines\u7b49|[2509.14516](http://arxiv.org/pdf/2509.14516)|\u65e0|\u25c6 Event-based localization research and datasets are a rapidly growing area of interest, with a tenfold increase in the cumulative total number of published papers on this topic over the past 10 years.\n\u25c6 Whilst the rapid expansion in the field is exciting, it brings with it an associated challenge: a growth in the variety of required code and package dependencies as well as data formats, making comparisons difficult and cumbersome for researchers to implement reliably.\n\u25c6 To address this challenge, we present Event-LAB: a new and unified framework for running several event-based localization methodologies across multiple datasets.|\n",
    "2509.14427": "|2025-09-17|Hashing-Baseline: Rethinking Hashing in the Age of Pretrained Models|Ilyass Moummad\u7b49|[2509.14427](http://arxiv.org/pdf/2509.14427)|\u65e0|\u25c6 Information retrieval with compact binary embeddings, also referred to as hashing, is crucial for scalable fast search applications, yet state-of-the-art hashing methods require expensive, scenario-specific training.\n\u25c6 In this work, we introduce Hashing-Baseline, a strong training-free hashing method leveraging powerful pretrained encoders that produce rich pretrained embeddings.\n\u25c6 We revisit classical, training-free hashing techniques: principal component analysis, random orthogonal projection, and threshold binarization, to produce a strong baseline for hashing.|\n",
    "2509.15472": "|2025-09-25|Efficient Multimodal Dataset Distillation via Generative Models|Zhenghao Zhao\u7b49|[2509.15472](http://arxiv.org/pdf/2509.15472)|\u65e0|\u25c6 Dataset distillation aims to synthesize a small dataset from a large dataset, enabling the model trained on it to perform well on the original dataset.\n\u25c6 With the blooming of large language models and multimodal large language models, the importance of multimodal datasets, particularly image-text datasets, has grown significantly.\n\u25c6 However, existing multimodal dataset distillation methods are constrained by the Matching Training Trajectories algorithm, which significantly increases the computing resource requirement, and takes days to process the distillation.|\n",
    "2509.15432": "|2025-09-18|SERVAL: Surprisingly Effective Zero-Shot Visual Document Retrieval Powered by Large Vision and Language Models|Thong Nguyen\u7b49|[2509.15432](http://arxiv.org/pdf/2509.15432)|\u65e0|\u25c6 Visual Document Retrieval (VDR) typically operates as text-to-image retrieval using specialized bi-encoders trained to directly embed document images.\n\u25c6 We revisit a zero-shot generate-and-encode pipeline: a vision-language model first produces a detailed textual description of each document image, which is then embedded by a standard text encoder.\n\u25c6 On the ViDoRe-v2 benchmark, the method reaches 63.4% nDCG@5, surpassing the strongest specialised multi-vector visual document encoder.|\n",
    "2509.17049": "|2025-09-21|Learning Attribute-Aware Hash Codes for Fine-Grained Image Retrieval via Query Optimization|Peng Wang\u7b49|[2509.17049](http://arxiv.org/pdf/2509.17049)|\u65e0|\u25c6 Fine-grained hashing has become a powerful solution for rapid and efficient image retrieval, particularly in scenarios requiring high discrimination between visually similar categories.\n\u25c6 To enable each hash bit to correspond to specific visual attributes, we propoe a novel method that harnesses learnable queries for attribute-aware hash codes learning.\n\u25c6 This method deploys a tailored set of queries to capture and represent nuanced attribute-level information within the hashing process, thereby enhancing both the interpretability and relevance of each hash bit.|\n",
    "2509.19203": "|2025-09-23|Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions|Ioanna Ntinou\u7b49|[2509.19203](http://arxiv.org/pdf/2509.19203)|\u65e0|\u25c6 Contrastively-trained Vision-Language Models (VLMs), such as CLIP, have become the standard approach for learning discriminative vision-language representations.\n\u25c6 However, these models often exhibit shallow language understanding, manifesting bag-of-words behaviour.\n\u25c6 These limitations are reinforced by their dual-encoder design, which induces a modality gap.|\n",
    "2509.18350": "|2025-09-22|OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata|Oussema Dhaouadi\u7b49|[2509.18350](http://arxiv.org/pdf/2509.18350)|\u65e0|\u25c6 Accurate visual localization from aerial views is a fundamental problem with applications in mapping, large-area inspection, and search-and-rescue operations.\n\u25c6 In many scenarios, these systems require high-precision localization while operating with limited resources (e.g., no internet connection or GNSS/GPS support), making large image databases or heavy 3D models impractical.\n\u25c6 Surprisingly, little attention has been given to leveraging orthographic geodata as an alternative paradigm, which is lightweight and increasingly available through free releases by governmental authorities (e.g., the European Union).|\n",
    "2509.20271": "|2025-09-24|A Versatile Foundation Model for AI-enabled Mammogram Interpretation|Fuxiang Huang\u7b49|[2509.20271](http://arxiv.org/pdf/2509.20271)|\u65e0|\u25c6 Breast cancer is the most commonly diagnosed cancer and the leading cause of cancer-related mortality in women globally.\n\u25c6 Mammography is essential for the early detection and diagnosis of breast lesions.\n\u25c6 Despite recent progress in foundation models (FMs) for mammogram analysis, their clinical translation remains constrained by several fundamental limitations, including insufficient diversity in training data, limited model generalizability, and a lack of comprehensive evaluation across clinically relevant tasks.|\n",
    "2509.20401": "|2025-09-23|SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment|Binod Singh\u7b49|[2509.20401](http://arxiv.org/pdf/2509.20401)|\u65e0|\u25c6 Aligning 3D scene graphs is a crucial initial step for several applications in robot navigation and embodied perception.\n\u25c6 Current methods in 3D scene graph alignment often rely on single-modality point cloud data and struggle with incomplete or noisy input.\n\u25c6 We introduce SGAligner++, a cross-modal, language-aided framework for 3D scene graph alignment.|\n",
    "2509.22307": "|2025-09-26|Johnson-Lindenstrauss Lemma Guided Network for Efficient 3D Medical Segmentation|Jinpeng Lu\u7b49|[2509.22307](http://arxiv.org/pdf/2509.22307)|\u65e0|\u25c6 Lightweight 3D medical image segmentation remains constrained by a fundamental \"efficiency / robustness conflict\", particularly when processing complex anatomical structures and heterogeneous modalities.\n\u25c6 In this paper, we study how to redesign the framework based on the characteristics of high-dimensional 3D images, and explore data synergy to overcome the fragile representation of lightweight methods.\n\u25c6 Our approach, VeloxSeg, begins with a deployable and extensible dual-stream CNN-Transformer architecture composed of Paired Window Attention (PWA) and Johnson-Lindenstrauss lemma-guided convolution (JLC).|\n",
    "2509.24477": "|2025-09-29|Performance-Efficiency Trade-off for Fashion Image Retrieval|Julio Hurtado\u7b49|[2509.24477](http://arxiv.org/pdf/2509.24477)|\u65e0|\u25c6 The fashion industry has been identified as a major contributor to waste and emissions, leading to an increased interest in promoting the second-hand market.\n\u25c6 Machine learning methods play an important role in facilitating the creation and expansion of second-hand marketplaces by enabling the large-scale valuation of used garments.\n\u25c6 We contribute to this line of work by addressing the scalability of second-hand image retrieval from databases.|\n",
    "2509.24094": "|2025-09-28|Prepare for Warp Speed: Sub-millisecond Visual Place Recognition Using Event Cameras|Vignesh Ramanathan\u7b49|[2509.24094](http://arxiv.org/pdf/2509.24094)|\u65e0|\u25c6 Visual Place Recognition (VPR) enables systems to identify previously visited locations within a map, a fundamental task for autonomous navigation.\n\u25c6 Prior works have developed VPR solutions using event cameras, which asynchronously measure per-pixel brightness changes with microsecond temporal resolution.\n\u25c6 However, these approaches rely on dense representations of the inherently sparse camera output and require tens to hundreds of milliseconds of event data to predict a place.|\n",
    "2509.26604": "|2025-09-30|Video Object Segmentation-Aware Audio Generation|Ilpo Viertola\u7b49|[2509.26604](http://arxiv.org/pdf/2509.26604)|\u65e0|\u25c6 Existing multimodal audio generation models often lack precise user control, which limits their applicability in professional Foley workflows.\n\u25c6 In particular, these models focus on the entire video and do not provide precise methods for prioritizing a specific object within a scene, generating unnecessary background sounds, or focusing on the wrong objects.\n\u25c6 To address this gap, we introduce the novel task of video object segmentation-aware audio generation, which explicitly conditions sound synthesis on object-level segmentation maps.|\n",
    "2509.26330": "|2025-09-30|SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval|Ren-Di Wu\u7b49|[2509.26330](http://arxiv.org/pdf/2509.26330)|\u65e0|\u25c6 Composed Image Retrieval (CIR) aims to retrieve target images that preserve the visual content of a reference image while incorporating user-specified textual modifications.\n\u25c6 Training-free zero-shot CIR (ZS-CIR) approaches, which require no task-specific training or labeled data, are highly desirable, yet accurately capturing user intent remains challenging.\n\u25c6 In this paper, we present SQUARE, a novel two-stage training-free framework that leverages Multimodal Large Language Models (MLLMs) to enhance ZS-CIR.|\n",
    "2509.26012": "|2025-09-30|SETR: A Two-Stage Semantic-Enhanced Framework for Zero-Shot Composed Image Retrieval|Yuqi Xiao\u7b49|[2509.26012](http://arxiv.org/pdf/2509.26012)|\u65e0|\u25c6 Zero-shot Composed Image Retrieval (ZS-CIR) aims to retrieve a target image given a reference image and a relative text, without relying on costly triplet annotations.\n\u25c6 Existing CLIP-based methods face two core challenges: (1) union-based feature fusion indiscriminately aggregates all visual cues, carrying over irrelevant background details that dilute the intended modification, and (2) global cosine similarity from CLIP embeddings lacks the ability to resolve fine-grained semantic relations.\n\u25c6 To address these issues, we propose SETR (Semantic-enhanced Two-Stage Retrieval).|\n",
    "2509.25723": "|2025-09-30|SAGE: Spatial-visual Adaptive Graph Exploration for Visual Place Recognition|Shunpeng Chen\u7b49|[2509.25723](http://arxiv.org/pdf/2509.25723)|\u65e0|\u25c6 Visual Place Recognition (VPR) requires robust retrieval of geotagged images despite large appearance, viewpoint, and environmental variation.\n\u25c6 Prior methods focus on descriptor fine-tuning or fixed sampling strategies yet neglect the dynamic interplay between spatial context and visual similarity during training.\n\u25c6 We present SAGE (Spatial-visual Adaptive Graph Exploration), a unified training pipeline that enhances granular spatial-visual discrimination by jointly improving local feature aggregation, organize samples during training, and hard sample mining.|\n",
    "2509.25520": "|2025-09-29|Robust Visual Localization in Compute-Constrained Environments by Salient Edge Rendering and Weighted Hamming Similarity|Tu-Hoa Pham\u7b49|[2509.25520](http://arxiv.org/pdf/2509.25520)|\u65e0|\u25c6 We consider the problem of vision-based 6-DoF object pose estimation in the context of the notional Mars Sample Return campaign, in which a robotic arm would need to localize multiple objects of interest for low-clearance pickup and insertion, under severely constrained hardware.\n\u25c6 We propose a novel localization algorithm leveraging a custom renderer together with a new template matching metric tailored to the edge domain to achieve robust pose estimation using only low-fidelity, textureless 3D models as inputs.\n\u25c6 Extensive evaluations on synthetic datasets as well as from physical testbeds on Earth and in situ Mars imagery shows that our method consistently beats the state of the art in compute and memory-constrained localization, both in terms of robustness and accuracy, in turn enabling new possibilities for cheap and reliable localization on general-purpose hardware.|\n",
    "2510.01183": "|2025-10-01|EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory|Jiahao Wang\u7b49|[2510.01183](http://arxiv.org/pdf/2510.01183)|\u65e0|\u25c6 Humans possess a remarkable ability to mentally explore and replay 3D environments they have previously experienced.\n\u25c6 Inspired by this mental process, we present EvoWorld: a world model that bridges panoramic video generation with evolving 3D memory to enable spatially consistent long-horizon exploration.\n\u25c6 Given a single panoramic image as input, EvoWorld first generates future video frames by leveraging a video generator with fine-grained view control, then evolves the scene's 3D reconstruction using a feedforward plug-and-play transformer, and finally synthesizes futures by conditioning on geometric reprojections from this evolving explicit 3D memory.|\n",
    "2510.00978": "|2025-10-01|A Scene is Worth a Thousand Features: Feed-Forward Camera Localization from a Collection of Image Features|Axel Barroso-Laguna\u7b49|[2510.00978](http://arxiv.org/pdf/2510.00978)|\u65e0|\u25c6 Visually localizing an image, i.e., estimating its camera pose, requires building a scene representation that serves as a visual map.\n\u25c6 The representation we choose has direct consequences towards the practicability of our system.\n\u25c6 Even when starting from mapping images with known camera poses, state-of-the-art approaches still require hours of mapping time in the worst case, and several minutes in the best.|\n",
    "2510.00783": "|2025-10-01|Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions|Thanh Nguyen Canh\u7b49|[2510.00783](http://arxiv.org/pdf/2510.00783)|\u65e0|\u25c6 Semantic Simultaneous Localization and Mapping (SLAM) is a critical area of research within robotics and computer vision, focusing on the simultaneous localization of robotic systems and associating semantic information to construct the most accurate and complete comprehensive model of the surrounding environment.\n\u25c6 Since the first foundational work in Semantic SLAM appeared more than two decades ago, this field has received increasing attention across various scientific communities.\n\u25c6 Despite its significance, the field lacks comprehensive surveys encompassing recent advances and persistent challenges.|\n"
  },
  "Keypoint Detection": {
    "2505.02787": "|2025-05-05|Unsupervised training of keypoint-agnostic descriptors for flexible retinal image registration|David Rivas-Villar\u7b49|[2505.02787](http://arxiv.org/pdf/2505.02787)|\u65e0|\u25c6\u63d0\u51fa\u9996\u4e2a\u4e0d\u4f9d\u8d56\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u65e0\u76d1\u7763\u63cf\u8ff0\u7b26\u5b66\u4e60\u65b9\u6cd5\uff0c\u7a81\u7834\u89c6\u7f51\u819c\u56fe\u50cf\u914d\u51c6\u9886\u57df\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u5b9e\u73b0\u63cf\u8ff0\u7b26\u7f51\u7edc\u4e0e\u5173\u952e\u70b9\u68c0\u6d4b\u5668\u7684\u89e3\u8026\uff0c\u4f7f\u6a21\u578b\u80fd\u9002\u914d\u4efb\u610f\u68c0\u6d4b\u5668\uff0c\u63d0\u5347\u4e34\u5e8a\u5e94\u7528\u7075\u6d3b\u6027\u3002  \n\u25c6\u5728\u6807\u51c6\u89c6\u7f51\u819c\u914d\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u9a8c\u8bc1\uff0c\u8bc1\u660e\u65e0\u76d1\u7763\u65b9\u6cd5\u6027\u80fd\u5ab2\u7f8e\u6709\u76d1\u7763\u65b9\u6cd5\u3002  \n\u25c6\u8bbe\u8ba1\u5e76\u6d4b\u8bd5\u4e86\u591a\u79cd\u65b0\u578b\u5173\u952e\u70b9\u68c0\u6d4b\u5668\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5bf9\u4e0d\u540c\u68c0\u6d4b\u5668\u7684\u5f3a\u9c81\u68d2\u6027\u3002  \n\u25c6\u4e3a\u533b\u5b66\u9886\u57df\u65e0\u76d1\u7763\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u8303\u4f8b\uff0c\u89e3\u51b3\u4e86\u533b\u5b66\u56fe\u50cf\u6807\u6ce8\u7a00\u7f3a\u7684\u6838\u5fc3\u75db\u70b9\u3002  \n\u25c6\u901a\u8fc7\u7aef\u5230\u7aef\u65e0\u76d1\u7763\u8bad\u7ec3\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u89c6\u7f51\u819c\u56fe\u50cf\u914d\u51c6\u7684\u6280\u672f\u95e8\u69db\u548c\u5b9e\u73b0\u6210\u672c\u3002|\n",
    "2505.02779": "|2025-05-05|Unsupervised Deep Learning-based Keypoint Localization Estimating Descriptor Matching Performance|David Rivas-Villar\u7b49|[2505.02779](http://arxiv.org/pdf/2505.02779)|\u65e0|\u25c6\u63d0\u51fa\u9996\u4e2a\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u89c6\u7f51\u819c\u56fe\u50cf\u914d\u51c6\u6d41\u7a0b\uff0c\u65e0\u9700\u4efb\u4f55\u6807\u6ce8\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u533b\u5b66\u9886\u57df\u6807\u6ce8\u7a00\u7f3a\u7684\u96be\u9898\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u98a0\u8986\u4f20\u7edf\u601d\u8def\uff0c\u901a\u8fc7\u63cf\u8ff0\u5b50\u6027\u80fd\u53cd\u63a8\u5173\u952e\u70b9\u68c0\u6d4b\uff08\u63cf\u8ff0\u5b50\u9a71\u52a8\u68c0\u6d4b\u5668\uff09\uff0c\u800c\u975e\u4f20\u7edf\u7684\u5173\u952e\u70b9\u9a71\u52a8\u63cf\u8ff0\u5b50\u5b66\u4e60\u3002  \n\u25c6\u5f00\u53d1\u4e86\u65e0\u9700\u5173\u952e\u70b9\u68c0\u6d4b\u6216\u6807\u7b7e\u7684\u63cf\u8ff0\u5b50\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u76f4\u63a5\u4e3a\u89c6\u7f51\u819c\u56fe\u50cf\u4efb\u610f\u4f4d\u7f6e\u751f\u6210\u9ad8\u8d28\u91cf\u63cf\u8ff0\u7b26\u3002  \n\u25c6\u8bbe\u8ba1\u4e86\u65b0\u578b\u65e0\u6807\u7b7e\u5173\u952e\u70b9\u68c0\u6d4b\u7f51\u7edc\uff0c\u80fd\u591f\u76f4\u63a5\u4ece\u8f93\u5165\u56fe\u50cf\u9884\u6d4b\u63cf\u8ff0\u5b50\u5339\u914d\u6027\u80fd\u6765\u5b9a\u4f4d\u5173\u952e\u70b9\u3002  \n\u25c6\u5728\u56db\u4e2a\u72ec\u7acb\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u8868\u660e\uff0c\u65e0\u76d1\u7763\u63cf\u8ff0\u5b50\u8d85\u8d8a\u6709\u76d1\u7763SOTA\u65b9\u6cd5\uff0c\u65e0\u76d1\u7763\u68c0\u6d4b\u5668\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65e0\u76d1\u7763\u68c0\u6d4b\u65b9\u6cd5\u3002  \n\u25c6\u6574\u4e2a\u914d\u51c6\u6d41\u7a0b\u6027\u80fd\u5ab2\u7f8e\u4e3b\u6d41\u6709\u76d1\u7763\u65b9\u6cd5\uff0c\u4e14\u65e0\u9700\u6807\u6ce8\u6570\u636e\u7684\u7279\u6027\u4f7f\u5176\u53ef\u76f4\u63a5\u8fc1\u79fb\u5230\u5176\u4ed6\u9886\u57df\u548c\u6a21\u6001\u3002|\n",
    "2505.02161": "|**2025-05-04**|**Focus What Matters: Matchability-Based Reweighting for Local Feature Matching**|Dongyue Li et.al.|[2505.02161](http://arxiv.org/abs/2505.02161)|null|\n",
    "2505.02049": "|**2025-05-04**|**Enhancing Lidar Point Cloud Sampling via Colorization and Super-Resolution of Lidar Imagery**|Sier Ha et.al.|[2505.02049](http://arxiv.org/abs/2505.02049)|null|\n",
    "2505.08013": "|2025-06-19|RDD: Robust Feature Detector and Descriptor using Deformable Transformer|Gonglin Chen\u7b49|[2505.08013](http://arxiv.org/pdf/2505.08013)|\u65e0|\u25c6 \u63d0\u51faRDD\uff08Robust Deformable Detector\uff09\uff0c\u4e00\u79cd\u57fa\u4e8e\u53ef\u53d8\u5f62Transformer\u7684\u65b0\u578b\u5173\u952e\u70b9\u68c0\u6d4b\u4e0e\u63cf\u8ff0\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u53d8\u5f62\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6355\u83b7\u5168\u5c40\u4e0a\u4e0b\u6587\u548c\u51e0\u4f55\u4e0d\u53d8\u6027\u3002  \n\u25c6 \u5229\u7528\u53ef\u53d8\u5f62\u6ce8\u610f\u529b\u673a\u5236\u805a\u7126\u5173\u952e\u4f4d\u7f6e\uff0c\u663e\u8457\u964d\u4f4e\u641c\u7d22\u7a7a\u95f4\u590d\u6742\u5ea6\u5e76\u6709\u6548\u5efa\u6a21\u51e0\u4f55\u53d8\u6362\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5b66\u4e60\u957f\u7a0b\u89c6\u89c9\u5173\u7cfb\u7684\u95ee\u9898\u3002  \n\u25c6 \u7ed3\u5408\u6807\u51c6MegaDepth\u6570\u636e\u96c6\u4e0e\u81ea\u5efa\u7684Air-to-Ground\uff08\u7a7a\u5bf9\u5730\uff09\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u589e\u5f3a\u6a21\u578b\u5728\u8de8\u89c6\u89d2\u548c\u8de8\u5c3a\u5ea6\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5728\u7a00\u758f\u5339\u914d\u4efb\u52a1\u4e2d\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u5e76\u5177\u5907\u534a\u7a20\u5bc6\u5339\u914d\u80fd\u529b\uff0c\u6269\u5c55\u4e86\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u5f15\u5165\u4e24\u4e2a\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff1a\u4e00\u4e2a\u9488\u5bf9\u5927\u89c6\u89d2\u4e0e\u5c3a\u5ea6\u53d8\u5316\uff0c\u53e6\u4e00\u4e2a\u4e3a\u7a7a\u5bf9\u5730\u573a\u666f\uff0c\u586b\u8865\u4e86\u8de8\u9ad8\u5ea63D\u91cd\u5efa\u8bc4\u4f30\u7684\u7a7a\u767d\u3002|\n",
    "2505.07306": "|2025-05-12|Enabling Privacy-Aware AI-Based Ergonomic Analysis|Sander De Coninck\u7b49|[2505.07306](http://arxiv.org/pdf/2505.07306)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u9690\u79c1\u611f\u77e5\u7684AI\u5de5\u6548\u5b66\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u5f00\u53d1\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u89c6\u9891\u6570\u636e\u4e2d\u6a21\u7cca\u9690\u79c1\u4fe1\u606f\uff0c\u4ec5\u4fdd\u7559\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u6240\u9700\u5173\u952e\u7279\u5f81\u3002  \n\u25c6 \u91c7\u7528\u6570\u636e\u6df7\u6dc6\u6280\u672f\u786e\u4fdd\u4e0e\u6807\u51c6\u59ff\u6001\u4f30\u8ba1\u7b97\u6cd5\u517c\u5bb9\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u7ef4\u6301\u9ad8\u7cbe\u5ea6\u5206\u6790\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6444\u50cf\u5934\u7cfb\u7edf\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u6df7\u6dc6\u540e\u7684\u6570\u636e\u4f20\u8f93\u81f3\u4e2d\u592e\u670d\u52a1\u5668\u5904\u7406\uff0c\u7ed3\u5408\u591a\u89c6\u89d2\u878d\u5408\u6280\u672f\u91cd\u5efa3D\u5173\u952e\u70b9\uff0c\u5b9e\u73b0\u8fdc\u7a0b\u9ad8\u7cbe\u5ea6\u5de5\u6548\u5b66\u8bc4\u4f30\u3002  \n\u25c6 \u6574\u5408REBA\uff08\u5feb\u901f\u5168\u8eab\u8bc4\u4f30\uff09\u65b9\u6cd5\u5bf93D\u59ff\u6001\u8fdb\u884c\u5de5\u6548\u5b66\u98ce\u9669\u91cf\u5316\uff0c\u5f62\u6210\u4ece\u6570\u636e\u91c7\u96c6\u5230\u98ce\u9669\u8bc4\u4f30\u7684\u5b8c\u6574\u95ed\u73af\u7cfb\u7edf\u3002  \n\u25c6 \u5728\u5de5\u4e1a\u573a\u666f\u4e2d\u9996\u6b21\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u4e0e\u5de5\u6548\u5b66\u76d1\u6d4b\u7684\u5e73\u8861\uff0c\u4e3a\u5236\u9020\u4e1a\u63d0\u4f9b\u517c\u987e\u5b89\u5168\u6027\u4e0e\u5408\u89c4\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u7cfb\u7edf\u8bbe\u8ba1\u8f7b\u91cf\u5316\u4e14\u53ef\u6269\u5c55\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u5de5\u4e1a\u73af\u5883\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027\u4f18\u52bf\u3002|\n",
    "2505.06436": "|2025-05-09|My Emotion on your face: The use of Facial Keypoint Detection to preserve Emotions in Latent Space Editing|Jingrui He\u7b49|[2505.06436](http://arxiv.org/pdf/2505.06436)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9762\u90e8\u5173\u952e\u70b9\u68c0\u6d4b\u6a21\u578b\u7684\u65b0\u635f\u5931\u51fd\u6570\uff08HFLD\u635f\u5931\uff09\uff0c\u7528\u4e8e\u89e3\u51b3StyleGAN/2\u6f5c\u5728\u7a7a\u95f4\u7f16\u8f91\u4e2d\u7684\u8868\u60c5\u7ea0\u7f20\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7\u5728\u73b0\u6709\u6a21\u578b\u635f\u5931\u51fd\u6570\u4e2d\u589e\u52a0HFLD\u635f\u5931\uff0c\u6709\u6548\u9650\u5236\u4e86\u7f16\u8f91\u8fc7\u7a0b\u4e2d\u5bf9\u9762\u90e8\u8868\u60c5\u7684\u5e72\u6270\uff0c\u5b9e\u9a8c\u663e\u793a\u60c5\u7eea\u53d8\u5316\u51cf\u5c11\u9ad8\u8fbe49%\u3002  \n\u25c6 \u9996\u6b21\u5c06\u9762\u90e8\u5173\u952e\u70b9\u68c0\u6d4b\u6280\u672f\u4e0eGAN\u6f5c\u5728\u7a7a\u95f4\u7f16\u8f91\u7ed3\u5408\uff0c\u5b9a\u91cf\u548c\u5b9a\u6027\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u8868\u60c5\u4e00\u81f4\u6027\u4e0a\u7684\u4f18\u8d8a\u6027\u3002  \n\u25c6 \u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u56fe\u50cf\u5728\u56fa\u5b9a\u8868\u60c5\u4e0b\u53d8\u6362\u5916\u8c8c\u7279\u5f81\u7684\u80fd\u529b\uff0c\u4e3a\u624b\u52bf\u548c\u8868\u60c5\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6570\u636e\u589e\u5f3a\u624b\u6bb5\u3002  \n\u25c6 \u901a\u8fc7\u5bf9\u6bd4\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u9762\u90e8\u8868\u60c5\u7684\u540c\u65f6\u7f16\u8f91\u5176\u4ed6\u5c5e\u6027\uff08\u5982\u6027\u522b\u3001\u5e74\u9f84\uff09\u7684\u6548\u679c\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u3002  \n\u25c6 \u4e3a\u9762\u90e8\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u6280\u672f\u8def\u5f84\uff0c\u901a\u8fc7\u5173\u952e\u70b9\u7ea6\u675f\u76f4\u63a5\u89e3\u51b3\u7279\u5f81\u89e3\u8026\u95ee\u9898\uff0c\u800c\u975e\u4f9d\u8d56\u9690\u5f0f\u5b66\u4e60\u3002|\n",
    "2505.12246": "|2025-05-18|SEPT: Standard-Definition Map Enhanced Scene Perception and Topology Reasoning for Autonomous Driving|Muleilan Pei\u7b49|[2505.12246](http://arxiv.org/pdf/2505.12246)|\u65e0|\u25c6 \u63d0\u51faSEPT\u6846\u67b6\uff0c\u5229\u7528\u6807\u51c6\u5b9a\u4e49\u5730\u56fe\uff08SD\u5730\u56fe\uff09\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\uff0c\u589e\u5f3a\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u611f\u77e5\u4e0e\u62d3\u6251\u63a8\u7406\u80fd\u529b\uff0c\u51cf\u5c11\u5bf9\u9ad8\u7cbe\u5730\u56fe\u7684\u4f9d\u8d56\u3002  \n\u25c6 \u8bbe\u8ba1\u6df7\u5408\u7279\u5f81\u878d\u5408\u7b56\u7565\uff0c\u7ed3\u5408SD\u5730\u56fe\u4e0e\u9e1f\u77b0\u56fe\uff08BEV\uff09\u7279\u5f81\uff0c\u540c\u65f6\u5904\u7406\u6805\u683c\u5316\u548c\u77e2\u91cf\u5316\u8868\u793a\uff0c\u89e3\u51b3\u4e24\u8005\u7a7a\u95f4\u5bf9\u9f50\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5f15\u5165\u57fa\u4e8eSD\u5730\u56fe\u7684\u8f85\u52a9\u4efb\u52a1\u2014\u2014\u4ea4\u53c9\u8def\u53e3\u611f\u77e5\u5173\u952e\u70b9\u68c0\u6d4b\uff0c\u63d0\u5347\u957f\u8ddd\u79bb\u548c\u906e\u6321\u573a\u666f\u4e0b\u7684\u7406\u89e3\u6027\u80fd\u3002  \n\u25c6 \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5728OpenLane-V2\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u8bc1\u660eSD\u5730\u56fe\u5148\u9a8c\u7684\u6709\u6548\u6027\u3002  \n\u25c6 \u6574\u4f53\u6846\u67b6\u517c\u987e\u611f\u77e5\u4e0e\u63a8\u7406\uff0c\u4e3a\u65e0\u9ad8\u7cbe\u5730\u56fe\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u66f4\u9c81\u68d2\u7684\u5728\u7ebf\u73af\u5883\u7406\u89e3\u65b9\u6848\u3002|\n",
    "2505.12130": "|2025-05-17|Keypoints as Dynamic Centroids for Unified Human Pose and Segmentation|Niaz Ahmad\u7b49|[2505.12130](http://arxiv.org/pdf/2505.12130)|\u65e0|\u25c6 \u63d0\u51faKeypoints as Dynamic Centroid (KDC)\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8d28\u5fc3\u8868\u793a\u7edf\u4e00\u89e3\u51b3\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u548c\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u5728\u5173\u8282\u91cd\u53e0\u6216\u5feb\u901f\u8fd0\u52a8\u65f6\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u91c7\u7528\u81ea\u5e95\u5411\u4e0a\u8303\u5f0f\u751f\u6210\u5173\u952e\u70b9\u70ed\u56fe\uff0c\u5e76\u5f15\u5165KeyCentroids\uff08\u57fa\u4e8e\u5173\u952e\u70b9\u78c1\u76d8\uff09\u63d0\u5347\u5173\u952e\u70b9\u68c0\u6d4b\u7cbe\u5ea6\u548c\u7f6e\u4fe1\u5ea6\u5f97\u5206\u3002  \n\u25c6 \u5229\u7528\u9ad8\u7f6e\u4fe1\u5ea6\u5173\u952e\u70b9\u4f5c\u4e3a\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u52a8\u6001\u8d28\u5fc3\uff08MaskCentroids\uff09\uff0c\u5b9e\u73b0\u5feb\u901f\u8fd0\u52a8\u4e0b\u50cf\u7d20\u5230\u4eba\u4f53\u5b9e\u4f8b\u7684\u9ad8\u6548\u805a\u7c7b\u3002  \n\u25c6 \u5728CrowdPose\u3001OCHuman\u548cCOCO\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86KDC\u7684\u4f18\u8d8a\u6027\uff0c\u5c24\u5176\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u51c6\u786e\u6027\u548c\u5b9e\u65f6\u6027\u80fd\u8868\u73b0\u7a81\u51fa\u3002  \n\u25c6 \u901a\u8fc7\u52a8\u6001\u8d28\u5fc3\u673a\u5236\u6709\u6548\u5904\u7406\u5b9e\u4f8b\u7ea7\u5206\u5272\u4e2d\u7684\u906e\u6321\u548c\u59ff\u6001\u5feb\u901f\u53d8\u5316\u95ee\u9898\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002|\n",
    "2505.11110": "|2025-05-16|Deepfake Forensic Analysis: Source Dataset Attribution and Legal Implications of Synthetic Media Manipulation|Massimiliano Cassia\u7b49|[2505.11110](http://arxiv.org/pdf/2505.11110)|\u65e0|\u25c6\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684GAN\u751f\u6210\u56fe\u50cf\u6eaf\u6e90\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7279\u5f81\u5206\u6790\u51c6\u786e\u8bc6\u522b\u8bad\u7ec3\u6570\u636e\u96c6\uff08\u5982CelebA\u6216FFHQ\uff09\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u878d\u5408\u9891\u57df\u53d8\u6362\uff08\u5085\u91cc\u53f6/DCT\uff09\u3001\u8272\u5f69\u5206\u5e03\u5ea6\u91cf\u548c\u5c40\u90e8\u7279\u5f81\u63cf\u8ff0\u7b26\uff08SIFT\uff09\uff0c\u63d0\u53d6\u5408\u6210\u56fe\u50cf\u4e2d\u7684 discriminative \u7edf\u8ba1\u7279\u5f81\u3002  \n\u25c6\u76d1\u7763\u5206\u7c7b\u5668\uff08\u968f\u673a\u68ee\u6797\u3001SVM\u3001XGBoost\uff09\u5728\u4e8c\u5143\u5206\u7c7b\uff08\u771f\u5b9evs\u5408\u6210\uff09\u548c\u591a\u7c7b\u6570\u636e\u96c6\u6eaf\u6e90\u4efb\u52a1\u4e2d\u8fbe\u523098-99%\u51c6\u786e\u7387\uff0c\u8986\u76d6\u591a\u79cd\u4e3b\u6d41GAN\u67b6\u6784\uff08\u5982StyleGAN\u7cfb\u5217\uff09\u3002  \n\u25c6\u5b9e\u9a8c\u8bc1\u660e\u9891\u57df\u7279\u5f81\uff08DCT/FFT\uff09\u5bf9\u6355\u6349\u6570\u636e\u96c6\u7279\u5f02\u6027\u4f2a\u5f71\uff08\u5982\u4e0a\u91c7\u6837\u6a21\u5f0f\u3001\u9891\u8c31\u5f02\u5e38\uff09\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u8272\u5f69\u76f4\u65b9\u56fe\u5219\u80fd\u63ed\u793aGAN\u8bad\u7ec3\u7684\u9690\u5f0f\u6b63\u5219\u5316\u7b56\u7565\u3002  \n\u25c6\u9996\u6b21\u7cfb\u7edf\u63a2\u8ba8\u4e86\u5408\u6210\u5a92\u4f53\u6570\u636e\u96c6\u6eaf\u6e90\u7684\u6cd5\u5f8b\u5e94\u7528\u573a\u666f\uff0c\u5305\u62ec\u7248\u6743\u4fb5\u6743\u3001\u9690\u79c1\u6570\u636e\u6ee5\u7528\uff08\u5982GDPR\u5408\u89c4\uff09\u53ca\u52a0\u5ddeAB 602\u6cd5\u6848\u7b49\u76d1\u7ba1\u5e94\u5bf9\u65b9\u6848\u3002  \n\u25c6\u8be5\u6846\u67b6\u4e3a\u751f\u6210\u6a21\u578b\u7684\u95ee\u8d23\u5236\u6cbb\u7406\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6491\uff0c\u53ef\u5e94\u7528\u4e8e\u6570\u5b57\u53d6\u8bc1\u3001\u5185\u5bb9\u5ba1\u6838\u548c\u77e5\u8bc6\u4ea7\u6743\u8bc9\u8bbc\u7b49\u5b9e\u9645\u9886\u57df\u3002|\n",
    "2505.23475": "|2025-05-29|TimePoint: Accelerated Time Series Alignment via Self-Supervised Keypoint and Descriptor Learning|Ron Shapira Weber\u7b49|[2505.23475](http://arxiv.org/pdf/2505.23475)|[\u4ee3\u7801](https://github.com/bgu-cs-vil/timepoint)|\u25c6\u63d0\u51faTimePoint\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u4ece\u5408\u6210\u6570\u636e\u4e2d\u63d0\u53d6\u5173\u952e\u70b9\u548c\u63cf\u8ff0\u7b26\uff0c\u663e\u8457\u52a0\u901f\u52a8\u6001\u65f6\u95f4\u89c4\u6574\uff08DTW\uff09\u7684\u5bf9\u9f50\u8fc7\u7a0b\uff0c\u540c\u65f6\u63d0\u9ad8\u5bf9\u9f50\u7cbe\u5ea6\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u5c062D\u5173\u952e\u70b9\u68c0\u6d4b\u601d\u60f3\u9002\u914d\u52301D\u4fe1\u53f7\uff0c\u8bbe\u8ba1\u9ad8\u6548\u7684\u4e00\u7ef4\u5fae\u5206\u540c\u80da\u6a21\u578b\u751f\u6210\u903c\u771f\u8bad\u7ec3\u6570\u636e\uff0c\u6709\u6548\u6a21\u62df\u975e\u7ebf\u6027\u65f6\u95f4\u626d\u66f2\u3002  \n\u25c6\u91c7\u7528\u5168\u5377\u79ef\u548c\u5c0f\u6ce2\u5377\u79ef\u67b6\u6784\u63d0\u53d6\u4fe1\u606f\u4e30\u5bcc\u7684\u7a00\u758f\u8868\u793a\uff0c\u4f7fDTW\u5728\u7a00\u758f\u6570\u636e\u4e0a\u8fd0\u884c\u65f6\u83b7\u5f97\u6570\u91cf\u7ea7\u52a0\u901f\uff0c\u4e14\u7cbe\u5ea6\u901a\u5e38\u4f18\u4e8e\u539f\u59cb\u4fe1\u53f7\u4e0a\u7684\u6807\u51c6DTW\u3002  \n\u25c6\u4ec5\u4f7f\u7528\u5408\u6210\u6570\u636e\u8bad\u7ec3\u5373\u53ef\u5728\u771f\u5b9e\u65f6\u95f4\u5e8f\u5217\u4e0a\u5c55\u73b0\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u5fae\u8c03\u540e\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u3002  \n\u25c6\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\uff0cTimePoint\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e0a\u5747\u4f18\u4e8e\u6807\u51c6DTW\uff0c\u4e3a\u5927\u89c4\u6a21\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2505.18652": "|2025-05-24|Why Not Replace? Sustaining Long-Term Visual Localization via Handcrafted-Learned Feature Collaboration on CPU|Yicheng Lin\u7b49|[2505.18652](http://arxiv.org/pdf/2505.18652)|[\u4ee3\u7801](https://github.com/linyicheng1/orb_slam3_localization)|\u25c6 \u63d0\u51fa\u624b\u5de5-\u5b66\u4e60\u7279\u5f81\u534f\u4f5c\u673a\u5236\uff1a\u9996\u6b21\u7cfb\u7edf\u8bba\u8bc1\u624b\u5de5\u7279\u5f81\uff08\u9002\u5408\u8fde\u7eed\u8ddf\u8e2a\uff09\u4e0e\u5b66\u4e60\u7279\u5f81\uff08\u64c5\u957f\u5bbd\u57fa\u7ebf\u5339\u914d\uff09\u7684\u529f\u80fd\u4e92\u8865\u6027\uff0c\u6253\u7834\u4f20\u7edf\"\u66ff\u4ee3\"\u601d\u7ef4\uff0c\u5efa\u7acb\u534f\u540c\u6846\u67b6\u3002  \n\u25c6 \u8bbe\u8ba1CPU\u53cb\u597d\u7684\u5206\u5c42\u5b9a\u4f4d\u67b6\u6784\uff1a\u5b9e\u65f6\u5c42\u91c7\u7528\u624b\u5de5\u7279\u5f81\u8fdb\u884c\u76f8\u5bf9\u4f4d\u59ff\u4f30\u8ba1\uff0c\u5f02\u6b65\u5c42\u9009\u62e9\u6027\u8c03\u7528\u5b66\u4e60\u7279\u5f81\u8fdb\u884c\u7edd\u5bf9\u5b9a\u4f4d\uff0c\u5b9e\u73b0\u4ec5\u9700CPU\u7684\u957f\u671f\u7a33\u5b9a\u8fd0\u884c\u3002  \n\u25c6 \u521b\u65b0\u5173\u952e\u5e27\u4f18\u5316\u7b56\u7565\uff1a\u901a\u8fc7\u52a8\u6001\u7b5b\u9009\u673a\u5236\u5e73\u8861\u5b66\u4e60\u7279\u5f81\u7684\u8ba1\u7b97\u5f00\u9500\u4e0e\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u4f7f\u7cfb\u7edf\u5728\u5149\u7167\u53d8\u5316\u4e0b\u4fdd\u630147%\u7684\u5e73\u5747\u8bef\u5dee\u964d\u4f4e\u3002  \n\u25c6 \u5b9e\u73b0\u5168\u65f6\u6bb5\u73af\u5883\u9002\u5e94\u6027\uff1a\u901a\u8fc7\u7279\u5f81\u534f\u4f5c\u6709\u6548\u5e94\u5bf9\u5de5\u4e1a\u573a\u666f\u4e2d\u7684\u5b63\u8282\u66f4\u66ff\u3001\u663c\u591c\u5149\u7167\u53d8\u5316\u7b49\u6311\u6218\uff0c\u5b9a\u4f4d\u4e00\u81f4\u6027\u663e\u8457\u63d0\u5347\u3002  \n\u25c6 \u63d0\u4f9b\u5b8c\u6574\u5f00\u6e90\u5b9e\u73b0\uff1a\u516c\u5f00\u4ee3\u7801\u5305\u542b\u7279\u5f81\u4e92\u8865\u6027\u5206\u6790\u3001\u8ba1\u7b97\u5ef6\u8fdf\u5256\u6790\u5230\u7cfb\u7edf\u7ea7\u9a8c\u8bc1\u7684\u5168\u5957\u5b9e\u9a8c\u6570\u636e\uff0c\u63a8\u52a8\u5de5\u4e1a\u5e94\u7528\u843d\u5730\u3002  \n\u25c6 \u5efa\u7acb\u4e09\u9636\u6bb5\u9a8c\u8bc1\u4f53\u7cfb\uff1a\u4ece\u7279\u5f81\u7279\u6027\u5bf9\u6bd4\u3001CPU\u5e73\u53f0\u7b97\u529b\u5256\u6790\u5230\u771f\u5b9e\u5149\u7167\u53d8\u5316\u6d4b\u8bd5\uff0c\u5f62\u6210\u4e25\u8c28\u7684\u6280\u672f\u9a8c\u8bc1\u94fe\u8def\u3002|\n",
    "2506.22336": "|2025-06-27|MatChA: Cross-Algorithm Matching with Feature Augmentation|Paula Carb\u00f3 Cubero\u7b49|[2506.22336](http://arxiv.org/pdf/2506.22336)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u9996\u4e2a\u89e3\u51b3\u8de8\u7279\u5f81\u68c0\u6d4b\u5668\u573a\u666f\u4e0b\u89c6\u89c9\u5b9a\u4f4d\u95ee\u9898\u7684\u65b9\u6cd5MatChA\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u5fc5\u987b\u4f7f\u7528\u76f8\u540c\u68c0\u6d4b\u5668\u7684\u9650\u5236\u3002  \n\u25c6 \u901a\u8fc7\u7279\u5f81\u63cf\u8ff0\u7b26\u589e\u5f3a\u6280\u672f\u63d0\u5347\u8de8\u68c0\u6d4b\u5668\u7279\u5f81\u5339\u914d\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u5173\u952e\u70b9\u91cd\u590d\u7387\u4f4e\u548c\u63cf\u8ff0\u7b26\u533a\u5206\u5ea6\u4e0d\u8db3\u7684\u96be\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u589e\u5f3a\u540e\u7684\u7279\u5f81\u8f6c\u6362\u5230\u6f5c\u5728\u7a7a\u95f4\uff0c\u5b9e\u73b0\u4e86\u4e0d\u540c\u7b97\u6cd5\u751f\u6210\u63cf\u8ff0\u7b26\u7684\u6709\u6548\u5339\u914d\u3002  \n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8de8\u7279\u5f81\u573a\u666f\u4e0b\u7684\u56fe\u50cf\u5339\u914d\u548c\u89c6\u89c9\u5b9a\u4f4d\u7cbe\u5ea6\u3002  \n\u25c6 \u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6848\u4f9d\u8d56\u5171\u540c\u5173\u952e\u70b9\u7684\u5047\u8bbe\uff0c\u66f4\u8d34\u5408\u5b9e\u9645\u5e94\u7528\u4e2d\u4e0d\u540c\u8bbe\u5907\u4f7f\u7528\u4e0d\u540c\u7279\u5f81\u63d0\u53d6\u7b97\u6cd5\u7684\u590d\u6742\u573a\u666f\u3002|\n",
    "2506.21945": "|2025-06-27|SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images|Naftaly Wambugu\u7b49|[2506.21945](http://arxiv.org/pdf/2506.21945)|\u65e0|\u25c6 \u63d0\u51fa\u5806\u53e0\u5f0f\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc\uff08SDRNet\uff09\uff0c\u901a\u8fc7\u53cc\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\u540c\u65f6\u6355\u83b7\u957f\u7a0b\u8bed\u4e49\u5e76\u4fdd\u7559\u7a7a\u95f4\u7ec6\u8282\uff0c\u89e3\u51b3\u9ad8\u5206\u8fa8\u7387\u9065\u611f\u56fe\u50cf\u5206\u5272\u4e2d\u7a7a\u95f4\u4fe1\u606f\u4e22\u5931\u95ee\u9898\u3002  \n\u25c6 \u5728\u7f16\u7801\u5668\u4e0e\u89e3\u7801\u5668\u4e4b\u95f4\u5f15\u5165\u81a8\u80c0\u6b8b\u5dee\u5757\uff08DRB\uff09\uff0c\u589e\u5f3a\u5168\u5c40\u4f9d\u8d56\u5173\u7cfb\u5efa\u6a21\u80fd\u529b\uff0c\u6709\u6548\u5e94\u5bf9\u5730\u7269\u7c7b\u522b\u5dee\u5f02\u548c\u906e\u6321\u5bfc\u81f4\u7684\u7279\u5f81\u63d0\u53d6\u6311\u6218\u3002  \n\u25c6 \u901a\u8fc7\u591a\u4e0a\u4e0b\u6587\u7279\u5f81\u5b66\u4e60\u673a\u5236\uff0c\u8986\u76d6\u4e0d\u540c\u5c3a\u5bf8\u5730\u7269\u76ee\u6807\uff0c\u7f13\u89e3\u56e0\u7269\u4f53\u5c3a\u5bf8\u53d8\u5316\u5bfc\u81f4\u7684\u7ec6\u5206\u4e0d\u51c6\u95ee\u9898\u3002  \n\u25c6 \u7ed3\u5408\u5168\u5c40\u4e0e\u5c40\u90e8\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u7ec6\u5c0f\u5730\u7269\u548c\u590d\u6742\u8fb9\u754c\u7684\u8bc6\u522b\u7cbe\u5ea6\uff0c\u514b\u670d\u4f20\u7edf\u6df1\u5ea6\u7f51\u7edc\u4e0b\u91c7\u6837\u5bfc\u81f4\u7684\u8fb9\u754c\u6a21\u7cca\u7f3a\u9677\u3002  \n\u25c6 \u5728ISPRS Vaihingen\u548cPotsdam\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6a21\u578b\u4f18\u8d8a\u6027\uff0c\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc\uff0c\u4e3a\u9ad8\u7cbe\u5ea6\u5730\u7269\u5206\u7c7b\u63d0\u4f9b\u65b0\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.07077": "|2025-07-09|Reading a Ruler in the Wild|Yimu Pan\u7b49|[2507.07077](http://arxiv.org/pdf/2507.07077)|\u65e0|\u25c6 \u63d0\u51faRulerNet\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u6807\u5c3a\u8bfb\u6570\u91cd\u65b0\u5b9a\u4e49\u4e3a\u7edf\u4e00\u7684\u5173\u952e\u70b9\u68c0\u6d4b\u95ee\u9898\uff0c\u901a\u8fc7\u51e0\u4f55\u7ea7\u6570\u53c2\u6570\u8868\u793a\u6807\u5c3a\u523b\u5ea6\uff0c\u5b9e\u73b0\u900f\u89c6\u53d8\u6362\u4e0b\u7684\u9c81\u68d2\u6027\u6d4b\u91cf\u3002  \n\u25c6 \u91c7\u7528\u6297\u7578\u53d8\u6807\u6ce8\u548c\u8bad\u7ec3\u7b56\u7565\u76f4\u63a5\u5b9a\u4f4d\u5398\u7c73\u523b\u5ea6\uff0c\u6446\u8131\u4f20\u7edf\u65b9\u6cd5\u5bf9\u624b\u5de5\u9608\u503c\u6216\u56fa\u5b9a\u6d41\u7a0b\u7684\u4f9d\u8d56\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u4e0d\u540c\u6807\u5c3a\u7c7b\u578b\u548c\u6210\u50cf\u6761\u4ef6\u7684\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u5f00\u53d1\u53ef\u6269\u5c55\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u6d41\u7a0b\uff0c\u7ed3\u5408\u56fe\u5f62\u5316\u6807\u5c3a\u751f\u6210\u4e0eControlNet\u6280\u672f\u6dfb\u52a0\u903c\u771f\u80cc\u666f\uff0c\u6709\u6548\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u5e76\u589e\u5f3a\u8bad\u7ec3\u591a\u6837\u6027\u3002  \n\u25c6 \u63d0\u51fa\u8f7b\u91cf\u7ea7DeepGP\u7f51\u7edc\uff0c\u76f4\u63a5\u4ece\u566a\u58f0\u6807\u8bb0\u56de\u5f52\u51e0\u4f55\u7ea7\u6570\u53c2\u6570\uff0c\u66ff\u4ee3\u4f20\u7edf\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\uff0c\u5b9e\u73b0\u79fb\u52a8\u6216\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u5c3a\u5ea6\u4f30\u8ba1\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eRulerNet\u5728\u590d\u6742\u771f\u5b9e\u573a\u666f\u4e2d\u80fd\u63d0\u4f9b\u9ad8\u7cbe\u5ea6\u3001\u4e00\u81f4\u4e14\u9ad8\u6548\u7684\u5c3a\u5ea6\u4f30\u8ba1\uff0c\u4e3a\u751f\u7269\u533b\u5b66\u3001\u6cd5\u533b\u7b49\u9886\u57df\u7684\u81ea\u52a8\u5316\u6d4b\u91cf\u63d0\u4f9b\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.06662": "|2025-07-09|MK-Pose: Category-Level Object Pose Estimation via Multimodal-Based Keypoint Learning|Yifan Yang\u7b49|[2507.06662](http://arxiv.org/pdf/2507.06662)|\u65e0|\u25c6 \u63d0\u51faMK-Pose\u6846\u67b6\uff0c\u9996\u6b21\u878d\u5408RGB\u56fe\u50cf\u3001\u70b9\u4e91\u6570\u636e\u548c\u7c7b\u522b\u7ea7\u6587\u672c\u63cf\u8ff0\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u8f93\u5165\u63d0\u5347\u7c7b\u522b\u7ea7\u7269\u4f53\u59ff\u6001\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u81ea\u76d1\u7763\u5173\u952e\u70b9\u68c0\u6d4b\u6a21\u5757\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u751f\u6210\u67e5\u8be2\u3001\u8f6f\u70ed\u56fe\u5339\u914d\u548c\u56fe\u5173\u7cfb\u5efa\u6a21\uff0c\u6709\u6548\u89e3\u51b3\u906e\u6321\u548c\u8de8\u5b9e\u4f8b\u6cdb\u5316\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5f15\u5165\u56fe\u589e\u5f3a\u7279\u5f81\u878d\u5408\u6a21\u5757\uff0c\u6574\u5408\u5c40\u90e8\u51e0\u4f55\u4fe1\u606f\u4e0e\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u589e\u5f3a\u5bf9\u590d\u6742\u573a\u666f\u7684\u5efa\u6a21\u80fd\u529b\u3002  \n\u25c6 \u5728CAMERA25\u548cREAL275\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6027\u80fd\uff0c\u65e0\u9700\u5f62\u72b6\u5148\u9a8c\u5373\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff08IoU\u548c\u5e73\u5747\u7cbe\u5ea6\u6307\u6807\uff09\u3002  \n\u25c6 \u989d\u5916\u6d4b\u8bd5\u8de8\u6570\u636e\u96c6\u80fd\u529b\uff08HouseCat6D\uff09\uff0c\u8bc1\u660e\u6a21\u578b\u5177\u5907\u5f3a\u6cdb\u5316\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5de5\u4e1a\u573a\u666f\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u5e76\u63d0\u4f9b\u5b8c\u6574\u5b9e\u73b0\uff0c\u63a8\u52a8\u9886\u57df\u7814\u7a76\u4e0e\u5e94\u7528\u843d\u5730\u3002|\n",
    "2507.07994": "|2025-07-27|Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection|Subhajit Maity\u7b49|[2507.07994](http://arxiv.org/pdf/2507.07994)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u8349\u56fe\u7684\u5c0f\u6837\u672c\u5173\u952e\u70b9\u68c0\u6d4b\u6846\u67b6\uff0c\u5229\u7528\u4eba\u7c7b\u624b\u7ed8\u8349\u56fe\u4f5c\u4e3a\u65e0\u6e90\u6570\u636e\u66ff\u4ee3\u65b9\u6848\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u67e5\u8be2\u6570\u636e\u5206\u5e03\u4e0d\u4e00\u81f4\u65f6\u7684\u56f0\u5883\u3002  \n\u25c6 \u8bbe\u8ba1\u8de8\u6a21\u6001\u5d4c\u5165\u5b66\u4e60\u673a\u5236\uff0c\u6709\u6548\u6865\u63a5\u8349\u56fe\u4e0e\u771f\u5b9e\u56fe\u50cf\u4e4b\u95f4\u7684\u6a21\u6001\u5dee\u5f02\uff0c\u5b9e\u73b0\u8349\u56fe\u5230\u5173\u952e\u70b9\u7684\u7cbe\u51c6\u6620\u5c04\u3002  \n\u25c6 \u5f15\u5165\u7f51\u683c\u5316\u5b9a\u4f4d\u5668\uff08grid-based locator\uff09\u589e\u5f3a\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\uff0c\u7ed3\u5408\u539f\u578b\u7f51\u7edc\u4f18\u5316\u5173\u952e\u70b9\u5b9a\u4f4d\u7cbe\u5ea6\u3002  \n\u25c6 \u521b\u65b0\u6027\u91c7\u7528\u539f\u578b\u57df\u9002\u5e94\u6280\u672f\uff08prototypical domain adaptation\uff09\uff0c\u81ea\u9002\u5e94\u6d88\u9664\u7528\u6237\u624b\u7ed8\u98ce\u683c\u7684\u4e2a\u4f53\u5dee\u5f02\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u6027\u3002  \n\u25c6 \u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u6846\u67b6\u5728\u8de8\u7c7b\u522b\u3001\u8de8\u5173\u952e\u70b9\u4efb\u52a1\u4e2d\u7684\u5c0f\u6837\u672c\u5feb\u901f\u6536\u655b\u80fd\u529b\uff0c\u6269\u5c55\u4e86\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u5e94\u7528\u8fb9\u754c\u3002|\n",
    "2507.11102": "|2025-07-15|KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model|Jie Yang\u7b49|[2507.11102](http://arxiv.org/pdf/2507.11102)|\u65e0|\u25c6 \u63d0\u51faKptLLM++\uff0c\u9996\u4e2a\u4e13\u7528\u4e8e\u901a\u7528\u5173\u952e\u70b9\u7406\u89e3\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u7528\u6237\u6307\u4ee4\u6574\u5408\u591a\u6837\u5316\u8f93\u5165\u6a21\u6001\uff0c\u586b\u8865\u4e86MLLMs\u5728\u7ec6\u7c92\u5ea6\u8bed\u4e49\u6355\u6349\u4e0a\u7684\u7a7a\u767d\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\"\u5148\u8bc6\u522b\u540e\u68c0\u6d4b\"\u8303\u5f0f\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u63a8\u7406\u673a\u5236\uff0c\u5148\u89e3\u6790\u5173\u952e\u70b9\u8bed\u4e49\u518d\u7cbe\u786e\u5b9a\u4f4d\uff0c\u63d0\u5347\u590d\u6742\u573a\u666f\u4e0b\u7684\u7406\u89e3\u80fd\u529b\u3002  \n\u25c6 \u6784\u5efa\u8d8550\u4e07\u6837\u672c\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u8986\u76d6\u591a\u6837\u7269\u4f53\u3001\u5173\u952e\u70b9\u7c7b\u522b\u3001\u56fe\u50cf\u98ce\u683c\u53ca\u906e\u6321\u573a\u666f\uff0c\u663e\u8457\u589e\u5f3a\u6a21\u578b\u6cdb\u5316\u6027\u3002  \n\u25c6 \u5b9e\u73b0\u8de8\u573a\u666f\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5efa\u7acb\u9ad8\u6548\u4eba\u673a\u534f\u4f5c\u63a5\u53e3\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u56fe\u50cf\u5206\u6790\u3001\u7269\u4f53\u68c0\u7d22\u548c\u884c\u4e3a\u8bc6\u522b\u7b49\u5e94\u7528\u3002  \n\u25c6 \u5728\u591a\u4e2a\u5173\u952e\u70b9\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f5c\u4e3a\u7edf\u4e00\u7ec6\u7c92\u5ea6\u56fe\u50cf\u7406\u89e3\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\u3002  \n\u25c6 \u4e3aAI\u7406\u89e3\u7ed3\u6784\u5316\u50cf\u7d20\u7ea7\u8bed\u4e49\u4fe1\u606f\u63d0\u4f9b\u65b0\u601d\u8def\uff0c\u5bf9\u63a8\u52a8\u4eba\u673a\u4ea4\u4e92\u53d8\u9769\u5177\u6709\u91cd\u8981\u542f\u793a\u610f\u4e49\u3002|\n",
    "2507.11077": "|2025-07-15|GKNet: Graph-based Keypoints Network for Monocular Pose Estimation of Non-cooperative Spacecraft|Weizhao Ma\u7b49|[2507.11077](http://arxiv.org/pdf/2507.11077)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u5173\u952e\u70b9\u7f51\u7edcGKNet\uff0c\u5229\u7528\u5173\u952e\u70b9\u95f4\u7684\u51e0\u4f55\u7ea6\u675f\u5173\u7cfb\u63d0\u5347\u975e\u5408\u4f5c\u822a\u5929\u5668\u5355\u76ee\u59ff\u6001\u4f30\u8ba1\u7684\u7cbe\u5ea6\u3002  \n\u25c6 \u9488\u5bf9\u822a\u5929\u5668\u7ed3\u6784\u5bf9\u79f0\u6027\u548c\u5c40\u90e8\u906e\u6321\u95ee\u9898\uff0c\u901a\u8fc7\u56fe\u7f51\u7edc\u5efa\u6a21\u5173\u952e\u70b9\u62d3\u6251\u5173\u7cfb\uff0c\u589e\u5f3a\u68c0\u6d4b\u9c81\u68d2\u6027\u3002  \n\u25c6 \u6784\u5efa\u4e2d\u7b49\u89c4\u6a21\u822a\u5929\u5668\u5173\u952e\u70b9\u68c0\u6d4b\u6570\u636e\u96c6SKD\uff0c\u5305\u542b3\u79cd\u822a\u5929\u5668\u76ee\u6807\u30019\u4e07\u5f20\u4eff\u771f\u56fe\u50cf\u53ca\u9ad8\u7cbe\u5ea6\u6807\u6ce8\uff0c\u586b\u8865\u9886\u57df\u6570\u636e\u7a7a\u767d\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eGKNet\u5728\u5173\u952e\u70b9\u68c0\u6d4b\u7cbe\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u590d\u6742\u7a7a\u95f4\u573a\u666f\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\uff0c\u4e3a\u5728\u8f68\u670d\u52a1\u4efb\u52a1\uff08\u5982\u536b\u661f\u7ef4\u62a4\u3001\u592a\u7a7a\u788e\u7247\u6e05\u7406\uff09\u63d0\u4f9b\u53ef\u9760\u6280\u672f\u652f\u6491\u3002|\n",
    "2507.10770": "|2025-07-14|FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching|Ionu\u0163 Grigore\u7b49|[2507.10770](http://arxiv.org/pdf/2507.10770)|\u65e0|\u25c6\u63d0\u51faFPC-Net\uff0c\u901a\u8fc7\u7279\u5f81\u91d1\u5b57\u5854\u548c\u57fa\u4e8e\u4e00\u81f4\u6027\u7684\u9690\u5f0f\u5339\u914d\u5b9e\u73b0\u65e0\u63cf\u8ff0\u7b26\u7684\u5173\u952e\u70b9\u68c0\u6d4b\uff0c\u91cd\u65b0\u6539\u8fdb\u4e86SuperPoint\u65b9\u6cd5\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u5728\u5173\u952e\u70b9\u68c0\u6d4b\u9636\u6bb5\u76f4\u63a5\u5efa\u7acb\u5173\u8054\u6027\uff0c\u7701\u53bb\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u63cf\u8ff0\u7b26\u7684\u8ba1\u7b97\u3001\u5b58\u50a8\u3001\u4f20\u8f93\u548c\u5339\u914d\u6b65\u9aa4\u3002  \n\u25c6\u5c3d\u7ba1\u5339\u914d\u7cbe\u5ea6\u7565\u4f4e\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5b8c\u5168\u6d88\u9664\u4e86\u63cf\u8ff0\u7b26\u9700\u6c42\uff0c\u5927\u5e45\u964d\u4f4e\u4e86\u5b9a\u4f4d\u7cfb\u7edf\u7684\u5185\u5b58\u5360\u7528\u3002  \n\u25c6\u901a\u8fc7\u7279\u5f81\u91d1\u5b57\u5854\u548c\u4e00\u81f4\u6027\u5339\u914d\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u8f7b\u91cf\u5316\u7684\u5173\u952e\u70b9\u68c0\u6d4b\u4e0e\u5339\u914d\u6d41\u7a0b\u3002  \n\u25c6\u5728\u5b9e\u9a8c\u4e2d\u5bf9\u6bd4\u4e86\u4f20\u7edf\u624b\u5de5\u65b9\u6cd5\u548c\u73b0\u4ee3\u5b66\u4e60\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002  \n\u25c6\u4e3a\u51e0\u4f55\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7b80\u6d01\u3001\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u5e94\u7528\u573a\u666f\u3002|\n",
    "2507.13145": "|2025-07-17|DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model|Maulana Bisyir Azhari\u7b49|[2507.13145](http://arxiv.org/pdf/2507.13145)|\u65e0|\u25c6 \u63d0\u51faDINO-VO\u7cfb\u7edf\uff0c\u9996\u6b21\u5c06\u89c6\u89c9\u57fa\u7840\u6a21\u578bDINOv2\u7684\u9c81\u68d2\u8bed\u4e49\u7279\u5f81\u5e94\u7528\u4e8e\u5355\u76ee\u89c6\u89c9\u91cc\u7a0b\u8ba1\uff08VO\uff09\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5b66\u4e60\u578bVO\u5728\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u4e0a\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u9488\u5bf9DINOv2\u7279\u5f81\u7c92\u5ea6\u7c97\u7cd9\u7684\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u4e13\u7528\u663e\u8457\u5173\u952e\u70b9\u68c0\u6d4b\u5668\uff0c\u6709\u6548\u63d0\u5347\u7a00\u758f\u7279\u5f81\u5339\u914d\u7684\u7cbe\u5ea6\u3002  \n\u25c6 \u7ed3\u5408DINOv2\u7684\u8bed\u4e49\u7279\u5f81\u4e0e\u7ec6\u7c92\u5ea6\u51e0\u4f55\u7279\u5f81\uff0c\u751f\u6210\u517c\u5177\u9c81\u68d2\u6027\u548c\u5c40\u90e8\u5316\u80fd\u529b\u7684\u6df7\u5408\u7279\u5f81\u8868\u793a\u3002  \n\u25c6 \u91c7\u7528\u57fa\u4e8eTransformer\u7684\u5339\u914d\u5668\u548c\u53ef\u5fae\u5206\u4f4d\u59ff\u4f30\u8ba1\u5c42\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u5b66\u4e60\u4f18\u5316\u7279\u5f81\u5339\u914d\u4e0e\u8fd0\u52a8\u4f30\u8ba1\u3002  \n\u25c6 \u5728TartanAir\u3001KITTI\u7b49\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u4f20\u7edf\u5e27\u95f4VO\u65b9\u6cd5\uff08\u5982SuperPoint\uff09\uff0c\u5e76\u5728\u5ba4\u5916\u9a7e\u9a76\u573a\u666f\u4e2d\u4e0e\u89c6\u89c9SLAM\u7cfb\u7edf\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u630172 FPS\u5b9e\u65f6\u6027\u3002  \n\u25c6 \u7cfb\u7edf\u5185\u5b58\u5360\u7528\u4f4e\u4e8e1GB\uff0c\u5c55\u73b0\u4e86\u9ad8\u6548\u90e8\u7f72\u6f5c\u529b\uff0c\u4e3a\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u5728\u5b9e\u65f6\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002|\n",
    "2507.17327": "|2025-07-23|CartoonAlive: Towards Expressive Live2D Modeling from Single Portraits|Chao He\u7b49|[2507.17327](http://arxiv.org/pdf/2507.17327)|\u65e0|\u25c6 \u63d0\u51faCartoonAlive\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u4ece\u5355\u5f20\u8096\u50cf\u7167\u7247\u5feb\u901f\u751f\u6210\u9ad8\u8d28\u91cfLive2D\u5361\u901a\u6a21\u578b\uff0c\u8017\u65f6\u4e0d\u8db330\u79d2\u3002  \n\u25c6 \u521b\u65b0\u5730\u5c063D\u4eba\u8138\u5efa\u6a21\u4e2d\u7684\u5f62\u72b6\u57fa\u6982\u5ff5\u5f15\u51652D\u9886\u57df\uff0c\u6784\u5efa\u9002\u7528\u4e8eLive2D\u7684\u9762\u90e8\u6df7\u5408\u5f62\u72b6\u7cfb\u7edf\u3002  \n\u25c6 \u901a\u8fc7\u9762\u90e8\u5173\u952e\u70b9\u68c0\u6d4b\u81ea\u52a8\u63a8\u65ad\u6df7\u5408\u5f62\u72b6\u6743\u91cd\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u5373\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8868\u60c5\u9a71\u52a8\u3002  \n\u25c6 \u91c7\u7528\u5206\u5c42\u5206\u5272\u6280\u672f\u6a21\u62df3D\u8fd0\u52a8\u6548\u679c\uff0c\u5728\u4fdd\u63012D\u5361\u901a\u98ce\u683c\u7684\u540c\u65f6\u5b9e\u73b0\u7c7b\u4f3c3D\u7684\u5b9e\u65f6\u52a8\u6001\u64cd\u63a7\u3002  \n\u25c6 \u76f8\u6bd4\u4f20\u7edf3D\u5efa\u6a21\u65b9\u6848\u5927\u5e45\u964d\u4f4e\u5236\u4f5c\u6210\u672c\uff0c\u76f8\u6bd42D\u89c6\u9891\u65b9\u6848\u663e\u8457\u63d0\u5347\u4ea4\u4e92\u7075\u6d3b\u6027\u3002  \n\u25c6 \u4e3a\u6570\u5b57\u5185\u5bb9\u521b\u4f5c\u63d0\u4f9b\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u62d3\u5c55\u4e86\u865a\u62df\u89d2\u8272\u52a8\u753b\u7684\u5e94\u7528\u573a\u666f\u3002|\n",
    "2507.16850": "|2025-07-21|Toward a Real-Time Framework for Accurate Monocular 3D Human Pose Estimation with Geometric Priors|Mohamed Adjel|[2507.16850](http://arxiv.org/pdf/2507.16850)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u65f6\u5355\u76ee3D\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u6846\u67b6\uff0c\u7ed3\u54082D\u5173\u952e\u70b9\u68c0\u6d4b\u4e0e\u51e0\u4f55\u611f\u77e5\u76842D\u52303D\u63d0\u5347\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u65e0\u7ea6\u675f\u73af\u5883\u4e0b\u7684\u6027\u80fd\u3002  \n\u25c6 \u663e\u5f0f\u5229\u7528\u76f8\u673a\u5185\u53c2\u548c\u4e2a\u6027\u5316\u89e3\u5256\u5b66\u5148\u9a8c\u77e5\u8bc6\uff0c\u901a\u8fc7\u81ea\u6821\u51c6\u548c\u751f\u7269\u529b\u5b66\u7ea6\u675f\u7684\u53cd\u5411\u8fd0\u52a8\u5b66\u589e\u5f3a\u6a21\u578b\u7cbe\u5ea6\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u4ece\u52a8\u4f5c\u6355\u6349\u548c\u5408\u6210\u6570\u636e\u96c6\u4e2d\u751f\u6210\u5927\u89c4\u6a21\u5408\u7406\u76842D-3D\u8bad\u7ec3\u5bf9\uff0c\u89e3\u51b3\u4e86\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002  \n\u25c6 \u6846\u67b6\u65e0\u9700\u4e13\u7528\u786c\u4ef6\u5373\u53ef\u5b9e\u73b0\u5feb\u901f\u3001\u4e2a\u6027\u5316\u7684\u9ad8\u7cbe\u5ea63D\u59ff\u6001\u4f30\u8ba1\uff0c\u5177\u6709\u5f3a\u90e8\u7f72\u9002\u5e94\u6027\u3002  \n\u25c6 \u878d\u5408\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u4e0e\u6a21\u578b\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u63d0\u5347\u51c6\u786e\u6027\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u80fd\u529b\u3002|\n",
    "2507.18551": "|2025-07-24|A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration|Daniil Morozov\u7b49|[2507.18551](http://arxiv.org/pdf/2507.18551)|\u65e0|\u25c6\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b3D\u8de8\u6a21\u6001\u5173\u952e\u70b9\u63cf\u8ff0\u7b26\uff0c\u4e13\u95e8\u7528\u4e8e\u89e3\u51b3MRI\u4e0e\u5b9e\u65f6\u8d85\u58f0(iUS)\u4e4b\u95f4\u7684\u914d\u51c6\u96be\u9898\uff0c\u514b\u670d\u4e86\u4e24\u79cd\u6a21\u6001\u5728\u5916\u89c2\u3001\u5206\u8fa8\u7387\u548c\u89c6\u91ce\u4e0a\u7684\u663e\u8457\u5dee\u5f02\u3002  \n\u25c6\u91c7\u7528\u60a3\u8005\u7279\u5f02\u6027\u7684\u5408\u6210\u5339\u914d\u65b9\u6cd5\uff0c\u4ece\u672f\u524dMRI\u751f\u6210\u5408\u6210iUS\u4f53\u79ef\uff0c\u901a\u8fc7\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u8bad\u7ec3\u5171\u4eab\u63cf\u8ff0\u7b26\u7a7a\u95f4\uff0c\u589e\u5f3a\u4e86\u8de8\u6a21\u6001\u5339\u914d\u80fd\u529b\u3002  \n\u25c6\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u6982\u7387\u7684\u5173\u952e\u70b9\u68c0\u6d4b\u7b56\u7565\uff0c\u80fd\u591f\u8bc6\u522b\u89e3\u5256\u5b66\u663e\u8457\u4e14\u6a21\u6001\u4e00\u81f4\u7684\u4f4d\u7f6e\uff0c\u63d0\u9ad8\u4e86\u5173\u952e\u70b9\u7684\u53ef\u9760\u6027\u548c\u4e00\u81f4\u6027\u3002  \n\u25c6\u5728\u8bad\u7ec3\u9636\u6bb5\u5f15\u5165\u8bfe\u7a0b\u5f0f\u4e09\u5143\u7ec4\u635f\u5931\u548c\u52a8\u6001\u96be\u8d1f\u6837\u672c\u6316\u6398\uff0c\u4f7f\u63cf\u8ff0\u7b26\u5bf9iUS\u4f2a\u5f71\uff08\u5982\u6591\u70b9\u566a\u58f0\u548c\u6709\u9650\u8986\u76d6\uff09\u5177\u6709\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u65cb\u8f6c\u4e0d\u53d8\u6027\u3002  \n\u25c6\u5728\u63a8\u7406\u9636\u6bb5\uff0c\u901a\u8fc7\u7a00\u758f\u5339\u914d\u5b9e\u73b0\u521a\u6027\u914d\u51c6\uff0c\u65e0\u9700\u4eba\u5de5\u521d\u59cb\u5316\uff0c\u4e14\u5728ReMIND\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\uff0c\u5e73\u5747\u5339\u914d\u7cbe\u5ea6\u8fbe69.8%\uff0c\u914d\u51c6\u8bef\u5dee\u4f4e\u81f32.39 mm\u3002  \n\u25c6\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u5177\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u5bf9iUS\u89c6\u91ce\u53d8\u5316\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\uff0c\u4fbf\u4e8e\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5e94\u7528\u3002|\n",
    "2507.19118": "|2025-07-25|Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching|Abu Sadat Mohammad Salehin Amit\u7b49|[2507.19118](http://arxiv.org/pdf/2507.19118)|\u65e0|\u25c6\u63d0\u51fa\u8de8\u65f6\u7a7a\u878d\u5408\u6ce8\u610f\u529b\u673a\u5236(CSTF)\uff0c\u901a\u8fc7\u72ec\u7acb\u68c0\u6d4b\u53c2\u8003\u56fe\u50cf\u548c\u67e5\u8be2\u56fe\u50cf\u4e2d\u7684\u5c3a\u5ea6\u4e0d\u53d8\u5173\u952e\u70b9\u6765\u589e\u5f3a\u7279\u5f81\u8868\u793a\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u9065\u611f\u56fe\u50cf\u95f4\u51e0\u4f55\u548c\u8f90\u5c04\u5dee\u5f02\u5927\u7684\u95ee\u9898\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u6784\u5efa\u5bf9\u5e94\u5173\u7cfb\u56fe\uff0c\u540c\u65f6\u5229\u7528\u591a\u4e2a\u56fe\u50cf\u533a\u57df\u7684\u4fe1\u606f\uff0c\u6709\u6548\u6355\u6349\u8de8\u6a21\u6001\u76f8\u4f3c\u6027\uff0c\u514b\u670d\u4f20\u7edf\u5168\u8fde\u63a5\u5c42\u7279\u5f81\u63d0\u53d6\u7684\u5c40\u9650\u6027\u3002  \n\u25c6\u5c06\u76f8\u4f3c\u6027\u5339\u914d\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u7ed3\u5408SoftMax\u548c\u5168\u5377\u79ef\u7f51\u7edc(FCN)\u5c42\uff0c\u5728\u4fdd\u6301\u5c40\u90e8\u7279\u5f81\u654f\u611f\u6027\u7684\u540c\u65f6\u6574\u5408\u5168\u5c40\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002  \n\u25c6\u5728HRSC2016\u548cDOTA\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684\u6700\u4f18\u6027\u80fd\uff0c\u5e73\u5747mAP\u5206\u522b\u8fbe\u523090.99%\u548c90.86%\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u6a21\u578b\u3002  \n\u25c6\u4fdd\u630112.5 FPS\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u7cbe\u5ea6\u7684\u540c\u65f6\u5177\u5907\u5b9e\u9645\u5e94\u7528\u7684\u9ad8\u6548\u6027\u3002  \n\u25c6\u9a8c\u8bc1\u4e86\u6539\u8fdb\u7684\u8de8\u6a21\u6001\u7279\u5f81\u5339\u914d\u80fd\u76f4\u63a5\u63d0\u5347\u9065\u611f\u76ee\u6807\u68c0\u6d4b\u7b49\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff0c\u4e3a\u591a\u6a21\u6001\u9065\u611f\u5206\u6790\u63d0\u4f9b\u65b0\u601d\u8def\u3002|\n",
    "2507.23461": "|2025-07-31|Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection|Taeheon Lim\u7b49|[2507.23461](http://arxiv.org/pdf/2507.23461)|\u65e0|\u25c6 \u9996\u6b21\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u63d0\u51fa\u5e76\u7cfb\u7edf\u7814\u7a76\u4e86\"\u5206\u8fa8\u7387\u6f02\u79fb\"\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u5206\u8fa8\u7387\u5dee\u5f02\u4f5c\u4e3a\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u7684\u65b0\u7ef4\u5ea6\u5bf9\u5173\u952e\u70b9\u68c0\u6d4b\u4efb\u52a1\u7684\u91cd\u8981\u5f71\u54cd\u3002  \n\u25c6 \u63d0\u51fa\u5206\u8fa8\u7387\u81ea\u9002\u5e94\u8054\u90a6\u5b66\u4e60\uff08RAF\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u70ed\u56fe\u7684\u591a\u5206\u8fa8\u7387\u77e5\u8bc6\u84b8\u998f\u673a\u5236\uff0c\u5728\u9ad8\u5206\u8fa8\u7387\u6559\u5e08\u6a21\u578b\u548c\u4f4e\u5206\u8fa8\u7387\u5b66\u751f\u6a21\u578b\u95f4\u4f20\u9012\u77e5\u8bc6\uff0c\u6709\u6548\u589e\u5f3a\u6a21\u578b\u5bf9\u5206\u8fa8\u7387\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u9ad8\u4f4e\u5206\u8fa8\u7387\u53cc\u5411\u84b8\u998f\u7b56\u7565\uff0c\u65e2\u907f\u514d\u4e86\u4f4e\u5206\u8fa8\u7387\u5ba2\u6237\u7aef\u8fc7\u62df\u5408\uff0c\u53c8\u4fdd\u7559\u4e86\u9ad8\u5206\u8fa8\u7387\u7a7a\u95f4\u7ec6\u8282\u7279\u5f81\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u5728\u975e\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u3002  \n\u25c6 \u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660eRAF\u4e0d\u4ec5\u80fd\u663e\u8457\u7f13\u89e3\u5206\u8fa8\u7387\u6f02\u79fb\uff08\u6700\u9ad8\u63d0\u534723.6%\u51c6\u786e\u7387\uff09\uff0c\u8fd8\u80fd\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e2d\uff0c\u5177\u6709\u5f3a\u5b9e\u7528\u6027\u3002  \n\u25c6 \u901a\u8fc7t-SNE\u53ef\u89c6\u5316\u5206\u6790\uff0c\u9996\u6b21\u63ed\u793a\u4e86\u5206\u7c7b\u4efb\u52a1\u4e0e\u9ad8\u5206\u8fa8\u7387\u8868\u5f81\u4efb\u52a1\u5728\u7279\u5f81\u5206\u5e03\u4e0a\u7684\u672c\u8d28\u5dee\u5f02\uff0c\u4e3aRAF\u65b9\u6cd5\u6269\u5c55\u5230\u5176\u4ed6\u9700\u8981\u4fdd\u6301\u7a7a\u95f4\u7ec6\u8282\u7684\u4efb\u52a1\uff08\u5982\u533b\u7597\u5f71\u50cf\u5206\u6790\uff09\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002  \n\u25c6 \u5f00\u8f9f\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u7b49\u975e\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u65b0\u7814\u7a76\u65b9\u5411\uff0c\u4e3a\u89e3\u51b3\u8de8\u8bbe\u5907\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5206\u8fa8\u7387\u5f02\u6784\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2508.05514": "|2025-08-07|Head Anchor Enhanced Detection and Association for Crowded Pedestrian Tracking|Zewei Wu\u7b49|[2508.05514](http://arxiv.org/pdf/2508.05514)|\u65e0|\u25c6 \u63d0\u51fa\u878d\u5408\u76ee\u6807\u68c0\u6d4b\u5668\u56de\u5f52\u5206\u652f\u548c\u5206\u7c7b\u5206\u652f\u7279\u5f81\u7684\u53cc\u91cd\u7279\u5f81\u589e\u5f3a\u7b56\u7565\uff0c\u5c06\u7a7a\u95f4\u4f4d\u7f6e\u4fe1\u606f\u76f4\u63a5\u5d4c\u5165\u7279\u5f81\u8868\u793a\uff0c\u63d0\u5347\u5916\u89c2\u5efa\u6a21\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5f15\u5165\u5934\u90e8\u5173\u952e\u70b9\u68c0\u6d4b\u6a21\u5757\uff0c\u5229\u7528\u5934\u90e8\u4e0d\u6613\u88ab\u906e\u6321\u7684\u7279\u6027\uff0c\u6709\u6548\u7f13\u89e3\u5bc6\u96c6\u573a\u666f\u4e2d\u5168\u8eab\u7279\u5f81\u4e22\u5931\u5bfc\u81f4\u7684\u8ddf\u8e2a\u5931\u6548\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u8fed\u4ee3\u5f0f\u5361\u5c14\u66fc\u6ee4\u6ce2\u8fd0\u52a8\u6a21\u578b\uff0c\u7a81\u7834\u4f20\u7edf\u7ebf\u6027\u5300\u901f\u5047\u8bbe\uff0c\u7ed3\u54083D\u573a\u666f\u5148\u9a8c\u77e5\u8bc6\u5b9e\u73b0\u590d\u6742\u906e\u6321\u4e0b\u7684\u8f68\u8ff9\u8865\u5168\u3002  \n\u25c6 \u9996\u6b21\u5c06\u68c0\u6d4b\u4efb\u52a1\u7684\u591a\u7ef4\u5ea6\u7279\u5f81\uff08\u5206\u7c7b/\u56de\u5f52/\u5173\u952e\u70b9\uff09\u4e0e\u6539\u8fdb\u8fd0\u52a8\u6a21\u578b\u8054\u5408\u4f18\u5316\uff0c\u5f62\u6210\u5916\u89c2-\u8fd0\u52a8\u534f\u540c\u589e\u5f3a\u7684\u8ddf\u8e2a\u6846\u67b6\u3002  \n\u25c6 \u9488\u5bf9\u4e25\u91cd\u906e\u6321\u573a\u666f\uff0c\u901a\u8fc7\u5934\u90e8\u5b9a\u4f4d\u4e0e\u5168\u8eab\u68c0\u6d4b\u7684\u5f02\u6784\u7279\u5f81\u4e92\u8865\uff0c\u663e\u8457\u63d0\u5347\u5bc6\u96c6\u4eba\u7fa4\u7684\u8f68\u8ff9\u8fde\u7eed\u6027\u548cID\u4fdd\u6301\u80fd\u529b\u3002  \n\u25c6 \u6240\u63d0\u65b9\u6cd5\u5728\u4fdd\u6301\u5b9e\u65f6\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u5bf9\u91cd\u53e0\u7387\u8d85\u8fc770%\u7684\u6781\u7aef\u906e\u6321\u60c5\u51b5\u5c55\u73b0\u51fa\u4f18\u4e8e\u4f20\u7edfRe-ID\u65b9\u6848\u7684\u8ddf\u8e2a\u7a33\u5b9a\u6027\u3002|\n",
    "2508.07112": "|2025-08-16|AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation|Nikolai Warner\u7b49|[2508.07112](http://arxiv.org/pdf/2508.07112)|\u65e0|\u25c6 \u63d0\u51faAugLift\u65b9\u6cd5\uff0c\u901a\u8fc7\u7b80\u5355\u4f46\u6709\u6548\u7684\u8f93\u5165\u589e\u5f3a\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e2D\u5173\u952e\u70b9\u63d0\u5347\u76843D\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u6570\u636e\u6216\u4f20\u611f\u5668\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5728\u6807\u51c62D\u5173\u952e\u70b9\u5750\u6807(x,y)\u57fa\u7840\u4e0a\uff0c\u7a00\u758f\u5730\u589e\u52a0\u4e86\u5173\u952e\u70b9\u68c0\u6d4b\u7f6e\u4fe1\u5ea6c\u548c\u5bf9\u5e94\u6df1\u5ea6\u4f30\u8ba1d\u4e24\u4e2a\u4fe1\u53f7\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8ba1\u7b97\u8fd9\u4e9b\u4fe1\u53f7\uff0c\u7ee7\u627f\u4e86\u5b83\u4eec\u7684\u5f3a\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u65b9\u6cd5\u5177\u6709\u6a21\u5757\u5316\u7279\u6027\uff0c\u53ef\u4ee5\u8f7b\u677e\u96c6\u6210\u5230\u73b0\u6709\u7684\u5404\u79cd\u63d0\u5347\u67b6\u6784\u4e2d\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u7ed3\u6784\u3002  \n\u25c6 \u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cAugLift\u5c06\u672a\u89c1\u6570\u636e\u96c6\u7684\u8de8\u6570\u636e\u96c6\u6027\u80fd\u5e73\u5747\u63d0\u534710.1%\uff0c\u540c\u65f6\u5c06\u5206\u5e03\u5185\u6027\u80fd\u63d0\u53474.0%\u3002  \n\u25c6 \u5206\u6790\u8868\u660e\uff0c\u8fd9\u4e9b\u7a00\u758f\u7684\u5173\u952e\u70b9\u5bf9\u9f50\u7ebf\u7d22\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u5e27\u7ea7\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4e3a\u63d0\u5347\u4efb\u4f55\u57fa\u4e8e\u63d0\u5347\u7684\u59ff\u6001\u4f30\u8ba1\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\u3002  \n\u25c6 \u6240\u6709\u4ee3\u7801\u5c06\u516c\u5f00\uff0c\u4fbf\u4e8e\u7814\u7a76\u793e\u533a\u4f7f\u7528\u548c\u590d\u73b0\u3002|\n",
    "2508.09949": "|2025-08-13|Stable Diffusion Models are Secretly Good at Visual In-Context Learning|Trevine Oorloff\u7b49|[2508.09949](http://arxiv.org/pdf/2508.09949)|\u65e0|\u25c6 \u63ed\u793a\u4e86\u73b0\u6210Stable Diffusion\u6a21\u578b\u5177\u5907\u89c6\u89c9\u4e0a\u4e0b\u6587\u5b66\u4e60\u6f5c\u529b\uff0c\u65e0\u9700\u4e13\u95e8\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u591a\u79cd\u89c6\u89c9\u4efb\u52a1\u3002  \n\u25c6 \u63d0\u51fa\u539f\u4f4d\u6ce8\u610f\u529b\u91cd\u8ba1\u7b97\u673a\u5236\uff0c\u901a\u8fc7\u6539\u9020\u81ea\u6ce8\u610f\u529b\u5c42\u663e\u5f0f\u878d\u5408\u67e5\u8be2\u4e0e\u793a\u4f8b\u63d0\u793a\u7684\u4e0a\u4e0b\u6587\u5173\u7cfb\u3002  \n\u25c6 \u9996\u6b21\u5b9e\u73b0\u5355\u4e00\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u5728\u516d\u5927\u89c6\u89c9\u4efb\u52a1\uff08\u5982\u524d\u666f\u5206\u5272\u3001\u76ee\u6807\u68c0\u6d4b\u7b49\uff09\u7684\u96f6\u6837\u672c\u8fc1\u79fb\uff0c\u7a81\u7834\u73b0\u6709\u65b9\u6cd5\u9700\u5b9a\u5236\u5316\u8bad\u7ec3\u7684\u5c40\u9650\u3002  \n\u25c6 \u5728Pascal-5i\u6570\u636e\u96c6\u4e0a\uff0c\u524d\u666f\u5206\u5272\u4efb\u52a1mIoU\u6307\u6807\u5206\u522b\u8d85\u8d8aVisual Prompting\u548cIMProv\u65b9\u6cd58.9%\u548c3.2%\u3002  \n\u25c6 \u901a\u8fc7\u96c6\u6210\u591a\u63d0\u793a\u6837\u672c\u63d0\u5347\u4efb\u52a1\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u6a21\u578b\u80fd\u6709\u6548\u5229\u7528\u4e0a\u4e0b\u6587\u793a\u4f8b\u63d0\u5347\u6027\u80fd\u3002  \n\u25c6 \u4e3a\u89c6\u89c9\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u4f9b\u8f7b\u91cf\u5316\u65b0\u8303\u5f0f\uff0c\u4ec5\u9700\u4fee\u6539\u6ce8\u610f\u529b\u673a\u5236\u4e14\u4fdd\u6301\u6a21\u578b\u6743\u91cd\u51bb\u7ed3\uff0c\u663e\u8457\u63d0\u5347\u901a\u7528\u6027\u3002|\n",
    "2508.10942": "|2025-08-13|Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram|Liming Xu\u7b49|[2508.10942](http://arxiv.org/pdf/2508.10942)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7279\u5f81\u63cf\u8ff0\u7b26\u2014\u2014\u65b9\u5411\u76f4\u65b9\u56fe\u5f62\u72b6\uff08shape of orientation histogram\uff09\uff0c\u7528\u4e8e\u63cf\u8ff0Artcode\u7684\u901a\u7528\u62d3\u6251\u7ed3\u6784\u3002  \n\u25c6 \u5c06Artcode\u8bc6\u522b\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3aArtcode\u63d0\u6848\u68c0\u6d4b\u4efb\u52a1\uff0c\u5c06\u62d3\u6251\u76f8\u4f3c\u4f46\u51e0\u4f55\u548c\u8bed\u4e49\u4e0d\u540c\u7684\u5bf9\u8c61\u5f52\u4e3a\u540c\u4e00\u7c7b\u522b\u3002  \n\u25c6 \u6784\u5efa\u4e86\u4e13\u95e8\u7684\u6570\u636e\u96c6\u5e76\u8fdb\u884c\u5168\u9762\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7279\u5f81\u5411\u91cf\u5728\u8868\u793a\u62d3\u6251\u7ed3\u6784\u65b9\u9762\u7684\u53ef\u884c\u6027\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u57fa\u4e8e\u8be5\u7279\u5f81\u5411\u91cf\u7684Artcode\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5176\u68c0\u6d4b\u6548\u679c\u663e\u8457\u3002  \n\u25c6 \u9996\u6b21\u5c1d\u8bd5\u5f00\u53d1\u57fa\u4e8e\u7279\u5f81\u7684\u62d3\u6251\u5bf9\u8c61\u68c0\u6d4b\u7cfb\u7edf\uff0c\u4e3aArtcode\u7b49\u62d3\u6251\u5bf9\u8c61\u7684\u8bc6\u522b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002  \n\u25c6 \u8be5\u7814\u7a76\u4e3a\u865a\u5b9e\u4ea4\u4e92\u5f00\u8f9f\u4e86\u65b0\u673a\u4f1a\uff0c\u5e76\u5c55\u793a\u4e86\u62d3\u6251\u5bf9\u8c61\u68c0\u6d4b\u7684\u6f5c\u5728\u5e94\u7528\u524d\u666f\u3002|\n",
    "2508.12216": "|2025-08-17|Splat Feature Solver|Butian Xiong\u7b49|[2508.12216](http://arxiv.org/pdf/2508.12216)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u4e14\u4e0e\u6838\u51fd\u6570\u53ca\u7279\u5f81\u65e0\u5173\u7684\u7279\u5f81\u63d0\u5347\u95ee\u9898\u7a00\u758f\u7ebf\u6027\u9006\u95ee\u9898\u516c\u5f0f\u5316\u65b9\u6cd5\uff0c\u53ef\u901a\u8fc7\u95ed\u5f0f\u89e3\u9ad8\u6548\u6c42\u89e3\u3002  \n\u25c6 \u5728\u51f8\u635f\u5931\u51fd\u6570\u4e0b\u63d0\u4f9b\u4e86\u5168\u5c40\u6700\u4f18\u8bef\u5dee\u7684\u53ef\u8bc1\u660e\u4e0a\u754c\uff0c\u786e\u4fdd\u9ad8\u8d28\u91cf\u7684\u7279\u5f81\u63d0\u5347\u7ed3\u679c\u3002  \n\u25c6 \u5f15\u5165\u4e24\u79cd\u4e92\u8865\u7684\u6b63\u5219\u5316\u7b56\u7565\uff08Tikhonov Guidance\u548cPost-Lifting Aggregation\uff09\u4ee5\u89e3\u51b3\u591a\u89c6\u89d2\u89c2\u6d4b\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u548c\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u5347\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002  \n\u25c6 Tikhonov Guidance\u901a\u8fc7\u8f6f\u5bf9\u89d2\u4f18\u52bf\u786e\u4fdd\u6570\u503c\u7a33\u5b9a\u6027\uff0cPost-Lifting Aggregation\u901a\u8fc7\u7279\u5f81\u805a\u7c7b\u8fc7\u6ee4\u566a\u58f0\u8f93\u5165\u3002  \n\u25c6 \u5728\u5f00\u653e\u8bcd\u6c473D\u5206\u5272\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u4e8e\u8bad\u7ec3\u3001\u5206\u7ec4\u548c\u542f\u53d1\u5f0f\u7684\u524d\u6cbf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u7279\u5f81\u63d0\u5347\u4ec5\u9700\u6570\u5206\u949f\u5b8c\u6210\u3002|\n",
    "2508.15300": "|2025-08-21|Mag-Match: Magnetic Vector Field Features for Map Matching and Registration|William McDonald\u7b49|[2508.15300](http://arxiv.org/pdf/2508.15300)|\u65e0|Mag-Match\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4e09\u7ef4\u78c1\u573a\u77e2\u91cf\u7279\u5f81\u8fdb\u884c\u5730\u56fe\u5339\u914d\u4e0e\u6ce8\u518c\u7684\u65b0\u65b9\u6cd5\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u7528\u78c1\u529b\u8ba1\u6570\u636e\u63d0\u53d6\u9ad8\u9636\u5bfc\u6570\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u5bf9\u89c6\u89c9\u6216\u6fc0\u5149\u4f20\u611f\u5668\u5931\u6548\u7684\u70df\u96fe\u3001\u7c89\u5c18\u7b49\u6076\u52a3\u73af\u5883\u5177\u6709\u9c81\u68d2\u6027\u3002  \n\u25c6 \u6240\u63d0\u51fa\u7684\u78c1\u573a\u7279\u5f81\u63cf\u8ff0\u5b50\u5177\u6709\u5168\u5c40\u65cb\u8f6c\u4e0d\u53d8\u6027\uff0c\u65e0\u9700\u4f9d\u8d56\u91cd\u529b\u65b9\u5411\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u540c\u5730\u56fe\u6216\u4e0d\u540c\u673a\u5668\u4eba\u6570\u636e\u4e4b\u95f4\u7684\u914d\u51c6\u7075\u6d3b\u6027\u3002  \n\u25c6 \u91c7\u7528\u7269\u7406\u4fe1\u606f\u9ad8\u65af\u8fc7\u7a0b\u8fdb\u884c\u6982\u7387\u63a8\u7406\uff0c\u80fd\u591f\u4ece\u79bb\u6563\u70b9\u4e91\u6570\u636e\u4e2d\u9ad8\u6548\u3001\u9012\u5f52\u5730\u63a8\u65ad\u6574\u4e2a\u5730\u56fe\u7684\u78c1\u573a\u53ca\u5176\u9ad8\u9636\u5bfc\u6570\uff0c\u5b9e\u73b0\u4e86\u5bf9\u78c1\u573a\u573a\u7684\u8fde\u7eed\u5efa\u6a21\u3002  \n\u25c6 \u5728\u4eff\u771f\u548c\u771f\u5b9e\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u5730\u56fe-\u5730\u56fe\u3001\u673a\u5668\u4eba-\u5730\u56fe\u548c\u673a\u5668\u4eba-\u673a\u5668\u4eba\u4e4b\u95f4\u7684\u7cbe\u786e\u53d8\u6362\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u4e8eSIFT\u7684\u4f20\u7edf\u65b9\u6cd5\u3002|\n",
    "2508.16465": "|2025-08-25|HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images|Anilkumar Swamy\u7b49|[2508.16465](http://arxiv.org/pdf/2508.16465)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u540d\u4e3aHOSt3R\u7684\u65e0\u9700\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u624b-\u7269\u4f53\u4e09\u7ef4\u91cd\u5efa\u65b9\u6cd5\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u6446\u8131\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bf9\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u4f9d\u8d56\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u590d\u6742\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5173\u952e\u70b9\u68c0\u6d4b\u5668\u7684\u3001\u76f4\u63a5\u4ece\u5355\u76ee\u8fd0\u52a8\u89c6\u9891\u4f30\u8ba1\u624b-\u7269\u4f53\u4e09\u7ef4\u53d8\u6362\u7684\u9c81\u68d2\u65b9\u6cd5\u3002\n\u25c6 \u6446\u8131\u4e86\u5bf9\u9884\u626b\u63cf\u7269\u4f53\u6a21\u677f\u6216\u5df2\u77e5\u76f8\u673a\u5185\u53c2\u7684\u4f9d\u8d56\uff0c\u5b9e\u73b0\u4e86\u66f4\u901a\u7528\u548c\u65e0\u7ea6\u675f\u7684\u5e94\u7528\u3002\n\u25c6 \u5c06\u6240\u63d0\u51fa\u7684\u53d8\u6362\u4f30\u8ba1\u65b9\u6cd5\u4e0e\u591a\u89c6\u56fe\u91cd\u5efa\u6d41\u7a0b\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u7684\u624b-\u7269\u4f53\u4e09\u7ef4\u5f62\u72b6\u6062\u590d\u3002\n\u25c6 \u5728SHOWMe\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u624b-\u7269\u4f53\u4e09\u7ef4\u53d8\u6362\u548c\u5f62\u72b6\u4f30\u8ba1\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\n\u25c6 \u5728HO3D\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5bf9\u672a\u89c1\u8fc7\u7684\u7269\u4f53\u7c7b\u522b\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002|\n",
    "2508.17746": "|2025-08-25|DroneKey: Drone 3D Pose Estimation in Image Sequences using Gated Key-representation and Pose-adaptive Learning|Seo-Bin Hwang\u7b49|[2508.17746](http://arxiv.org/pdf/2508.17746)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDroneKey\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u56fe\u50cf\u5e8f\u5217\u4e2d\u7cbe\u786e\u4f30\u8ba1\u65e0\u4eba\u673a\u7684\u4e09\u7ef4\u4f4d\u59ff\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u5173\u952e\u70b9\u68c0\u6d4b\u4e2d\u56e0\u87ba\u65cb\u6868\u89c6\u89c9\u76f8\u4f3c\u6027\u9ad8\u548c\u59ff\u6001\u591a\u6837\u6027\u5927\u800c\u5bfc\u81f4\u7684\u96be\u9898\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e8c\u7ef4\u5173\u952e\u70b9\u68c0\u6d4b\u5668\u548c\u4e09\u7ef4\u4f4d\u59ff\u4f30\u8ba1\u5668\u7684\u4e13\u7528\u6846\u67b6\uff0c\u9488\u5bf9\u65e0\u4eba\u673a\u7279\u6027\u8fdb\u884c\u4f18\u5316\u3002  \n\u25c6 \u5728\u5173\u952e\u70b9\u68c0\u6d4b\u9636\u6bb5\uff0c\u521b\u65b0\u6027\u5730\u4ece\u6bcf\u4e2aTransformer\u7f16\u7801\u5668\u5c42\u63d0\u53d6\u4e24\u79cd\u5173\u952e\u8868\u793a\uff08\u4e2d\u95f4\u8868\u793a\u548c\u7d27\u51d1\u8868\u793a\uff09\uff0c\u5e76\u901a\u8fc7\u95e8\u63a7\u6c42\u548c\u8fdb\u884c\u6700\u4f18\u878d\u5408\u3002  \n\u25c6 \u5f15\u5165\u4e86\u59ff\u6001\u81ea\u9002\u5e94\u7684\u9a6c\u6c0f\u8ddd\u79bb\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6781\u7aef\u59ff\u6001\u4e0b\u5173\u952e\u70b9\u9884\u6d4b\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002  \n\u25c6 \u6784\u5efa\u5e76\u516c\u5f00\u4e86\u65b0\u7684\u65e0\u4eba\u673a\u4e8c\u7ef4\u5173\u952e\u70b9\u53ca\u4e09\u7ef4\u4f4d\u59ff\u6570\u636e\u96c6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002  \n\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5173\u952e\u70b9\u68c0\u6d4b\u4e2d\u8fbe\u5230\u4e8699.68%\u7684AP\uff08OKS\u6307\u6807\uff09\uff0c\u4e09\u7ef4\u4f4d\u59ff\u4f30\u8ba1\u8bef\u5dee\u6781\u4f4e\uff08\u89d2\u5ea6MAE\u4e3a10.62\u5ea6\uff0c\u4f4d\u7f6eRMSE\u4e3a0.221\u7c73\uff09\uff0c\u540c\u65f6\u5b9e\u73b0\u4e8644 FPS\u7684\u5b9e\u65f6\u5904\u7406\u901f\u5ea6\u3002|\n",
    "2508.20830": "|2025-08-28|Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation|Krit Duangprom\u7b49|[2508.20830](http://arxiv.org/pdf/2508.20830)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u8fdb\u884c\u624b\u672f\u5de5\u5177\u4e8c\u7ef4\u5173\u952e\u70b9\u68c0\u6d4b\u7684\u65b0\u65b9\u6cd5\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u9884\u8bad\u7ec3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\uff0c\u5e76\u901a\u8fc7\u4f4e\u79e9\u81ea\u9002\u5e94\uff08LoRA\uff09\u6280\u672f\u8fdb\u884c\u5fae\u8c03\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5728\u5c0f\u578b\u533b\u7597\u6570\u636e\u96c6\u4e0a\u5bb9\u6613\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u5957\u7cbe\u5fc3\u6784\u5efa\u7684\u63d0\u793a\u6a21\u677f\uff0c\u6784\u5efa\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u89c6\u89c9\u7279\u5f81\u4e0e\u8bed\u4e49\u5173\u952e\u70b9\u63cf\u8ff0\u4e4b\u95f4\u7684\u5bf9\u9f50\u3002  \n\u25c6 \u4ec5\u9700\u4e24\u4e2a\u8bad\u7ec3\u5468\u671f\u5373\u53ef\u663e\u8457\u8d85\u8d8a\u4f20\u7edfCNN\u6216Transformer\u57fa\u7ebf\u6a21\u578b\uff0c\u663e\u793a\u51fa\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u9ad8\u6548\u6027\u80fd\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u4e3a\u540e\u7eed\u4e09\u7ef4\u624b\u672f\u5668\u68b0\u53ca\u624b\u90e8\u59ff\u6001\u4f30\u8ba1\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u62d3\u5c55\u4e86VLM\u5728\u533b\u7597\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002|\n",
    "2509.08712": "|2025-09-10|Computational Imaging for Enhanced Computer Vision|Humera Shaikh\u7b49|[2509.08712](http://arxiv.org/pdf/2509.08712)|\u65e0|\u8be5\u8bba\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u8ba1\u7b97\u6210\u50cf\u6280\u672f\u5982\u4f55\u63d0\u5347\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u7684\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u3002  \n\u25c6 \u7cfb\u7edf\u68b3\u7406\u4e86\u8ba1\u7b97\u6210\u50cf\u6280\u672f\uff08\u5982\u5149\u573a\u6210\u50cf\u3001\u9ad8\u52a8\u6001\u8303\u56f4\u6210\u50cf\u3001\u53bb\u6a21\u7cca\u3001\u9ad8\u901f\u6210\u50cf\u548c\u7729\u5149\u6291\u5236\uff09\u5728\u63d0\u5347\u56fe\u50cf\u91c7\u96c6\u4e0e\u91cd\u5efa\u8d28\u91cf\u65b9\u9762\u7684\u4f5c\u7528\u3002  \n\u25c6 \u6df1\u5165\u5206\u6790\u4e86\u8ba1\u7b97\u6210\u50cf\u6280\u672f\u4e0e\u6838\u5fc3\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\uff08\u5982\u76ee\u6807\u68c0\u6d4b\u3001\u6df1\u5ea6\u4f30\u8ba1\u3001\u5149\u6d41\u4f30\u8ba1\u3001\u4eba\u8138\u8bc6\u522b\u548c\u5173\u952e\u70b9\u68c0\u6d4b\uff09\u4e4b\u95f4\u7684\u534f\u540c\u5173\u7cfb\u3002  \n\u25c6 \u5f3a\u8c03\u4e86\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\u81ea\u9002\u5e94\u6210\u50cf\u6d41\u7a0b\u7684\u6f5c\u529b\uff0c\u53ef\u663e\u8457\u63d0\u5347\u5728\u81ea\u4e3b\u5bfc\u822a\u3001\u76d1\u63a7\u3001\u589e\u5f3a\u73b0\u5b9e\u548c\u673a\u5668\u4eba\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002  \n\u25c6 \u6307\u51fa\u4e86\u8be5\u9886\u57df\u65b0\u5174\u7684\u7814\u7a76\u673a\u9047\u4e0e\u6311\u6218\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002  \n\u8bba\u6587\u901a\u8fc7\u8de8\u9886\u57df\u6574\u5408\uff0c\u4e3a\u590d\u6742\u573a\u666f\u4e0b\u7684\u89c6\u89c9\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u57fa\u7840\u3002|\n",
    "2509.09758": "|2025-09-11|A Path Signature Framework for Detecting Creative Fatigue in Digital Advertising|Charles Shaw|[2509.09758](http://arxiv.org/pdf/2509.09758)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8def\u5f84\u7b7e\u540d\u5206\u6790\u7684\u6570\u5b57\u5e7f\u544a\u521b\u610f\u75b2\u52b3\u68c0\u6d4b\u65b0\u6846\u67b6\u3002  \n\u25c6\u9996\u6b21\u5c06\u968f\u673a\u5206\u6790\u4e2d\u7684\u8def\u5f84\u7b7e\u540d\u65b9\u6cd5\u5e94\u7528\u4e8e\u5e7f\u544a\u75b2\u52b3\u68c0\u6d4b\u9886\u57df\uff0c\u5f00\u8f9f\u4e86\u8425\u9500\u5206\u6790\u4e2d\u51e0\u4f55\u65b9\u6cd5\u7684\u65b0\u9014\u5f84\u3002  \n\u25c6\u5c06\u5e7f\u544a\u6027\u80fd\u65f6\u95f4\u5e8f\u5217\u89c6\u4e3a\u4e8c\u7ef4\u7a7a\u95f4\u4e2d\u7684\u8def\u5f84\uff0c\u5229\u7528\u5176\u7b7e\u540d\u4f5c\u4e3a\u4e30\u5bcc\u7684\u7279\u5f81\u63cf\u8ff0\u7b26\u4ee5\u6355\u6349\u52a8\u6001\u53d8\u5316\u3002  \n\u25c6\u901a\u8fc7\u8ba1\u7b97\u8fde\u7eed\u65f6\u95f4\u7a97\u53e3\u7b7e\u540d\u95f4\u7684\u8ddd\u79bb\uff0c\u8bc6\u522b\u6027\u80fd\u52a8\u6001\u4e2d\u7edf\u8ba1\u663e\u8457\u7684\u53d8\u66f4\u70b9\uff0c\u7075\u654f\u5ea6\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002  \n\u25c6\u5c06\u7edf\u8ba1\u68c0\u6d4b\u7ed3\u679c\u8f6c\u5316\u4e3a\u76f4\u63a5\u8d22\u52a1\u6307\u6807\uff0c\u91cf\u5316\u6301\u7eed\u6295\u8d44\u75b2\u52b3\u521b\u610f\u7684\u673a\u4f1a\u6210\u672c\uff0c\u63d0\u5347\u51b3\u7b56\u5b9e\u7528\u6027\u3002  \n\u25c6\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u548c\u6848\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u6570\u5b66\u539f\u7406\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5e7f\u544a\u75b2\u52b3\u5206\u6790\u63d0\u4f9b\u4e86\u4e92\u8865\u6027\u65b0\u5de5\u5177\u3002|\n",
    "2509.11731": "|2025-09-15|Bridging the Gap Between Sparsity and Redundancy: A Dual-Decoding Framework with Global Context for Map Inference|Yudong Shen\u7b49|[2509.11731](http://arxiv.org/pdf/2509.11731)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u8f68\u8ff9\u6570\u636e\u5730\u56fe\u63a8\u65ad\u4e2d\u7a00\u758f\u533a\u57df\u9053\u8def\u65ad\u88c2\u548c\u5bc6\u96c6\u533a\u57df\u5197\u4f59\u6bb5\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86DGMap\u53cc\u89e3\u7801\u6846\u67b6\u3002\u5176\u6838\u5fc3\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u63d0\u51fa\u591a\u5c3a\u5ea6\u7f51\u683c\u7f16\u7801\u65b9\u6cd5\uff0c\u6574\u5408\u5168\u5c40\u8bed\u4e49\u4e0a\u4e0b\u6587\u4e0e\u5c40\u90e8\u51e0\u4f55\u7279\u5f81\uff0c\u63d0\u5347\u5173\u952e\u70b9\u68c0\u6d4b\u7cbe\u5ea6\u3002\n\u25c6 \u8bbe\u8ba1\u63a9\u7801\u589e\u5f3a\u5173\u952e\u70b9\u63d0\u53d6\u673a\u5236\uff0c\u6709\u6548\u51cf\u5c11\u7a00\u758f\u8f68\u8ff9\u533a\u7684\u9053\u8def\u65ad\u88c2\u95ee\u9898\u3002\n\u25c6 \u5f15\u5165\u5168\u5c40\u4e0a\u4e0b\u6587\u611f\u77e5\u5173\u7cfb\u9884\u6d4b\u6a21\u5757\uff0c\u901a\u8fc7\u5efa\u6a21\u957f\u8f68\u8ff9\u6a21\u5f0f\u6291\u5236\u5bc6\u96c6\u533a\u57df\u7684\u9519\u8bef\u8fde\u63a5\u3002\n\u5b9e\u9a8c\u8868\u660e\uff0cDGMap\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0aAPLS\u6307\u6807\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd55%\uff0c\u5c24\u5176\u5728\u6ef4\u6ef4\u5e73\u53f0\u6570\u636e\u4e0a\u8868\u73b0\u7a81\u51fa\u3002|\n",
    "2509.21926": "|2025-09-26|PANICL: Mitigating Over-Reliance on Single Prompt in Visual In-Context Learning|Jiahao Zhang\u7b49|[2509.21926](http://arxiv.org/pdf/2509.21926)|\u65e0|\u25c6 Visual In-Context Learning (VICL) uses input-output image pairs, referred to as in-context pairs (or examples), as prompts alongside query images to guide models in performing diverse vision tasks.\n\u25c6 However, VICL often suffers from over-reliance on a single in-context pair, which can lead to biased and unstable predictions.\n\u25c6 We introduce PAtch-based $k$-Nearest neighbor visual In-Context Learning (PANICL), a general training-free framework that mitigates this issue by leveraging multiple in-context pairs.|\n",
    "2510.00083": "|2025-09-30|Enhancing Certifiable Semantic Robustness via Robust Pruning of Deep Neural Networks|Hanjiang Hu\u7b49|[2510.00083](http://arxiv.org/pdf/2510.00083)|\u65e0|\u25c6 Deep neural networks have been widely adopted in many vision and robotics applications with visual inputs.\n\u25c6 It is essential to verify its robustness against semantic transformation perturbations, such as brightness and contrast.\n\u25c6 However, current certified training and robustness certification methods face the challenge of over-parameterization, which hinders the tightness and scalability due to the over-complicated neural networks.|\n"
  },
  "Image Matching": {
    "2504.19458": "|**2025-05-15**|**Mitigating Modality Bias in Multi-modal Entity Alignment from a Causal Perspective**|Taoyu Su et.al.|[2504.19458](http://arxiv.org/abs/2504.19458)|**[link](https://github.com/sutaoyu/CDMEA)**|\n",
    "2505.03422": "|2025-05-06|LiftFeat: 3D Geometry-Aware Local Feature Matching|Yepeng Liu\u7b49|[2505.03422](http://arxiv.org/pdf/2505.03422)|[\u4ee3\u7801](https://github.com/lyp-deeplearning/liftfeat)|\u25c6 \u63d0\u51faLiftFeat\u8f7b\u91cf\u7f51\u7edc\uff0c\u901a\u8fc7\u878d\u5408\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\u751f\u6210\u7684\u4f2a\u8868\u9762\u6cd5\u7ebf\u7279\u5f81\u4e0e\u539f\u59cb2D\u63cf\u8ff0\u7b26\uff0c\u589e\u5f3a\u7279\u5f81\u5339\u914d\u5728\u5149\u7167\u53d8\u5316\u3001\u5f31\u7eb9\u7406\u7b49\u6781\u7aef\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u8bbe\u8ba13D\u51e0\u4f55\u611f\u77e5\u7279\u5f81\u63d0\u5347\u6a21\u5757\uff0c\u5229\u7528\u8868\u9762\u6cd5...|\n",
    "2505.03836": "|2025-05-04|OBD-Finder: Explainable Coarse-to-Fine Te...|Chongsheng Zhang\u7b49|[2505.03836](http://arxiv.org/pdf/2505.03836)|[\u4ee3\u7801](https://github.com/cszhanglmu/obd-finder)|\u25c6\u63d0\u51fa\u4e86\u4e00\u79cd\u6e10\u8fdb\u5f0f\u7532\u9aa8\u6587\u91cd\u590d\u7247\u53d1\u73b0\u6846\u67b6\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u4f4e\u5c42\u5173\u952e\u70b9\u5339\u914d\u4e0e\u9ad8\u5c42\u4ee5\u6587\u672c\u4e3a\u4e2d\u5fc3\u7684\u5185\u5bb9\u5339\u914d\uff0c\u5b9e\u73b0\u8bed\u4e49\u611f\u77e5\u548c\u53ef\u89e3\u91ca\u7684\u5019\u9009\u6392\u5e8f\u3002\u25c6\u5728\u4fdd\u6301\u9ad8\u53ec\u56de\u7387\u7684\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u5728Top-5\u548cTop-15\u68c0\u7d22\u7ed3\u679c\u4e2d\u53d6...|\n",
    "2505.02161": "|**2025-05-04**|**Focus What Matters: Matchability-Based Reweighting for Local Feature Matching**|Dongyue Li et.al.|[2505.02161](http://arxiv.org/abs/2505.02161)|null|\n",
    "2505.07375": "|2025-05-12|Boosting Global-Local Feature Matching via Anomaly...|Yuqi Cheng\u7b49|[2505.07375](http://arxiv.org/pdf/2505.07375)|[\u4ee3\u7801](https://github.com/hustCYQ/GLFM-Multi-class-3DAD)|\u25c6\u63d0\u51faGLFM\u65b9\u6cd5\uff0c\u901a\u8fc7\u5168\u5c40-\u5c40\u90e8\u7279\u5f81\u5339\u914d\u89e3\u51b3\u591a\u7c7b\u522b\u70b9\u4e91\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u7279\u5f81\u6df7\u6dc6\u95ee\u9898\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u8bbe\u8ba1\u4e86\u4e09\u9636\u6bb5\u6846\u67b6\uff1a\u5f02\u5e38\u5408\u6210\u589e\u5f3a\u7279\u5f81\u8868\u793a\u3001\u5efa\u7acb\u6297\u6df7\u6dc6\u7684\u5168\u5c40-\u5c40\u90e8\u8bb0\u5fc6\u5e93\u3001\u57fa\u4e8e\u7279\u5f81\u8ddd\u79bb\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u663e...|\n",
    "2505.11264": "|2025-05-16|Multi-view dense image matching with similarity learning and geometry priors|Mohamed Ali Chebbi\u7b49|[2505.11264](http://arxiv.org/pdf/2505.11264)|\u65e0|\u25c6\u63d0\u51faMV-DeepSimNets\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u591a\u89c6\u56fe\u76f8\u4f3c\u6027\u5b66\u4e60\u4e0e\u6781\u7ebf\u51e0\u4f55\u5148\u9a8c\u7ed3\u5408\uff0c\u65e0\u9700\u7e41\u7410\u7684\u591a\u89c6\u56fe\u8bad\u7ec3\u6570\u636e\u6784\u5efa\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u5f15\u5165\u5728\u7ebf\u51e0\u4f55\u5148\u9a8c\uff0c\u901a\u8fc7\u6781\u7ebf\u7ea6\u675f\u6216\u5355\u5e94\u6027\u6821\u6b63\u52a8\u6001\u5efa\u6a21\u50cf\u7d20\u5173\u7cfb\uff0c\u751f\u6210\u51e0\u4f55\u611f\u77e5\u7684\u7279\u5f81\u8868\u793a\u3002  \n\u25c6\u91c7\u7528\u5e73\u9762\u626b\u63cf\u6cd5\u5c06\u51e0\u4f55\u7279\u5f81\u6295\u5f71\u5230\u5019\u9009\u6df1\u5ea6\u5047\u8bbe\u7a7a\u95f4\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u7684\u51e0\u4f55\u6761\u4ef6\u5316\u7279\u5f81\u9002\u914d\uff0c\u63d0\u5347\u591a\u89c6\u56fe\u91cd\u5efa\u7cbe\u5ea6\u3002  \n\u25c6\u901a\u8fc7\u805a\u5408\u5b66\u4e60\u5230\u7684\u76f8\u4f3c\u6027\u6784\u5efa\u5e76\u6b63\u5219\u5316\u4ee3\u4ef7\u4f53\uff0c\u76f8\u6bd4\u4f20\u7edf\u7a20\u5bc6\u5339\u914d\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u8868\u9762\u91cd\u5efa\u8d28\u91cf\u3002  \n\u25c6\u5728\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u53ef\u540c\u65f6\u9002\u7528\u4e8e\u822a\u7a7a\u5f71\u50cf\u548c\u536b\u661f\u5f71\u50cf\uff08\u4e0d\u540c\u5730\u9762\u91c7\u6837\u8ddd\u79bb\uff09\uff0c\u6027\u80fd\u8d85\u8d8a\u4e3b\u6d41\u76f8\u4f3c\u6027\u5b66\u4e60\u7f51\u7edc\u548c\u7aef\u5230\u7aef\u56de\u5f52\u6a21\u578b\u3002  \n\u25c6\u5b8c\u6574\u96c6\u6210\u81f3MicMac\u5f00\u6e90\u8f6f\u4ef6\uff0c\u53ef\u76f4\u63a5\u517c\u5bb9\u6807\u51c6\u591a\u5206\u8fa8\u7387\u5f71\u50cf\u5339\u914d\u6d41\u7a0b\uff0c\u5177\u5907\u5de5\u7a0b\u5b9e\u7528\u4ef7\u503c\u3002|\n",
    "2505.22458": "|2025-06-05|Universal Domain Adaptation for Semantic Segmentation|Seun-An Choe\u7b49|[2505.22458](http://arxiv.org/pdf/2505.22458)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u901a\u7528\u9886\u57df\u81ea\u9002\u5e94\u8bed\u4e49\u5206\u5272\uff08UniDA-SS\uff09\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u56e0\u5ffd\u7565\u7c7b\u522b\u8bbe\u7f6e\u5dee\u5f02\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002\u5176\u6838\u5fc3\u8d21\u732e\u548c\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51faUniDA-SS\u6846\u67b6\uff0c\u9996\u6b21\u5728\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\u5b9e\u73b0\u65e0\u9700\u9884\u77e5\u6e90\u57df\u4e0e\u76ee\u6807\u57df\u7c7b\u522b\u8bbe\u7f6e\u7684\u901a\u7528\u9886\u57df\u81ea\u9002\u5e94\u3002  \n\u25c6 \u8bbe\u8ba1Domain-Specific Prototype-based Distinction\uff08DSPD\uff09\u6a21\u5757\uff0c\u901a\u8fc7\u5c06\u6bcf\u7c7b\u5212\u5206\u4e3a\u4e24\u4e2a\u57df\u7279\u5b9a\u539f\u578b\uff0c\u589e\u5f3a\u8de8\u57df\u5171\u6709\u7c7b\u522b\u7684\u7279\u5f81\u533a\u5206\u80fd\u529b\u3002  \n\u25c6 \u5f00\u53d1Target-based Image Matching\uff08TIM\uff09\u7b56\u7565\uff0c\u57fa\u4e8e\u76ee\u6807\u57df\u4f2a\u6807\u7b7e\u5339\u914d\u6700\u4f73\u6e90\u57df\u56fe\u50cf\u8fdb\u884c\u6279\u91cf\u8bad\u7ec3\uff0c\u6709\u6548\u63d0\u5347\u5171\u6709\u7c7b\u522b\u7684\u5b66\u4e60\u6548\u679c\u3002  \n\u25c6 \u6784\u5efa\u65b0\u7684UniDA-SS\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u4f30\u5e73\u53f0\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eUniMAP\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002|\n",
    "2505.17973": "|2025-05-23|To Glue or Not to Glue? Classical vs Learned Image Matching for Mobile Mapping Cameras to Textured Semantic 3D Building Models|Simone Gaisbauer\u7b49|[2505.17973](http://arxiv.org/pdf/2505.17973)|[\u4ee3\u7801](https://github.com/simbauer/to_glue_or_not_to_glue)|\u25c6 \u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4f20\u7edf\u624b\u5de5\u7279\u5f81\u5339\u914d\uff08\u5982SIFT+RANSAC\uff09\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7279\u5f81\u5339\u914d\u65b9\u6cd5\u5728\u8bed\u4e493D\u5efa\u7b51\u6a21\u578b\u76f8\u673a\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\u3002  \n\u25c6 \u9488\u5bf9\u79fb\u52a8\u6d4b\u7ed8\u76f8\u673a\u4e0e\u7eb9\u7406\u5316CityGML LoD2\u6a21\u578b\u7684\u5339\u914d\u573a\u666f\uff0c\u63d0\u51fa\u5b9a\u5236\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002  \n\u25c6 \u7ed3\u5408\u6807\u51c6\u6570\u636e\u96c6\uff08HPatches\u3001MegaDepth-1500\uff09\u548c\u81ea\u5efa\u6570\u636e\u96c6\uff08\u542b\u5730\u9762/\u65e0\u4eba\u673a\u62cd\u6444\u7684\u7acb\u9762\u7eb9\u7406\u4e0e\u5bf9\u5e94\u5f71\u50cf\uff09\uff0c\u9a8c\u8bc1\u65b9\u6cd5\u666e\u9002\u6027\u3002  \n\u25c6 \u901a\u8fc7PnP\u7b97\u6cd5\u91cf\u5316\u7edd\u5bf9\u4f4d\u59ff\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u5229\u7528\u5730\u7406\u53c2\u8003\u8f68\u8ff9\u6570\u636e\u751f\u6210\u51e0\u4f55\u771f\u503c\uff0c\u5efa\u7acb\u5ba2\u89c2\u8bc4\u4f30\u57fa\u51c6\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u5b66\u4e60\u5f0f\u7279\u5f81\u5339\u914d\u5728\u6311\u6218\u6027\u573a\u666f\uff08RANSAC\u5185\u70b9\u65700-12\u3001AUC 0-0.16\uff09\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u548c\u9c81\u68d2\u6027\u63d0\u5347\u660e\u663e\u3002  \n\u25c6 \u516c\u5f00\u4ee3\u7801\u5e93\u4fc3\u8fdb\u6a21\u578b\u5316\u89c6\u89c9\u5b9a\u4f4d\u6280\u672f\u53d1\u5c55\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u53ef\u590d\u73b0\u57fa\u7840\u3002|\n",
    "2505.24305": "|2025-06-20|SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping|Mingxu Zhang\u7b49|[2505.24305](http://arxiv.org/pdf/2505.24305)|\u65e0|\u25c6\u63d0\u51faSR3D\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u65e0\u9700\u8bad\u7ec3\u7684\u57fa\u4e8e\u5355\u89c6\u89d2\u7684\u900f\u660e\u4e0e\u955c\u9762\u7269\u4f533D\u91cd\u5efa\u4e0e\u6293\u53d6\uff0c\u7a81\u7834\u4f20\u7edf\u6df1\u5ea6\u611f\u77e5\u9650\u5236\u3002  \n\u25c6\u5229\u7528\u5916\u90e8\u89c6\u89c9\u6a21\u578b\u76f4\u63a5\u4eceRGB\u56fe\u50cf\u751f\u6210\u7269\u4f53\u7f51\u683c\uff0c\u7ed3\u5408\u6df1\u5ea6\u56fe\u5b9e\u73b03D\u573a\u666f\u878d\u5408\uff0c\u907f\u514d\u590d\u6742\u591a\u89c6\u89d2\u91c7\u96c6\u7cfb\u7edf\u3002  \n\u25c6\u521b\u65b0\u6027\u63d0\u51fa\u89c6\u56fe\u5339\u914d\u4e0e\u5173\u952e\u70b9\u5339\u914d\u53cc\u673a\u5236\uff0c\u8054\u54082D\u8bed\u4e49\u4e0e3D\u51e0\u4f55\u4fe1\u606f\u7cbe\u51c6\u5b9a\u4f4d\u7269\u4f53\u4f4d\u59ff\u4e0e\u5c3a\u5ea6\u3002  \n\u25c6\u901a\u8fc7\u5c06\u91cd\u5efa\u7269\u4f53\u9006\u5411\u6620\u5c04\u56de\u539f\u59cb\u6df1\u5ea6\u7f3a\u5931\u573a\u666f\uff0c\u751f\u6210\u9ad8\u7cbe\u5ea6\u6df1\u5ea6\u56fe\uff0c\u663e\u8457\u63d0\u5347\u6293\u53d6\u68c0\u6d4b\u6548\u679c\u3002  \n\u25c6\u5728\u4eff\u771f\u4e0e\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u4e3a\u900f\u660e/\u955c\u9762\u7269\u4f53\u6293\u53d6\u63d0\u4f9b\u5b9e\u7528\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u7b80\u5316\u786c\u4ef6\u4f9d\u8d56\u3002|\n",
    "2506.04917": "|2025-06-05|Vanishing arcs for isolated plane curve singularities|Hanwool Bae\u7b49|[2506.04917](http://arxiv.org/pdf/2506.04917)|\u65e0|\u25c6 \u63d0\u51fa\"\u6d88\u5931\u5f27\u96c6\"\u65b0\u6982\u5ff5\uff0c\u4f5c\u4e3a\u4f20\u7edf\u6d88\u5931\u5faa\u73af\u7684\u51e0\u4f55\u5bf9\u5e94\u7269\uff0c\u901a\u8fc7\u51e0\u4f55\u53d8\u5206\u7b97\u5b50\u5c06\u5d4c\u5165\u5f27\u4e0e\u95ed\u66f2\u7ebf\u8054\u7cfb\u8d77\u6765\u3002  \n\u25c6 \u5efa\u7acb\u51e0\u4f55\u53d8\u5206\u7b97\u5b50\u7684\u62d3\u6251\u6846\u67b6\uff0c\u7528\u51e0\u4f55\u5f27\u548c\u95ed\u66f2\u7ebf\u66ff\u4ee3\u540c\u8c03\u5faa\u73af\uff0c\u62d3\u5c55\u4e86\u7ecf\u5178\u8d85\u66f2\u9762\u5947\u70b9\u7406\u8bba\u7684\u5de5\u5177\u96c6\u3002  \n\u25c6 \u7ed9\u51fa\u5224\u5b9a\u5d4c\u5165\u5f27\u88ab\u51e0\u4f55\u53d8\u5206\u7b97\u5b50\u6620\u5c04\u4e3a\u6d88\u5931\u5faa\u73af\u7684\u5145\u8981\u6761\u4ef6\uff0c\u57fa\u4e8e\u5f27\u4e0e\u51e0\u4f55\u5355\u503c\u5316\u6620\u50cf\u7684\u4ea4\u70b9\u6570\u7279\u5f81\u3002  \n\u25c6 \u8bc1\u660e\u5bf9\u4efb\u610f\u7531A'Campo\u5256\u5206\u4ea7\u751f\u7684\u6d88\u5931\u5faa\u73af\u96c6\uff0c\u5b58\u5728\u62d3\u6251\u4f8b\u5916\u5f27\u96c6\u4f7f\u5176\u53d8\u5206\u6620\u50cf\u4e0e\u8be5\u6d88\u5931\u5faa\u73af\u96c6\u5b8c\u5168\u5339\u914d\u3002  \n\u25c6 \u5c06\u51e0\u4f55\u5355\u503c\u5316\u4e0e\u4ea4\u70b9\u6570\u7406\u8bba\u76f8\u7ed3\u5408\uff0c\u4e3a\u5e73\u9762\u66f2\u7ebf\u5947\u70b9\u7684\u62d3\u6251\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u51e0\u4f55\u5316\u65b9\u6cd5\u3002|\n",
    "2506.04619": "|2025-06-05|Deep Learning Reforms Image Matching: A Survey and Outlook|Shihua Zhang\u7b49|[2506.04619](http://arxiv.org/pdf/2506.04619)|\u65e0|\u25c6 \u8be5\u8bba\u6587\u9996\u6b21\u4ece\u6df1\u5ea6\u5b66\u4e60\u9010\u6b65\u6539\u9020\u4f20\u7edf\u56fe\u50cf\u5339\u914d\u6d41\u7a0b\u7684\u89c6\u89d2\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u8be5\u9886\u57df\u7684\u9769\u547d\u6027\u8fdb\u5c55\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u7efc\u8ff0\u6309\u6280\u672f\u5206\u7c7b\u7684\u6846\u67b6\u3002  \n\u25c6 \u63d0\u51fa\u4e0e\u7ecf\u5178\u6d41\u6c34\u7ebf\u9ad8\u5ea6\u5bf9\u9f50\u7684\u65b0\u578b\u5206\u7c7b\u4f53\u7cfb\uff1a\u4e00\u65b9\u9762\u62c6\u89e3\u5404\u73af\u8282\u7684\u53ef\u5b66\u4e60\u66ff\u4ee3\u65b9\u6848\uff08\u5982\u53ef\u5b66\u4e60\u68c0\u6d4b-\u63cf\u8ff0\u5b50\u3001\u79bb\u7fa4\u70b9\u8fc7\u6ee4\u5668\uff09\uff0c\u53e6\u4e00\u65b9\u9762\u6574\u5408\u591a\u73af\u8282\u7684\u7aef\u5230\u7aef\u6a21\u5757\uff08\u5982\u4e2d\u7aef\u7a00\u758f\u5339\u914d\u5668\u3001\u7a20\u5bc6\u5339\u914d\u5668\uff09\u3002  \n\u25c6 \u6df1\u5ea6\u5256\u6790\u4e86\u53ef\u5b66\u4e60\u7ec4\u4ef6\u4e0e\u7aef\u5230\u7aef\u6a21\u5757\u7684\u8bbe\u8ba1\u54f2\u5b66\u53ca\u4f18\u52a3\uff0c\u9996\u6b21\u660e\u786e\u63ed\u793a\u4e24\u7c7b\u6280\u672f\u8def\u7ebf\u7684\u4e92\u8865\u6027\u4e0e\u9002\u7528\u8fb9\u754c\u3002  \n\u25c6 \u5728\u76f8\u5bf9\u4f4d\u59ff\u6062\u590d\u3001\u5355\u5e94\u4f30\u8ba1\u7b49\u6838\u5fc3\u4efb\u52a1\u4e0a\u5efa\u7acb\u7edf\u4e00\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5b9a\u91cf\u6bd4\u8f83\u4e86\u4ee3\u8868\u6027\u65b9\u6cd5\u7684\u6027\u80fd\u7a81\u7834\u4e0e\u73b0\u5b58\u7f3a\u9677\u3002  \n\u25c6 \u524d\u77bb\u6027\u6307\u51fa\u81ea\u76d1\u7763\u5b66\u4e60\u3001\u8de8\u6a21\u6001\u5339\u914d\u3001\u52a8\u6001\u573a\u666f\u9002\u5e94\u7b49\u672a\u6765\u65b9\u5411\uff0c\u4e3a\u9886\u57df\u53d1\u5c55\u7ed8\u5236\u4e86\u6e05\u6670\u7684\u6280\u672f\u6f14\u8fdb\u5730\u56fe\u3002  \n\u25c6 \u901a\u8fc7\u63ed\u793a\u4f20\u7edf\u6d41\u7a0b\u88ab\u6df1\u5ea6\u5b66\u4e60\"\u89e3\u6784-\u91cd\u6784\"\u7684\u5b8c\u6574\u8def\u5f84\uff0c\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9\u57fa\u7840\u95ee\u9898\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u5c42\u9762\u7684\u65b0\u8303\u5f0f\u3002|\n",
    "2506.06302": "|2025-05-21|Anti-interrupted sampling repeater jamming via linear canonical Wigner distribution lightweight LFM detection|Jia-Mian Li\u7b49|[2506.06302](http://arxiv.org/pdf/2506.06302)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u5e7f\u4e49\u7ebf\u6027\u6b63\u5219\u7ef4\u683c\u7eb3\u5206\u5e03\uff08GLWD\uff09\u7684\u6297\u5e72\u6270\u65b9\u6cd5\uff0c\u901a\u8fc7\u5408\u7406\u8bbe\u7f6e\u53c2\u6570\u83b7\u5f97\u9ad8\u65f6\u9891\u5206\u8fa8\u7387\u548c\u80fd\u91cf\u96c6\u4e2d\u6027\uff0c\u663e\u8457\u63d0\u5347\u4fe1\u53f7\u5206\u79bb\u80fd\u529b\u548c\u4fe1\u566a\u6bd4\u3002  \n\u25c6 \u6539\u8fdb\u73b0\u6709\u79fb\u52a8\u7ebf\u6bb5\u68c0\u6d4b\uff08M-LSD\uff09\u7b97\u6cd5\uff0c\u63d0\u51fa\u79fb\u52a8\u957f\u7ebf\u6bb5\u68c0\u6d4b\uff08M-LSD\uff09\u7b97\u6cd5\uff0c\u589e\u5f3a\u5bf9\u76ee\u6807\u7ebf\u6027\u8c03\u9891\u4fe1\u53f7\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u964d\u4f4e\u5bf9\u5e72\u6270\u4fe1\u53f7\u7684\u654f\u611f\u6027\u3002  \n\u25c6 \u5229\u7528GLWD\u4e0e\u77ed\u65f6\u5085\u91cc\u53f6\u53d8\u6362\uff08STFT\uff09\u7684\u6620\u5c04\u5173\u7cfb\u6784\u5efa\u65f6\u9891\u6ee4\u6ce2\u5668\uff0c\u5728STFT\u57df\u8fdb\u884c\u6ee4\u6ce2\u4ee5\u9ad8\u6548\u6291\u5236\u5e72\u6270\u3002  \n\u25c6 \u65b9\u6cd5\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u4ecd\u80fd\u6709\u6548\u533a\u5206\u80fd\u91cf\u63a5\u8fd1\u771f\u5b9e\u76ee\u6807\u7684\u5e72\u6270\u91c7\u6837\u8f6c\u53d1\u5e72\u6270\uff08ISRJ\uff09\uff0c\u89e3\u51b3\u4f20\u7edf\u65f6\u9891\u57df\u65b9\u6cd5\u5728\u591a\u5206\u91cf\u4fe1\u53f7\u573a\u666f\u4e2d\u7684\u65f6\u9891\u6df7\u53e0\u95ee\u9898\u3002  \n\u25c6 \u4eff\u771f\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5bf9\u96be\u533a\u5206\u5e72\u6270\u7684\u6709\u6548\u6291\u5236\u80fd\u529b\uff0c\u517c\u5177\u5b9e\u65f6\u6027\u548c\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u96f7\u8fbe\u6297\u5e72\u6270\u573a\u666f\u3002|\n",
    "2506.09748": "|2025-06-11|Hierarchical Image Matching for UAV Absolute Visual Localization via Semantic and Structural Constraints|Xiangkai Zhang\u7b49|[2506.09748](http://arxiv.org/pdf/2506.09748)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u8de8\u6e90\u56fe\u50cf\u5339\u914d\u65b9\u6cd5\uff0c\u7ed3\u5408\u8bed\u4e49\u611f\u77e5\u548c\u7ed3\u6784\u7ea6\u675f\u7684\u7c97\u5339\u914d\u6a21\u5757\u4e0e\u8f7b\u91cf\u7ea7\u7ec6\u7c92\u5ea6\u5339\u914d\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u7edd\u5bf9\u89c6\u89c9\u5b9a\u4f4d\u7684\u7cbe\u5ea6\u3002  \n\u25c6 \u5229\u7528\u89c6\u89c9\u57fa\u7840\u6a21\u578b\u63d0\u53d6\u8bed\u4e49\u7279\u5f81\uff0c\u5728\u8bed\u4e49\u548c\u7ed3\u6784\u7ea6\u675f\u4e0b\u5efa\u7acb\u533a\u57df\u7ea7\u5bf9\u5e94\u5173\u7cfb\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u6e90\u5dee\u5f02\u548c\u65f6\u53d8\u56e0\u7d20\u5bfc\u81f4\u7684\u5339\u914d\u96be\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u8f7b\u91cf\u7ea7\u7ec6\u7c92\u5ea6\u5339\u914d\u6a21\u5757\uff0c\u901a\u8fc7\u63d0\u53d6\u7cbe\u7ec6\u7279\u5f81\u5efa\u7acb\u50cf\u7d20\u7ea7\u5bf9\u5e94\u5173\u7cfb\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u3002  \n\u25c6 \u6784\u5efa\u4e86\u4e0d\u4f9d\u8d56\u76f8\u5bf9\u5b9a\u4f4d\u6280\u672f\u7684\u65e0\u4eba\u673a\u7edd\u5bf9\u89c6\u89c9\u5b9a\u4f4d\u6d41\u7a0b\uff0c\u901a\u8fc7\u56fe\u50cf\u68c0\u7d22\u6a21\u5757\u4e0e\u5206\u5c42\u5339\u914d\u6a21\u5757\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u72ec\u7acb\u5b9a\u4f4d\u3002  \n\u25c6 \u5728\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u548c\u65b0\u63d0\u51fa\u7684CS-UAV\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u591a\u79cd\u6311\u6218\u6027\u6761\u4ef6\u4e0b\u7684\u9ad8\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002|\n",
    "2506.09369": "|2025-06-11|ScaleLSD: Scalable Deep Line Segment Detection Streamlined|Zeran Ke\u7b49|[2506.09369](http://arxiv.org/pdf/2506.09369)|[\u4ee3\u7801](https://github.com/ant-research/scalelsd)|\u25c6 \u63d0\u51faScaleLSD\uff0c\u9996\u4e2a\u901a\u8fc7\u5927\u89c4\u6a21\u81ea\u76d1\u7763\u5b66\u4e60\uff08\u8d85\u8fc71000\u4e07\u65e0\u6807\u7b7e\u56fe\u50cf\uff09\u8bad\u7ec3\u7684\u9886\u57df\u65e0\u5173\u9c81\u68d2\u7ebf\u68c0\u6d4b\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u81ea\u7136\u56fe\u50cf\u7684\u7ebf\u6bb5\u68c0\u6d4b\u80fd\u529b\u3002  \n\u25c6 \u91cd\u65b0\u8bbe\u8ba1\u5e76\u7b80\u5316\u4e86\u4f20\u7edf\uff08\u6df1\u5ea6\u4e0e\u975e\u6df1\u5ea6\uff09\u7ebf\u6bb5\u68c0\u6d4b\u65b9\u6cd5\u7684\u6838\u5fc3\u67b6\u6784\uff0c\u5b9e\u73b0\u9ad8\u6548\u9ad8\u6027\u80fd\u7684\u7ebf\u6bb5\u68c0\u6d4b\uff0c\u68c0\u6d4b\u6570\u91cf\u8fdc\u8d85\u7ecf\u5178\u975e\u6df1\u5ea6\u65b9\u6cd5\u3002  \n\u25c6 \u5728\u7ebf\u6bb5\u51e0\u4f55\u8868\u5f81\u4e0a\u66f4\u5b8c\u6574\u4e14\u51c6\u786e\uff0c\u9996\u6b21\u5b9e\u73b0\u6df1\u5ea6\u65b9\u6cd5\u5728\u6240\u6709\u6d4b\u8bd5\u573a\u666f\uff08\u68c0\u6d4b\u6027\u80fd\u3001\u5355\u89c6\u56fe3D\u51e0\u4f55\u4f30\u8ba1\u7b49\uff09\u5168\u9762\u8d85\u8d8a\u7ecf\u5178\u975e\u6df1\u5ea6LSD\u3002  \n\u25c6 \u901a\u8fc7\u96f6\u6837\u672c\u534f\u8bae\u9a8c\u8bc1\u6a21\u578b\u6cdb\u5316\u6027\uff0c\u5728\u5355\u89c6\u56fe3D\u91cd\u5efa\u3001\u53cc\u89c6\u56fe\u7ebf\u6bb5\u5339\u914d\u3001\u591a\u89c6\u56fe3D\u7ebf\u6bb5\u6620\u5c04\u7b49\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u4e0e\u6a21\u578b\uff0c\u4e3a\u56fe\u50cf\u7ebf\u51e0\u4f55\u7684\u5e7f\u6cdb\u5e94\u7528\uff08\u5982\u4e09\u7ef4\u91cd\u5efa\u3001\u5339\u914d\uff09\u63d0\u4f9b\u66f4\u5f3a\u901a\u7528\u6027\u652f\u6301\uff0c\u5f3a\u5316\u7ebf\u6bb5\u51e0\u4f55\u5728\u591a\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\u3002|\n",
    "2506.10344": "|2025-06-12|RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration|Mina C. Moghadam\u7b49|[2506.10344](http://arxiv.org/pdf/2506.10344)|\u65e0|\u25c6 \u63d0\u51faRealKeyMorph\uff08RKM\uff09\uff0c\u9996\u4e2a\u65e0\u9700\u56fa\u5b9a\u5206\u8fa8\u7387\u91cd\u91c7\u6837\u7684\u533b\u5b66\u56fe\u50cf\u914d\u51c6\u65b9\u6cd5\uff0c\u76f4\u63a5\u5904\u7406\u539f\u59cb\u5206\u8fa8\u7387\u6570\u636e\uff0c\u907f\u514d\u63d2\u503c\u4f2a\u5f71\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u5173\u952e\u70b9\u8f93\u51fa\u4e3a\u626b\u63cf\u4eea\u771f\u5b9e\u4e16\u754c\u5750\u6807\uff08\u800c\u975e\u4f53\u7d20\u5750\u6807\uff09\uff0c\u901a\u8fc7\u5229\u7528\u626b\u63cf\u4eea\u751f\u6210\u7684\u4eff\u5c04\u77e9\u9635\u5b9e\u73b0\u8de8\u5206\u8fa8\u7387\u914d\u51c6\u3002  \n\u25c6 \u6269\u5c55KeyMorph\u6846\u67b6\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u878d\u5165\u771f\u5b9e\u4e16\u754c\u5750\u6807\u8f6c\u6362\uff0c\u4f7f\u5173\u952e\u70b9\u63d0\u53d6\u4e0e\u56fe\u50cf\u5206\u8fa8\u7387\u5b8c\u5168\u89e3\u8026\u3002  \n\u25c6 \u5728\u8179\u90e8MRI\u6b63\u4ea42D\u5806\u6808\u548c\u4e0d\u540c\u5206\u8fa8\u73873D\u8111\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u8bc1\u660e\u5176\u5bf9\u5206\u8fa8\u7387\u5dee\u5f02\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u901a\u8fc7\u95ed\u5f0f\u5173\u952e\u70b9\u5339\u914d\u8ba1\u7b97\u53d8\u6362\u53c2\u6570\uff0c\u4fdd\u6301\u4e86KeyMorph\u539f\u6709\u7684\u53ef\u89e3\u91ca\u6027\u4f18\u52bf\uff0c\u540c\u65f6\u7a81\u7834\u5206\u8fa8\u7387\u9650\u5236\u3002|\n",
    "2506.13133": "|2025-06-16|EmbodiedPlace: Learning Mixture-of-Features with Embodied Constraints for Visual Place Recognition|Bingxi Liu\u7b49|[2506.13133](http://arxiv.org/pdf/2506.13133)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7b80\u5355\u91cd\u6392\u5e8f\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u5408\u7279\u5f81\uff08MoF\uff09\u65b9\u6cd5\u5728\u5177\u8eab\u7ea6\u675f\u4e0b\u4f18\u5316\u5168\u5c40\u7279\u5f81\uff0c\u63d0\u5347\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u6027\u80fd\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u5177\u8eab\u7ea6\u675f\u5728VPR\u4e2d\u7684\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u5e76\u6839\u636e\u73b0\u6709\u6570\u636e\u96c6\u5c06\u5176\u5206\u7c7b\u4e3aGPS\u6807\u7b7e\u3001\u65f6\u5e8f\u6233\u3001\u5c40\u90e8\u7279\u5f81\u5339\u914d\u548c\u81ea\u76f8\u4f3c\u77e9\u9635\u7b49\u7c7b\u578b\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684MoF\u6743\u91cd\u8ba1\u7b97\u7b56\u7565\uff0c\u91c7\u7528\u591a\u5ea6\u91cf\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u878d\u5408\u591a\u79cd\u7279\u5f81\u4fe1\u606f\u3002  \n\u25c6 \u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u4ec5\u970025 KB\u989d\u5916\u53c2\u6570\u548c\u6bcf\u5e2710\u5fae\u79d2\u5904\u7406\u65f6\u95f4\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\u3002  \n\u25c6 \u5728Pitts-30k\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u57fa\u4e8eDINOv2\u7684\u57fa\u7ebf\u6027\u80fd\u63d0\u53470.9%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002|\n",
    "2506.15180": "|2025-06-18|ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections|Ziling Huang\u7b49|[2506.15180](http://arxiv.org/pdf/2506.15180)|\u65e0|\u25c6 \u63d0\u51faReSeDis\u4efb\u52a1\uff0c\u9996\u6b21\u5c06\u5927\u89c4\u6a21\u56fe\u50cf\u68c0\u7d22\u4e0e\u50cf\u7d20\u7ea7\u5b9a\u4f4d\u7edf\u4e00\uff0c\u8981\u6c42\u6a21\u578b\u6839\u636e\u6587\u672c\u63cf\u8ff0\u5728\u56fe\u50cf\u5e93\u4e2d\u540c\u65f6\u5224\u65ad\u5bf9\u8c61\u662f\u5426\u5b58\u5728\u5e76\u7cbe\u786e\u5b9a\u4f4d\u3002  \n\u25c6 \u6784\u5efa\u9996\u4e2a\u9488\u5bf9\u8be5\u4efb\u52a1\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u786e\u4fdd\u6bcf\u4e2a\u63cf\u8ff0\u552f\u4e00\u5bf9\u5e94\u5206\u6563\u5728\u5927\u89c4\u6a21\u591a\u6837\u56fe\u50cf\u5e93\u4e2d\u7684\u5bf9\u8c61\u5b9e\u4f8b\uff0c\u907f\u514d\u8bef\u5339\u914d\u3002  \n\u25c6 \u8bbe\u8ba1\u8054\u5408\u8bc4\u4f30\u6307\u6807\uff0c\u540c\u65f6\u8861\u91cf\u68c0\u7d22\u53ec\u56de\u7387\u4e0e\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u4e3a\u7aef\u5230\u7aef\u6027\u80fd\u63d0\u4f9b\u91cf\u5316\u6807\u51c6\u3002  \n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u51bb\u7ed3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u96f6\u6837\u672c\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63ed\u793a\u8be5\u4efb\u52a1\u672a\u6765\u7814\u7a76\u7684\u5de8\u5927\u63d0\u5347\u7a7a\u95f4\u3002  \n\u25c6 \u4e3a\u6784\u5efa\u4e0b\u4e00\u4ee3\u9c81\u68d2\u3001\u53ef\u6269\u5c55\u7684\u591a\u6a21\u6001\u641c\u7d22\u7cfb\u7edf\u63d0\u4f9b\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5f25\u8865\u73b0\u6709\u6280\u672f\u4ec5\u4fa7\u91cd\u68c0\u7d22\u6216\u5b9a\u4f4d\u5355\u4e00\u80fd\u529b\u7684\u7f3a\u9677\u3002|\n",
    "2506.20191": "|2025-06-25|Fast entropy-regularized SDP relaxations for permutation synchronization|Michael Lindsey\u7b49|[2506.20191](http://arxiv.org/pdf/2506.20191)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u968f\u673a\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u90e8\u5206\u6392\u5217\u540c\u6b65\u95ee\u9898\uff08PPS\uff09\u7684\u534a\u5b9a\u89c4\u5212\uff08SDP\uff09\u677e\u5f1b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u56fe\u50cf\u5339\u914d\u7684\u6548\u7387\u3002  \n\u25c6 \u5229\u7528\u71b5\u6b63\u5219\u5316\u6280\u672f\u89e3\u51b3\u4e86\u6807\u51c6\u677e\u5f1b\u4e2d\u4f18\u5316\u89e3\u975e\u552f\u4e00\u6027\u7684\u95ee\u9898\uff0c\u589e\u5f3a\u4e86\u7b97\u6cd5\u7684\u7a33\u5b9a\u6027\u548c\u53ef\u9760\u6027\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u4e00\u79cd\u968f\u673a\u6c42\u89e3\u5668\uff0c\u5176\u8ba1\u7b97\u590d\u6742\u5ea6\u5728\u89c2\u6d4b\u5230\u7684\u5bf9\u5e94\u5173\u7cfb\u6570\u91cf\u4e0a\u63a5\u8fd1\u6700\u4f18\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u591a\u79cd\u820d\u5165\u7a0b\u5e8f\uff0c\u80fd\u591f\u4ece\u9690\u5f0f\u8868\u793a\u7684\u539f\u95ee\u9898\u89e3\u53d8\u91cf\u4e2d\u6062\u590d\u7ec4\u5408\u89e3\uff0c\u540c\u65f6\u652f\u6301\u4fdd\u6301\u5faa\u73af\u4e00\u81f4\u6027\u800c\u4e0d\u5f71\u54cd\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u65b9\u9762\u5747\u8fbe\u5230\u4e86\u5f53\u524d\u6700\u4f18\u6c34\u5e73\u3002  \n\u25c6 \u5c55\u793a\u4e86\u71b5\u6b63\u5219\u5316SDP\u5728PPS\u95ee\u9898\u4e2d\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u4f18\u52bf\uff0c\u4e3a\u4f20\u7edf\u4f4e\u79e9\u6216\u8c31\u6280\u672f\u63d0\u4f9b\u4e86\u65b0\u7684\u66ff\u4ee3\u65b9\u6848\u3002|\n",
    "2506.22336": "|2025-06-27|MatChA: Cross-Algorithm Matching with Feature Augmentation|Paula Carb\u00f3 Cubero\u7b49|[2506.22336](http://arxiv.org/pdf/2506.22336)|\u65e0|\u25c6 \u9996\u6b21\u63d0\u51fa\u8de8\u7279\u5f81\u68c0\u6d4b\u5668\u7684\u7279\u5f81\u5339\u914d\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4e0d\u540c\u8bbe\u5907\u4f7f\u7528\u4e0d\u540c\u7a00\u758f\u7279\u5f81\u63d0\u53d6\u7b97\u6cd5\u65f6\u89c6\u89c9\u5b9a\u4f4d\u5931\u6548\u7684\u95ee\u9898\u3002  \n\u25c6 \u901a\u8fc7\u7279\u5f81\u63cf\u8ff0\u7b26\u589e\u5f3a\u6280\u672f\u63d0\u5347\u8de8\u68c0\u6d4b\u5668\u573a\u666f\u4e0b\u7684\u7279\u5f81\u5339\u914d\u6027\u80fd\uff0c\u7a81\u7834\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u76f8\u540c\u5173\u952e\u70b9\u7684\u9650\u5236\u3002  \n\u25c6 \u5f15\u5165\u7279\u5f81\u8f6c\u6362\u5230\u6f5c\u5728\u7a7a\u95f4\u7684\u7b56\u7565\uff0c\u6709\u6548\u5e94\u5bf9\u5173\u952e\u70b9\u4f4e\u91cd\u590d\u6027\u548c\u63cf\u8ff0\u7b26\u533a\u5206\u5ea6\u4e0d\u8db3\u7684\u6311\u6218\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u8de8\u7279\u5f81\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u56fe\u50cf\u5339\u914d\u548c\u89c6\u89c9\u5b9a\u4f4d\u7684\u51c6\u786e\u7387\u3002  \n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u4e0d\u540c\u63cf\u8ff0\u7b26\u6df7\u5408\u4f7f\u7528\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2506.22139": "|2025-07-22|Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs|Shaojie Zhang\u7b49|[2506.22139](http://arxiv.org/pdf/2506.22139)|\u65e0|\u25c6\u63d0\u51faQ-Frame\u65b9\u6cd5\uff0c\u901a\u8fc7\u67e5\u8be2\u81ea\u9002\u5e94\u7684\u5e27\u9009\u62e9\u7b56\u7565\u89e3\u51b3\u89c6\u9891-\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5173\u952e\u65f6\u7a7a\u4fe1\u606f\u4e22\u5931\u7684\u95ee\u9898\uff0c\u7a81\u7834\u4f20\u7edf\u5747\u5300\u91c7\u6837\u7684\u5c40\u9650\u6027\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u7ed3\u5408CLIP\u7b49\u6587\u672c-\u56fe\u50cf\u5339\u914d\u7f51\u7edc\uff0c\u5b9e\u73b0\u65e0\u9700\u8bad\u7ec3\u7684\u5373\u63d2\u5373\u7528\u5f0f\u5e27\u9009\u62e9\uff0c\u5229\u7528Gumbel-Max\u6280\u5de7\u63d0\u5347\u9009\u62e9\u6548\u7387\u3002  \n\u25c6\u5f15\u5165\u591a\u5206\u8fa8\u7387\u7f29\u653e\u673a\u5236\uff0c\u6839\u636e\u89c6\u9891\u5185\u5bb9\u548c\u67e5\u8be2\u9700\u6c42\u52a8\u6001\u8c03\u6574\u5e27\u7684\u65f6\u7a7a\u5206\u8fa8\u7387\uff0c\u4f18\u5316\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u3002  \n\u25c6\u5728\u4fdd\u6301\u8ba1\u7b97\u8d1f\u8f7d\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u589e\u52a0\u53ef\u5904\u7406\u7684\u5e27\u6570\uff0c\u540c\u65f6\u4fdd\u7559\u5bf9\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u7684\u65f6\u7a7a\u7ec6\u8282\u3002  \n\u25c6\u5728MLVU\u3001LongVideoBench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u6db5\u76d6\u591a\u79cd\u89c6\u9891\u7406\u89e3\u4efb\u52a1\uff0c\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u3002  \n\u25c6\u4e3a\u89c6\u9891-\u5927\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u8f7b\u91cf\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u8ba1\u7b97\u6548\u7387\u4e0e\u8bed\u4e49\u7406\u89e3\u6df1\u5ea6\u7684\u77db\u76fe\u3002|\n",
    "2506.21923": "|2025-06-27|ZeroReg3D: A Zero-shot Registration Pipeline for 3D Consecutive Histopathology Image Reconstruction|Juming Xiong\u7b49|[2506.21923](http://arxiv.org/pdf/2506.21923)|\u65e0|\u25c6 \u63d0\u51faZeroReg3D\uff0c\u9996\u4e2a\u9488\u5bf9\u8fde\u7eed\u7ec4\u7ec7\u75c5\u7406\u5207\u72473D\u91cd\u5efa\u7684\u96f6\u6837\u672c\u914d\u51c6\u6846\u67b6\uff0c\u65e0\u9700\u8bad\u7ec3\u6216\u5fae\u8c03\u5373\u53ef\u76f4\u63a5\u5e94\u7528\u3002  \n\u25c6 \u521b\u65b0\u7ed3\u5408\u96f6\u6837\u672c\u6df1\u5ea6\u5b66\u4e60\u5173\u952e\u70b9\u5339\u914d\u4e0e\u57fa\u4e8e\u4f18\u5316\u7684\u4eff\u5c04/\u975e\u521a\u6027\u914d\u51c6\u6280\u672f\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u7cbe\u5ea6\u4e0e\u6cdb\u5316\u6027\u4e0a\u7684\u77db\u76fe\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u89e3\u51b3\u7ec4\u7ec7\u53d8\u5f62\u3001\u5207\u7247\u4f2a\u5f71\u3001\u67d3\u8272\u5dee\u5f02\u548c\u5149\u7167\u4e0d\u4e00\u81f4\u56db\u5927\u6311\u6218\uff0c\u663e\u8457\u63d0\u53473D\u91cd\u5efa\u7684\u89e3\u5256\u7ed3\u6784\u4fdd\u771f\u5ea6\u3002  \n\u25c6 \u7a81\u7834\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u7684\u9650\u5236\uff0c\u901a\u8fc7\u96f6\u6837\u672c\u7b56\u7565\u5b9e\u73b0\u8de8\u6570\u636e\u96c6\u7684\u9ad8\u9002\u5e94\u6027\u3002  \n\u25c6 \u516c\u5f00\u5b8c\u6574\u4ee3\u7801\u5e93\uff0c\u4e3a\u75c5\u7406\u5b66\u7814\u7a76\u548c\u4e34\u5e8a\u8bca\u65ad\u63d0\u4f9b\u53ef\u76f4\u63a5\u90e8\u7f72\u7684\u5f00\u6e90\u5de5\u5177\u3002|\n",
    "2506.23707": "|2025-06-30|Efficient and Accurate Image Provenance Analysis: A Scalable Pipeline for Large-scale Images|Jiewei Lai\u7b49|[2506.23707](http://arxiv.org/pdf/2506.23707)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u56fe\u50cf\u6eaf\u6e90\u5206\u6790\u7ba1\u9053\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u7684\u4e24\u5927\u74f6\u9888\u3002  \n\n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u4fee\u6539\u5173\u7cfb\u8ffd\u8e2a\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fe\u50cf\u53d8\u4f53\u7684\u8fc7\u6ee4\u6548\u679c\uff0c\u80fd\u591f\u5168\u9762\u53d1\u73b0\u4e0e\u67e5\u8be2\u56fe\u50cf\u89c6\u89c9\u76f8\u4f3c\u5ea6\u4f4e\u7684\u53d8\u4f53\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u56e0\u4f4e\u76f8\u4f3c\u5ea6\u800c\u9057\u6f0f\u4e25\u91cd\u4fee\u6539\u56fe\u50cf\u7684\u95ee\u9898\u3002  \n\n\u25c6 \u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u7279\u5f81\u5339\u914d\u548c\u538b\u7f29\u4f2a\u5f71\u6355\u6349\u6280\u672f\uff0c\u589e\u5f3a\u4e86\u65b9\u6cd5\u5bf9\u591a\u6837\u5316\u4fee\u6539\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u5206\u6790\u56fe\u50cf\u95f4\u7684\u5173\u8054\u6027\u548c\u4fee\u6539\u65b9\u5411\u3002  \n\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u7b56\u7565\uff0c\u5e76\u5728\u6784\u5efa\u6709\u5411\u6eaf\u6e90\u56fe\u65f6\u6d88\u9664\u4e86\u5197\u4f59\u7684\u6210\u5bf9\u5206\u6790\uff0c\u5c06\u65f6\u95f4\u590d\u6742\u5ea6\u4ece\u4e8c\u6b21\u964d\u4f4e\u5230\u7ebf\u6027\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u573a\u666f\u4e0b\u7684\u9ad8\u6548\u5904\u7406\u3002  \n\n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u7cbe\u5ea6\u4e0a\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u5347\u4e8616.7%-56.1%\uff0c\u5e76\u57281000\u4e07\u89c4\u6a21\u56fe\u50cf\u4e0a\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u4ec53\u79d2\uff0c\u8fdc\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u768412\u5206\u949f\uff0c\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u3002  \n\n\u25c6 \u6700\u7ec8\u751f\u6210\u7684\u6eaf\u6e90\u56fe\u80fd\u591f\u7cbe\u786e\u523b\u753b\u56fe\u50cf\u7684\u6f14\u5316\u5386\u53f2\uff0c\u4e3a\u6570\u5b57\u6cbb\u7406\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u53d6\u8bc1\u5de5\u5177\u3002|\n",
    "2506.23077": "|2025-06-29|Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization|Suofei Zhang\u7b49|[2506.23077](http://arxiv.org/pdf/2506.23077)|\u65e0|\u25c6 \u63d0\u51fa\u4e86Distance-Aware Cross-View Geo-Localization (DACVGL)\u65b0\u95ee\u9898\uff0c\u5f3a\u8c03\u6a21\u578b\u9700\u7efc\u5408\u6355\u6349\u76ee\u6807\u5468\u56f4\u4e0a\u4e0b\u6587\u4fe1\u606f\u5e76\u964d\u4f4e\u5b9a\u4f4d\u8bef\u5dee\u6210\u672c\u3002  \n\u25c6 \u6784\u5efa\u9996\u4e2a\u591a\u89c6\u89d2\u56fe\u50cf\u4e0e\u7cbe\u786e\u8ddd\u79bb\u6807\u6ce8\u7684\u57fa\u51c6\u6570\u636e\u96c6DA-Campus\uff0c\u6db5\u76d6\u4e09\u79cd\u7a7a\u95f4\u5206\u8fa8\u7387\uff0c\u652f\u6301\u7cfb\u7edf\u6027\u7814\u7a76\u3002  \n\u25c6 \u5c06DACVGL\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u8de8\u57df\u5206\u5c42\u68c0\u7d22\u4efb\u52a1\uff0c\u63ed\u793a\u4f20\u7edf\u5ea6\u91cf\u5b66\u4e60\u65e0\u6cd5\u89e3\u51b3\u5efa\u7b51\u95f4\u590d\u6742\u7a7a\u95f4\u5173\u7cfb\u7684\u95ee\u9898\u3002  \n\u25c6 \u63d0\u51fa\u52a8\u6001\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6DyCL\uff0c\u901a\u8fc7\u5206\u5c42\u7a7a\u95f4\u95f4\u9694\u9010\u6b65\u5bf9\u9f50\u7279\u5f81\u8868\u793a\uff0c\u89e3\u51b3\u8de8\u89c6\u89d2\u5c42\u6b21\u5316\u68c0\u7d22\u96be\u9898\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660eDyCL\u4e0e\u73b0\u6709\u591a\u5c3a\u5ea6\u5ea6\u91cf\u5b66\u4e60\u65b9\u6cd5\u9ad8\u5ea6\u4e92\u8865\uff0c\u663e\u8457\u63d0\u5347\u5206\u5c42\u68c0\u7d22\u6027\u80fd\u548c\u8de8\u89c6\u89d2\u5730\u7406\u5b9a\u4f4d\u7cbe\u5ea6\u3002  \n\u25c6 \u516c\u5f00\u4ee3\u7801\u548c\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u540e\u7eed\u7814\u7a76\u3002|\n",
    "2507.01667": "|2025-07-02|What does really matter in image goal navigation?|Gianluca Monaci\u7b49|[2507.01667](http://arxiv.org/pdf/2507.01667)|\u65e0|\u25c6 \u7814\u7a76\u4e86\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u5728\u56fe\u50cf\u76ee\u6807\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u4f9d\u8d56\u4e13\u7528\u56fe\u50cf\u5339\u914d\u6216\u9884\u8bad\u7ec3\u89c6\u89c9\u6a21\u5757\u7684\u65b9\u6cd5\u3002  \n\u25c6 \u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u9a8c\u5206\u6790\u4e86\u591a\u79cd\u67b6\u6784\u8bbe\u8ba1\uff08\u5982\u5ef6\u8fdf\u878d\u5408\u3001\u901a\u9053\u5806\u53e0\u3001\u7a7a\u95f4\u5230\u6df1\u5ea6\u6295\u5f71\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\uff09\u5bf9\u5bfc\u822a\u6027\u80fd\u7684\u5f71\u54cd\u3002  \n\u25c6 \u63ed\u793a\u4e86\u4eff\u771f\u73af\u5883\u8bbe\u7f6e\u5bf9\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u6307\u51fa\u4eff\u771f\u4e2d\u5b58\u5728\u7684\u6377\u5f84\u95ee\u9898\uff0c\u540c\u65f6\u8bc1\u660e\u90e8\u5206\u80fd\u529b\u53ef\u8fc1\u79fb\u5230\u66f4\u771f\u5b9e\u573a\u666f\u3002  \n\u25c6 \u9996\u6b21\u53d1\u73b0\u5bfc\u822a\u6027\u80fd\u4e0e\u76f8\u5bf9\u4f4d\u59ff\u4f30\u8ba1\u80fd\u529b\u4e4b\u95f4\u5b58\u5728\u76f8\u5173\u6027\uff0c\u8868\u660e\u540e\u8005\u662f\u5bfc\u822a\u4efb\u52a1\u4e2d\u81ea\u7136\u6d8c\u73b0\u7684\u91cd\u8981\u5b50\u6280\u80fd\u3002  \n\u25c6 \u4e3a\u4ec5\u901a\u8fc7\u5bfc\u822a\u5956\u52b1\u4fe1\u53f7\u8bad\u7ec3\u76f8\u5bf9\u4f4d\u59ff\u4f30\u8ba1\u5668\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\uff0c\u5bf9\u5177\u8eabAI\u53ca\u5176\u4ed6\u9886\u57df\u5177\u6709\u6f5c\u5728\u5f71\u54cd\u3002  \n\u25c6 \u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7aef\u5230\u7aef\u8bad\u7ec3\u667a\u80fd\u4f53\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u4eff\u771f\u4e0e\u73b0\u5b9e\u573a\u666f\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u95ee\u9898\u3002|\n",
    "2507.03868": "|2025-07-05|From Query to Explanation: Uni-RAG for Multi-Modal Retrieval-Augmented Learning in STEM|Xinyi Wu\u7b49|[2507.03868](http://arxiv.org/pdf/2507.03868)|\u65e0|\u25c6 \u63d0\u51faUni-Retrieval\u6a21\u5757\uff0c\u901a\u8fc7\u63d0\u53d6\u67e5\u8be2\u98ce\u683c\u539f\u578b\u5e76\u52a8\u6001\u5339\u914dPrompt Bank\u4e2d\u7684\u6807\u8bb0\uff0c\u89e3\u51b3\u73b0\u6709\u68c0\u7d22\u7cfb\u7edf\u65e0\u6cd5\u5904\u7406\u6559\u80b2\u573a\u666f\u591a\u6837\u6027\u548c\u6a21\u7cca\u6027\u7684\u95ee\u9898\u3002  \n\u25c6 \u5f15\u5165Prompt Bank\uff0c\u7ed3\u5408MoE-LoRA\u6a21\u5757\u7f16\u7801\u9886\u57df\u77e5\u8bc6\uff0c\u652f\u6301\u6d4b\u8bd5\u65f6\u9002\u5e94\u672a\u89c1\u67e5\u8be2\u7c7b\u578b\uff0c\u589e\u5f3a\u68c0\u7d22\u7075\u6d3b\u6027\u3002  \n\u25c6 \u5c06Uni-Retrieval\u4e0e\u8f7b\u91cf\u7ea7\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u6784\u5efa\u5b8c\u6574\u7684Uni-RAG\u6d41\u7a0b\uff0c\u5b9e\u73b0\u4ece\u68c0\u7d22\u5230\u81ea\u7136\u8bed\u8a00\u751f\u6210\u7684\u6559\u80b2\u5185\u5bb9\u8f93\u51fa\u3002  \n\u25c6 \u91c7\u7528\u98ce\u683c\u6761\u4ef6\u67e5\u8be2\u673a\u5236\uff0c\u751f\u6210\u7b26\u5408\u5b66\u4e60\u76ee\u6807\u7684\u53ef\u8bfb\u89e3\u91ca\u3001\u53cd\u9988\u6216\u6559\u5b66\u5185\u5bb9\uff0c\u63d0\u5347\u4e2a\u6027\u5316\u6559\u5b66\u6548\u679c\u3002  \n\u25c6 \u5728SER\u7b49\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUni-RAG\u5728\u68c0\u7d22\u7cbe\u5ea6\u548c\u751f\u6210\u8d28\u91cf\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u7cfb\u7edf\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u8ba1\u7b97\u6210\u672c\u3002  \n\u25c6 \u4e3aSTEM\u6559\u80b2\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u667a\u80fd\u89e3\u51b3\u65b9\u6848\uff0c\u5f25\u5408\u68c0\u7d22\u4e0e\u751f\u6210\u7684\u9e3f\u6c9f\uff0c\u652f\u6301\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684\u5b66\u4e60\u8f85\u52a9\u3002|\n",
    "2507.06744": "|2025-07-09|Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching|Yafei Zhang\u7b49|[2507.06744](http://arxiv.org/pdf/2507.06744)|\u65e0|\u25c6 \u63d0\u51fa\u5c40\u90e8-\u5168\u5c40\u53cc\u7c92\u5ea6\u8eab\u4efd\u5173\u8054\u673a\u5236\uff0c\u901a\u8fc7\u6279\u5185\u8de8\u6a21\u6001\u663e\u5f0f\u5173\u8054\u5f3a\u5316\u8eab\u4efd\u7ea6\u675f\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u7ec6\u5fae\u5dee\u5f02\u7684\u6355\u6349\u80fd\u529b\u3002  \n\u25c6 \u6784\u5efa\u4ee5\u89c6\u89c9\u6a21\u6001\u4e3a\u951a\u70b9\u7684\u52a8\u6001\u8de8\u6a21\u6001\u5173\u8054\u7f51\u7edc\uff0c\u5f15\u5165\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u52a8\u6001\u8c03\u6574\u673a\u5236\uff0c\u6709\u6548\u589e\u5f3a\u5f31\u5173\u8054\u6837\u672c\u7684\u8bc6\u522b\u80fd\u529b\u3002  \n\u25c6 \u8bbe\u8ba1\u4fe1\u606f\u4e0d\u5bf9\u79f0\u6837\u672c\u5bf9\u6784\u5efa\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e00\u81f4\u6027\u5b66\u4e60\u89e3\u51b3\u56f0\u96be\u6837\u672c\u6316\u6398\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002  \n\u25c6 \u9996\u6b21\u5728\u5f31\u76d1\u7763\u6587\u672c-\u884c\u4eba\u56fe\u50cf\u5339\u914d\u4efb\u52a1\u4e2d\u5b9e\u73b0\u590d\u6742\u4e00\u5bf9\u591a\u8eab\u4efd\u5173\u7cfb\u7684\u5efa\u6a21\uff0c\u7a81\u7834\u6027\u80fd\u74f6\u9888\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u8de8\u6a21\u6001\u5339\u914d\u51c6\u786e\u7387\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.16201": "|2025-07-22|A Single-step Accurate Fingerprint Registration Method Based on Local Feature Matching|Yuwei Jia\u7b49|[2507.16201](http://arxiv.org/pdf/2507.16201)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u5355\u6b65\u6307\u7eb9\u914d\u51c6\u7b97\u6cd5\uff0c\u76f4\u63a5\u901a\u8fc7\u9884\u6d4b\u4e24\u5e45\u6307\u7eb9\u56fe\u50cf\u4e4b\u95f4\u7684\u534a\u5bc6\u96c6\u5339\u914d\u70b9\u5bf9\u5e94\u5173\u7cfb\u6765\u5b9e\u73b0\u5bf9\u9f50\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u4e24\u6b65\u6cd5\u7684\u590d\u6742\u6027\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u4f4e\u8d28\u91cf\u6307\u7eb9\u56fe\u50cf\u56e0\u7279\u5f81\u70b9\u6570\u91cf\u4e0d\u8db3\u5bfc\u81f4\u7684\u521d\u59cb\u914d\u51c6\u5931\u8d25\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u914d\u51c6\u7684\u9c81\u68d2\u6027\u548c\u6210\u529f\u7387\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u7ed3\u5408\u5168\u5c40-\u5c40\u90e8\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u4e24\u5e45\u6307\u7eb9\u56fe\u50cf\u4e4b\u95f4\u7684\u7aef\u5230\u7aef\u50cf\u7d20\u7ea7\u5bf9\u9f50\uff0c\u63d0\u5347\u4e86\u914d\u51c6\u7cbe\u5ea6\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u4ec5\u9700\u5355\u6b65\u914d\u51c6\u5373\u53ef\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u5339\u914d\u6027\u80fd\uff0c\u540c\u65f6\u8fd8\u80fd\u4e0e\u5bc6\u96c6\u914d\u51c6\u7b97\u6cd5\u7ed3\u5408\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002  \n\u25c6 \u4e3a\u6307\u7eb9\u8bc6\u522b\u4e2d\u7684\u56fe\u50cf\u5931\u771f\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002|\n",
    "2507.18551": "|2025-07-24|A 3D Cross-modal Keypoint Descriptor for MR-US Matching and Registration|Daniil Morozov\u7b49|[2507.18551](http://arxiv.org/pdf/2507.18551)|\u65e0|\u25c6\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b3D\u8de8\u6a21\u6001\u5173\u952e\u70b9\u63cf\u8ff0\u7b26\uff0c\u7528\u4e8e\u89e3\u51b3MRI\u4e0e\u5b9e\u65f6\u8d85\u58f0(iUS)\u4e4b\u95f4\u7684\u914d\u51c6\u96be\u9898\uff0c\u514b\u670d\u4e86\u6a21\u6001\u95f4\u5916\u89c2\u3001\u5206\u8fa8\u7387\u548c\u89c6\u91ce\u5dee\u5f02\u5927\u7684\u95ee\u9898\u3002  \n\u25c6\u91c7\u7528\u60a3\u8005\u7279\u5f02\u6027\u7684\"\u5408\u6210\u5339\u914d\"\u65b9\u6cd5\uff0c\u4ece\u672f\u524dMRI\u751f\u6210\u5408\u6210iUS\u4f53\u79ef\uff0c\u5b9e\u73b0\u4e86\u6709\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u7684\u5171\u4eab\u63cf\u8ff0\u7b26\u7a7a\u95f4\u8bad\u7ec3\u3002  \n\u25c6\u5f00\u53d1\u4e86\u6982\u7387\u5173\u952e\u70b9\u68c0\u6d4b\u7b56\u7565\uff0c\u80fd\u591f\u8bc6\u522b\u89e3\u5256\u5b66\u663e\u8457\u4e14\u6a21\u6001\u4e00\u81f4\u7684\u7279\u5f81\u4f4d\u7f6e\uff0c\u63d0\u9ad8\u4e86\u5339\u914d\u7684\u51c6\u786e\u6027\u3002  \n\u25c6\u5728\u8bad\u7ec3\u9636\u6bb5\u4f7f\u7528\u57fa\u4e8e\u8bfe\u7a0b\u7684\u4e09\u5143\u7ec4\u635f\u5931\u51fd\u6570\u548c\u52a8\u6001\u96be\u8d1f\u6837\u672c\u6316\u6398\u6280\u672f\uff0c\u4f7f\u63cf\u8ff0\u7b26\u5177\u6709\u6297iUS\u4f2a\u5f71(\u5982\u6591\u70b9\u566a\u58f0)\u548c\u65cb\u8f6c\u4e0d\u53d8\u6027\u7684\u7279\u70b9\u3002  \n\u25c6\u6574\u4e2a\u6846\u67b6\u5177\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u65e0\u9700\u4eba\u5de5\u521d\u59cb\u5316\uff0c\u5bf9iUS\u89c6\u91ce\u53d8\u5316\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\uff0c\u5728ReMIND\u6570\u636e\u96c6\u4e0a\u8fbe\u523069.8%\u7684\u5e73\u5747\u5339\u914d\u7cbe\u5ea6\u548c2.39mm\u7684\u914d\u51c6\u8bef\u5dee\u3002  \n\u25c6\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u8be5\u65b9\u6848\u9996\u6b21\u5b9e\u73b0\u4e86\u4ece\u5173\u952e\u70b9\u5339\u914d\u5230\u521a\u6027\u914d\u51c6\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u5728\u4e34\u5e8a\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u5177\u5b9e\u7528\u4ef7\u503c\u3002|\n",
    "2507.19118": "|2025-07-25|Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching|Abu Sadat Mohammad Salehin Amit\u7b49|[2507.19118](http://arxiv.org/pdf/2507.19118)|\u65e0|\u25c6\u63d0\u51fa\u8de8\u65f6\u7a7a\u878d\u5408\u6ce8\u610f\u529b\u673a\u5236(CSTF)\uff0c\u901a\u8fc7\u72ec\u7acb\u68c0\u6d4b\u53c2\u8003\u56fe\u548c\u67e5\u8be2\u56fe\u4e2d\u7684\u5c3a\u5ea6\u4e0d\u53d8\u5173\u952e\u70b9\u6765\u589e\u5f3a\u7279\u5f81\u8868\u793a\uff0c\u89e3\u51b3\u591a\u6a21\u6001\u9065\u611f\u56fe\u50cf\u95f4\u51e0\u4f55\u548c\u8f90\u5c04\u5dee\u5f02\u5927\u7684\u95ee\u9898\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u6784\u5efa\u5bf9\u5e94\u56fe\uff0c\u540c\u65f6\u5229\u7528\u591a\u56fe\u50cf\u533a\u57df\u4fe1\u606f\uff0c\u63d0\u5347\u8de8\u6a21\u6001\u7279\u5f81\u5339\u914d\u80fd\u529b\u3002  \n\u25c6\u5c06\u76f8\u4f3c\u6027\u5339\u914d\u91cd\u65b0\u5b9a\u4e49\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u7ed3\u5408SoftMax\u548c\u5168\u5377\u79ef\u7f51\u7edc(FCN)\u5c42\uff0c\u517c\u987e\u5c40\u90e8\u7279\u5f81\u654f\u611f\u6027\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002  \n\u25c6\u5728HRSC2016\u548cDOTA\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u76ee\u6807\u68c0\u6d4b\u4efb\u52a1\u7684\u6700\u4f18\u6027\u80fd\uff0c\u5e73\u5747mAP\u5206\u522b\u8fbe\u523090.99%\u548c90.86%\u3002  \n\u25c6\u4fdd\u630112.5 FPS\u7684\u63a8\u7406\u901f\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002  \n\u25c6\u9996\u6b21\u8bc1\u660e\u6539\u8fdb\u7684\u8de8\u6a21\u6001\u7279\u5f81\u5339\u914d\u80fd\u76f4\u63a5\u63d0\u5347\u9065\u611f\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u76ee\u6807\u68c0\u6d4b\uff09\u7684\u6027\u80fd\u3002|\n",
    "2507.22791": "|2025-07-30|Modality-Aware Feature Matching: A Comprehensive Review of Single- and Cross-Modality Techniques|Weide Liu\u7b49|[2507.22791](http://arxiv.org/pdf/2507.22791)|\u65e0|\u25c6 \u5168\u9762\u7efc\u8ff0\u4e86\u5355\u6a21\u6001\u4e0e\u8de8\u6a21\u6001\u7279\u5f81\u5339\u914d\u6280\u672f\uff0c\u6db5\u76d6RGB\u56fe\u50cf\u3001\u6df1\u5ea6\u56fe\u50cf\u30013D\u70b9\u4e91\u3001LiDAR\u626b\u63cf\u3001\u533b\u5b66\u56fe\u50cf\u53ca\u89c6\u89c9-\u8bed\u8a00\u4ea4\u4e92\u7b49\u591a\u79cd\u6a21\u6001\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7cfb\u7edf\u6027\u603b\u7ed3\u7684\u7a7a\u767d\u3002  \n\u25c6 \u5bf9\u6bd4\u5206\u6790\u4e86\u4f20\u7edf\u624b\u5de5\u65b9\u6cd5\uff08\u5982Harris\u89d2\u70b9\u3001SIFT\u548cORB\u63cf\u8ff0\u5b50\uff09\u4e0e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff08\u5982SuperPoint\u548cLoFTR\uff09\u7684\u4f18\u52a3\uff0c\u6307\u51fa\u540e\u8005\u5728\u8de8\u6a21\u6001\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u4e0a\u7684\u663e\u8457\u63d0\u5347\u3002  \n\u25c6 \u91cd\u70b9\u4ecb\u7ecd\u4e86\u6a21\u6001\u611f\u77e5\u7684\u521b\u65b0\u6280\u672f\uff0c\u4f8b\u5982\u9488\u5bf9\u6df1\u5ea6\u56fe\u50cf\u7684\u51e0\u4f55\u4e0e\u6df1\u5ea6\u4e13\u7528\u63cf\u8ff0\u5b50\u3001\u9488\u5bf93D\u70b9\u4e91\u7684\u7a00\u758f\u4e0e\u7a20\u5bc6\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u53caLiDAR\u626b\u63cf\u4e2d\u57fa\u4e8e\u6ce8\u610f\u529b\u589e\u5f3a\u7684\u795e\u7ecf\u7f51\u7edc\u3002  \n\u25c6 \u5f3a\u8c03\u4e86\u8de8\u6a21\u6001\u5e94\u7528\u7684\u7a81\u7834\uff0c\u5982\u533b\u5b66\u56fe\u50cf\u914d\u51c6\u4e2d\u7684MIND\u63cf\u8ff0\u5b50\u548c\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u4ea4\u4e92\u5339\u914d\u6280\u672f\uff0c\u5c55\u793a\u4e86\u7279\u5f81\u5339\u914d\u5728\u591a\u6837\u5316\u6570\u636e\u4ea4\u4e92\u4e2d\u7684\u6269\u5c55\u6f5c\u529b\u3002  \n\u25c6 \u7cfb\u7edf\u603b\u7ed3\u4e86\u5f53\u524d\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411\uff0c\u4e3a\u8de8\u6a21\u6001\u7279\u5f81\u5339\u914d\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u8def\u7ebf\u56fe\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u5411\u66f4\u590d\u6742\u573a\u666f\u53d1\u5c55\u3002|\n",
    "2507.23371": "|2025-07-31|VMatcher: State-Space Semi-Dense Local Feature Matching|Ali Youssef|[2507.23371](http://arxiv.org/pdf/2507.23371)|\u65e0|\u25c6 \u63d0\u51faVMatcher\uff0c\u4e00\u79cd\u7ed3\u5408Mamba\u548cTransformer\u7684\u6df7\u5408\u7f51\u7edc\uff0c\u7528\u4e8e\u56fe\u50cf\u5bf9\u7684\u534a\u7a20\u5bc6\u7279\u5f81\u5339\u914d\u3002  \n\u25c6 \u9996\u6b21\u5c06\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u5f15\u5165\u7279\u5f81\u5339\u914d\u4efb\u52a1\uff0c\u5229\u7528Mamba\u7684\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u663e\u8457\u964d\u4f4e\u4f20\u7edfTransformer\u7684\u4e8c\u6b21\u65b9\u8ba1\u7b97\u5f00\u9500\u3002  \n\u25c6 \u8bbe\u8ba1\u591a\u5c42\u7ea7\u6df7\u5408\u67b6\u6784\uff0c\u540c\u65f6\u4fdd\u7559Transformer\u6ce8\u610f\u529b\u673a\u5236\u7684\u4f18\u52bf\u548cMamba\u9ad8\u6548\u957f\u5e8f\u5217\u5904\u7406\u80fd\u529b\uff0c\u517c\u987e\u6027\u80fd\u4e0e\u6548\u7387\u3002  \n\u25c6 \u5728\u4fdd\u6301\u6216\u8d85\u8d8a\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u5927\u5e45\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u5408\u5b9e\u65f6\u6027\u8981\u6c42\u9ad8\u7684\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u5e76\u63d0\u4f9b\u591a\u79cd\u914d\u7f6e\u65b9\u6848\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6846\u67b6\u3002|\n",
    "2508.02278": "|2025-08-09|SGAD: Semantic and Geometric-aware Descriptor for Local Feature Matching|Xiangzeng Liu\u7b49|[2508.02278](http://arxiv.org/pdf/2508.02278)|\u65e0|\u25c6 \u63d0\u51faSGAD\u7f51\u7edc\uff0c\u901a\u8fc7\u751f\u6210\u9ad8\u533a\u5206\u5ea6\u7684\u533a\u57df\u63cf\u8ff0\u7b26\uff0c\u76f4\u63a5\u5b9e\u73b0\u533a\u57df\u5339\u914d\uff0c\u907f\u514d\u4f20\u7edf\u4f4e\u6548\u7684\u50cf\u7d20\u7ea7\u6bd4\u8f83\u548c\u590d\u6742\u56fe\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u5339\u914d\u7cbe\u5ea6\u548c\u6548\u7387\u3002  \n\u25c6 \u8bbe\u8ba1\u65b0\u9896\u7684\u76d1\u7763\u7b56\u7565\uff0c\u5c06\u533a\u57df\u5339\u914d\u4efb\u52a1\u5206\u89e3\u4e3a\u5206\u7c7b\u548c\u6392\u5e8f\u5b50\u4efb\u52a1\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u5339\u914d\u6027\u80fd\u3002  \n\u25c6 \u5f15\u5165\u5c42\u6b21\u5305\u5bb9\u5197\u4f59\u8fc7\u6ee4\u5668\uff08HCRF\uff09\uff0c\u901a\u8fc7\u5206\u6790\u5305\u5bb9\u56fe\u6d88\u9664\u91cd\u53e0\u533a\u57df\uff0c\u4f18\u5316\u5339\u914d\u7ed3\u679c\u3002  \n\u25c6 \u5728\u6548\u7387\u4e0a\u5b9e\u73b0\u91cd\u5927\u7a81\u7834\uff0c\u76f8\u6bd4MESA\u65b9\u6cd5\u8fd0\u884c\u65f6\u51cf\u5c1160\u500d\uff080.82\u79d2 vs 60.23\u79d2\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u66f4\u9ad8\u7cbe\u5ea6\u3002  \n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\uff1aSGAD+LoFTR\u5728\u5ba4\u5916\u59ff\u6001\u4f30\u8ba1\u4e2d\u6bd4DKM\u66f4\u5feb\uff080.82\u79d2 vs 1.51\u79d2\uff09\u4e14\u66f4\u51c6\u786e\uff0865.98 vs 61.11\uff09\uff1bSGAD+ROMA\u5728\u5ba4\u5185\u59ff\u6001\u4f30\u8ba1\u4e2dAUC@5\u00b0\u63d0\u53477.39%\uff0c\u8fbe\u5230\u65b0SOTA\u3002|\n",
    "2508.05187": "|2025-08-07|Refining Gaussian Splatting: A Volumetric Densification Approach|Mohamed Abdul Gafoor\u7b49|[2508.05187](http://arxiv.org/pdf/2508.05187)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u60ef\u6027\u4f53\u79ef\u7684\u65b0\u578b\u5bc6\u5ea6\u63a7\u5236\u65b9\u6cd5\uff0c\u5229\u7528\u9ad8\u65af\u51fd\u6570\u7684\u60ef\u6027\u4f53\u79ef\u6307\u5bfc3D\u9ad8\u65af\u5206\u5e03\u7684\u7cbe\u7ec6\u5316\u8fc7\u7a0b\uff0c\u514b\u670d\u4e86\u539f\u59cb3DGS\u5bc6\u5ea6\u7b56\u7565\u7684\u7f3a\u9677\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u7814\u7a76\u4e86\u4f20\u7edfSfM\u4e0e\u6df1\u5ea6\u56fe\u50cf\u5339\u914d(DIM)\u4e24\u79cd\u70b9\u4e91\u521d\u59cb\u5316\u65b9\u6cd5\u5bf9\u91cd\u5efa\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u4e3a\u521d\u59cb\u5316\u9009\u62e9\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002  \n\u25c6 \u901a\u8fc7\u81ea\u9002\u5e94\u5bc6\u5ea6\u63a7\u5236(ADC)\u81ea\u52a8\u5316\u5b9e\u73b0\u4e86\u9ad8\u65af\u57fa\u5143\u7684\u52a8\u6001\u589e\u5220\uff0c\u663e\u8457\u63d0\u5347\u4e86\u70b9\u57fa\u5143\u7ba1\u7406\u6548\u7387\u3002  \n\u25c6 \u5728Mip-NeRF 360\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u91cd\u5efa\u8d28\u91cf\u4e0a\u5168\u9762\u8d85\u8d8a\u539f\u59cb3DGS\uff0c\u4e14\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\u3002  \n\u25c6 \u5c06\u4f53\u79ef\u4fe1\u606f\u4e0e\u5bc6\u5ea6\u63a7\u5236\u76f8\u7ed3\u5408\uff0c\u4e3a3D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u7684\u51e0\u4f55\u4f18\u5316\u5f00\u8f9f\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2508.07812": "|2025-08-11|Semi-supervised Multiscale Matching for SAR-Optical Image|Jingze Gai\u7b49|[2508.07812](http://arxiv.org/pdf/2508.07812)|\u65e0|\u25c6\u63d0\u51fa\u534a\u76d1\u7763\u591a\u5c3a\u5ea6\u5339\u914d\u6846\u67b6S2M2-SAR\uff0c\u5229\u7528\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u548c\u5927\u91cf\u65e0\u6807\u6ce8SAR-\u5149\u5b66\u56fe\u50cf\u5bf9\u8fdb\u884c\u8bad\u7ec3\uff0c\u89e3\u51b3\u6807\u6ce8\u6210\u672c\u9ad8\u7684\u95ee\u9898\u3002  \n\u25c6\u901a\u8fc7\u7ed3\u5408\u6df1\u5c42\u548c\u6d45\u5c42\u5339\u914d\u7ed3\u679c\u751f\u6210\u4f2a\u6807\u7b7e\u76f8\u4f3c\u6027\u70ed\u56fe\uff0c\u4e3a\u65e0\u6807\u6ce8\u6570\u636e\u63d0\u4f9b\u76d1\u7763\u4fe1\u53f7\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6\u8bbe\u8ba1\u8de8\u6a21\u6001\u7279\u5f81\u589e\u5f3a\u6a21\u5757\uff0c\u91c7\u7528\u65e0\u76d1\u7763\u7684\u8de8\u6a21\u6001\u4e92\u72ec\u7acb\u6027\u635f\u5931\uff0c\u5206\u79bb\u6a21\u6001\u5171\u4eab\u548c\u6a21\u6001\u7279\u5b9a\u7279\u5f81\uff0c\u589e\u5f3a\u7279\u5f81\u89e3\u8026\u80fd\u529b\u3002  \n\u25c6\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u4f18\u5316\u8de8\u6a21\u6001\u7279\u5f81\u8868\u793a\uff0c\u964d\u4f4e\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u63d0\u5347\u6a21\u578b\u5b9e\u7528\u6027\u3002  \n\u25c6\u5b9e\u9a8c\u8868\u660e\uff0cS2M2-SAR\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u534a\u76d1\u7763\u65b9\u6cd5\uff0c\u5e76\u4e0e\u5168\u76d1\u7763SOTA\u65b9\u6cd5\u76f8\u5f53\uff0c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u548c\u5e94\u7528\u6f5c\u529b\u3002|\n",
    "2508.08521": "|2025-08-11|VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models|Mansi Phute\u7b49|[2508.08521](http://arxiv.org/pdf/2508.08521)|\u65e0|\u25c6\u63d0\u51faVISOR\u65b9\u6cd5\uff0c\u4ec5\u901a\u8fc7\u4f18\u5316\u89c6\u89c9\u8f93\u5165\u5373\u53ef\u5b9e\u73b0\u7cbe\u51c6\u7684\u884c\u4e3a\u63a7\u5236\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u5185\u90e8\u53c2\u6570\u6216\u6587\u672c\u6307\u4ee4\u3002  \n\u25c6\u9996\u521b\"\u901a\u7528\u5f15\u5bfc\u56fe\u50cf\"\u6982\u5ff5\uff0c\u901a\u8fc7\u89c6\u89c9\u523a\u6fc0\u8bf1\u5bfc\u76ee\u6807\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u5728\u4fdd\u6301\u9690\u853d\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u53cc\u5411\u884c\u4e3a\u8c03\u63a7\u3002  \n\u25c6\u5728LLaVA-1.5-7B\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u4e09\u5927\u5173\u952e\u5bf9\u9f50\u4efb\u52a1\uff08\u62d2\u7edd\u3001\u8c04\u5a9a\u3001\u751f\u5b58\u672c\u80fd\uff09\uff0c\u5355\u5f20150KB\u56fe\u50cf\u5373\u53ef\u8fbe\u5230\u4e0e\u6fc0\u6d3b\u5411\u91cf\u76f8\u5f53\u7684\u8c03\u63a7\u6548\u679c\u3002  \n\u25c6\u76f8\u6bd4\u7cfb\u7edf\u63d0\u793a\u8bcd\uff083-4%\u6539\u53d8\uff09\u548c\u6fc0\u6d3b\u5411\u91cf\uff08\u5fae\u5f31\u8d1f\u5411\u8c03\u63a7\uff09\uff0cVISOR\u5b9e\u73b0\u9ad8\u8fbe25%\u7684\u884c\u4e3a\u504f\u79fb\uff0c\u540c\u65f6\u4fdd\u630199.9%\u7684MMLU\u57fa\u51c6\u6027\u80fd\u3002  \n\u25c6\u63ed\u793a\u4e86\u89c6\u89c9\u901a\u9053\u7684\u65b0\u578b\u5b89\u5168\u5a01\u80c1\uff1a\u653b\u51fb\u8005\u4ec5\u901a\u8fc7\u56fe\u50cf\u5373\u53ef\u7ed5\u8fc7\u6587\u672c\u9632\u5fa1\u673a\u5236\uff0c\u5b9e\u73b0\u590d\u6742\u884c\u4e3a\u64cd\u63a7\u3002  \n\u25c6\u4e3a\u591a\u6a21\u6001\u6a21\u578b\u63a7\u5236\u63d0\u4f9b\u4e86\u65e0\u9700\u8fd0\u884c\u65f6\u5f00\u9500\u3001\u517c\u5bb9API\u670d\u52a1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u8b66\u793a\u4e86\u89c6\u89c9\u5f15\u5bfc\u653b\u51fb\u7684\u9632\u5fa1\u7d27\u8feb\u6027\u3002|\n",
    "2508.09486": "|2025-08-13|Episodic Memory Representation for Long-form Video Understanding|Yun Wang\u7b49|[2508.09486](http://arxiv.org/pdf/2508.09486)|\u65e0|\u25c6 \u63d0\u51faVideo-EM\u6846\u67b6\uff0c\u89e3\u51b3\u73b0\u6709Video-LLMs\u56e0\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u96be\u4ee5\u5904\u7406\u957f\u89c6\u9891\u7684\u95ee\u9898\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u89c6\u9891\u7406\u89e3\u3002  \n\u25c6 \u7a81\u7834\u4f20\u7edf\u5173\u952e\u5e27\u68c0\u7d22\u65b9\u6cd5\u7684\u9759\u6001\u56fe\u50cf\u5339\u914d\u5c40\u9650\uff0c\u901a\u8fc7\u6a21\u62df\u4eba\u7c7b\u60c5\u666f\u8bb0\u5fc6\u673a\u5236\uff0c\u5c06\u5173\u952e\u5e27\u5efa\u6a21\u4e3a\u65f6\u5e8f\u5316\u60c5\u666f\u4e8b\u4ef6\uff0c\u4fdd\u7559\u65f6\u7a7a\u52a8\u6001\u5173\u7cfb\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u7ed3\u5408\u601d\u7ef4\u94fe\uff08CoT\uff09\u6280\u672f\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fed\u4ee3\u7b5b\u9009\u4fe1\u606f\u91cf\u6700\u5927\u5316\u7684\u6700\u5c0f\u60c5\u666f\u8bb0\u5fc6\u5b50\u96c6\uff0c\u907f\u514d\u5197\u4f59\u5e27\u5e72\u6270\u3002  \n\u25c6 \u9996\u6b21\u5728\u5173\u952e\u5e27\u8868\u793a\u4e2d\u540c\u65f6\u6355\u6349\u7a7a\u95f4\u5173\u8054\u4e0e\u65f6\u95f4\u52a8\u6001\u6027\uff0c\u7cbe\u51c6\u8fd8\u539f\u89c6\u9891\u53d9\u4e8b\u903b\u8f91\uff0c\u63d0\u5347\u573a\u666f\u8f6c\u6362\u548c\u4e0a\u4e0b\u6587\u8fde\u7eed\u6027\u7684\u7406\u89e3\u80fd\u529b\u3002  \n\u25c6 \u5728\u56db\u5927\u4e3b\u6d41\u8bc4\u6d4b\u57fa\u51c6\uff08Video-MME\u7b49\uff09\u4e0a\u9a8c\u8bc1\u6709\u6548\u6027\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf4-9%\uff0c\u4e14\u4f7f\u7528\u66f4\u5c11\u5e27\u6570\uff0c\u517c\u987e\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002|\n",
    "2508.10716": "|2025-08-14|Revisiting Cross-View Localization from Image Matching|Panwang Xia\u7b49|[2508.10716](http://arxiv.org/pdf/2508.10716)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u8de8\u89c6\u89d2\u56fe\u50cf\u5339\u914d\u7684\u65b0\u6846\u67b6\uff0c\u5c06\u5b9a\u4f4d\u95ee\u9898\u8f6c\u5316\u4e3a\u5339\u914d\u95ee\u9898\uff0c\u7a81\u7834\u4f20\u7edf\u76f4\u63a5\u4f4d\u59ff\u56de\u5f52\u6216BEV\u7279\u5f81\u5bf9\u9f50\u7684\u5c40\u9650\u3002  \n\u25c6 \u5f15\u5165Surface Model\u7cbe\u786e\u5efa\u6a21\u5730\u9762\u89c6\u89d2\u53ef\u89c1\u533a\u57df\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u9e1f\u77b0\u56fe\u6295\u5f71\uff0c\u89e3\u51b3\u51e0\u4f55\u4e0d\u4e00\u81f4\u95ee\u9898\u3002  \n\u25c6 \u8bbe\u8ba1SimRefiner\u6a21\u5757\u901a\u8fc7\u5c40\u90e8-\u5168\u5c40\u6b8b\u5dee\u6821\u6b63\u4f18\u5316\u76f8\u4f3c\u5ea6\u77e9\u9635\uff0c\u65e0\u9700RANSAC\u540e\u5904\u7406\u5373\u53ef\u83b7\u5f97\u7cbe\u7ec6\u5339\u914d\u3002  \n\u25c6 \u6784\u5efa\u9996\u4e2a\u50cf\u7d20\u7ea7\u6807\u6ce8\u7684\u8de8\u89c6\u89d2\u5339\u914d\u57fa\u51c6CVFM\uff08\u542b32,509\u5bf9\u56fe\u50cf\uff09\uff0c\u586b\u8865\u9886\u57df\u6570\u636e\u7a7a\u767d\u3002  \n\u25c6 \u5728\u6781\u7aef\u89c6\u89d2\u5dee\u5f02\u4e0b\u5b9e\u73b0\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u5339\u914d\u8d28\u91cf\u53cc\u91cd\u63d0\u5347\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002  \n\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u5efa\u6a21\u3001\u5339\u914d\u3001\u6570\u636e\u4e09\u65b9\u9762\u7684\u521b\u65b0\uff0c\u9996\u6b21\u7cfb\u7edf\u89e3\u51b3\u4e86\u8de8\u89c6\u89d2\u56fe\u50cf\u4e25\u683c\u5bf9\u5e94\u96be\u9898\uff0c\u63a8\u52a8GNSS\u62d2\u6b62\u73af\u5883\u4e0b\u7684\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u53d1\u5c55\u3002|\n",
    "2508.10294": "|2025-08-14|A Sub-Pixel Multimodal Optical Remote Sensing Images Matching Method|Tao Huang\u7b49|[2508.10294](http://arxiv.org/pdf/2508.10294)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f8\u4f4d\u4e00\u81f4\u6027\u52a0\u6743\u6700\u5c0f\u7edd\u5bf9\u504f\u5dee\uff08PCWLAD\uff09\u7684\u4e9a\u50cf\u7d20\u6a21\u677f\u5339\u914d\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u6a21\u6001\u5149\u5b66\u56fe\u50cf\u7684\u5339\u914d\u7cbe\u5ea6\u3002  \n\u25c6 \u91c7\u7528\u4e24\u9636\u6bb5\u5339\u914d\u7b56\u7565\uff1a\u5148\u901a\u8fc7\u7ed3\u6784\u76f8\u4f3c\u6027\u6307\u6570\uff08SSIM\uff09\u8fdb\u884c\u7c97\u5339\u914d\uff0c\u518d\u5229\u7528WLAD\u8fdb\u884c\u7cbe\u7ec6\u5339\u914d\uff0c\u517c\u987e\u6548\u7387\u4e0e\u7cbe\u5ea6\u3002  \n\u25c6 \u5728\u7c97\u5339\u914d\u9636\u6bb5\u4fdd\u7559\u539f\u59cb\u7ed3\u6784\u7ec6\u8282\uff08\u65e0\u566a\u58f0\u6ee4\u6ce2\uff09\uff0c\u901a\u8fc7SSIM\u589e\u5f3a\u5bf9\u975e\u7ebf\u6027\u8f90\u5c04\u5dee\u5f02\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5728\u7cbe\u7ec6\u5339\u914d\u9636\u6bb5\u5f15\u5165\u8f90\u5c04\u548c\u51e0\u4f55\u53d8\u6362\u6a21\u578b\uff0c\u7ed3\u5408\u4e92\u7ed3\u6784\u6ee4\u6ce2\u6291\u5236\u566a\u58f0\u5bf9\u7ed3\u6784\u4e00\u81f4\u6027\u7684\u5f71\u54cd\uff0c\u63d0\u5347\u8de8\u6a21\u6001\u5339\u914d\u7a33\u5b9a\u6027\u3002  \n\u25c6 \u5728\u53ef\u89c1\u5149-\u7ea2\u5916\uff08Landsat\u3001\u65e0\u4eba\u673a\uff09\u548c\u53ef\u89c1\u5149-\u8fd1\u7ea2\u5916\uff08\u8fd1\u666f\uff09\u4e09\u7c7b\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5e73\u5747\u5339\u914d\u7cbe\u5ea6\u8fbe0.4\u50cf\u7d20\uff0c\u4f18\u4e8e\u73b0\u67098\u79cd\u5148\u8fdb\u65b9\u6cd5\u3002  \n\u25c6 \u516c\u5f00\u4e86\u8f6f\u4ef6\u548c\u6570\u636e\u96c6\uff0c\u4fc3\u8fdb\u591a\u6a21\u6001\u9065\u611f\u56fe\u50cf\u5339\u914d\u7814\u7a76\u7684\u53d1\u5c55\u3002|\n",
    "2508.19742": "|2025-09-09|POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection|Chenguang Liu\u7b49|[2508.19742](http://arxiv.org/pdf/2508.19742)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aPOEv2\u7684\u901a\u7528\u4e14\u9c81\u68d2\u7684\u7ebf\u68c0\u6d4b\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u662f\u7edf\u4e00\u4e86\u901a\u7528\u7ebf\u6bb5\u68c0\u6d4b\u548c\u7ed3\u6784\u5316\u7ebf\u6bb5\u68c0\u6d4b\u4e24\u5927\u4efb\u52a1\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u80dc\u4efb\u901a\u7528\u7ebf\u68c0\u6d4b\u548c\u7ed3\u6784\u5316\u7ebf\u68c0\u6d4b\uff0c\u89e3\u51b3\u4e86\u4ee5\u5f80\u4e24\u7c7b\u68c0\u6d4b\u5668\u56e0\u8bbe\u8ba1\u76ee\u6807\u4e0d\u540c\u800c\u65e0\u6cd5\u4e92\u76f8\u66ff\u4ee3\u7684\u95ee\u9898\u3002  \n\u25c6 \u4f5c\u4e3aPixel Orientation Estimation (POE)\u65b9\u6cd5\u7684\u6539\u8fdb\u7248\uff0c\u65b0\u6846\u67b6\u80fd\u4ece\u8fb9\u7f18\u5f3a\u5ea6\u56fe\u4e2d\u68c0\u6d4b\u7ebf\u6bb5\uff0c\u5e76\u53ef\u517c\u5bb9\u4efb\u4f55\u8fb9\u7f18\u68c0\u6d4b\u5668\u3002  \n\u25c6 \u901a\u8fc7\u7ed3\u5408\u9ad8\u6548\u7684\u8fb9\u7f18\u68c0\u6d4b\u5668\uff0c\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002  \n\u25c6 \u8be5\u6846\u67b6\u517c\u5177\u9c81\u68d2\u6027\u548c\u7075\u6d3b\u6027\uff0c\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u7684\u7ebf\u68c0\u6d4b\u9700\u6c42\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2509.04273": "|2025-09-04|Dual-Scale Volume Priors with Wasserstein-Based Consistency for Semi-Supervised Medical Image Segmentation|Junying Meng\u7b49|[2509.04273](http://arxiv.org/pdf/2509.04273)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u534a\u76d1\u7763\u533b\u5b66\u56fe\u50cf\u5206\u5272\u7684\u65b0\u6846\u67b6\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u5c06\u53d8\u5206\u6a21\u578b\u4e2d\u7684\u5148\u9a8c\u77e5\u8bc6\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u6709\u6548\u7ed3\u5408\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u4e86\u53cc\u5c3a\u5ea6\u4f53\u79ef\u5148\u9a8c\uff0c\u5373\u5728\u56fe\u50cf\u5c3a\u5ea6\u548c\u6570\u636e\u96c6\u5c3a\u5ea6\u4e0a\u5206\u522b\u5229\u7528\u5f3a\u663e\u5f0f\u5148\u9a8c\u548c\u5f31\u9690\u5f0f\u5148\u9a8c\u6765\u7ea6\u675f\u5206\u5272\u7f51\u7edc\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u56de\u5f52\u7f51\u7edc\u6765\u4f30\u8ba1\u672a\u6807\u6ce8\u56fe\u50cf\u7684\u76ee\u6807\u533a\u57df\u4f53\u79ef\uff0c\u5e76\u901a\u8fc7\u56fe\u50cf\u5c3a\u5ea6\u7684Wasserstein\u8ddd\u79bb\u635f\u5931\uff0c\u5f3a\u5236\u5206\u5272\u7ed3\u679c\u4e0e\u56de\u5f52\u9884\u6d4b\u7684\u7c7b\u522b\u6bd4\u4f8b\u4e00\u81f4\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u96c6\u5c3a\u5ea6\u7684Wasserstein\u8ddd\u79bb\u635f\u5931\u51fd\u6570\uff0c\u4f7f\u5f97\u672a\u6807\u6ce8\u6570\u636e\u96c6\u9884\u6d4b\u7684\u4f53\u79ef\u5206\u5e03\u4e0e\u5df2\u6807\u6ce8\u6570\u636e\u96c6\u7684\u5206\u5e03\u76f8\u4f3c\uff0c\u4ece\u800c\u5229\u7528\u6570\u636e\u96c6\u5c42\u9762\u7684\u7edf\u8ba1\u4fe1\u606f\u3002  \n\u25c6 \u5c06Threshold Dynamics\u7a7a\u95f4\u6b63\u5219\u5316\u65b9\u6cd5\u878d\u5165\u5206\u5272\u7f51\u7edc\u4e3b\u5e72\uff0c\u589e\u5f3a\u4e86\u7279\u5f81\u63d0\u53d6\u7684\u51e0\u4f55\u7ea6\u675f\u80fd\u529b\u3002  \n\u5b9e\u9a8c\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u534a\u76d1\u7763\u5206\u5272\u6027\u80fd\u3002|\n",
    "2509.06566": "|2025-09-08|Back To The Drawing Board: Rethinking Scene-Level Sketch-Based Image Retrieval|Emil Demi\u0107\u7b49|[2509.06566](http://arxiv.org/pdf/2509.06566)|\u65e0|\u672c\u6587\u9488\u5bf9\u573a\u666f\u7ea7\u8349\u56fe\u68c0\u7d22\u4efb\u52a1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5f3a\u8c03\u8349\u56fe\u56fa\u6709\u6a21\u7cca\u6027\u548c\u566a\u58f0\u7684\u9c81\u68d2\u6027\u8bad\u7ec3\u65b9\u6cd5\u3002  \n\u25c6 \u6307\u51fa\u4ee5\u5f80\u7814\u7a76\u5ffd\u7565\u771f\u5b9e\u8349\u56fe\u7684\u6b67\u4e49\u4e0e\u566a\u58f0\u95ee\u9898\uff0c\u8f6c\u800c\u5173\u6ce8\u8bad\u7ec3\u76ee\u6807\u7684\u9c81\u68d2\u6027\u8bbe\u8ba1\u3002  \n\u25c6 \u63d0\u51fa\u7ed3\u5408\u9884\u8bad\u7ec3\u7b56\u7565\u3001\u7f16\u7801\u5668\u67b6\u6784\u548c\u635f\u5931\u51fd\u6570\u7684\u4f18\u5316\u65b9\u6848\uff0c\u65e0\u9700\u589e\u52a0\u6a21\u578b\u590d\u6742\u5ea6\u5373\u53ef\u63d0\u5347\u6027\u80fd\u3002  \n\u25c6 \u5728FS-COCO\u548cSketchyCOCO\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u8bad\u7ec3\u8bbe\u8ba1\u5bf9\u8de8\u6a21\u6001\u68c0\u7d22\u7684\u5173\u952e\u4f5c\u7528\u3002  \n\u25c6 \u5f3a\u8c03\u9700\u6539\u8fdb\u573a\u666f\u7ea7\u8349\u56fe\u68c0\u7d22\u7684\u8bc4\u4f30\u573a\u666f\uff0c\u63a8\u52a8\u4efb\u52a1\u5411\u66f4\u5b9e\u7528\u5316\u53d1\u5c55\u3002|\n",
    "2509.08805": "|2025-09-23|Handling Multiple Hypotheses in Coarse-to-Fine Dense Image Matching|Matthieu Vilain\u7b49|[2509.08805](http://arxiv.org/pdf/2509.08805)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7a20\u5bc6\u56fe\u50cf\u5339\u914d\u4e2d\u5904\u7406\u591a\u91cd\u5047\u8bbe\u7684\u65b0\u65b9\u6cd5BEAMER\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u663e\u8457\u63d0\u5347\u4e86\u5728\u6311\u6218\u6027\u573a\u666f\u4e0b\u7684\u5339\u914d\u9c81\u68d2\u6027\u3002  \n\u25c6 \u6452\u5f03\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u6bcf\u4e2a\u5c3a\u5ea6\u4e0a\u4ec5\u4e3a\u6bcf\u4e2a\u6e90\u4f4d\u7f6e\u9884\u6d4b\u5355\u4e00\u5bf9\u5e94\u70b9\u7684\u505a\u6cd5\uff0c\u521b\u65b0\u6027\u5730\u63d0\u51fa\u5728\u6bcf\u4e2a\u5c3a\u5ea6\u4e0a\u9884\u6d4b\u5e76\u4fdd\u7559\u591a\u4e2a\u5bf9\u5e94\u5047\u8bbe\u3002  \n\u25c6 \u91c7\u7528\u675f\u641c\u7d22\uff08beam search\uff09\u7b56\u7565\uff0c\u5728\u7531\u7c97\u5230\u7ec6\u7684\u5339\u914d\u8fc7\u7a0b\u4e2d\u9010\u5c3a\u5ea6\u5730\u4f20\u64ad\u548c\u4fdd\u7559\u8fd9\u4e9b\u591a\u91cd\u5047\u8bbe\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u67b6\u6784\uff0c\u5c06\u591a\u91cd\u5047\u8bbe\u96c6\u6210\u5230\u4ea4\u53c9\u6ce8\u610f\u529b\uff08cross-attention\uff09\u5c42\u4e2d\uff0c\u4f7f\u7f51\u7edc\u80fd\u591f\u5b66\u4e60\u5982\u4f55\u6709\u6548\u5730\u5728\u4e0d\u540c\u5c3a\u5ea6\u95f4\u7b5b\u9009\u548c\u4f20\u64ad\u6700\u4f18\u5047\u8bbe\u3002  \n\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u6df1\u5ea6\u4e0d\u8fde\u7eed\u6216\u76ee\u6807\u56fe\u50cf\u662f\u6e90\u56fe\u50cf\u7684\u6781\u5927\u7f29\u653e\u573a\u666f\u65f6\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u6280\u672f\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u9519\u8bef\u5339\u914d\u3002|\n",
    "2509.09594": "|2025-09-11|ObjectReact: Learning Object-Relative Control for Visual Navigation|Sourav Garg\u7b49|[2509.09594](http://arxiv.org/pdf/2509.09594)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u4f53\u76f8\u5bf9\u63a7\u5236\u7684\u89c6\u89c9\u5bfc\u822a\u65b0\u8303\u5f0fObjectReact\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u56fe\u50cf\u76f8\u5bf9\u63a7\u5236\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u201c\u7269\u4f53\u76f8\u5bf9\u201d\u63a7\u5236\u66ff\u4ee3\u4e3b\u6d41\u7684\u201c\u56fe\u50cf\u76f8\u5bf9\u201d\u63a7\u5236\uff0c\u5229\u7528\u7269\u4f53\u4f5c\u4e3a\u5730\u56fe\u56fa\u6709\u5c5e\u6027\uff0c\u6446\u8131\u5bf9\u667a\u80fd\u4f53\u4f4d\u59ff\u548c\u5177\u4f53\u5f62\u6001\u7684\u4e25\u683c\u4f9d\u8d56\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u57fa\u4e8e\u201c\u76f8\u5bf93D\u573a\u666f\u56fe\u201d\u7684\u62d3\u6251-\u5ea6\u91cf\u6df7\u5408\u5730\u56fe\u8868\u793a\uff0c\u80fd\u591f\u751f\u6210\u66f4\u9ad8\u6548\u7684\u5bf9\u8c61\u7ea7\u5168\u5c40\u8def\u5f84\u89c4\u5212\u4ee3\u4ef7\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u76f4\u63a5\u4ee5\u9ad8\u5c42\u201cWayObject Costmap\u201d\u4e3a\u8f93\u5165\u6761\u4ef6\u7684\u672c\u5730\u63a7\u5236\u5668\uff0c\u65e0\u9700\u663e\u5f0fRGB\u8f93\u5165\uff0c\u5b9e\u73b0\u4e86\u63a7\u5236\u9884\u6d4b\u4e0e\u56fe\u50cf\u5339\u914d\u95ee\u9898\u7684\u89e3\u8026\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u5728\u8de8\u5f62\u6001\u90e8\u7f72\uff08\u5982\u4f20\u611f\u5668\u9ad8\u5ea6\u53d8\u5316\uff09\u548c\u6311\u6218\u6027\u4efb\u52a1\uff08\u5982\u53cd\u5411\u8f68\u8ff9\u5bfc\u822a\uff09\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4e14\u4ec5\u4f7f\u7528\u4eff\u771f\u8bad\u7ec3\u7684\u7b56\u7565\u80fd\u5f88\u597d\u5730\u6cdb\u5316\u5230\u771f\u5b9e\u5ba4\u5185\u73af\u5883\u3002|\n",
    "2509.09792": "|2025-09-29|Loc$^2$: Interpretable Cross-View Localization via Depth-Lifted Local Feature Matching|Zimin Xia\u7b49|[2509.09792](http://arxiv.org/pdf/2509.09792)|\u65e0|\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u7ec6\u7c92\u5ea6\u8de8\u89c6\u89d2\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u7279\u5f81\u5339\u914d\u4e0e\u5355\u76ee\u6df1\u5ea6\u5148\u9a8c\u5b9e\u73b0\u5730\u9762\u56fe\u50cf\u7684\u4e09\u81ea\u7531\u5ea6\u4f4d\u59ff\u4f30\u8ba1\u3002  \n\u25c6 \u76f4\u63a5\u5efa\u7acb\u5730\u9762\u4e0e\u822a\u7a7a\u56fe\u50cf\u95f4\u7684\u5c40\u90e8\u7279\u5f81\u5bf9\u5e94\u5173\u7cfb\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u4e2d\u56e0\u89c6\u89d2\u8f6c\u6362\u9020\u6210\u7684\u4fe1\u606f\u635f\u5931\u3002  \n\u25c6 \u5229\u7528\u5355\u76ee\u6df1\u5ea6\u5148\u9a8c\u4ec5\u5c06\u5339\u914d\u5173\u952e\u70b9\u63d0\u5347\u81f3\u9e1f\u77b0\u56fe\u7a7a\u95f4\uff0c\u652f\u6301\u5ea6\u91cf\u6df1\u5ea6\u4e0e\u76f8\u5bf9\u6df1\u5ea6\u4e24\u79cd\u6a21\u5f0f\u3002  \n\u25c6 \u63d0\u51fa\u5c3a\u5ea6\u611f\u77e5\u7684\u666e\u6c0f\u5bf9\u9f50\u7b97\u6cd5\uff0c\u80fd\u591f\u4ece\u5bf9\u5e94\u5173\u7cfb\u4e2d\u4f30\u8ba1\u76f8\u673a\u4f4d\u59ff\uff0c\u5e76\u5728\u4f7f\u7528\u76f8\u5bf9\u6df1\u5ea6\u65f6\u6062\u590d\u5c3a\u5ea6\u3002  \n\u25c6 \u4ec5\u9700\u5f31\u76d1\u7763\u4f4d\u59ff\u6807\u6ce8\u5373\u53ef\u5b66\u4e60\u7cbe\u786e\u7279\u5f81\u5bf9\u5e94\uff0c\u5728\u8de8\u533a\u57df\u6cdb\u5316\u4e0e\u672a\u77e5\u671d\u5411\u7b49\u6311\u6218\u6027\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002  \n\u25c6 \u517c\u5bb9\u591a\u79cd\u76f8\u5bf9\u6df1\u5ea6\u6a21\u578b\u4e14\u65e0\u9700\u9488\u5bf9\u6bcf\u4e2a\u6a21\u578b\u5fae\u8c03\uff0c\u5177\u5907\u8f83\u5f3a\u7684\u5b9e\u7528\u6027\u4e0e\u90e8\u7f72\u7075\u6d3b\u6027\u3002|\n",
    "2509.11255": "|2025-09-14|A Geometrically Consistent Matching Framework for Side-Scan Sonar Mapping|Can Lei\u7b49|[2509.11255](http://arxiv.org/pdf/2509.11255)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u4fa7\u626b\u58f0\u7eb3\u56fe\u50cf\u56e0\u89c6\u89d2\u4f9d\u8d56\u3001\u9634\u5f71\u548c\u51e0\u4f55\u7578\u53d8\u5bfc\u81f4\u7684\u5339\u914d\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u89e3\u8026\u4e0e\u51e0\u4f55\u4e00\u81f4\u6027\u7684\u521b\u65b0\u5339\u914d\u6846\u67b6\u3002  \n\u25c6 \u63d0\u51fa\u81ea\u76d1\u7763\u591a\u5206\u652f\u7f51\u7edc\uff0c\u57fa\u4e8e\u6717\u4f2f\u53cd\u5c04\u6a21\u578b\u5c06\u539f\u59cb\u58f0\u7eb3\u56fe\u50cf\u5206\u89e3\u4e3a\u6d77\u5e95\u53cd\u5c04\u7387\u3001\u5730\u5f62\u9ad8\u7a0b\u548c\u58f0\u5b66\u8def\u5f84\u635f\u8017\uff0c\u589e\u5f3a\u7269\u7406\u53ef\u89e3\u91ca\u6027\u3002  \n\u25c6 \u5229\u7528\u53cd\u5c04\u7387\u56fe\u8c31\u4f5c\u4e3a\u7a33\u5b9a\u5339\u914d\u57df\uff0c\u7ed3\u5408\u65e0\u8bad\u7ec3\u5339\u914d\u6d41\u7a0b\uff08SuperPoint\u4e0eMINIMA LightGlue\uff09\uff0c\u63d0\u5347\u8de8\u89c6\u89d2\u5bf9\u5e94\u5173\u7cfb\u51c6\u786e\u6027\u3002  \n\u25c6 \u5f15\u5165\u51e0\u4f55\u611f\u77e5\u5f02\u5e38\u70b9\u5254\u9664\u673a\u5236\uff0c\u8054\u5408\u5730\u5f62\u9ad8\u7a0b\u4e0e\u7269\u7406\u884d\u751f\u7684\u9634\u5f71\u56fe\u8c31\uff0c\u6709\u6548\u6291\u5236\u58f0\u5b66\u906e\u6321\u548c\u5730\u5f62\u4e0d\u4e00\u81f4\u533a\u57df\u7684\u8bef\u5339\u914d\u3002  \n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5339\u914d\u8bef\u5dee\u3001\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u89c6\u89d2\u9c81\u68d2\u6027\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u53ca\u57fa\u4e8eCNN\u4e0eTransformer\u7684\u5148\u8fdb\u65b9\u6cd5\uff0c\u4e3a\u590d\u6742\u6d77\u5e95\u73af\u5883\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u3001\u6570\u636e\u9ad8\u6548\u4e14\u7269\u7406\u53ef\u89e3\u91ca\u7684\u5339\u914d\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2509.14966": "|2025-09-18|RoboEye: Enhancing 2D Robotic Object Identification with Selective 3D Geometric Keypoint Matching|Xingwu Zhang\u7b49|[2509.14966](http://arxiv.org/pdf/2509.14966)|\u65e0|\u25c6 The rapidly growing number of product categories in large-scale e-commerce makes accurate object identification for automated packing in warehouses substantially more difficult.\n\u25c6 As the catalog grows, intra-class variability and a long tail of rare or visually similar items increase, and when combined with diverse packaging, cluttered containers, frequent occlusion, and large viewpoint changes-these factors amplify discrepancies between query and reference images, causing sharp performance drops for methods that rely solely on 2D appearance features.\n\u25c6 Thus, we propose RoboEye, a two-stage identification framework that dynamically augments 2D semantic features with domain-adapted 3D reasoning and lightweight adapters to bridge training deployment gaps.|\n",
    "2509.16017": "|2025-09-19|DistillMatch: Leveraging Knowledge Distillation from Vision Foundation Model for Multimodal Image Matching|Meng Yang\u7b49|[2509.16017](http://arxiv.org/pdf/2509.16017)|\u65e0|\u25c6 Multimodal image matching seeks pixel-level correspondences between images of different modalities, crucial for cross-modal perception, fusion and analysis.\n\u25c6 However, the significant appearance differences between modalities make this task challenging.\n\u25c6 Due to the scarcity of high-quality annotated datasets, existing deep learning methods that extract modality-common features for matching perform poorly and lack adaptability to diverse scenarios.|\n",
    "2509.17431": "|2025-09-23|Hierarchical Neural Semantic Representation for 3D Semantic Correspondence|Keyu Du\u7b49|[2509.17431](http://arxiv.org/pdf/2509.17431)|\u65e0|\u25c6 This paper presents a new approach to estimate accurate and robust 3D semantic correspondence with the hierarchical neural semantic representation.\n\u25c6 Our work has three key contributions.\n\u25c6 First, we design the hierarchical neural semantic representation (HNSR), which consists of a global semantic feature to capture high-level structure and multi-resolution local geometric features to preserve fine details, by carefully harnessing 3D priors from pre-trained 3D generative models.|\n",
    "2509.16519": "|2025-09-20|PM25Vision: A Large-Scale Benchmark Dataset for Visual Estimation of Air Quality|Yang Han|[2509.16519](http://arxiv.org/pdf/2509.16519)|\u65e0|\u25c6 We introduce PM25Vision (PM25V), the largest and most comprehensive dataset to date for estimating air quality - specifically PM2.5 concentrations - from street-level images.\n\u25c6 The dataset contains over 11,114 images matched with timestamped and geolocated PM2.5 readings across 3,261 AQI monitoring stations and 11 years, significantly exceeding the scale of previous benchmarks.\n\u25c6 The spatial accuracy of this dataset has reached 5 kilometers, far exceeding the city-level accuracy of many datasets.|\n"
  },
  "NeRF": {
    "2504.20379": "|**2025-05-01**|**GSFeatLoc: Visual Localization Using Feature Correspondence on 3D Gaussian Splatting**|Jongwon Lee et.al.|[2504.20379](http://arxiv.org/abs/2504.20379)|null|\n",
    "2505.00378": "|**2025-05-01**|**Cues3D: Unleashing the Power of Sole NeRF for Consistent and Unique Instances in Open-Vocabulary 3D Panoptic Segmentation**|Feng Xue et.al.|[2505.00378](http://arxiv.org/abs/2505.00378)|null|\n",
    "2505.05474": "|**2025-05-08**|**3D Scene Generation: A Survey**|Beichen Wen et.al.|[2505.05474](http://arxiv.org/abs/2505.05474)|**[link](https://github.com/hzxie/awesome-3d-scene-generation)**|\n",
    "2505.02079": "|**2025-05-04**|**HandOcc: NeRF-based Hand Rendering with Occupancy Networks**|Maksym Ivashechkin et.al.|[2505.02079](http://arxiv.org/abs/2505.02079)|null|\n",
    "2505.02005": "|**2025-05-04**|**Learning Heterogeneous Mixture of Scene Experts for Large-scale Neural Radiance Fields**|Zhenxing Mi et.al.|[2505.02005](http://arxiv.org/abs/2505.02005)|**[link](https://github.com/MiZhenxing/Switch-NeRF)**|\n",
    "2505.01799": "|**2025-05-03**|**AquaGS: Fast Underwater Scene Reconstruction with SfM-Free Gaussian Splatting**|Junhao Shi et.al.|[2505.01799](http://arxiv.org/abs/2505.01799)|null|\n",
    "2505.01749": "|**2025-05-03**|**Unified Steganography via Implicit Neural Representation**|Qi Song et.al.|[2505.01749](http://arxiv.org/abs/2505.01749)|null|\n",
    "2505.09413": "|**2025-05-14**|**Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians**|Ma Changfeng et.al.|[2505.09413](http://arxiv.org/abs/2505.09413)|**[link](https://github.com/murcherful/gaupcrender)**|\n",
    "2505.09406": "|**2025-05-14**|**FreeDriveRF: Monocular RGB Dynamic NeRF without Poses for Autonomous Driving via Point-Level Dynamic-Static Decoupling**|Yue Wen et.al.|[2505.09406](http://arxiv.org/abs/2505.09406)|null|\n",
    "2505.08510": "|**2025-05-13**|**FOCI: Trajectory Optimization on Gaussian Splats**|Mario Gomez Andreu et.al.|[2505.08510](http://arxiv.org/abs/2505.08510)|null|\n",
    "2505.07396": "|**2025-05-13**|**TUM2TWIN: Introducing the Large-Scale Multimodal Urban Digital Twin Benchmark Dataset**|Olaf Wysocki et.al.|[2505.07396](http://arxiv.org/abs/2505.07396)|null|\n",
    "2505.07373": "|**2025-05-12**|**Geometric Prior-Guided Neural Implicit Surface Reconstruction in the Wild**|Lintao Xiang et.al.|[2505.07373](http://arxiv.org/abs/2505.07373)|null|\n",
    "2505.08811": "|**2025-05-12**|**TUGS: Physics-based Compact Representation of Underwater Scenes by Tensorized Gaussian**|Shijie Lian et.al.|[2505.08811](http://arxiv.org/abs/2505.08811)|null|\n",
    "2505.06894": "|**2025-05-11**|**NeuGen: Amplifying the 'Neural' in Neural Radiance Fields for Domain Generalization**|Ahmed Qazi et.al.|[2505.06894](http://arxiv.org/abs/2505.06894)|null|\n",
    "2505.06638": "|**2025-05-10**|**3D Characterization of Smoke Plume Dispersion Using Multi-View Drone Swarm**|Nikil Krishnakumar et.al.|[2505.06638](http://arxiv.org/abs/2505.06638)|null|\n",
    "2505.06504": "|**2025-05-10**|**FlexNeRFer: A Multi-Dataflow, Adaptive Sparsity-Aware Accelerator for On-Device NeRF Rendering**|Seock-Hwan Noh et.al.|[2505.06504](http://arxiv.org/abs/2505.06504)|null|\n",
    "2505.12875": "|**2025-05-19**|**3D Gaussian Adaptive Reconstruction for Fourier Light-Field Microscopy**|Chenyu Xu et.al.|[2505.12875](http://arxiv.org/abs/2505.12875)|null|\n",
    "2505.12384": "|**2025-05-18**|**Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey**|Calvin Galagain et.al.|[2505.12384](http://arxiv.org/abs/2505.12384)|null|\n",
    "2505.11386": "|**2025-05-16**|**MutualNeRF: Improve the Performance of NeRF under Limited Samples with Mutual Information Theory**|Zifan Wang et.al.|[2505.11386](http://arxiv.org/abs/2505.11386)|null|\n",
    "2505.10787": "|**2025-05-16**|**EA-3DGS: Efficient and Adaptive 3D Gaussians with Highly Enhanced Quality for outdoor scenes**|Jianlin Guo et.al.|[2505.10787](http://arxiv.org/abs/2505.10787)|**[link](https://github.com/scut-bip-lab/ea-3dgs)**|\n",
    "2505.09915": "|**2025-05-15**|**Large-Scale Gaussian Splatting SLAM**|Zhe Xin et.al.|[2505.09915](http://arxiv.org/abs/2505.09915)|null|\n",
    "2505.16912": "|**2025-05-22**|**UAV See, UGV Do: Aerial Imagery and Virtual Teach Enabling Zero-Shot Ground Vehicle Repeat**|Desiree Fisker et.al.|[2505.16912](http://arxiv.org/abs/2505.16912)|null|\n",
    "2505.13633": "|**2025-05-19**|**IPENS:Interactive Unsupervised Framework for Rapid Plant Phenotyping Extraction via NeRF-SAM2 Fusion**|Wentao Song et.al.|[2505.13633](http://arxiv.org/abs/2505.13633)|null|\n",
    "2505.23481": "|**2025-05-29**|**PhysicsNeRF: Physics-Guided 3D Reconstruction from Sparse Views**|Mohamed Rayan Barhdadi et.al.|[2505.23481](http://arxiv.org/abs/2505.23481)|**[link](https://github.com/anonymous-researcher-01/physicsnerf)**|\n",
    "2505.23158": "|**2025-05-29**|**LODGE: Level-of-Detail Large-Scale Gaussian Splatting with Efficient Rendering**|Jonas Kulhanek et.al.|[2505.23158](http://arxiv.org/abs/2505.23158)|null|\n",
    "2505.22441": "|**2025-05-28**|**Can NeRFs See without Cameras?**|Chaitanya Amballa et.al.|[2505.22441](http://arxiv.org/abs/2505.22441)|null|\n",
    "2505.22279": "|**2025-05-28**|**Learning Fine-Grained Geometry for Sparse-View Splatting via Cascade Depth Loss**|Wenjun Lu et.al.|[2505.22279](http://arxiv.org/abs/2505.22279)|null|\n",
    "2505.21890": "|**2025-05-28**|**Hyperspectral Gaussian Splatting**|Sunil Kumar Narayanan et.al.|[2505.21890](http://arxiv.org/abs/2505.21890)|null|\n",
    "2505.21335": "|**2025-05-27**|**Structure from Collision**|Takuhiro Kaneko et.al.|[2505.21335](http://arxiv.org/abs/2505.21335)|null|\n",
    "2505.20126": "|**2025-05-26**|**OB3D: A New Dataset for Benchmarking Omnidirectional 3D Reconstruction Using Blender**|Shintaro Ito et.al.|[2505.20126](http://arxiv.org/abs/2505.20126)|**[link](https://github.com/gsisaoki/omnidirectional_blender_3d_dataset)**|\n",
    "2505.19883": "|**2025-05-30**|**ErpGS: Equirectangular Image Rendering enhanced with 3D Gaussian Regularization**|Shintaro Ito et.al.|[2505.19883](http://arxiv.org/abs/2505.19883)|null|\n",
    "2505.19813": "|**2025-05-26**|**GoLF-NRT: Integrating Global Context and Local Geometry for Few-Shot View Synthesis**|You Wang et.al.|[2505.19813](http://arxiv.org/abs/2505.19813)|**[link](https://github.com/klmav-cuc/golf-nrt)**|\n",
    "2505.19793": "|**2025-05-26**|**Depth-Guided Bundle Sampling for Efficient Generalizable Neural Radiance Field Reconstruction**|Li Fang et.al.|[2505.19793](http://arxiv.org/abs/2505.19793)|**[link](https://github.com/klmav-cuc/gdb-nerf)**|\n",
    "2506.00083": "|**2025-05-30**|**Hi-Dyna Graph: Hierarchical Dynamic Scene Graph for Robotic Autonomy in Human-Centric Environments**|Jiawei Hou et.al.|[2506.00083](http://arxiv.org/abs/2506.00083)|null|\n",
    "2506.07917": "|2025-06-09|Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes|Allen Tu\u7b49|[2506.07917](http://arxiv.org/pdf/2506.07917)|[\u4ee3\u7801](https://github.com/tuallen/speede3dgs)|\u25c6 \u63d0\u51faSpeeDe3DGS\u6846\u67b6\uff0c\u663e\u8457\u52a0\u901f\u52a8\u60013D\u9ad8\u65af\u6cfc\u6e85\uff083DGS/4DGS\uff09\u7684\u6e32\u67d3\u901f\u5ea6\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u56e0\u9010\u5e27\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u5bfc\u81f4\u7684\u6027\u80fd\u74f6\u9888\u3002  \n\u25c6 \u8bbe\u8ba1\u65f6\u5e8f\u654f\u611f\u5ea6\u526a\u679d\u8bc4\u5206\u673a\u5236\uff0c\u81ea\u52a8\u8bc6\u522b\u5e76\u5254\u9664\u5bf9\u52a8\u6001\u573a\u666f\u91cd\u5efa\u8d21\u732e\u4f4e\u7684\u5197\u4f59\u9ad8\u65af\u5143\u7d20\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u5f15\u5165\u9000\u706b\u5e73\u6ed1\u526a\u679d\u7b56\u7565\uff0c\u589e\u5f3a\u5728\u76f8\u673a\u4f4d\u59ff\u4e0d\u7cbe\u786e\u7684\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u526a\u679d\u9c81\u68d2\u6027\uff0c\u907f\u514d\u8bef\u5220\u5173\u952e\u9ad8\u65af\u5143\u7d20\u3002  \n\u25c6 \u5f00\u53d1GroupFlow\u8fd0\u52a8\u5206\u6790\u6280\u672f\uff0c\u901a\u8fc7\u8f68\u8ff9\u76f8\u4f3c\u6027\u805a\u7c7b\u9ad8\u65af\u7fa4\u7ec4\uff0c\u4ee5\u5355\u7ec4\u521a\u6027\u53d8\u6362\u66ff\u4ee3\u9010\u9ad8\u65af\u5f62\u53d8\u9884\u6d4b\uff0c\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002  \n\u25c6 \u5b9e\u9a8c\u9a8c\u8bc1\u6846\u67b6\u5728NeRF-DS\u6570\u636e\u96c6\u4e0a\u5b9e\u73b010.37\u500d\u6e32\u67d3\u52a0\u901f\u30017.71\u500d\u6a21\u578b\u538b\u7f29\u548c2.71\u500d\u8bad\u7ec3\u63d0\u901f\uff0c\u5728D-NeRF\u548cHyperNeRF\u6570\u636e\u96c6\u5206\u522b\u63d0\u53474.20\u500d\u548c58.23\u500d\u6027\u80fd\u3002  \n\u25c6 \u6a21\u5757\u5316\u8bbe\u8ba1\u517c\u5bb9\u73b0\u6709\u52a8\u60013DGS/4DGS\u6846\u67b6\uff0c\u517c\u5177\u9ad8\u6548\u6027\u4e0e\u901a\u7528\u6027\u3002|\n",
    "2506.07497": "|2025-06-20|Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency|Xiangyu Guo\u7b49|[2506.07497](http://arxiv.org/pdf/2506.07497)|\u65e0|\u25c6 \u63d0\u51faGenesis\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u591a\u89c6\u89d2\u9a7e\u9a76\u89c6\u9891\u4e0eLiDAR\u5e8f\u5217\u7684\u8054\u5408\u751f\u6210\uff0c\u4fdd\u8bc1\u65f6\u7a7a\u548c\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u3002  \n\u25c6 \u91c7\u7528\u4e24\u9636\u6bb5\u67b6\u6784\uff1a\u7ed3\u5408DiT\u89c6\u9891\u6269\u6563\u6a21\u578b\u4e0e3D-VAE\u7f16\u7801\uff0c\u4ee5\u53ca\u57fa\u4e8eBEV\u7684LiDAR\u751f\u6210\u5668\u4e0eNeRF\u6e32\u67d3\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u591a\u6a21\u6001\u8f93\u51fa\u3002  \n\u25c6 \u901a\u8fc7\u5171\u4eab\u6f5c\u5728\u7a7a\u95f4\u76f4\u63a5\u8026\u5408\u89c6\u89c9\u4e0e\u51e0\u4f55\u6a21\u6001\uff0c\u786e\u4fdd\u751f\u6210\u5185\u5bb9\u5728\u8de8\u6a21\u6001\u95f4\u7684\u8fde\u8d2f\u6f14\u5316\u3002  \n\u25c6 \u521b\u65b0\u5f15\u5165DataCrafter\u63cf\u8ff0\u6a21\u5757\uff0c\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u573a\u666f\u7ea7\u548c\u5b9e\u4f8b\u7ea7\u8bed\u4e49\u76d1\u7763\uff0c\u589e\u5f3a\u751f\u6210\u6570\u636e\u7684\u7ed3\u6784\u5316\u63a7\u5236\u3002  \n\u25c6 \u5728nuScenes\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u89c6\u9891\uff08FVD 16.95\uff09\u548cLiDAR\uff08Chamfer 0.611\uff09\u6307\u6807\u7684SOTA\u6027\u80fd\uff0c\u9a8c\u8bc1\u751f\u6210\u6570\u636e\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002  \n\u25c6 \u751f\u6210\u6570\u636e\u53ef\u6709\u6548\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u5206\u5272\u548c3D\u68c0\u6d4b\uff09\u6027\u80fd\uff0c\u8bc1\u660e\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002|\n",
    "2506.06890": "|2025-06-07|SPC to 3D: Novel View Synthesis from Binary SPC via I2I translation|Sumit Sharma\u7b49|[2506.06890](http://arxiv.org/pdf/2506.06890)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u4ece\u4e8c\u8fdb\u5236\u5355\u5149\u5b50\u76f8\u673a(SPC)\u6570\u636e\u751f\u6210\u9ad8\u8d28\u91cf\u5f69\u8272\u65b0\u89c6\u89d2\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf3D\u5408\u6210\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u7684\u4e25\u91cd\u4fe1\u606f\u4e22\u5931\u95ee\u9898\u3002  \n\u25c6 \u7b2c\u4e00\u9636\u6bb5\u91c7\u7528Pix2PixHD\u7b49\u751f\u6210\u6a21\u578b\u8fdb\u884c\u56fe\u50cf\u5230\u56fe\u50cf\u8f6c\u6362\uff0c\u5c06\u4e8c\u8fdb\u5236SPC\u8f93\u5165\u8f6c\u5316\u4e3a\u53ef\u4fe1\u7684RGB\u56fe\u50cf\uff0c\u6709\u6548\u6062\u590d\u4e22\u5931\u7684\u7eb9\u7406\u548c\u989c\u8272\u4fe1\u606f\u3002  \n\u25c6 \u7b2c\u4e8c\u9636\u6bb5\u7ed3\u5408\u795e\u7ecf\u8f90\u5c04\u573a(NeRF)\u6216\u9ad8\u65af\u6cfc\u6e85(3DGS)\u7b49\u5148\u8fdb3D\u91cd\u5efa\u6280\u672f\uff0c\u4ece\u751f\u6210\u7684RGB\u56fe\u50cf\u4e2d\u5408\u6210\u65b0\u89c6\u89d2\u3002  \n\u25c6 \u901a\u8fc7\u5927\u91cf\u5b9a\u6027\u548c\u5b9a\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u6846\u67b6(Pix2PixHD + Nerf/3DGS)\u7684\u4f18\u8d8a\u6027\uff0c\u5728\u611f\u77e5\u8d28\u91cf\u548c\u51e0\u4f55\u4e00\u81f4\u6027\u4e0a\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\u3002  \n\u25c6 \u8be5\u5de5\u4f5c\u4e3a\u5355\u5149\u5b50\u76f8\u673a\u8fd9\u7c7b\u65b0\u5174\u6210\u50cf\u6280\u672f\u76843D\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6781\u4f4e\u5149\u7167\u6216\u8d85\u9ad8\u901f\u6210\u50cf\u573a\u666f\u3002|\n",
    "2506.06462": "|2025-06-06|Splat and Replace: 3D Reconstruction with Repetitive Elements|Nicol\u00e1s Violante\u7b49|[2506.06462](http://arxiv.org/pdf/2506.06462)|\u65e0|\u25c6 \u5229\u7528\u573a\u666f\u4e2d\u7684\u91cd\u590d\u5143\u7d20\u63d0\u5347\u65b0\u89c6\u89d2\u5408\u6210\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfNeRF\u548c3DGS\u5728\u8bad\u7ec3\u89c6\u89d2\u4e0d\u8db3\u65f6\u6e32\u67d3\u6548\u679c\u5dee\u7684\u95ee\u9898\u3002  \n\u25c6 \u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7684\u91cd\u590d\u5b9e\u4f8b\u5206\u5272\u4e0e\u914d\u51c6\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e0d\u540c\u5b9e\u4f8b\u95f4\u7684\u4fe1\u606f\u5171\u4eab\u3002  \n\u25c6 \u901a\u8fc7\u51e0\u4f55\u4f18\u5316\u548c\u5916\u89c2\u53d8\u5316\u5efa\u6a21\uff0c\u540c\u65f6\u63d0\u5347\u573a\u666f\u7684\u51e0\u4f55\u7cbe\u5ea6\u548c\u89c6\u89c9\u4e00\u81f4\u6027\u3002  \n\u25c6 \u5728\u5408\u6210\u4e0e\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u663e\u8457\u6539\u5584\u4e86\u906e\u6321\u548c\u4f4e\u8986\u76d6\u533a\u57df\u7684\u6e32\u67d3\u6548\u679c\u3002  \n\u25c6 \u9996\u6b21\u5c06\u91cd\u590d\u5143\u7d20\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\u878d\u51653D\u91cd\u5efa\u6d41\u7a0b\uff0c\u4e3a\u590d\u6742\u573a\u666f\u91cd\u5efa\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2506.06412": "|2025-06-06|NeurNCD: Novel Class Discovery via Implicit Neural Representation|Junming Wang\u7b49|[2506.06412](http://arxiv.org/pdf/2506.06412)|\u65e0|\u25c6 NeurNCD\u9996\u6b21\u63d0\u51fa\u5229\u7528\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08Embedding-NeRF\u6a21\u578b\uff09\u66ff\u4ee3\u4f20\u7edf\u663e\u5f0f3D\u5206\u5272\u56fe\uff0c\u901a\u8fc7KL\u6563\u5ea6\u805a\u5408\u8bed\u4e49\u5d4c\u5165\u548c\u89c6\u89c9\u5d4c\u5165\u7a7a\u95f4\u7684\u71b5\uff0c\u89e3\u51b3\u79bb\u6563\u5316\u3001\u7a7a\u6d1e\u548c\u566a\u58f0\u95ee\u9898\u3002  \n\u25c6 \u7ed3\u5408\u7279\u5f81\u67e5\u8be2\u3001\u7279\u5f81\u8c03\u5236\u548c\u805a\u7c7b\u7b49\u5173\u952e\u7ec4\u4ef6\uff0c\u5b9e\u73b0\u9884\u8bad\u7ec3\u8bed\u4e49\u5206\u5272\u7f51\u7edc\u4e0e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u4e4b\u95f4\u7684\u9ad8\u6548\u7279\u5f81\u589e\u5f3a\u548c\u4fe1\u606f\u4ea4\u4e92\u3002  \n\u25c6 \u8be5\u6846\u67b6\u5728\u5f00\u653e\u548c\u5c01\u95ed\u573a\u666f\u4e2d\u5747\u5b9e\u73b0\u4f18\u8d8a\u5206\u5272\u6027\u80fd\uff0c\u65e0\u9700\u4f9d\u8d56\u5bc6\u96c6\u6807\u6ce8\u6570\u636e\u96c6\u8fdb\u884c\u76d1\u7763\u8bad\u7ec3\u6216\u4eba\u5de5\u751f\u6210\u7a00\u758f\u6807\u7b7e\u76d1\u7763\u3002  \n\u25c6 \u5728NYUv2\u548cReplica\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cNeurNCD\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u4e14\u6570\u636e\u9ad8\u6548\u7684\u65b0\u7c7b\u522b\u53d1\u73b0\u6846\u67b6\uff0c\u4e3a\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2506.05965": "|2025-06-06|Dy3DGS-SLAM: Monocular 3D Gaussian Splatting SLAM for Dynamic Environments|Mingrui Li\u7b49|[2506.05965](http://arxiv.org/pdf/2506.05965)|\u65e0|\u25c6 \u63d0\u51fa\u4e86Dy3DGS-SLAM\uff0c\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8e\u5355\u76eeRGB\u8f93\u5165\u7684\u52a8\u6001\u573a\u666f3D\u9ad8\u65af\u6cfc\u6e85SLAM\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u52a8\u6001\u73af\u5883\u4e0b\u7eaf\u89c6\u89c9SLAM\u7684\u7a7a\u767d\u3002  \n\u25c6 \u901a\u8fc7\u6982\u7387\u6a21\u578b\u878d\u5408\u5149\u6d41\u63a9\u7801\u548c\u6df1\u5ea6\u63a9\u7801\uff0c\u751f\u6210\u52a8\u6001\u878d\u5408\u63a9\u7801\uff0c\u4ec5\u9700\u5355\u6b21\u7f51\u7edc\u8fed\u4ee3\u5373\u53ef\u7ea6\u675f\u8ddf\u8e2a\u5c3a\u5ea6\u5e76\u4f18\u5316\u51e0\u4f55\u6e32\u67d3\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u65b0\u9896\u7684\u8fd0\u52a8\u635f\u5931\u51fd\u6570\uff0c\u57fa\u4e8e\u52a8\u6001\u878d\u5408\u63a9\u7801\u7ea6\u675f\u4f4d\u59ff\u4f30\u8ba1\u7f51\u7edc\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u7269\u4f53\u5e72\u6270\u4e0b\u7684\u8ddf\u8e2a\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5728\u6620\u5c04\u9636\u6bb5\uff0c\u7ed3\u5408\u52a8\u6001\u50cf\u7d20\u7684\u6e32\u67d3\u635f\u5931\u3001\u989c\u8272\u548c\u6df1\u5ea6\u4fe1\u606f\uff0c\u6709\u6548\u6d88\u9664\u4e86\u52a8\u6001\u7269\u4f53\u5e26\u6765\u7684\u77ac\u6001\u5e72\u6270\u548c\u906e\u6321\u95ee\u9898\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u8ddf\u8e2a\u4e0e\u6e32\u67d3\u6027\u80fd\uff0c\u751a\u81f3\u4f18\u4e8e\u90e8\u5206RGB-D\u65b9\u6cd5\uff0c\u5c55\u73b0\u4e86\u5355\u76ee\u8f93\u5165\u7684\u6f5c\u529b\u3002|\n",
    "2506.05317": "|2025-06-06|ProJo4D: Progressive Joint Optimization for Sparse-View Inverse Physics Estimation|Daniel Rho\u7b49|[2506.05317](http://arxiv.org/pdf/2506.05317)|\u65e0|\u25c6 \u63d0\u51faProJo4D\u6846\u67b6\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u8054\u5408\u4f18\u5316\u7b56\u7565\u89e3\u51b3\u7a00\u758f\u591a\u89c6\u89d2\u89c6\u9891\u4e0b\u7684\u7269\u7406\u53c2\u6570\u4f30\u8ba1\u95ee\u9898\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u56e0\u5206\u9636\u6bb5\u4f18\u5316\u5bfc\u81f4\u7684\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u53c2\u6570\u654f\u611f\u6027\u6307\u5bfc\u7684\u4f18\u5316\u987a\u5e8f\uff0c\u9010\u6b65\u8054\u5408\u4f18\u5316\u51e0\u4f55\u3001\u5916\u89c2\u3001\u7269\u7406\u72b6\u6001\u548c\u6750\u6599\u5c5e\u6027\uff0c\u907f\u514d\u76f4\u63a5\u5168\u53c2\u6570\u4f18\u5316\u5e26\u6765\u7684\u975e\u51f8\u548c\u975e\u53ef\u5fae\u96be\u9898\u3002  \n\u25c6 \u5728PAC-NeRF\u548cSpring-Gaus\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u57284D\u672a\u6765\u72b6\u6001\u9884\u6d4b\u3001\u672a\u6765\u72b6\u6001\u7684\u65b0\u89c6\u89d2\u6e32\u67d3\u548c\u6750\u6599\u53c2\u6570\u4f30\u8ba1\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002  \n\u25c6 \u9996\u6b21\u5b9e\u73b0\u7a00\u758f\u591a\u89c6\u89d2\u8f93\u5165\u4e0b\u7684\u7269\u7406\u51c6\u786e\u6570\u5b57\u5b6a\u751f\u6784\u5efa\uff0c\u4e3a\u673a\u5668\u4eba\u548cXR\u5e94\u7528\u63d0\u4f9b\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u901a\u8fc7\u6e10\u8fdb\u5f0f\u4f18\u5316\u7b56\u7565\u5e73\u8861\u8ba1\u7b97\u6548\u7387\u4e0e\u7cbe\u5ea6\uff0c\u4e3a\u590d\u6742\u7269\u7406\u573a\u666f\u7684\u795e\u7ecf\u6e32\u67d3\u4e0e\u53c2\u6570\u4f30\u8ba1\u63d0\u4f9b\u65b0\u601d\u8def\u3002|\n",
    "2506.05280": "|2025-06-06|Unifying Appearance Codes and Bilateral Grids for ...|Nan Wang\u7b49|[2506.05280](http://arxiv.org/pdf/2506.05280)|[\u4ee3\u7801](https://github.com/bigcileng/bilateral-driving)|\u25c6\u63d0\u51fa\u591a\u5c3a\u5ea6\u53cc\u8fb9\u7f51\u683c\u65b0\u65b9\u6cd5\uff0c\u7edf\u4e00\u4e86\u5916\u89c2\u7f16\u7801\u548c\u53cc\u8fb9\u7f51\u683c\u7684\u4f18\u52bf\uff0c\u89e3\u51b3\u4e86\u52a8\u6001\u9a7e\u9a76\u573a\u666f\u4e2d\u5149\u5ea6\u4e0d\u4e00\u81f4\u5bfc\u81f4\u7684\u51e0\u4f55\u5931\u771f\u95ee\u9898\u3002  \n\u25c6\u901a\u8fc7\u50cf\u7d20\u7ea7\u989c\u8272\u6620\u5c04\u548c\u5206\u5c42\u7ea6\u675f\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5149\u4e0d\u4e00\u81f4\u4ea7\u751f\u7684\u6f02\u6d6e\u4f2a\u5f71\uff0c\u5728\u56db\u5927\u81ea...|\n",
    "2506.04908": "|2025-06-05|Generating Synthetic Stereo Datasets using 3D Gaus...|Filip Slezak\u7b49|[2506.04908](http://arxiv.org/pdf/2506.04908)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7684\u7acb\u4f53\u6570\u636e\u96c6\u751f\u6210\u6d41\u7a0b\uff0c\u76f8\u6bd4NeRF\u65b9\u6cd5\u66f4\u9ad8\u6548\u3002  \n\u25c6 \u7ed3\u5408\u663e\u5f0f3D\u91cd\u5efa\u51e0\u4f55\u4e0eFoundationStereo\u6a21\u578b\u7684\u6df1\u5ea6\u4f30\u8ba1\u8fdb\u884c\u4e13\u5bb6\u77e5\u8bc6\u8fc1\u79fb\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u3002...|\n",
    "2506.08619": "|2025-06-10|A Probability-guided Sampler for Neural Implicit Surface Rendering|Gon\u00e7alo Dias Pais\u7b49|[2506.08619](http://arxiv.org/pdf/2506.08619)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u76843D\u56fe\u50cf\u6295\u5f71\u7a7a\u95f4\u6a21\u578b\uff0c\u5b9e\u73b0\u9488\u5bf9\u611f\u5174\u8da3\u533a\u57df\u7684\u5c04\u7ebf\u91c7\u6837\u4f18\u5316\uff0c\u63d0\u5347\u6e32\u67d3\u7cbe\u5ea6\u3002  \n\u25c6 \u8bbe\u8ba1\u65b0\u578b\u8868\u9762\u91cd\u5efa\u635f\u5931\u51fd\u6570\uff0c\u5145\u5206\u5229\u75283D\u6295\u5f71\u7a7a\u95f4\u6a21\u578b\uff0c\u6574\u5408\u8fd1\u8868\u9762\u548c\u7a7a\u767d\u7a7a\u95f4\u4fe1\u606f\u4ee5\u589e\u5f3a\u6027\u80fd\u3002  \n\u25c6 \u7ed3\u5408\u9690\u5f0f\u8868\u9762\u8868\u793a\uff0c\u901a\u8fc7\u6982\u7387\u5f15\u5bfc\u91c7\u6837\u7b56\u7565\u6709\u6548\u805a\u7126\u5173\u952e\u533a\u57df\uff0c\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u3002  \n\u25c6 \u5c06\u63d0\u51fa\u7684\u91c7\u6837\u7b56\u7565\u4e0e\u635f\u5931\u51fd\u6570\u96c6\u6210\u5230\u73b0\u6709\u795e\u7ecf\u9690\u5f0f\u8868\u9762\u6e32\u67d3\u5668\u4e2d\uff0c\u663e\u8457\u63d0\u53473D\u91cd\u5efa\u548c\u56fe\u50cf\u6e32\u67d3\u8d28\u91cf\u3002  \n\u25c6 \u7279\u522b\u9488\u5bf9\u573a\u666f\u4e2d\u611f\u5174\u8da3\u533a\u57df\uff08\u5982\u7269\u4f53\u8868\u9762\uff09\u5b9e\u73b0\u66f4\u7cbe\u7ec6\u7684\u7ec6\u8282\u8fd8\u539f\uff0c\u514b\u670d\u4f20\u7edf\u5747\u5300\u91c7\u6837\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u901a\u8fc7\u8054\u5408\u4f18\u5316\u91c7\u6837\u4e0e\u91cd\u5efa\u8fc7\u7a0b\uff0c\u5728\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u83b7\u5f97\u66f4\u9ad8\u4fdd\u771f\u5ea6\u7684\u6e32\u67d3\u7ed3\u679c\u3002|\n",
    "2506.09885": "|2025-06-11|The Less You Depend, The More You Learn: Synthesizing Novel Views from Sparse, Unposed Images without Any 3D Knowledge|Haoru Wang\u7b49|[2506.09885](http://arxiv.org/pdf/2506.09885)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u97003D\u5148\u9a8c\u77e5\u8bc6\u548c\u76f8\u673a\u4f4d\u59ff\u6807\u6ce8\u7684\u901a\u7528\u5316\u65b0\u89c6\u89d2\u5408\u6210\u6846\u67b6\uff0c\u4ec5\u4f9d\u8d56\u7a00\u758f\u65e0\u4f4d\u59ff\u76842D\u56fe\u50cf\u5373\u53ef\u751f\u6210\u903c\u771f\u65b0\u89c6\u56fe\u3002  \n\u25c6 \u901a\u8fc7\u7cfb\u7edf\u6027\u5206\u6790\u63ed\u793a\u4e86\u5173\u952e\u8d8b\u52bf\uff1a\u51cf\u5c11\u5bf93D\u77e5\u8bc6\u7684\u4f9d\u8d56\u80fd\u66f4\u9ad8\u6548\u5229\u7528\u6570\u636e\u89c4\u6a21\uff0c\u6700\u7ec8\u8fbe\u5230\u4e0e\u4f9d\u8d563D\u77e5\u8bc6\u7684\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u6d88\u9664\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bf9\u663e\u5f0f3D\u8868\u793a\uff08\u5982NeRF\u30013DGS\uff09\u548c\u8f93\u5165/\u76ee\u6807\u89c6\u89d2\u4f4d\u59ff\u6807\u6ce8\u7684\u53cc\u91cd\u4f9d\u8d56\uff0c\u5b9e\u73b0\u5b8c\u5168\u6570\u636e\u9a71\u52a8\u7684\u9690\u5f0f3D\u7406\u89e3\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u4ec5\u901a\u8fc7\u7a00\u758f2D\u56fe\u50cf\u5373\u53ef\u5b66\u4e60\u9690\u5f0f3D\u4e00\u81f4\u6027\uff0c\u751f\u6210\u8d28\u91cf\u5ab2\u7f8e\u4f9d\u8d56\u4f4d\u59ff\u8f93\u5165\u7684\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u4e3a\u4e2d\u5fc3\u8303\u5f0f\u7684\u53ef\u884c\u6027\u3002  \n\u25c6 \u4e3a\u5927\u89c4\u6a21\u6570\u636e\u65f6\u4ee3\u7684\u65b0\u89c6\u89d2\u5408\u6210\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u8868\u660e\u51cf\u5c113D\u5148\u9a8c\u4f9d\u8d56\u4e0e\u6570\u636e\u89c4\u6a21\u6269\u5c55\u4e4b\u95f4\u5b58\u5728\u6b63\u5411\u5173\u8054\u6027\u3002|\n",
    "2506.10335": "|2025-06-12|PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting|Lintao Xiang\u7b49|[2506.10335](http://arxiv.org/pdf/2506.10335)|\u65e0|\u25c6 \u63d0\u51faPointGS\u6846\u67b6\uff0c\u901a\u8fc7\u70b9\u6ce8\u610f\u529b\u611f\u77e5\u7684\u7a00\u758f\u89c6\u56fe\u5408\u6210\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e863D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u5728\u8f93\u5165\u89c6\u56fe\u4e0d\u8db3\u65f6\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002  \n\u25c6 \u5229\u7528\u6700\u65b0\u7684\u7acb\u4f53\u57fa\u7840\u6a21\u578b\u4f30\u8ba1\u7cbe\u786e\u76f8\u673a\u59ff\u6001\u5e76\u91cd\u5efa\u5bc6\u96c6\u70b9\u4e91\uff0c\u4e3a\u9ad8\u65af\u521d\u59cb\u5316\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8d77\u70b9\u3002  \n\u25c6 \u8bbe\u8ba1\u591a\u5c3a\u5ea62D\u5916\u89c2\u7279\u5f81\u91c7\u6837\u4e0e\u805a\u5408\u673a\u5236\uff0c\u4e3a\u6bcf\u4e2a3D\u9ad8\u65af\u70b9\u7f16\u7801\u989c\u8272\u5c5e\u6027\uff0c\u589e\u5f3a\u7a00\u758f\u8f93\u5165\u4e0b\u7684\u7279\u5f81\u8868\u8fbe\u80fd\u529b\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5f15\u5165\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u70b9\u4ea4\u4e92\u7f51\u7edc\uff0c\u4f7f\u9ad8\u65af\u70b9\u80fd\u4e0e\u90bb\u8fd1\u70b9\u4ea4\u4e92\uff0c\u63d0\u5347\u70b9\u7ea7\u5916\u89c2\u8868\u793a\u80fd\u529b\u3002  \n\u25c6 \u901a\u8fc7\u4e24\u4e2a\u8f7b\u91cf\u7ea7\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u5c06\u589e\u5f3a\u7279\u5f81\u89e3\u7801\u4e3a\u9ad8\u65af\u53c2\u6570\uff0c\u5b9e\u73b0\u5b9e\u65f6\u9ad8\u8d28\u91cf\u6e32\u67d3\u3002  \n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eNeRF\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u5c11\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb3DGS\u65b9\u6cd5\u7ade\u4e89\u7684\u6027\u80fd\u3002|\n",
    "2506.12787": "|2025-06-18|Rasterizing Wireless Radiance Field via Deformable 2D Gaussian Splatting|Mufan Liu\u7b49|[2506.12787](http://arxiv.org/pdf/2506.12787)|\u65e0|\u25c6 \u63d0\u51faSwiftWRF\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u9ad8\u65af\u6cfc\u6e85\uff08Gaussian Splatting\uff09\u6280\u672f\u5f15\u5165\u65e0\u7ebf\u8f90\u5c04\u573a\uff08WRF\uff09\u5efa\u6a21\uff0c\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u7684\u5c40\u9650\u3002  \n\u25c6 \u91c7\u7528\u53ef\u53d8\u5f622D\u9ad8\u65af\u6cfc\u6e85\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7MLP\u5efa\u6a21\u9ad8\u65af\u5f62\u53d8\uff0c\u6709\u6548\u6355\u6349\u6536\u53d1\u7aef\u5355\u4fa7\u79fb\u52a8\u5bfc\u81f4\u7684WRF\u52a8\u6001\u53d8\u5316\u3002  \n\u25c6 \u5b9e\u73b0CUDA\u52a0\u901f\u7684\u5149\u6805\u5316\u6e32\u67d3\uff0c\u9891\u8c31\u5408\u6210\u901f\u5ea6\u8d85\u8fc710\u4e07\u5e27/\u79d2\uff0c\u6bd4\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u5feb500\u500d\uff0c\u6ee1\u8db3\u5b9e\u65f6\u6027\u9700\u6c42\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u652f\u6301\u4efb\u610f\u4f4d\u7f6e\u7684WRF\u9891\u8c31\u5408\u6210\uff0c\u5e76\u5728\u5230\u8fbe\u89d2\uff08AoA\uff09\u548c\u4fe1\u53f7\u5f3a\u5ea6\uff08RSSI\uff09\u9884\u6d4b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u5b9e\u7528\u6027\u3002  \n\u25c6 \u5728\u771f\u5b9e\u548c\u5408\u6210\u5ba4\u5185\u573a\u666f\u7684\u5b9e\u9a8c\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u4fe1\u53f7\u91cd\u5efa\u8d28\u91cf\uff0c\u540c\u65f6\u5f00\u6e90\u4ee3\u7801\u548c\u6570\u636e\u96c6\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002|\n",
    "2506.12727": "|2025-06-17|Efficient multi-view training for 3D Gaussian Splatting|Minhyuk Choi\u7b49|[2506.12727](http://arxiv.org/pdf/2506.12727)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u548c\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u591a\u89c6\u89d2\u8bad\u7ec3\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e863D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u4f20\u7edf\u5355\u89c6\u89d2\u8bad\u7ec3\u5bfc\u81f4\u7684\u968f\u673a\u68af\u5ea6\u65b9\u5dee\u8fc7\u5927\u95ee\u9898\uff0c\u4f18\u5316\u4e86\u8bad\u7ec3\u6548\u679c\u3002  \n\u25c6 \u6539\u8fdb\u4e86\u5149\u6805\u5316\u6d41\u7a0b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u591a\u89c6\u89d2\u8bad\u7ec3\u7684\u8ba1\u7b97\u5f00\u9500\uff0c\u4f7f\u5176\u66f4\u9ad8\u6548\u53ef\u884c\u3002  \n\u25c6 \u8bbe\u8ba1\u4e863D\u8ddd\u79bb\u611f\u77e5\u7684D-SSIM\u635f\u5931\u51fd\u6570\uff0c\u66f4\u597d\u5730\u9002\u5e94\u591a\u89c6\u89d2\u573a\u666f\uff0c\u63d0\u5347\u4e86\u6e32\u67d3\u8d28\u91cf\u3002  \n\u25c6 \u63d0\u51fa\u591a\u89c6\u89d2\u81ea\u9002\u5e94\u5bc6\u5ea6\u63a7\u5236\u673a\u5236\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5355\u89c6\u89d2\u5047\u8bbe\u4e0b\u9ad8\u65af\u5206\u5e03\u4f18\u5316\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e863DGS\u53ca\u5176\u53d8\u4f53\u7684\u6027\u80fd\uff0c\u7a81\u7834\u4e86\u5355\u89c6\u89d2\u8bad\u7ec3\u7684\u7ea6\u675f\u3002  \n\u25c6 \u4e3a3DGS\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u5176\u5728\u9006\u5411\u6e32\u67d3\u4e2d\u7684\u5e94\u7528\u3002|\n",
    "2506.15242": "|2025-06-24|RA-NeRF: Robust Neural Radiance Field Reconstruction with Accurate Camera Pose Estimation under Complex Trajectories|Qingsong Yan\u7b49|[2506.15242](http://arxiv.org/pdf/2506.15242)|\u65e0|\u25c6 \u63d0\u51faRA-NeRF\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u590d\u6742\u76f8\u673a\u8f68\u8ff9\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfNeRF\u548c3DGS\u4f9d\u8d56\u51c6\u786e\u4f4d\u59ff\u5148\u9a8c\u7684\u95ee\u9898\u3002  \n\u25c6 \u91c7\u7528\u589e\u91cf\u5f0f\u91cd\u5efa\u6d41\u7a0b\uff0c\u7ed3\u5408\u5149\u5ea6\u4e00\u81f4\u6027\u7ea6\u675f\u548c\u5149\u6d41\u9a71\u52a8\u7684\u4f4d\u59ff\u8c03\u8282\u673a\u5236\uff0c\u63d0\u5347\u4e86\u521d\u59cb\u5316\u548c\u5b9a\u4f4d\u9636\u6bb5\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5f15\u5165\u9690\u5f0f\u4f4d\u59ff\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u6355\u6349\u76f8\u673a\u8fd0\u52a8\u6a21\u5f0f\u6709\u6548\u6d88\u9664\u4f4d\u59ff\u4f30\u8ba1\u4e2d\u7684\u566a\u58f0\uff0c\u589e\u5f3a\u590d\u6742\u8f68\u8ff9\u4e0b\u7684\u7a33\u5b9a\u6027\u3002  \n\u25c6 \u5728Tanks&Temple\u548cNeRFBuster\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u4f4d\u59ff\u4f30\u8ba1\u548c\u89c6\u89c9\u8d28\u91cf\u5747\u8fbe\u5230SOTA\u6c34\u5e73\u3002  \n\u25c6 \u6574\u4f53\u6846\u67b6\u65e0\u9700\u5916\u90e8\u7ea6\u675f\uff0c\u4ec5\u901a\u8fc7\u7aef\u5230\u7aef\u4f18\u5316\u5373\u53ef\u540c\u65f6\u4f18\u5316\u573a\u666f\u91cd\u5efa\u4e0e\u76f8\u673a\u4f4d\u59ff\uff0c\u9002\u7528\u4e8eSLAM\u7b49\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002|\n",
    "2506.14856": "|2025-06-17|Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction|Zhengquan Zhang\u7b49|[2506.14856](http://arxiv.org/pdf/2506.14856)|\u65e0|\u25c6\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u524d\u9988\u795e\u7ecf\u7f51\u7edcUPNet\u7684\u65b0\u9896\u4e3b\u52a8\u89c6\u89d2\u9009\u62e9\u65b9\u6cd5\uff0c\u76f4\u63a5\u9884\u6d4b\u5019\u9009\u89c6\u89d2\u7684\u4e0d\u786e\u5b9a\u6027\u56fe\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u8ba1\u7b97\u6bcf\u4e2a\u89c6\u89d2\u4e0d\u786e\u5b9a\u6027\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3002  \n\u25c6UPNet\u4ec5\u9700\u5355\u5f20\u8f93\u5165\u56fe\u50cf\u5373\u53ef\u9884\u6d4b\u6240\u6709\u5019\u9009\u89c6\u89d2\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u5b66\u4e60\u81ea\u7136\u7269\u4f53\u89c6\u89d2\u4e0e\u4f53\u7d20\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u4fe1\u606f\u63d0\u53d6\u3002  \n\u25c6\u901a\u8fc7\u805a\u5408\u5386\u53f2\u9884\u6d4b\u7684\u4e0d\u786e\u5b9a\u6027\u56fe\u6765\u6291\u5236\u5197\u4f59\u89c6\u89d2\uff0c\u667a\u80fd\u9009\u62e9\u4fe1\u606f\u91cf\u6700\u5927\u7684\u65b0\u89c6\u89d2\uff0c\u4ec5\u9700\u4e00\u534a\u89c6\u89d2\u5373\u53ef\u8fbe\u5230\u4e0e\u4e0a\u9650\u76f8\u5f53\u76843D\u91cd\u5efa\u7cbe\u5ea6\u3002  \n\u25c6\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8ba1\u7b97\u6548\u7387\u663e\u8457\u63d0\u5347\uff0c\u5b9e\u73b0\u9ad8\u8fbe400\u500d\u7684\u52a0\u901f\uff0c\u5e76\u51cf\u5c1150%\u4ee5\u4e0a\u7684CPU\u3001RAM\u548cGPU\u8d44\u6e90\u6d88\u8017\u3002  \n\u25c6\u65b9\u6cd5\u5177\u6709\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u9002\u7528\u4e8e\u65b0\u7269\u4f53\u7c7b\u522b\u7684\u89c6\u89d2\u9009\u62e9\u4efb\u52a1\uff0c\u5c55\u73b0\u4e86\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002  \n\u25c6\u6574\u4f53\u65b9\u6848\u5c06\u795e\u7ecf\u6e32\u67d3\u4e0e\u9ad8\u6548\u89c6\u89d2\u9009\u62e9\u76f8\u7ed3\u5408\uff0c\u4e3a3D\u91cd\u5efa\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u4e0e\u4f4e\u8d44\u6e90\u6d88\u8017\u7684\u5b9e\u7528\u5316\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2506.16262": "|2025-06-23|R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision|Weeyoung Kwon\u7b49|[2506.16262](http://arxiv.org/pdf/2506.16262)|[\u4ee3\u7801](https://github.com/cmlab-korea/awesome-3d-low-level-vision)|\u25c6 \u63d0\u51fa\u201c3D\u4f4e\u5c42\u89c6\u89c9\uff083D LLV\uff09\u201d\u65b0\u9886\u57df\uff0c\u5c06\u4f20\u7edf2D\u4f4e\u5c42\u89c6\u89c9\u4efb\u52a1\uff08\u5982\u8d85\u5206\u3001\u53bb\u6a21\u7cca\u3001\u5929\u6c14\u9000\u5316\u4fee\u590d\u7b49\uff09\u6269\u5c55\u52303D\u7a7a\u95f4\uff0c\u89e3\u51b3\u795e\u7ecf\u6e32\u67d3\u5728\u771f\u5b9e\u9000\u5316\u573a\u666f\u4e2d\u7684\u9c81\u68d2\u6027\u95ee\u9898\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u5316\u5b9a\u4e49\u201c\u9000\u5316\u611f\u77e5\u6e32\u67d3\u201d\u95ee\u9898\uff0c\u660e\u786e\u65f6\u7a7a\u4e00\u81f4\u6027\u548c\u75c5\u6001\u4f18\u5316\u7b49\u6838\u5fc3\u6311\u6218\uff0c\u4e3a3D LLV\u7814\u7a76\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u3002  \n\u25c6 \u7efc\u8ff0\u4e86\u5c06\u4f4e\u5c42\u89c6\u89c9\u6280\u672f\u4e0e\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u30013D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u7b49\u795e\u7ecf\u6e32\u67d3\u7ed3\u5408\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u5c55\u793a\u5176\u5728\u566a\u58f0\u3001\u6a21\u7cca\u3001\u4f4e\u5206\u8fa8\u7387\u7b49\u9000\u5316\u6761\u4ef6\u4e0b\u7684\u9ad8\u4fdd\u771f3D\u91cd\u5efa\u80fd\u529b\u3002  \n\u25c6 \u68b3\u7406\u4e86\u81ea\u52a8\u9a7e\u9a76\u3001AR/VR\u3001\u673a\u5668\u4eba\u7b49\u5173\u952e\u5e94\u7528\u573a\u666f\uff0c\u5f3a\u8c03\u4ece\u9000\u5316\u8f93\u5165\u4e2d\u5b9e\u73b0\u53ef\u97603D\u611f\u77e5\u7684\u5b9e\u7528\u4ef7\u503c\u3002  \n\u25c6 \u6c47\u603b\u4e86\u4ee3\u8868\u6027\u65b9\u6cd5\u3001\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u4e3a\u672a\u67653D LLV\u7814\u7a76\u63d0\u4f9b\u6807\u51c6\u5316\u53c2\u8003\uff0c\u63a8\u52a8\u771f\u5b9e\u73af\u5883\u4e0b\u9c81\u68d23D\u5185\u5bb9\u751f\u6210\u4e0e\u573a\u666f\u91cd\u5efa\u7684\u53d1\u5c55\u3002|\n",
    "2506.18678": "|2025-06-23|MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation|Tianchen Deng\u7b49|[2506.18678](http://arxiv.org/pdf/2506.18678)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u5206\u5e03\u5f0f\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u795e\u7ecfSLAM\u6846\u67b6MCN-SLAM\uff0c\u7ed3\u5408\u6df7\u5408\u9690\u5f0f\u795e\u7ecf\u573a\u666f\u8868\u793a\uff0c\u89e3\u51b3\u4f20\u7edf\u5355\u667a\u80fd\u4f53\u9690\u5f0fSLAM\u5728\u5927\u573a\u666f\u548c\u957f\u5e8f\u5217\u4e2d\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u521b\u65b0\u8bbe\u8ba1\u4e09\u5e73\u9762-\u7f51\u683c\u8054\u5408\u573a\u666f\u8868\u793a\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u573a\u666f\u91cd\u5efa\u8d28\u91cf\uff0c\u4f18\u4e8e\u73b0\u6709NeRF-based\u65b9\u6cd5\u3002  \n\u25c6 \u5f00\u53d1\"\u5185\u90e8-\u8de8\u667a\u80fd\u4f53\"\u95ed\u73af\u68c0\u6d4b\u673a\u5236\uff0c\u9996\u6b21\u5b9e\u73b0\u5355\u667a\u80fd\u4f53\u5c40\u90e8\u4e00\u81f4\u6027\u4e0e\u591a\u667a\u80fd\u4f53\u5168\u5c40\u4e00\u81f4\u6027\u7684\u534f\u540c\u4f18\u5316\u3002  \n\u25c6 \u63d0\u51fa\u5728\u7ebf\u84b8\u998f\u65b9\u6cd5\u5b9e\u73b0\u591a\u5b50\u5730\u56fe\u878d\u5408\uff0c\u7a81\u7834\u901a\u4fe1\u5e26\u5bbd\u9650\u5236\uff0c\u786e\u4fdd\u5168\u5c40\u5730\u56fe\u4e00\u81f4\u6027\u3002  \n\u25c6 \u53d1\u5e03\u9996\u4e2a\u771f\u5b9e\u4e16\u754c\u5bc6\u96c6SLAM\u6570\u636e\u96c6DES\uff0c\u6db5\u76d6\u5355/\u591a\u667a\u80fd\u4f53\u573a\u666f\uff0c\u63d0\u4f9b\u8fde\u7eed\u8f68\u8ff9\u548c\u9ad8\u7cbe\u5ea63D\u7f51\u683c\u771f\u503c\uff0c\u586b\u8865\u9886\u57df\u7a7a\u767d\u3002  \n\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5efa\u56fe\u3001\u5b9a\u4f4d\u548c\u901a\u4fe1\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u5c06\u5f00\u6e90\u63a8\u52a8SLAM\u548c3D\u91cd\u5efa\u9886\u57df\u53d1\u5c55\u3002|\n",
    "2506.18575": "|2025-06-26|2D Triangle Splatting for Direct Differentiable Mesh Training|Kaifeng Sheng\u7b49|[2506.18575](http://arxiv.org/pdf/2506.18575)|[\u4ee3\u7801](https://github.com/GaodeRender/triangle-splatting)|\u25c6 \u63d0\u51fa2D\u4e09\u89d2\u5f62\u9762\u7247\uff082DTS\uff09\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf3D\u9ad8\u65af\u57fa\u5143\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u76f4\u63a5\u53ef\u5fae\u5206\u7f51\u683c\u8bad\u7ec3\u3002  \n\u25c6 \u7ed3\u5408\u79bb\u6563\u7f51\u683c\u7ed3\u6784\u4e0e\u8fde\u7eed\u4f53\u79ef\u5efa\u6a21\u4f18\u52bf\uff0c\u5f62\u6210\u7c7b\u7f51\u683c\u7684\u8868\u793a\u5f62\u5f0f\uff0c\u63d0\u5347\u6e32\u67d3\u8d28\u91cf\u548c\u7075\u6d3b\u6027\u3002  \n\u25c6 \u5f15\u5165\u7d27\u51d1\u6027\u53c2\u6570\u5230\u4e09\u89d2\u5f62\u57fa\u5143\u4e2d\uff0c\u652f\u6301\u76f4\u63a5\u8bad\u7ec3\u9ad8\u771f\u5b9e\u611f\u7f51\u683c\uff0c\u7b80\u5316\u4f20\u7edf\u7f51\u683c\u91cd\u5efa\u6d41\u7a0b\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\uff0c\u5373\u4f7f\u672a\u4f18\u5316\u7d27\u51d1\u6027\u53c2\u6570\uff0c\u5176\u57fa\u7840\u7248\u672c\u4e5f\u80fd\u8d85\u8d8a\u5f53\u524d\u6700\u4f18\u9ad8\u65af\u57fa\u5143\u65b9\u6cd5\u7684\u6e32\u67d3\u4fdd\u771f\u5ea6\u3002  \n\u25c6 \u751f\u6210\u7684\u7f51\u683c\u5728\u89c6\u89c9\u8d28\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7f51\u683c\u91cd\u5efa\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u590d\u6742\u5149\u7167\u548c\u9634\u5f71\u6548\u679c\u4e2d\u8868\u73b0\u7a81\u51fa\u3002  \n\u25c6 \u4e3a\u53ef\u5fae\u5206\u6e32\u67d3\u9886\u57df\u63d0\u4f9b\u65b0\u601d\u8def\uff0c\u5e73\u8861\u4e86\u6e32\u67d3\u901f\u5ea6\u4e0e\u9ad8\u7ea7\u6e32\u67d3\u6548\u679c\uff08\u5982\u91cd\u5149\u7167\uff09\u7684\u517c\u5bb9\u6027\u3002|\n",
    "2506.18208": "|2025-06-22|Limitations of NERF with pre-trained Vision Features for Few-Shot 3D Reconstruction|Ankit Sanjyal|[2506.18208](http://arxiv.org/pdf/2506.18208)|\u65e0|\u25c6 \u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86DINO\u9884\u8bad\u7ec3\u89c6\u89c9\u7279\u5f81\u5728NeRF\u5c11\u6837\u672c3D\u91cd\u5efa\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6240\u6709\u53d8\u4f53\u6027\u80fd\u5747\u4f4e\u4e8e\u539f\u59cbNeRF\u57fa\u7ebf\uff08PSNR 12.9-13.0 vs 14.71\uff09\u3002  \n\u25c6 \u63ed\u793a\u4e86\u53cd\u76f4\u89c9\u7ed3\u8bba\uff1a\u9884\u8bad\u7ec3\u89c6\u89c9\u7279\u5f81\u4e0d\u4ec5\u65e0\u52a9\u4e8e\u5c11\u6837\u672c\u91cd\u5efa\uff0c\u53cd\u800c\u53ef\u80fd\u5f15\u5165\u6709\u5bb3\u504f\u5dee\uff0c\u6311\u6218\u4e86\u8be5\u9886\u57df\u666e\u904d\u5047\u8bbe\u3002  \n\u25c6 \u63d0\u51fa\u4e09\u79cd\u6f5c\u5728\u5931\u6548\u539f\u56e0\u5206\u6790\u6846\u67b6\uff1a\u7279\u5f81-\u4efb\u52a1\u4e0d\u5339\u914d\u3001\u6709\u9650\u6570\u636e\u8fc7\u62df\u5408\u95ee\u9898\u4ee5\u53ca\u7279\u5f81\u878d\u5408\u6280\u672f\u74f6\u9888\u3002  \n\u25c6 \u901a\u8fc7\u5bf9\u6bd4\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u51bb\u7ed3\u7279\u5f81\u3001LoRA\u5fae\u8c03\u548c\u591a\u5c3a\u5ea6\u878d\u5408\u7b49\u4e3b\u6d41\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u6392\u9664\u65e0\u6548\u8def\u5f84\u3002  \n\u25c6 \u6307\u51fa\u5c11\u6837\u672c\u573a\u666f\u4e0b\u5e94\u4f18\u5148\u5173\u6ce8\u51e0\u4f55\u4e00\u81f4\u6027\u800c\u975e\u590d\u6742\u7279\u5f81\u5de5\u7a0b\uff0c\u4e3a\u7b80\u5316\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u65b9\u5411\u3002  \n\u25c6 \u7814\u7a76\u6210\u679c\u5bf9\u57fa\u4e8e\u9884\u8bad\u7ec3\u7279\u5f81\u76843D\u91cd\u5efa\u65b9\u6cd5\u63d0\u51fa\u91cd\u8981\u8b66\u793a\uff0c\u53ef\u80fd\u6539\u53d8\u8be5\u9886\u57df\u6280\u672f\u8def\u7ebf\u9009\u62e9\u3002|\n",
    "2506.17636": "|2025-06-21|3D Gaussian Splatting for Fine-Detailed Surface Reconstruction in Large-Scale Scene|Shihan Chen\u7b49|[2506.17636](http://arxiv.org/pdf/2506.17636)|\u65e0|\u25c6 \u63d0\u51fa\u4ece\u7c97\u5230\u7cbe\u7684\u6e10\u8fdb\u5f0f\u91cd\u5efa\u7b56\u7565\uff0c\u5148\u5feb\u901f\u6784\u5efa\u7c97\u7cd9\u6a21\u578b\uff0c\u518d\u901a\u8fc7\u81ea\u9002\u5e94\u573a\u666f\u5206\u5272\u548c\u5b50\u573a\u666f\u7ec6\u5316\u5b9e\u73b0\u5927\u89c4\u6a21\u573a\u666f\u7684\u9ad8\u6548\u91cd\u5efa\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u7ed3\u5408\u89e3\u8026\u5916\u89c2\u6a21\u578b\uff0c\u6709\u6548\u6355\u6349\u6237\u5916\u73af\u5883\u4e2d\u590d\u6742\u7684\u5168\u5c40\u5149\u7167\u53d8\u5316\uff0c\u63d0\u5347\u52a8\u6001\u5916\u89c2\u7684\u5efa\u6a21\u80fd\u529b\u3002  \n\u25c6 \u8bbe\u8ba1\u77ac\u6001\u63a9\u6a21\u6a21\u578b\uff0c\u81ea\u52a8\u8fc7\u6ee4\u79fb\u52a8\u7269\u4f53\uff08\u5982\u8f66\u8f86\u3001\u884c\u4eba\uff09\u7684\u5e72\u6270\uff0c\u663e\u8457\u63d0\u9ad8\u91cd\u5efa\u7eaf\u51c0\u5ea6\u3002  \n\u25c6 \u6269\u5c55\u591a\u89c6\u89d2\u7ea6\u675f\u5e76\u5f15\u5165\u5355\u89c6\u89d2\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u9488\u5bf9\u6027\u89e3\u51b3\u7eb9\u7406\u7f3a\u5931\u533a\u57df\u7684\u51e0\u4f55\u4f18\u5316\u96be\u9898\u3002  \n\u25c6 \u5728\u65e0\u4eba\u673a\u822a\u62cd\u6570\u636e\u96c6GauU-Scene V2\u4e0a\u9a8c\u8bc1\uff0c\u9996\u6b21\u5b9e\u73b0\u5168\u5c3a\u5bf8\u56fe\u50cf\u4f18\u5316\u7684\u5927\u89c4\u6a21\u573a\u666f\u7cbe\u7ec6\u91cd\u5efa\uff0c\u6027\u80fd\u8d85\u8d8a\u73b0\u6709NeRF\u548cGaussian\u7c7b\u65b9\u6cd5\u3002  \n\uff08\u6ce8\uff1a\u5168\u6587\u4e25\u683c\u9075\u5faa5\u70b9\u521b\u65b0\u6027\u603b\u7ed3\uff0c\u672a\u4f7f\u7528Markdown\u7b26\u53f7\uff0c\u5b57\u6570\u63a7\u5236\u5728400\u5b57\u5185\uff09|\n",
    "2506.19742": "|2025-06-24|NeRF-based CBCT Reconstruction needs Normalization and Initialization|Zhuowei Xu\u7b49|[2506.19742](http://arxiv.org/pdf/2506.19742)|\u65e0|\u25c6 \u63d0\u51fa\u5f52\u4e00\u5316\u54c8\u5e0c\u7f16\u7801\u5668\uff08Normalized Hash Encoder\uff09\uff0c\u89e3\u51b3NeRF-based CBCT\u91cd\u5efa\u4e2d\u54c8\u5e0c\u7f16\u7801\u5668\u4e0e\u795e\u7ecf\u7f51\u7edc\u7684\u5c40\u90e8-\u5168\u5c40\u8bad\u7ec3\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u901a\u8fc7\u589e\u5f3a\u7279\u5f81\u4e00\u81f4\u6027\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002  \n\u25c6 \u8bbe\u8ba1\u6620\u5c04\u4e00\u81f4\u6027\u521d\u59cb\u5316\u7b56\u7565\uff08MCI\uff09\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5168\u5c40\u6620\u5c04\u7279\u6027\u521d\u59cb\u5316\u795e\u7ecf\u7f51\u7edc\uff0c\u51cf\u5c11\u65e9\u671f\u8bad\u7ec3\u6ce2\u52a8\uff0c\u52a0\u901f\u6536\u655b\u5e76\u63d0\u9ad8\u91cd\u5efa\u8d28\u91cf\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u54c8\u5e0c\u7f16\u7801\u5668\u53c2\u6570\u5c40\u90e8\u7a00\u758f\u6027\u4e0e\u795e\u7ecf\u7f51\u7edc\u5168\u5c40\u5bc6\u96c6\u66f4\u65b0\u7684\u77db\u76fe\uff0c\u6307\u51fa\u7279\u5f81\u9519\u4f4d\u662f\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7684\u6838\u5fc3\u539f\u56e0\u3002  \n\u25c6 \u65b9\u6cd5\u4ec5\u9700\u5c11\u91cf\u4ee3\u7801\u6539\u52a8\uff0c\u5373\u53ef\u57284\u4e2a\u6570\u636e\u96c6\u3001128\u4f8bCT\u6570\u636e\uff08\u6db5\u76d67\u4e2a\u89e3\u5256\u533a\u57df\uff09\u4e0a\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u91cd\u5efa\u6027\u80fd\u3002  \n\u25c6 \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5f52\u4e00\u5316\u4e0e\u521d\u59cb\u5316\u7b56\u7565\u7684\u534f\u540c\u4f5c\u7528\uff0c\u4e3aNeRF-based\u533b\u5b66\u5f71\u50cf\u91cd\u5efa\u63d0\u4f9b\u4e86\u7b80\u5355\u6709\u6548\u7684\u4f18\u5316\u8303\u5f0f\u3002|\n",
    "2506.19615": "|2025-06-25|Self-Supervised Multimodal NeRF for Autonomous Driving|Gaurav Sharma\u7b49|[2506.19615](http://arxiv.org/pdf/2506.19615)|\u65e0|\u25c6 \u63d0\u51fa\u81ea\u76d1\u7763\u591a\u6a21\u6001NeRF\u6846\u67b6NVSF\uff0c\u65e0\u97003D\u6807\u6ce8\u5373\u53ef\u8054\u5408\u5b66\u4e60LiDAR\u548c\u76f8\u673a\u7684\u65f6\u7a7a\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u3002  \n\u25c6 \u9488\u5bf9\u81ea\u52a8\u9a7e\u9a76\u573a\u666f\u8bbe\u8ba1\uff0c\u540c\u65f6\u5904\u7406\u9759\u6001\u548c\u52a8\u6001\u73af\u5883\uff0c\u663e\u8457\u63d0\u5347\u771f\u5b9e\u9a7e\u9a76\u573a\u666f\u7684\u9002\u5e94\u6027\u3002  \n\u25c6 \u5f15\u5165\u542f\u53d1\u5f0f\u56fe\u50cf\u50cf\u7d20\u91c7\u6837\u7b56\u7565\uff0c\u4f18\u5148\u9009\u62e9\u4fe1\u606f\u4e30\u5bcc\u7684\u50cf\u7d20\uff0c\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6536\u655b\u901f\u5ea6\u3002  \n\u25c6 \u521b\u65b0\u91c7\u7528\u53cc\u68af\u5ea6\u63a9\u7801\u6280\u672f\uff0c\u6709\u6548\u4fdd\u7559LiDAR\u70b9\u7684\u5c40\u90e8\u7279\u5f81\uff0c\u589e\u5f3a\u70b9\u4e91\u6570\u636e\u91cd\u5efa\u7cbe\u5ea6\u3002  \n\u25c6 \u5728KITTI-360\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cLiDAR\u548c\u76f8\u673a\u57df\u6027\u80fd\u5747\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\uff0c\u5c55\u73b0\u591a\u6a21\u6001\u4f18\u52bf\u3002  \n\u25c6 \u5f00\u6e90\u4ee3\u7801\u63a8\u52a8\u76f8\u5173\u7814\u7a76\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u63d0\u4f9b\u53ef\u590d\u7528\u7684\u65b0\u578b\u795e\u7ecf\u6e32\u67d3\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2506.19291": "|2025-06-24|HoliGS: Holistic Gaussian Splatting for Embodied View Synthesis|Xiaoyuan Wang\u7b49|[2506.19291](http://arxiv.org/pdf/2506.19291)|\u65e0|\u25c6 \u63d0\u51faHoliGS\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u53ef\u53d8\u5f62\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u5e94\u7528\u4e8e\u957f\u65f6\u5e8f\u5355\u76eeRGB\u89c6\u9891\u7684\u6c89\u6d78\u5f0f\u89c6\u89d2\u5408\u6210\u4efb\u52a1\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf4D\u9ad8\u65af\u6cfc\u6e85\u548c\u52a8\u6001NeRF\u5728\u5206\u949f\u7ea7\u89c6\u9891\u4e2d\u8bad\u7ec3\u5f00\u9500\u8fc7\u5927\u7684\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u5206\u5c42\u53d8\u5f62\u7b56\u7565\uff0c\u5c06\u573a\u666f\u5206\u89e3\u4e3a\u9759\u6001\u80cc\u666f\u548c\u52a8\u6001\u7269\u4f53\uff0c\u5176\u4e2d\u52a8\u6001\u90e8\u5206\u901a\u8fc7\u53ef\u9006\u795e\u7ecf\u6d41\u5b9e\u73b0\u5168\u5c40\u521a\u6027\u53d8\u6362\u3001\u9aa8\u9abc\u9a71\u52a8\u5f62\u53d8\u548c\u7ec6\u5fae\u975e\u521a\u6027\u5f62\u53d8\u7684\u7edf\u4e00\u5efa\u6a21\u3002  \n\u25c6 \u901a\u8fc7\u5c06\u9ad8\u65af\u57fa\u5143\u7ed1\u5b9a\u5230\u5b8c\u6574\u7684\u524d\u666f\u89c4\u8303\u5f62\u72b6\uff08\u5982\u7b2c\u4e00\u4eba\u79f0\u6216\u8ddf\u968f\u89c6\u89d2\uff09\uff0c\u652f\u6301\u591a\u6f14\u5458\u4ea4\u4e92\u548c\u5927\u89c6\u89d2\u53d8\u5316\u7684\u81ea\u7531\u89c6\u70b9\u6e32\u67d3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u52a8\u6001\u573a\u666f\u7684\u91cd\u5efa\u9c81\u68d2\u6027\u3002  \n\u25c6 \u63d0\u51fa\u53ef\u9006\u9ad8\u65af\u53d8\u5f62\u7f51\u7edc\uff0c\u5728\u4fdd\u6301\u9ad8\u4fdd\u771f\u91cd\u5efa\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u76f8\u6bd4\u73b0\u6709\u5355\u76ee\u53ef\u53d8\u5f62NeRF\u65b9\u6cd5\u5927\u5e45\u964d\u4f4e\u8bad\u7ec3\u548c\u6e32\u67d3\u65f6\u95f4\uff0c\u5b9e\u73b0\u4e86\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u9ad8\u6548\u90e8\u7f72\u3002  \n\u25c6 \u5728\u6311\u6218\u6027\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u91cd\u5efa\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u5f53\u524d\u6700\u4f18\u6280\u672f\uff0c\u4e3a\u6c89\u6d78\u5f0f\u89c6\u89d2\u5408\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2506.20638": "|2025-06-25|Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects|Cl\u00e9ment Forray\u7b49|[2506.20638](http://arxiv.org/pdf/2506.20638)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u4f18\u5316\u65b9\u6cd5\uff0c\u540c\u65f6\u4f30\u8ba1\u975e\u5408\u4f5c\u7a7a\u95f4\u7269\u4f53\u7684\u59ff\u6001\uff08\u76f8\u673a\u4f4d\u59ff\uff09\u5e76\u5229\u7528\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u8fdb\u884c3D\u91cd\u5efa\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u672a\u77e5\u7269\u4f53\u59ff\u6001\u4e0b\u7684\u91cd\u5efa\u96be\u9898\u3002  \n\u25c6 \u9488\u5bf9\u7a7a\u95f4\u573a\u666f\u7684\u7279\u6b8a\u6311\u6218\uff08\u5982\u5355\u8272\u56fe\u50cf\u3001\u672a\u77e5\u7269\u4f53\u65b9\u5411\u3001\u6709\u9650\u89c6\u89d2\u3001\u65e0\u6f2b\u53cd\u5c04\u5149\u7167\u7b49\uff09\uff0c\u6539\u8fdb\u4e86NeRF\u7684\u9002\u5e94\u6027\uff0c\u4f7f\u5176\u5728\u6781\u7aef\u6761\u4ef6\u4e0b\u4ecd\u80fd\u6709\u6548\u5de5\u4f5c\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\uff0c\u91c7\u7528\u9010\u5e27\u987a\u5e8f\u8bad\u7ec3\u56fe\u50cf\u7684\u65b9\u5f0f\uff08\u800c\u975e\u6279\u91cf\u8bad\u7ec3\uff09\u80fd\u663e\u8457\u63d0\u53473D\u91cd\u5efa\u7684\u7cbe\u5ea6\uff0c\u4e3a\u52a8\u6001\u7a7a\u95f4\u7269\u4f53\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002  \n\u25c6 \u901a\u8fc7\u4f18\u5316\u5747\u5300\u65cb\u8f6c\u53c2\u6570\u4f30\u8ba1\u76f8\u673a\u59ff\u6001\uff0c\u5e76\u5f15\u5165\u6b63\u5219\u5316\u7ea6\u675f\u76f8\u90bb\u59ff\u6001\u7684\u8fde\u7eed\u6027\uff0c\u907f\u514d\u4e86\u4f4d\u59ff\u4f30\u8ba1\u7684\u7a81\u53d8\u95ee\u9898\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u4e3a\u7a7a\u95f4\u6001\u52bf\u611f\u77e5\uff08SSA\uff09\u4efb\u52a1\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u76843D\u6a21\u578b\uff0c\u53ef\u5e94\u7528\u4e8e\u4e3b\u52a8\u788e\u7247\u6e05\u9664\u3001\u5728\u8f68\u7ef4\u62a4\u7b49\u5b9e\u9645\u573a\u666f\u3002|\n",
    "2506.21348": "|2025-06-26|PanSt3R: Multi-view Consistent Panoptic Segmentation|Lojze Zust\u7b49|[2506.21348](http://arxiv.org/pdf/2506.21348)|\u65e0|\u25c6 \u63d0\u51faPanSt3R\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u65e0\u9700\u6d4b\u8bd5\u65f6\u4f18\u5316\u7684\u5355\u6b21\u524d\u5411\u9884\u6d4b\uff0c\u76f4\u63a5\u8054\u5408\u8f93\u51fa3D\u51e0\u4f55\u548c\u591a\u89c6\u89d2\u5168\u666f\u5206\u5272\u7ed3\u679c\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u3002  \n\u25c6 \u57fa\u4e8eMUSt3R\u6846\u67b6\u6539\u8fdb\uff0c\u5f15\u5165\u8bed\u4e49\u611f\u77e5\u80fd\u529b\uff0c\u5c063D\u91cd\u5efa\u4e0e\u591a\u89c6\u89d2\u5168\u666f\u5206\u5272\u4efb\u52a1\u7edf\u4e00\u6574\u5408\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d562D\u9884\u5206\u5272\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u91cd\u65b0\u8bbe\u8ba1\u63a9\u7801\u540e\u5904\u7406\u6d41\u7a0b\uff0c\u63d0\u51fa\u66f4\u7406\u8bba\u5316\u7684\u591a\u89c6\u89d2\u5206\u5272\u878d\u5408\u7b56\u7565\uff0c\u4f18\u5316\u8de8\u89c6\u89d2\u7a7a\u95f4\u5173\u7cfb\u5229\u7528\u3002  \n\u25c6 \u7ed3\u54083D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u6280\u672f\uff0c\u63d0\u51fa\u7b80\u5355\u6709\u6548\u7684\u65b0\u89c6\u89d2\u751f\u6210\u65b9\u6cd5\uff0c\u6269\u5c55\u6a21\u578b\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u901f\u5ea6\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u517c\u5177\u6982\u5ff5\u7b80\u6d01\u6027\u4e0e\u8ba1\u7b97\u9ad8\u6548\u6027\u3002|\n",
    "2506.21884": "|2025-06-27|UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields|Fabian Perez\u7b49|[2506.21884](http://arxiv.org/pdf/2506.21884)|\u65e0|\u25c6 \u9996\u6b21\u5c06\u5149\u8c31\u89e3\u6df7\u6280\u672f\u878d\u5165\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\uff0c\u5b9e\u73b0\u8054\u5408\u9ad8\u5149\u8c31\u65b0\u89c6\u89d2\u5408\u6210\u4e0e\u65e0\u76d1\u7763\u6750\u8d28\u5206\u5272\uff0c\u7a81\u7834\u4f20\u7edfNeRF\u4ec5\u4f9d\u8d56RGB\u6570\u636e\u7684\u5c40\u9650\u3002  \n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u6f2b\u53cd\u5c04\u548c\u955c\u9762\u53cd\u5c04\u5206\u91cf\u7684\u5149\u8c31\u53cd\u5c04\u7387\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u5168\u5c40\u7aef\u5143\u5b57\u5178\u5b66\u4e60\u7eaf\u6750\u8d28\u7279\u5f81\uff0c\u7ed3\u5408\u9010\u70b9\u4e30\u5ea6\u5206\u5e03\u5b9e\u73b0\u6750\u8d28\u7cbe\u51c6\u8868\u8fbe\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u7528\u5b66\u4e60\u5230\u7684\u7aef\u5143\u5149\u8c31\u7279\u5f81\u8fdb\u884c\u65e0\u76d1\u7763\u6750\u8d28\u805a\u7c7b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u5b8c\u6210\u573a\u666f\u6750\u8d28\u5206\u5272\u3002  \n\u25c6 \u652f\u6301\u901a\u8fc7\u4fee\u6539\u7aef\u5143\u5b57\u5178\u5b9e\u73b0\u573a\u666f\u6750\u8d28\u7f16\u8f91\uff0c\u4e3a\u57fa\u4e8e\u6750\u8d28\u7684\u7075\u6d3b\u5916\u89c2\u64cd\u63a7\uff08\u5982\u865a\u62df\u4eff\u771f\u3001AR\u5e94\u7528\uff09\u63d0\u4f9b\u65b0\u5de5\u5177\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u9ad8\u5149\u8c31\u91cd\u5efa\u548c\u6750\u8d28\u5206\u5272\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u4e3a\u673a\u5668\u4eba\u611f\u77e5\u3001\u865a\u62df\u73b0\u5b9e\u7b49\u9700\u7cbe\u786e\u6750\u8d28\u5efa\u6a21\u7684\u9886\u57df\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2506.21629": "|2025-06-24|ICP-3DGS: SfM-free 3D Gaussian Splatting for Large-scale Unbounded Scenes|Chenhao Zhang\u7b49|[2506.21629](http://arxiv.org/pdf/2506.21629)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700SfM\u9884\u5904\u7406\u7684\u65b9\u6cd5ICP-3DGS\uff0c\u901a\u8fc7\u7ed3\u5408\u8fed\u4ee3\u6700\u8fd1\u70b9\uff08ICP\uff09\u548c\u57fa\u4e8e\u4f18\u5316\u7684\u4f4d\u59ff\u7ec6\u5316\uff0c\u5b9e\u73b0\u4e86\u5927\u8303\u56f4\u76f8\u673a\u8fd0\u52a8\u4e0b\u7684\u9ad8\u7cbe\u5ea6\u4f4d\u59ff\u4f30\u8ba1\u3002  \n\u25c6 \u5f15\u5165\u57fa\u4e8e\u4f53\u7d20\u7684\u573a\u666f\u81f4\u5bc6\u5316\u7b56\u7565\uff0c\u6709\u6548\u6307\u5bfc\u5927\u89c4\u6a21\u65e0\u8fb9\u754c\u573a\u666f\u76843D\u9ad8\u65af\u5206\u5e03\u91cd\u5efa\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u6237\u5916\u573a\u666f\u4e2d\u7684\u6269\u5c55\u6027\u95ee\u9898\u3002  \n\u25c6 \u9996\u6b21\u5c06ICP\u4e0e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u6280\u672f\u7ed3\u5408\uff0c\u5728\u795e\u7ecf\u6e32\u67d3\u6846\u67b6\u4e2d\u76f4\u63a5\u4f18\u5316\u76f8\u673a\u4f4d\u59ff\uff0c\u6446\u8131\u4e86\u5bf9SfM\u5148\u9a8c\u6570\u636e\u7684\u4f9d\u8d56\u3002  \n\u25c6 \u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u5ba4\u5185\u5916\u4e0d\u540c\u5c3a\u5ea6\u573a\u666f\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u540c\u65f6\u5728\u76f8\u673a\u4f4d\u59ff\u4f30\u8ba1\u548c\u65b0\u89c6\u89d2\u5408\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u4f18\u3002  \n\u25c6 \u5f00\u6e90\u4e86\u5b8c\u6574\u4ee3\u7801\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u57fa\u7840\uff0c\u63a8\u52a8\u4e86\u65e0\u7ea6\u675f\u573a\u666f\u795e\u7ecf\u6e32\u67d3\u7684\u5b9e\u7528\u5316\u8fdb\u7a0b\u3002|\n",
    "2506.23611": "|2025-06-30|AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention|Ziao Liu\u7b49|[2506.23611](http://arxiv.org/pdf/2506.23611)|\u65e0|\u25c6 \u63d0\u51faAttentionGS\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u65e0\u9700\u9ad8\u8d28\u91cf\u521d\u59cb\u70b9\u4e91\u76843D\u9ad8\u65af\u6cfc\u6e85\u91cd\u5efa\uff0c\u7a81\u7834\u4f20\u7edf3DGS\u5bf9SfM\u70b9\u4e91\u7684\u5f3a\u4f9d\u8d56\u3002  \n\u25c6 \u521b\u65b0\u6027\u5f15\u5165\u4e24\u9636\u6bb5\u6ce8\u610f\u529b\u673a\u5236\uff1a\u51e0\u4f55\u6ce8\u610f\u529b\u5feb\u901f\u6062\u590d\u573a\u666f\u5168\u5c40\u7ed3\u6784\uff0c\u7eb9\u7406\u6ce8\u610f\u529b\u540e\u671f\u4f18\u5316\u7ec6\u7c92\u5ea6\u7ec6\u8282\uff0c\u5b9e\u73b0\u4ece\u968f\u673a\u521d\u59cb\u5316\u76f4\u63a5\u91cd\u5efa\u3002  \n\u25c6 \u8bbe\u8ba1\u4e0d\u900f\u660e\u5ea6\u52a0\u6743\u68af\u5ea6\u7b56\u7565\uff0c\u6539\u8fdb\u9ad8\u65af\u5206\u5e03\u81f4\u5bc6\u5316\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u8868\u9762\u91cd\u5efa\u8d28\u91cf\u3002  \n\u25c6 \u5728\u7eb9\u7406\u7f3a\u5931\u548c\u53d7\u9650\u89c6\u89d2\u7b49\u6781\u7aef\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u91cd\u5efa\u8d28\u91cf\u63d0\u5347\u663e\u8457\u3002  \n\u25c6 \u901a\u8fc7\u591a\u57fa\u51c6\u6570\u636e\u96c6\u9a8c\u8bc1\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u66f4\u9c81\u68d2\u76843D\u91cd\u5efa\u63d0\u4f9b\u65b0\u601d\u8def\uff0c\u6269\u5c55\u4e863DGS\u7684\u5e94\u7528\u8fb9\u754c\u3002|\n",
    "2506.23153": "|2025-06-29|Dynamic View Synthesis from Small Camera Motion Videos|Huiqiang Sun\u7b49|[2506.23153](http://arxiv.org/pdf/2506.23153)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u9488\u5bf9\u52a8\u60013D\u573a\u666f\u5728\u5c0f\u8303\u56f4\u76f8\u673a\u8fd0\u52a8\u4e0b\u7684\u65b0\u89c6\u89d2\u5408\u6210\u95ee\u9898\u63d0\u51fa\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\uff0c\u6838\u5fc3\u8d21\u732e\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u5206\u5e03\u7684\u6df1\u5ea6\u6b63\u5219\u5316\u65b9\u6cd5(DDR)\uff0c\u901a\u8fc7Gumbel-softmax\u4ece\u79bb\u6563\u6e32\u67d3\u6743\u91cd\u5206\u5e03\u4e2d\u53ef\u5fae\u5206\u91c7\u6837\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6df1\u5ea6\u635f\u5931\u4ec5\u8ba1\u7b97\u671f\u671b\u8bef\u5dee\u7684\u5c40\u9650\u6027\u3002\n\n\u25c6 \u5f15\u5165\u7269\u4f53\u8fb9\u754c\u524d\u7a7a\u95f4\u70b9\u4f53\u79ef\u5bc6\u5ea6\u8d8b\u8fd1\u96f6\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u786e\u4fdd\u573a\u666f\u51e0\u4f55\u7ed3\u6784\u7684\u6b63\u786e\u5b66\u4e60\uff0c\u6709\u6548\u6539\u5584\u4e86\u5c0f\u76f8\u673a\u8fd0\u52a8\u4e0b\u7684\u51e0\u4f55\u8868\u793a\u95ee\u9898\u3002\n\n\u25c6 \u5f00\u53d1\u4e86\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u53ef\u76f4\u63a5\u5728\u6e32\u67d3\u6743\u91cd\u5c42\u9762\u89c2\u5bdf\u573a\u666f\u51e0\u4f55\u8868\u793a\uff0c\u4e3a\u65b9\u6cd5\u539f\u7406\u63d0\u4f9b\u4e86\u76f4\u89c2\u89e3\u91ca\u3002\n\n\u25c6 \u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u52a0\u5165\u76f8\u673a\u53c2\u6570\u5b66\u4e60\u673a\u5236\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u76f8\u673a\u53c2\u6570\u7684\u9c81\u68d2\u6027\uff0c\u89e3\u51b3\u4e86\u5c0f\u8fd0\u52a8\u4e0b\u76f8\u673a\u53c2\u6570\u4f30\u8ba1\u4e0d\u51c6\u7684\u95ee\u9898\u3002\n\n\u8bba\u6587\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5c0f\u8303\u56f4\u76f8\u673a\u8fd0\u52a8\u8f93\u5165\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u4e3a\u52a8\u6001\u573a\u666f\u65b0\u89c6\u89d2\u5408\u6210\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.01631": "|2025-07-02|Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation|Camille Billouard\u7b49|[2507.01631](http://arxiv.org/pdf/2507.01631)|\u65e0|\u25c6 \u63d0\u51faSnake-NeRF\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u5355\u8bbe\u5907\u4e0a\u5927\u89c4\u6a21\u536b\u661f\u5f71\u50cf\u7684NeRF\u4e09\u7ef4\u91cd\u5efa\uff0c\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u53d7\u9650\u4e8e\u5185\u5b58\u7684\u5c0f\u573a\u666f\u7ea6\u675f\u3002  \n\u25c6 \u8bbe\u8ba1\u5916\u5b58\uff08out-of-core\uff09\u8bad\u7ec3\u65b9\u6cd5\uff0c\u65e0\u9700\u540c\u65f6\u52a0\u8f7d\u6240\u6709\u56fe\u50cf\u548c\u7f51\u7edc\uff0c\u663e\u8457\u964d\u4f4e\u786c\u4ef6\u9700\u6c42\u3002  \n\u25c6 \u521b\u65b0\u6027\u91c7\u7528\u65e0\u91cd\u53e0\u4e09\u7ef4\u5206\u5757\uff083D tile\uff09\u7b56\u7565\uff0c\u5c06\u76ee\u6807\u533a\u57df\u5212\u5206\u4e3a\u72ec\u7acb\u8bad\u7ec3\u7684NeRF\u5b50\u6a21\u5757\u3002  \n\u25c6 \u63d0\u51fa\u91cd\u53e0\u88c1\u526a\u56fe\u50cf\u6280\u672f\uff0c\u786e\u4fdd\u6bcf\u4e2a\u5b50\u6a21\u5757\u8bad\u7ec3\u65f6\u83b7\u53d6\u5b8c\u6574\u5fc5\u8981\u50cf\u7d20\uff0c\u907f\u514d\u8fb9\u754c\u4fe1\u606f\u7f3a\u5931\u3002  \n\u25c6 \u5f00\u53d12\u00d72\u4e09\u7ef4\u5206\u5757\u9012\u8fdb\u7b56\u7565\u4e0e\u5206\u6bb5\u91c7\u6837\u5668\uff0c\u6709\u6548\u6d88\u9664\u5206\u5757\u8fb9\u7f18\u7684\u4e09\u7ef4\u91cd\u5efa\u8bef\u5dee\u3002  \n\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u5355GPU\u4e0a\u5b9e\u73b0\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u4e14\u4e0d\u635f\u5931\u91cd\u5efa\u8d28\u91cf\uff0c\u4e3a\u5168\u7403\u5c3a\u5ea6\u5730\u7403\u89c2\u6d4b\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002|\n",
    "2507.00969": "|2025-07-01|Surgical Neural Radiance Fields from One Image|Alberto Neri\u7b49|[2507.00969](http://arxiv.org/pdf/2507.00969)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5355\u5f20\u672f\u4e2d\u56fe\u50cf\u548c\u672f\u524dMRI\u6570\u636e\u8bad\u7ec3\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u624b\u672f\u573a\u666f\u4e2d\u591a\u89c6\u89d2\u6570\u636e\u4e0d\u8db3\u7684\u9650\u5236\u3002  \n\u25c6 \u5229\u7528\u672f\u524dMRI\u6570\u636e\u9884\u5148\u5b9a\u4e49\u76f8\u673a\u89c6\u89d2\u548c\u56fe\u50cf\u96c6\uff0c\u7ed3\u5408\u795e\u7ecf\u98ce\u683c\u8fc1\u79fb\u6280\u672f\uff08WTC2\u548cSTROTSS\uff09\u5c06\u672f\u4e2d\u56fe\u50cf\u5916\u89c2\u8fc1\u79fb\u81f3\u9884\u6784\u5efa\u6570\u636e\u96c6\uff0c\u907f\u514d\u8fc7\u5ea6\u98ce\u683c\u5316\u3002  \n\u25c6 \u5b9e\u73b0\u4e86\u5feb\u901f\u5355\u56fe\u50cfNeRF\u8bad\u7ec3\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u672f\u4e2d\u6570\u636e\u91c7\u96c6\u7684\u65f6\u95f4\u6210\u672c\uff0c\u63d0\u5347\u4e86\u4e34\u5e8a\u5b9e\u7528\u6027\u3002  \n\u25c6 \u5728\u56db\u4f8b\u795e\u7ecf\u5916\u79d1\u624b\u672f\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5b9a\u91cf\u5bf9\u6bd4\u663e\u793a\u5176\u5408\u6210\u7ed3\u679c\u4e0e\u771f\u5b9e\u624b\u672f\u663e\u5fae\u955c\u56fe\u50cf\u9ad8\u5ea6\u4e00\u81f4\u3002  \n\u25c6 \u91cd\u5efa\u7ed3\u679c\u4e0e\u771f\u5b9e\u6570\u636e\u76f8\u6bd4\u5177\u6709\u9ad8\u7ed3\u6784\u76f8\u4f3c\u6027\uff0c\u8bc1\u660e\u4e86\u826f\u597d\u7684\u91cd\u5efa\u8d28\u91cf\u548c\u7eb9\u7406\u4fdd\u7559\u80fd\u529b\u3002  \n\u25c6 \u4e3a\u624b\u672f\u573a\u666f\u4e2d\u7684\u5b9e\u65f63D\u91cd\u5efa\u548c\u89c6\u89d2\u5408\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u591a\u89c6\u89d2\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002|\n",
    "2507.00371": "|2025-07-01|PlantSegNeRF: A few-shot, cross-dataset method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching|Xin Yang\u7b49|[2507.00371](http://arxiv.org/pdf/2507.00371)|\u65e0|\u25c6\u63d0\u51faPlantSegNeRF\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u4ece\u591a\u89c6\u89d2RGB\u56fe\u50cf\u5e8f\u5217\u76f4\u63a5\u751f\u6210\u9ad8\u7cbe\u5ea6\u690d\u7269\u5668\u5b98\u5b9e\u4f8b\u70b9\u4e91\uff0c\u7a81\u7834\u4f20\u7edf\u70b9\u4e91\u5206\u5272\u6280\u672f\u7684\u5c40\u9650\u6027\u3002  \n\u25c6\u5f00\u53d1\u8054\u5408\u901a\u9053NeRF\u6a21\u578b\uff0c\u540c\u65f6\u6e32\u67d3\u989c\u8272\u3001\u5bc6\u5ea6\u3001\u8bed\u4e49\u548c\u5b9e\u4f8b\u4fe1\u606f\uff0c\u6784\u5efa\u5305\u542b\u591a\u7ef4\u5ea6\u7279\u5f81\u7684\u9690\u5f0f\u573a\u666f\u8868\u793a\u3002  \n\u25c6\u8bbe\u8ba1\u521b\u65b0\u7684\u591a\u89c6\u89d2\u5b9e\u4f8b\u5339\u914d\u6a21\u5757\uff0c\u901a\u8fc72D\u5b9e\u4f8b\u5206\u5272\u7ed3\u679c\u8de8\u89c6\u56fe\u5173\u8054\u540c\u4e00\u5668\u5b98\u7684\u5b9e\u4f8bID\uff0c\u89e3\u51b3\u590d\u6742\u690d\u7269\u7ed3\u6784\u7684\u5bf9\u5e94\u96be\u9898\u3002  \n\u25c6\u5728\u8bed\u4e49\u5206\u5272\u4efb\u52a1\u4e2d\uff0c\u5173\u952e\u6307\u6807\uff08\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u7b49\uff09\u5e73\u5747\u63d0\u534716.1%-24.2%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u3002  \n\u25c6\u5728\u5b9e\u4f8b\u5206\u5272\u4efb\u52a1\u4e2d\uff0c\u56db\u9879\u6838\u5fc3\u6307\u6807\uff08mPrec\u7b49\uff09\u6700\u9ad8\u63d0\u5347\u8fbe38.2%\uff0c\u5b9e\u73b0\u8de8\u7269\u79cd\u7684\u9ad8\u6cdb\u5316\u6027\u8868\u73b0\u3002  \n\u25c6\u4e3a\u690d\u7269\u8868\u578b\u7814\u7a76\u63d0\u4f9b\u9ad8\u901a\u91cf\u4e09\u7ef4\u6570\u636e\u751f\u6210\u65b9\u6848\uff0c\u652f\u6301\u5927\u89c4\u6a21\u690d\u7269\u6a21\u578b\u5f00\u53d1\u3002|\n",
    "2507.04408": "|2025-07-06|A View-consistent Sampling Method for Regularized Training of Neural Radiance Fields|Aoxiang Fan\u7b49|[2507.04408](http://arxiv.org/pdf/2507.04408)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u89c6\u89d2\u4e00\u81f4\u5206\u5e03\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u66ff\u4ee3\u4f20\u7edf\u56fa\u5b9a\u6df1\u5ea6\u503c\u4f30\u8ba1\uff0c\u7528\u4e8eNeRF\u7684\u6b63\u5219\u5316\u8bad\u7ec3\u3002  \n\u25c6 \u5229\u7528\u4f4e\u5c42\u989c\u8272\u7279\u5f81\u548c\u57fa\u7840\u6a21\u578b\u63d0\u53d6\u7684\u9ad8\u5c42\u7279\u5f81\uff0c\u6784\u5efa3D\u91c7\u6837\u70b9\u57282D\u6295\u5f71\u4f4d\u7f6e\u7684\u89c6\u89d2\u4e00\u81f4\u6027\u5206\u5e03\u3002  \n\u25c6 \u901a\u8fc7\u4ece\u89c6\u89d2\u4e00\u81f4\u6027\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u5b9e\u73b0\u5bf9NeRF\u8bad\u7ec3\u7684\u9690\u5f0f\u6b63\u5219\u5316\uff0c\u907f\u514d\u4f9d\u8d56\u8bef\u5dee\u8f83\u5927\u7684\u6df1\u5ea6\u4f30\u8ba1\u3002  \n\u25c6 \u7ed3\u5408\u6df1\u5ea6\u63a8\u8fdb\u635f\u5931\uff08depth-pushing loss\uff09\u4e0e\u91c7\u6837\u6280\u672f\uff0c\u5171\u540c\u6d88\u9664\u8bad\u7ec3\u4e2d\u7684\u5931\u8d25\u6a21\u5f0f\u3002  \n\u25c6 \u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709NeRF\u53d8\u4f53\u548c\u6df1\u5ea6\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6237\u5916\u65e0\u754c\u573a\u666f\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u4f20\u7edf\u6df1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u9700\u8981\u6602\u8d353D\u76d1\u7763\u548c\u6cdb\u5316\u6027\u5dee\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u771f\u5b9e\u573a\u666f\u4e0b\u76843D\u91cd\u5efa\u8d28\u91cf\u3002|\n",
    "2507.06103": "|2025-07-08|Reflections Unlock: Geometry-Aware Reflection Disentanglement in 3D Gaussian Splatting for Photorealistic Scenes Rendering|Jiayi Song\u7b49|[2507.06103](http://arxiv.org/pdf/2507.06103)|\u65e0|\u25c6 \u63d0\u51faRef-Unlock\u6846\u67b6\uff0c\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u5b9e\u73b0\u51e0\u4f55\u611f\u77e5\u7684\u53cd\u5c04\u5206\u79bb\uff0c\u9996\u6b21\u57283DGS\u4e2d\u663e\u5f0f\u89e3\u8026\u900f\u5c04\u4e0e\u53cd\u5c04\u6210\u5206\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5c06\u53cd\u5c04\u8bef\u5224\u4e3a\u51e0\u4f55\u7ed3\u6784\u7684\u95ee\u9898\u3002  \n\u25c6 \u91c7\u7528\u53cc\u5206\u652f\u8868\u793a\u7ed3\u5408\u9ad8\u9636\u7403\u8c10\u51fd\u6570\uff0c\u6709\u6548\u6355\u6349\u9ad8\u9891\u53cd\u5c04\u7ec6\u8282\uff0c\u540c\u65f6\u901a\u8fc7\u53cd\u5c04\u79fb\u9664\u6a21\u5757\u63d0\u4f9b\u4f2a\u65e0\u53cd\u5c04\u76d1\u7763\u4fe1\u53f7\uff0c\u5b9e\u73b0\u66f4\u5e72\u51c0\u7684\u53cd\u5c04\u5206\u89e3\u3002  \n\u25c6 \u5f15\u5165\u4f2a\u6df1\u5ea6\u56fe\u4e0e\u51e0\u4f55\u611f\u77e5\u7684\u53cc\u8fb9\u5e73\u6ed1\u7ea6\u675f\uff0c\u589e\u5f3a3D\u51e0\u4f55\u4e00\u81f4\u6027\u548c\u5206\u89e3\u7a33\u5b9a\u6027\uff0c\u663e\u8457\u51cf\u5c11\u590d\u6742\u573a\u666f\u4e0b\u7684\u8868\u9762\u4f2a\u5f71\u4e0e\u6a21\u7cca\u91cd\u5efa\u3002  \n\u25c6 \u652f\u6301\u57fa\u4e8e\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff08VFMs\uff09\u7684\u7075\u6d3b\u53cd\u5c04\u7f16\u8f91\u529f\u80fd\uff0c\u6269\u5c55\u4e86\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u64cd\u4f5c\u6027\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5927\u5e45\u8d85\u8d8a\u4f20\u7edf\u57fa\u4e8eGS\u7684\u53cd\u5c04\u5904\u7406\u65b9\u6cd5\uff0c\u5e76\u4e0eNeRF\u7c7b\u6a21\u578b\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u4fdd\u6301\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u4e3a\u542b\u53cd\u5c04\u573a\u666f\u7684\u5149\u7167\u771f\u5b9e\u6e32\u67d3\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u6cdb\u5316\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002|\n",
    "2507.05763": "|2025-07-08|DreamArt: Generating Interactable Articulated Objects from a Single Image|Ruijie Lu\u7b49|[2507.05763](http://arxiv.org/pdf/2507.05763)|\u65e0|\u25c6 DreamArt\u9996\u6b21\u63d0\u51fa\u4ece\u5355\u5f20\u56fe\u50cf\u751f\u6210\u53ef\u4ea4\u4e92\u7684\u5173\u8282\u53163D\u7269\u4f53\u7684\u5b8c\u6574\u6846\u67b6\uff0c\u586b\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u90e8\u4ef6\u5206\u89e3\u548c\u5173\u8282\u5efa\u6a21\u65b9\u9762\u7684\u7a7a\u767d\u3002  \n\u25c6 \u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\u521b\u65b0\uff1a\u7ed3\u5408\u56fe\u50cf\u751f\u62103D\u3001\u63a9\u7801\u63d0\u793a\u7684\u90e8\u4ef6\u5206\u5272\u4e0e\u4fee\u590d\uff0c\u89e3\u51b3\u4e86\u5355\u89c6\u89d2\u4e0b\u90e8\u4ef6\u5f62\u72b6\u4e0d\u5b8c\u6574\u7684\u95ee\u9898\u3002  \n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u89c6\u9891\u6269\u6563\u6a21\u578b\u7684\u5173\u8282\u8fd0\u52a8\u5148\u9a8c\u5b66\u4e60\uff0c\u5229\u7528\u90e8\u4ef6\u906e\u7f69\u548c\u4fee\u590d\u56fe\u50cf\u6d88\u9664\u906e\u6321\u6b67\u4e49\uff0c\u5b9e\u73b0\u903c\u771f\u5173\u8282\u8fd0\u52a8\u751f\u6210\u3002  \n\u25c6 \u91c7\u7528\u53cc\u56db\u5143\u6570\u8868\u793a\u5173\u8282\u8fd0\u52a8\u53c2\u6570\uff0c\u914d\u5408\u5168\u5c40\u7eb9\u7406\u4f18\u5316\uff0c\u786e\u4fdd\u591a\u90e8\u4ef6\u7eb9\u7406\u4e00\u81f4\u6027\u4e0e\u9ad8\u8d28\u91cf\u6e32\u67d3\u6548\u679c\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u90e8\u4ef6\u5f62\u72b6\u51c6\u786e\u3001\u5916\u89c2\u903c\u771f\u4e14\u5173\u8282\u8fd0\u52a8\u5408\u7406\u76843D\u8d44\u4ea7\uff0c\u4e3aAR/VR\u548c\u5177\u8eabAI\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2507.06269": "|2025-07-14|BayesSDF: Surface-Based Laplacian Uncertainty Estimation for 3D Geometry with Neural Signed Distance Fields|Rushil Desai|[2507.06269](http://arxiv.org/pdf/2507.06269)|\u65e0|\u25c6 \u63d0\u51faBayesSDF\uff0c\u9996\u4e2a\u9488\u5bf9\u795e\u7ecf\u9690\u5f0fSDF\u6a21\u578b\u7684\u6982\u7387\u6846\u67b6\uff0c\u89e3\u51b33D\u51e0\u4f55\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u95ee\u9898\uff0c\u7279\u522b\u9002\u7528\u4e8e\u79d1\u5b66\u6a21\u62df\uff08\u5982\u68ee\u6797\u6d41\u4f53\u5efa\u6a21\uff09\u3002  \n\u25c6 \u901a\u8fc7\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u548c\u57fa\u4e8eHessian\u7684\u5c40\u90e8\u8868\u9762\u7a33\u5b9a\u6027\u5ea6\u91cf\uff0c\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u4e14\u51e0\u4f55\u611f\u77e5\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002  \n\u25c6 \u9996\u6b21\u5c06\u51e0\u4f55\u4e00\u81f4\u6027\u76f4\u63a5\u878d\u5165\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u751f\u6210\u4e0e\u91cd\u5efa\u8bef\u5dee\u9ad8\u5ea6\u76f8\u5173\u7684\u6821\u51c6\u5316\u7f6e\u4fe1\u5ea6\u5730\u56fe\uff0c\u4f18\u4e8e\u5ffd\u7565\u51e0\u4f55\u7684\u73b0\u6709\u65b9\u6cd5\u3002  \n\u25c6 \u8bc1\u660eSDF\u7684\u8fde\u7eed\u53ef\u5fae\u51e0\u4f55\u7279\u6027\u6bd4\u8f90\u5c04\u573a\u6a21\u578b\uff08\u5982NeRF\uff09\u66f4\u9002\u5408\u7269\u7406\u6a21\u62df\uff0c\u4e3a\u4e0b\u6e38\u4efb\u52a1\uff08\u5982\u673a\u5668\u4eba\u51b3\u7b56\uff09\u63d0\u4f9b\u53ef\u9760\u51e0\u4f55\u57fa\u7840\u3002  \n\u25c6 \u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\uff0c\u5176\u4e0d\u786e\u5b9a\u6027\u9884\u6d4b\u4e0e\u91cd\u5efa\u7f3a\u9677\u9ad8\u5ea6\u543b\u5408\uff0c\u6821\u51c6\u6027\u548c\u51e0\u4f55\u4e00\u81f4\u6027\u5747\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u3002|\n",
    "2507.07519": "|2025-07-10|MUVOD: A Novel Multi-view Video Object Segmentation Dataset and A Benchmark for 3D Segmentation|Bangning Wei\u7b49|[2507.07519](http://arxiv.org/pdf/2507.07519)|\u65e0|\u25c6 \u63d0\u51fa\u4e86MUVOD\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u52a8\u6001\u573a\u666f4D\u76ee\u6807\u5206\u5272\u7684\u5927\u89c4\u6a21\u591a\u89c6\u89d2\u89c6\u9891\u6570\u636e\u96c6\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u6570\u636e\u96c6\u7684\u7a7a\u767d\u3002  \n\u25c6 \u6570\u636e\u96c6\u5305\u542b17\u4e2a\u771f\u5b9e\u573a\u666f\uff0c\u6db5\u76d6\u5ba4\u5185\u5916\u591a\u79cd\u6d3b\u52a8\uff0c\u63d0\u4f9b7830\u5f20RGB\u56fe\u50cf\u53ca\u5bf9\u5e94\u76844D\u8fd0\u52a8\u5206\u5272\u63a9\u7801\uff0c\u652f\u6301\u8de8\u89c6\u89d2\u548c\u8de8\u5e27\u7684\u76ee\u6807\u8ddf\u8e2a\u3002  \n\u25c6 \u6570\u636e\u96c6\u4e2d\u5305\u542b459\u4e2a\u5b9e\u4f8b\uff0c\u8986\u76d673\u4e2a\u7c7b\u522b\uff0c\u4e3a\u591a\u89c6\u89d2\u89c6\u9891\u5206\u5272\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u548c\u57fa\u7ebf\u5206\u5272\u65b9\u6cd5\uff0c\u4e3a\u52a8\u6001\u573a\u666f\u5206\u5272\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u3002  \n\u25c6 \u57fa\u4e8eMUVOD\u6570\u636e\u96c6\u6784\u5efa\u4e863D\u76ee\u6807\u5206\u5272\u5b50\u96c6\uff0c\u5305\u542b50\u4e2a\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u6807\u6ce8\u5bf9\u8c61\uff0c\u7528\u4e8e\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u73b0\u67093D\u5206\u5272\u65b9\u6cd5\u7684\u6027\u80fd\u3002  \n\u25c6 \u6570\u636e\u96c6\u6765\u6e90\u591a\u6837\uff0c\u5305\u542b\u4e0d\u540c\u76f8\u673a\u8bbe\u5907\u91c7\u96c6\u7684\u89c6\u89d2\uff089-46\u4e2a\u89c6\u89d2\uff09\uff0c\u589e\u5f3a\u4e86\u6570\u636e\u96c6\u7684\u6cdb\u5316\u6027\u548c\u5b9e\u7528\u6027\u3002|\n",
    "2507.09987": "|2025-07-14|VoxelRF: Voxelized Radiance Field for Fast Wireless Channel Modeling|Zihang Zeng\u7b49|[2507.09987](http://arxiv.org/pdf/2507.09987)|\u65e0|\u25c6 \u63d0\u51faVoxelRF\u65b0\u578b\u795e\u7ecf\u8868\u793a\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f53\u7d20\u5316\u8f90\u5c04\u573a\u5b9e\u73b0\u590d\u6742\u73af\u5883\u4e2d\u65e0\u7ebf\u4fe1\u9053\u7684\u5feb\u901f\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u7cbe\u5ea6\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u4e0a\u7684\u5e73\u8861\u96be\u9898\u3002  \n\u25c6 \u7528\u57fa\u4e8e\u4f53\u7d20\u7f51\u683c\u7684\u4e09\u7ebf\u6027\u63d2\u503c\u66ff\u4ee3NeRF\u4e2d\u6602\u8d35\u7684\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\uff0c\u7ed3\u5408\u4e24\u4e2a\u6d45\u5c42MLP\u5206\u522b\u5efa\u6a21\u4f20\u64ad\u548c\u53d1\u5c04\u7aef\u76f8\u5173\u6548\u5e94\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002  \n\u25c6 \u5f15\u5165\u6e10\u8fdb\u5f0f\u5b66\u4e60\u7b56\u7565\uff0c\u9010\u6b65\u4f18\u5316\u4f53\u7d20\u7f51\u683c\u5206\u8fa8\u7387\uff0c\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b\u5e76\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u91c7\u7528\u7a7a\u533a\u57df\u8df3\u8fc7\u6280\u672f\uff0c\u907f\u514d\u5bf9\u65e0\u4fe1\u53f7\u533a\u57df\u7684\u5197\u4f59\u8ba1\u7b97\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u3002  \n\u25c6 \u8bbe\u8ba1\u80cc\u666f\u71b5\u635f\u5931\u51fd\u6570\uff0c\u589e\u5f3a\u6a21\u578b\u5bf9\u7a00\u758f\u4fe1\u53f7\u533a\u57df\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u63d0\u5347\u6574\u4f53\u7cbe\u5ea6\u3002  \n\u5b9e\u9a8c\u8868\u660e\uff0cVoxelRF\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u80fd\u4ee5\u66f4\u4f4e\u8ba1\u7b97\u91cf\u8fbe\u5230\u7ade\u4e89\u6027\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u548c\u8d44\u6e90\u53d7\u9650\u7684\u65e0\u7ebf\u901a\u4fe1\u573a\u666f\u3002|\n",
    "2507.09168": "|2025-07-12|Stable Score Distillation|Haiming Zhu\u7b49|[2507.09168](http://arxiv.org/pdf/2507.09168)|\u65e0|\u25c6 \u63d0\u51fa\u7a33\u5b9a\u5206\u6570\u84b8\u998f\uff08SSD\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5206\u7c7b\u5668\u951a\u5b9a\u5230\u6e90\u63d0\u793a\u8bcd\uff0c\u663e\u8457\u63d0\u5347\u7f16\u8f91\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u548c\u5bf9\u9f50\u6027\u3002  \n\u25c6 \u5229\u7528\u65e0\u5206\u7c7b\u5668\u5f15\u5bfc\uff08CFG\uff09\u65b9\u7a0b\u5b9e\u73b0\u8de8\u63d0\u793a\u8bcd\u5bf9\u9f50\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u6052\u5b9a\u7a7a\u6587\u672c\u5206\u652f\u7a33\u5b9a\u4f18\u5316\u8fc7\u7a0b\uff0c\u907f\u514d\u51b2\u7a81\u4fe1\u53f7\u3002  \n\u25c6 \u8bbe\u8ba1\u63d0\u793a\u8bcd\u589e\u5f3a\u5206\u652f\uff0c\u4e13\u95e8\u5f3a\u5316\u98ce\u683c\u8f6c\u6362\u7b49\u7f16\u8f91\u4efb\u52a1\u7684\u4fee\u6539\u5f3a\u5ea6\uff0c\u63d0\u5347\u7f16\u8f91\u6548\u679c\u3002  \n\u25c6 \u5728\u4fdd\u6301\u539f\u59cb\u5185\u5bb9\u7ed3\u6784\u7684\u540c\u65f6\uff0c\u786e\u4fdd\u7f16\u8f91\u8f68\u8ff9\u4e0e\u6e90\u63d0\u793a\u8bcd\u7d27\u5bc6\u5bf9\u9f50\uff0c\u5b9e\u73b0\u5c40\u90e8\u7cbe\u51c6\u7f16\u8f91\u4e14\u4e0d\u5f71\u54cd\u5468\u56f4\u533a\u57df\u3002  \n\u25c6 \u57282D\u548c3D\u7f16\u8f91\u4efb\u52a1\uff08\u5982NeRF\u548c\u6587\u672c\u9a71\u52a8\u98ce\u683c\u7f16\u8f91\uff09\u4e2d\u8fbe\u5230\u6700\u4f18\u6548\u679c\uff0c\u6536\u655b\u66f4\u5feb\u4e14\u590d\u6742\u5ea6\u66f4\u4f4e\u3002|\n",
    "2507.09005": "|2025-07-11|From images to properties: a NeRF-driven framework for granular material parameter inversion|Cheng-Hsi Hsiao\u7b49|[2507.09005](http://arxiv.org/pdf/2507.09005)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684NeRF\u4e0eMPM\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u89c2\u6d4b\u53cd\u6f14\u9897\u7c92\u6750\u6599\u53c2\u6570\uff0c\u5b9e\u73b0\u4e86\u4ece\u56fe\u50cf\u5230\u7269\u6027\u53c2\u6570\u7684\u8de8\u6a21\u6001\u63a8\u7406\u3002  \n\u25c6 \u5229\u7528NeRF\u4ece\u591a\u89c6\u89d2\u521d\u59cb\u56fe\u50cf\u91cd\u5efa\u9ad8\u7cbe\u5ea63D\u51e0\u4f55\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u590d\u6742\u8868\u9762\u7ec6\u8282\u6355\u6349\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u4e3aMPM\u4eff\u771f\u63d0\u4f9b\u51c6\u786e\u521d\u59cb\u6761\u4ef6\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u91c7\u7528\u65f6\u5e8f\u53cc\u56fa\u5b9a\u76f8\u673a\u56fe\u50cf\u4f5c\u4e3a\u89c2\u6d4b\u6570\u636e\uff0c\u901a\u8fc7\u4eff\u771f\u6e32\u67d3\u4e0e\u771f\u5b9e\u56fe\u50cf\u7684\u6bd4\u5bf9\u6784\u5efa\u76ee\u6807\u51fd\u6570\uff0c\u5b9e\u73b0\u7eaf\u89c6\u89c9\u9a71\u52a8\u7684\u53c2\u6570\u53cd\u6f14\u3002  \n\u25c6 \u5f15\u5165\u8d1d\u53f6\u65af\u4f18\u5316\u9ad8\u6548\u641c\u7d22\u6469\u64e6\u89d2\u53c2\u6570\uff0c\u5c06\u53cd\u6f14\u8bef\u5dee\u63a7\u5236\u57282\u5ea6\u4ee5\u5185\uff0c\u9a8c\u8bc1\u4e86\u7eaf\u89c6\u89c9\u53cd\u5206\u6790\u7684\u53ef\u884c\u6027\u3002  \n\u25c6 \u8be5\u6846\u67b6\u4e3a\u65e0\u6cd5\u76f4\u63a5\u6d4b\u91cf\u7269\u6027\u7684\u5b9e\u9645\u573a\u666f\uff08\u5982\u9065\u611f\u3001\u707e\u5bb3\u8bc4\u4f30\uff09\u63d0\u4f9b\u4e86\u975e\u63a5\u89e6\u5f0f\u6750\u6599\u8868\u5f81\u65b0\u601d\u8def\uff0c\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002|\n",
    "2507.12132": "|2025-07-16|DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi|Navid Hasanzadeh\u7b49|[2507.12132](http://arxiv.org/pdf/2507.12132)|\u65e0|\u25c6 \u63d0\u51faDoRF\uff08\u591a\u666e\u52d2\u8f90\u5c04\u573a\uff09\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u601d\u60f3\u5f15\u5165Wi-Fi\u4f20\u611f\u9886\u57df\uff0c\u901a\u8fc7\u4e00\u7ef4\u591a\u666e\u52d2\u901f\u5ea6\u6295\u5f71\u91cd\u5efa3D\u6f5c\u5728\u8fd0\u52a8\u8868\u5f81\u3002  \n\u25c6 \u6784\u5efa\u4e86\u7edf\u4e00\u7684\u8fd0\u52a8\u591a\u666e\u52d2\u8f90\u5c04\u573a\uff0c\u63d0\u4f9b\u6d3b\u52a8\u5168\u666f\u89c6\u89d2\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u73af\u5883\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5229\u7528Wi-Fi CSI\u63d0\u53d6\u7684\u591a\u666e\u52d2\u901f\u5ea6\u6295\u5f71\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u73af\u5883\u7279\u5b9a\u7279\u5f81\u7684\u9650\u5236\u3002  \n\u25c6 \u6240\u63d03D\u6f5c\u5728\u8868\u5f81\u80fd\u6709\u6548\u6355\u6349\u4eba\u4f53\u6d3b\u52a8\u65f6\u7a7a\u7279\u6027\uff0c\u6bd4\u73b0\u67092D\u65b9\u6cd5\u66f4\u5177\u5224\u522b\u529b\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u73af\u5883\u3001\u8de8\u7528\u6237\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u63a8\u52a8Wi-Fi\u4f20\u611f\u8d70\u5411\u5b9e\u7528\u5316\u3002  \n\u25c6 \u4e3a\u65e0\u7ebf\u611f\u77e5\u5f00\u8f9f\u65b0\u601d\u8def\uff0c\u5c06\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u4f53\u79ef\u6e32\u67d3\u6280\u672f\u6210\u529f\u8fc1\u79fb\u81f3\u5c04\u9891\u4fe1\u53f7\u5904\u7406\u9886\u57df\u3002|\n",
    "2507.11971": "|2025-07-16|HPR3D: Hierarchical Proxy Representation for High-Fidelity 3D Reconstruction and Controllable Editing|Tielong Wang\u7b49|[2507.11971](http://arxiv.org/pdf/2507.11971)|\u65e0|\u25c6\u63d0\u51fa\u65b0\u578b3D\u5206\u5c42\u4ee3\u7406\u8282\u70b9\u8868\u793a\uff08HPR3D\uff09\uff0c\u901a\u8fc7\u7269\u4f53\u8868\u9762\u53ca\u5185\u90e8\u7684\u7a00\u758f\u5c42\u7ea7\u6811\u72b6\u4ee3\u7406\u8282\u70b9\u7f51\u7edc\u7edf\u4e00\u8868\u5f81\u5f62\u72b6\u4e0e\u7eb9\u7406\uff0c\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u4efb\u52a1\u5c40\u9650\u6027\u7684\u6846\u67b6\u521b\u65b0\u3002  \n\u25c6\u6bcf\u4e2a\u4ee3\u7406\u8282\u70b9\u91c7\u7528\u8f7b\u91cfMLP\u9690\u5f0f\u7f16\u7801\u5c40\u90e8\u51e0\u4f55\u4e0e\u7eb9\u7406\u4fe1\u606f\uff0c\u7ed3\u5408\u90bb\u8fd1\u53ca\u7236\u8282\u70b9\u7684\u9ad8\u6548\u795e\u7ecf\u63d2\u503c\u89e3\u7801\u673a\u5236\uff0c\u5b9e\u73b0\u590d\u6742\u6027\u4e0e\u4fdd\u771f\u5ea6\u7684\u52a8\u6001\u5e73\u8861\u3002  \n\u25c6\u5c42\u7ea7\u7ed3\u6784\u5929\u7136\u652f\u6301\u8bed\u4e49\u5bf9\u9f50\uff0c\u7528\u6237\u53ef\u76f4\u63a5\u901a\u8fc7\u62d6\u62fd\u4ee3\u7406\u8282\u70b9\u5b9e\u73b0\u76f4\u89c2\u7f16\u8f91\uff0c\u89e3\u51b3\u4e86NeRF\u7ed3\u6784\u6a21\u7cca\u5bfc\u81f4\u7684\u64cd\u63a7\u96be\u9898\u3002  \n\u25c6\u7a00\u758f\u8282\u70b9\u5206\u5e03\u4e0e\u5206\u5c42\u67e5\u8be2\u673a\u5236\u663e\u8457\u964d\u4f4e\u6570\u636e\u590d\u6742\u5ea6\uff08\u76f8\u6bd4\u7f51\u683c\u9876\u70b9\u5bc6\u5ea6\u548cNeRF\u4f53\u7d20\u91c7\u6837\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e9a\u6beb\u7c73\u7ea7\u91cd\u5efa\u7cbe\u5ea6\u3002  \n\u25c6\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u8868\u793a\u5728\u91cd\u5efa\u8d28\u91cf\uff08PSNR\u63d0\u53472.1dB\uff09\u3001\u7f16\u8f91\u6548\u7387\uff08\u4ea4\u4e92\u5ef6\u8fdf<10ms\uff09\u548c\u8de8\u4efb\u52a1\u901a\u7528\u6027\uff08\u91cd\u5efa/\u751f\u6210/\u9a71\u52a8\uff09\u4e0a\u7684\u7efc\u5408\u4f18\u52bf\u3002|\n",
    "2507.13929": "|2025-07-18|TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views|Hsiang-Hui Hung\u7b49|[2507.13929](http://arxiv.org/pdf/2507.13929)|\u65e0|\u25c6 TimeNeRF\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u795e\u7ecf\u6e32\u67d3\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u5c11\u91cf\u8f93\u5165\u89c6\u56fe\u4e0b\u6e32\u67d3\u4efb\u610f\u89c6\u89d2\u548c\u4efb\u610f\u65f6\u95f4\u70b9\u7684\u65b0\u89c6\u56fe\uff0c\u89e3\u51b3\u4e86\u591a\u89c6\u56fe\u91c7\u96c6\u6210\u672c\u9ad8\u548c\u573a\u666f\u91cd\u590d\u4f18\u5316\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u9996\u6b21\u63a2\u7d22\u4e86NeRF\u5728\u65f6\u5e8f3D\u573a\u666f\u5efa\u6a21\u4e2d\u7684\u6f5c\u529b\uff0c\u586b\u8865\u4e86\u5f53\u524d\u6280\u672f\u5728\u8be5\u9886\u57df\u7684\u7a7a\u767d\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5143\u5b87\u5b99\u4e2d\u663c\u591c\u81ea\u7136\u8fc7\u6e21\u7684\u6c89\u6d78\u5f0f\u4f53\u9a8c\u9700\u6c42\u3002  \n\u25c6 \u7ed3\u5408\u591a\u89c6\u56fe\u7acb\u4f53\u89c6\u89c9\u3001\u795e\u7ecf\u8f90\u5c04\u573a\u548c\u8de8\u6570\u636e\u96c6\u89e3\u8026\u7b56\u7565\uff0c\u6784\u5efa\u4e86\u9690\u5f0f\u5185\u5bb9\u8f90\u5c04\u573a\uff0c\u5b9e\u73b0\u4e86\u573a\u666f\u8868\u793a\u548c\u65f6\u95f4\u7ef4\u5ea6\u5efa\u6a21\u7684\u7edf\u4e00\u6846\u67b6\u3002  \n\u25c6 \u65e0\u9700\u9010\u573a\u666f\u4f18\u5316\u5373\u53ef\u5728\u5c11\u6837\u672c\u6761\u4ef6\u4e0b\u751f\u6210\u65b0\u89c6\u56fe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6e32\u67d3\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u80fd\u6709\u6548\u6355\u6349\u4ece\u9ece\u660e\u5230\u9ec4\u660f\u7684\u590d\u6742\u81ea\u7136\u573a\u666f\u53d8\u5316\u3002  \n\u25c6 \u901a\u8fc7\u4f53\u6e32\u67d3\u6280\u672f\u5408\u6210\u4efb\u610f\u65f6\u95f4\u70b9\u7684\u903c\u771f\u65b0\u89c6\u56fe\uff0c\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u5e73\u6ed1\u8fc7\u6e21\uff0c\u4e3a\u52a8\u6001\u573a\u666f\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002|\n",
    "2507.13648": "|2025-07-18|EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation|Seungjun Moon\u7b49|[2507.13648](http://arxiv.org/pdf/2507.13648)|\u65e0|\u25c6 \u63d0\u51faEPSilon\u6846\u67b6\uff0c\u901a\u8fc7\u9ad8\u6548\u70b9\u91c7\u6837\u7b56\u7565\u663e\u8457\u63d0\u5347\u57fa\u4e8e\u6df7\u5408\u8868\u793a\uff08SMPL\u7f51\u683c+NeRF\uff09\u76843D\u865a\u62df\u4eba\u751f\u6210\u6548\u7387\uff0c\u517c\u987e\u751f\u6210\u8d28\u91cf\u4e0e\u901f\u5ea6\u3002  \n\u25c6 \u521b\u65b0\u6027\u8bbe\u8ba1\u7a7a\u5c04\u7ebf\u5254\u9664\uff08ERO\uff09\u65b9\u6cd5\uff0c\u76f4\u63a5\u8df3\u8fc7\u7a7a\u573a\u666f\u4e2d\u7684\u5149\u7ebf\u8ba1\u7b97\uff0c\u51cf\u5c11\u65e0\u6548\u91c7\u6837\u70b9\u3002  \n\u25c6 \u63d0\u51fa\u7a7a\u533a\u95f4\u5254\u9664\uff08EIO\uff09\u6280\u672f\uff0c\u8fdb\u4e00\u6b65\u538b\u7f29\u5149\u7ebf\u91c7\u6837\u533a\u95f4\uff0c\u4ec5\u4fdd\u7559\u8863\u7269\u6216\u7f51\u683c\u8986\u76d6\u7684\u6709\u6548\u533a\u57df\u3002  \n\u25c6 \u901a\u8fc7\u7cbe\u7ec6\u5316\u91c7\u6837\u7b56\u7565\uff0c\u5b9e\u73b0\u5355\u9636\u6bb5NeRF\u7ed3\u6784\uff0c\u65e0\u9700\u4f20\u7edf\u5206\u5c42\u91c7\u6837\uff0c\u7b80\u5316\u6a21\u578b\u67b6\u6784\u3002  \n\u25c6 \u5b9e\u9a8c\u8868\u660e\uff0cEPSilon\u4ec5\u97003.9%\u7684\u91c7\u6837\u70b9\u5373\u53ef\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u7ea620\u500d\uff0c\u8bad\u7ec3\u6536\u655b\u52a0\u5feb4\u500d\u3002|\n",
    "2507.14596": "|2025-07-19|DiSCO-3D : Discovering and segmenting Sub-Concepts from Open-vocabulary queries in NeRF|Doriand Petit\u7b49|[2507.14596](http://arxiv.org/pdf/2507.14596)|\u65e0|\u25c6 DiSCO-3D\u9996\u6b21\u63d0\u51fa3D\u5f00\u653e\u8bcd\u6c47\u5b50\u6982\u5ff5\u53d1\u73b0\u4efb\u52a1\uff0c\u7ed3\u5408\u573a\u666f\u5185\u5bb9\u548c\u7528\u6237\u67e5\u8be2\u9700\u6c42\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u76843D\u8bed\u4e49\u5206\u5272\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u57fa\u4e8e\u795e\u7ecf\u573a\u8868\u793a\uff0c\u5c06\u65e0\u76d1\u7763\u5206\u5272\u4e0e\u5f31\u5f00\u653e\u8bcd\u6c47\u6307\u5bfc\u76f8\u7ed3\u5408\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u4ec5\u9002\u5e94\u5355\u4e00\u4efb\u52a1\u6216\u573a\u666f\u7684\u9650\u5236\u3002  \n\u25c6 \u901a\u8fc7\u5f00\u653e\u8bcd\u6c47\u67e5\u8be2\uff0cDiSCO-3D\u80fd\u591f\u52a8\u6001\u53d1\u73b0\u5e76\u5206\u5272\u5b50\u6982\u5ff5\uff0c\u9002\u5e94\u591a\u6837\u5316\u7684\u7528\u6237\u9700\u6c42\u3002  \n\u25c6 \u5728\u5f00\u653e\u8bcd\u6c47\u548c\u65e0\u76d1\u7763\u5206\u5272\u7684\u8fb9\u7f18\u6848\u4f8b\u4e2d\uff0cDiSCO-3D\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u6cdb\u5316\u80fd\u529b\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u4e3a\u673a\u5668\u4eba\u3001\u81ea\u52a8\u9a7e\u9a76\u7b49\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u9ad8\u5c42\u6b21\u7684\u573a\u666f\u7406\u89e3\u80fd\u529b\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002|\n",
    "2507.14501": "|2025-07-19|Advances in Feed-Forward 3D Reconstruction and View Synthesis: A Survey|Jiahui Zhang\u7b49|[2507.14501](http://arxiv.org/pdf/2507.14501)|\u65e0|\u25c6 \u7cfb\u7edf\u68b3\u7406\u4e86\u57fa\u4e8e\u524d\u9988\u5f0f\u6df1\u5ea6\u5b66\u4e60\u76843D\u91cd\u5efa\u4e0e\u89c6\u56fe\u5408\u6210\u6280\u672f\uff0c\u63d0\u51fa\u6309\u8868\u793a\u67b6\u6784\uff08\u5982\u70b9\u4e91\u30013D\u9ad8\u65af\u6cfc\u6e85\u3001\u795e\u7ecf\u8f90\u5c04\u573a\u7b49\uff09\u7684\u5206\u7c7b\u4f53\u7cfb\u3002  \n\u25c6 \u91cd\u70b9\u5206\u6790\u4e86\u65e0\u59ff\u6001\u91cd\u5efa\u3001\u52a8\u60013D\u91cd\u5efa\u30013D\u611f\u77e5\u56fe\u50cf/\u89c6\u9891\u5408\u6210\u7b49\u5173\u952e\u4efb\u52a1\uff0c\u62d3\u5c55\u4e86\u5728\u6570\u5b57\u4eba\u3001SLAM\u7b49\u9886\u57df\u7684\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u5bf9\u6bd4\u4f20\u7edf\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\uff0c\u7a81\u663e\u524d\u9988\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u4e0e\u6cdb\u5316\u80fd\u529b\u4e0a\u7684\u7a81\u7834\uff0c\u63a8\u52a8AR/VR\u7b49\u5b9e\u65f6\u5e94\u7528\u843d\u5730\u3002  \n\u25c6 \u9996\u6b21\u6574\u5408\u8be5\u9886\u57df\u5e38\u7528\u6570\u636e\u96c6\u4e0e\u8bc4\u4f30\u534f\u8bae\uff0c\u4e3a\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u6807\u51c6\u5316\u8bc4\u6d4b\u57fa\u51c6\u3002  \n\u25c6 \u6307\u51fa\u52a8\u6001\u573a\u666f\u5efa\u6a21\u3001\u8de8\u6a21\u6001\u751f\u6210\u7b49\u5f00\u653e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002|\n",
    "2507.16406": "|2025-07-22|Sparse-View 3D Reconstruction: Recent Advances and Open Challenges|Tanveer Younis\u7b49|[2507.16406](http://arxiv.org/pdf/2507.16406)|\u65e0|\u25c6 \u8be5\u8bba\u6587\u9996\u6b21\u5c06\u7a00\u758f\u89c6\u89d23D\u91cd\u5efa\u9886\u57df\u7684\u51e0\u4f55\u65b9\u6cd5\u3001\u795e\u7ecf\u9690\u5f0f\u6a21\u578b\uff08\u5982NeRF\uff09\u548c\u751f\u6210\u5f0f\u65b9\u6cd5\uff08\u5982\u6269\u6563\u6a21\u578b\uff09\u7eb3\u5165\u7edf\u4e00\u6846\u67b6\u8fdb\u884c\u7cfb\u7edf\u7efc\u8ff0\u3002  \n\u25c6 \u6df1\u5165\u5206\u6790\u4e86\u7a00\u758f\u573a\u666f\u4e0b\u51e0\u4f55\u6b63\u5219\u5316\u3001\u663e\u5f0f\u5f62\u72b6\u5efa\u6a21\u548c\u751f\u6210\u63a8\u7406\u5982\u4f55\u89e3\u51b3\u6d6e\u6e38\u4f2a\u5f71\u548c\u4f4d\u59ff\u6a21\u7cca\u7b49\u5173\u952e\u95ee\u9898\u3002  \n\u25c6 \u5bf9\u6bd4\u4e863D\u9ad8\u65af\u6cfc\u6e85\u7b49\u663e\u5f0f\u70b9\u4e91\u65b9\u6cd5\u4e0e\u795e\u7ecf\u9690\u5f0f\u65b9\u6cd5\u5728\u7cbe\u5ea6\u3001\u6548\u7387\u548c\u6cdb\u5316\u6027\u65b9\u9762\u7684\u6743\u8861\u5173\u7cfb\u3002  \n\u25c6 \u63d0\u51fa\u5f53\u524d\u9886\u57df\u5c1a\u672a\u89e3\u51b3\u7684\u6311\u6218\uff0c\u5305\u62ec\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u548c\u65e0\u4f4d\u59ff\u7ea6\u675f\u7684\u91cd\u5efa\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002  \n\u25c6 \u7279\u522b\u5f3a\u8c03\u89c6\u89c9\u57fa\u7840\u6a21\u578b\uff08VFMs\uff09\u548c3D\u539f\u751f\u751f\u6210\u5148\u9a8c\u5728\u7a00\u758f\u91cd\u5efa\u4e2d\u7684\u521b\u65b0\u5e94\u7528\u6f5c\u529b\u3002  \n\u25c6 \u533a\u522b\u4e8e\u4ee5\u5f80\u7efc\u8ff0\uff0c\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u68b3\u7406\u4e86\u6269\u6563\u6a21\u578b\u4e0e\u795e\u7ecf\u9690\u5f0f\u65b9\u6cd5\u7684\u878d\u5408\u6846\u67b6\u53ca\u5176\u5728\u7a00\u758f\u6570\u636e\u4e0b\u7684\u4f18\u52bf\u3002|\n",
    "2507.17351": "|2025-07-23|Exploring Active Learning for Label-Efficient Training of Semantic Neural Radiance Field|Yuzhe Zhu\u7b49|[2507.17351](http://arxiv.org/pdf/2507.17351)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u548c\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u5c06\u4e3b\u52a8\u5b66\u4e60\u5e94\u7528\u4e8e\u8bed\u4e49\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u7684\u8bad\u7ec3\uff0c\u4ee5\u964d\u4f4e\u50cf\u7d20\u7ea7\u6807\u6ce8\u7684\u9ad8\u6210\u672c\u3002  \n\u25c6 \u7814\u7a76\u4e86\u8bed\u4e49NeRF\u4e3b\u52a8\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\uff0c\u5305\u62ec\u9009\u62e9\u7c92\u5ea6\u548c\u9009\u62e9\u7b56\u7565\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u86513D\u51e0\u4f55\u7ea6\u675f\u7684\u6837\u672c\u9009\u62e9\u7b56\u7565\uff0c\u63d0\u5347\u4e86\u4e3b\u52a8\u5b66\u4e60\u7684\u6548\u679c\u3002  \n\u25c6 \u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u8bed\u4e49NeRF\u8bad\u7ec3\u7684\u6807\u6ce8\u6210\u672c\uff0c\u76f8\u6bd4\u968f\u673a\u91c7\u6837\u53ef\u964d\u4f4e2\u500d\u4ee5\u4e0a\u3002  \n\u25c6 \u4e3a\u8bed\u4e49\u573a\u666f\u7406\u89e3\u7684\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u8303\u5f0f\u3002  \n\u25c6 \u9996\u6b21\u7cfb\u7edf\u63a2\u7d22\u4e86\u4e3b\u52a8\u5b66\u4e60\u57283D\u8bed\u4e49\u795e\u7ecf\u8868\u793a\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002|\n",
    "2507.18023": "|2025-07-24|High-fidelity 3D Gaussian Inpainting: preserving multi-view consistency and photorealistic details|Jun Zhou\u7b49|[2507.18023](http://arxiv.org/pdf/2507.18023)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85(3DGS)\u7684\u9ad8\u4fdd\u771f\u4e09\u7ef4\u4fee\u590d\u6846\u67b6\uff0c\u901a\u8fc7\u7a00\u758f\u4fee\u590d\u89c6\u56fe\u91cd\u5efa\u5b8c\u6574\u4e09\u7ef4\u573a\u666f  \n\u25c6 \u8bbe\u8ba1\u81ea\u52a8\u63a9\u819c\u4f18\u5316\u6d41\u7a0b\uff0c\u7ed3\u5408\u9ad8\u65af\u573a\u666f\u8fc7\u6ee4\u4e0e\u53cd\u5411\u6295\u5f71\u6280\u672f\uff0c\u7cbe\u51c6\u5b9a\u4f4d\u906e\u6321\u533a\u57df\u5e76\u5b9e\u73b0\u903c\u771f\u8fb9\u754c\u4fee\u590d  \n\u25c6 \u521b\u65b0\u6027\u5f00\u53d1\u533a\u57df\u7ea7\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u4f18\u5316\u7b56\u7565\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u91cd\u8981\u6027\u8bc4\u4f30\u7f13\u89e3\u89c6\u89d2\u4e0d\u4e00\u81f4\u95ee\u9898  \n\u25c6 \u5b9e\u73b0\u7ec6\u7c92\u5ea6\u4f18\u5316\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4fee\u590d\u7ed3\u679c\u4e2d\u9ad8\u9891\u7ec6\u8282\u7684\u4fdd\u771f\u5ea6\u4e0e\u771f\u5b9e\u611f  \n\u25c6 \u5728\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u672c\u65b9\u6cd5\u5728\u89c6\u89c9\u8d28\u91cf\u548c\u591a\u89c6\u89d2\u4e00\u81f4\u6027\u65b9\u9762\u5747\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u6280\u672f  \n\u8be5\u5de5\u4f5c\u89e3\u51b3\u4e86\u4e09\u7ef4\u573a\u666f\u4fee\u590d\u4e2d\u89c6\u89d2\u4e0d\u4e00\u81f4\u548c\u7ec6\u8282\u5931\u771f\u7684\u6838\u5fc3\u96be\u9898\uff0c\u4e3a\u4e09\u7ef4\u5185\u5bb9\u521b\u4f5c\u63d0\u4f9b\u4e86\u65b0\u5de5\u5177\u3002|\n",
    "2507.19474": "|2025-07-25|DINO-SLAM: DINO-informed RGB-D SLAM for Neural Implicit and Explicit Representations|Ziren Gong\u7b49|[2507.19474](http://arxiv.org/pdf/2507.19474)|\u65e0|\u25c6 \u63d0\u51faDINO-SLAM\u6846\u67b6\uff0c\u901a\u8fc7DINO\u7279\u5f81\u589e\u5f3a\u795e\u7ecf\u9690\u5f0f\uff08NeRF\uff09\u548c\u663e\u5f0f\uff083DGS\uff09SLAM\u7cfb\u7edf\u7684\u573a\u666f\u8868\u793a\u80fd\u529b\u3002  \n\u25c6 \u8bbe\u8ba1\u573a\u666f\u7ed3\u6784\u7f16\u7801\u5668\uff08SSE\uff09\uff0c\u5c06\u539f\u59cbDINO\u7279\u5f81\u5347\u7ea7\u4e3a\u589e\u5f3a\u7248EDINO\uff0c\u6709\u6548\u6355\u6349\u573a\u666f\u5c42\u6b21\u7ed3\u6784\u548c\u5143\u7d20\u95f4\u5173\u7cfb\u3002  \n\u25c6 \u5f00\u53d1\u4e24\u79cd\u57fa\u4e8eEDINO\u7684SLAM\u8303\u5f0f\uff0c\u5206\u522b\u9488\u5bf9NeRF\u548c3DGS\u5b9e\u73b0\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027\u3002  \n\u25c6 \u5728Replica\u3001ScanNet\u548cTUM\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u6027\u80fd\uff0c\u8d85\u8d8a\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u8bc1\u660e\u901a\u7528\u573a\u666f\u9002\u5e94\u80fd\u529b\u3002  \n\u25c6 \u9996\u6b21\u5c06DINO\u8bed\u4e49\u5148\u9a8c\u4e0e\u51e0\u4f55\u91cd\u5efa\u7ed3\u5408\uff0c\u4e3a\u52a8\u6001/\u5f31\u7eb9\u7406\u573a\u666f\u63d0\u4f9b\u66f4\u5168\u9762\u7684\u8868\u793a\u65b9\u6848\u3002|\n",
    "2507.19459": "|2025-07-25|Fast Learning of Non-Cooperative Spacecraft 3D Models through Primitive Initialization|Pol Francesch Huc\u7b49|[2507.19459](http://arxiv.org/pdf/2507.19459)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8eCNN\u76843D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u521d\u59cb\u5316\u65b9\u6cd5\uff0c\u4ec5\u9700\u5355\u76ee\u56fe\u50cf\u5373\u53ef\u751f\u6210\u7c97\u7cd93D\u6a21\u578b\u548c\u76ee\u6807\u59ff\u6001\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u591a\u89c6\u89d2\u7cbe\u786e\u59ff\u6001\u7684\u95ee\u9898\u3002  \n\u25c6 \u5f00\u53d1\u652f\u6301\u566a\u58f0\u6216\u9690\u5f0f\u59ff\u6001\u4f30\u8ba1\u7684\u8bad\u7ec3\u6d41\u7a0b\uff0c\u7a81\u7834NeRF/3DGS\u5728\u592a\u7a7a\u573a\u666f\u4e2d\u5fc5\u987b\u4f9d\u8d56\u7cbe\u786e\u59ff\u6001\u7684\u9650\u5236\u3002  \n\u25c6 \u901a\u8fc7\u5206\u6790\u4e0d\u540c\u521d\u59cb\u5316\u53d8\u4f53\uff0c\u663e\u8457\u964d\u4f4e\u9ad8\u7cbe\u5ea63D\u6a21\u578b\u7684\u8bad\u7ec3\u6210\u672c\uff0c\u6240\u9700\u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570\u548c\u8f93\u5165\u56fe\u50cf\u6570\u91cf\u51cf\u5c11\u81f3\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002  \n\u25c6 CNN\u6a21\u5757\u96c6\u6210\u591a\u79cd\u59ff\u6001\u4f30\u8ba1\u6280\u672f\u53d8\u4f53\uff0c\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u7075\u6d3b\u6027\uff0c\u5e76\u5728\u566a\u58f0\u59ff\u6001\u6761\u4ef6\u4e0b\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u5373\u4f7f\u4f7f\u7528\u4e0d\u5b8c\u7f8e\u7684\u59ff\u6001\u76d1\u7763\uff0c\u8be5\u6846\u67b6\u4ecd\u80fd\u5b66\u4e60\u9ad8\u4fdd\u771f3D\u8868\u793a\uff0c\u4e3a\u592a\u7a7a\u5e94\u7528\u4e2d\u7684\u65b0\u89c6\u89d2\u5408\u6210\u6280\u672f\u94fa\u5e73\u9053\u8def\u3002|\n",
    "2507.19328": "|2025-07-25|NerT-CA: Efficient Dynamic Reconstruction from Sparse-view X-ray Coronary Angiography|Kirsten W. H. Maas\u7b49|[2507.19328](http://arxiv.org/pdf/2507.19328)|\u65e0|\u25c6 NerT-CA\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u795e\u7ecf\u5f20\u91cf\u8868\u793a\u65b9\u6cd5\uff0c\u7ed3\u5408\u795e\u7ecf\u573a\u4e0e\u5f20\u91cf\u573a\u4f18\u52bf\uff0c\u663e\u8457\u63d0\u5347\u7a00\u758f\u89c6\u89d2X\u5c04\u7ebf\u51a0\u72b6\u52a8\u8109\u9020\u5f71\uff08CA\uff09\u7684\u52a8\u60014D\u91cd\u5efa\u6548\u7387\u3002  \n\u25c6 \u901a\u8fc7\u5c06CA\u573a\u666f\u5206\u89e3\u4e3a\u4f4e\u79e9\u9759\u6001\u6210\u5206\uff08\u5f20\u91cf\u573a\uff09\u4e0e\u52a8\u6001\u7a00\u758f\u6210\u5206\uff08\u795e\u7ecf\u573a\uff09\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56MLP\u5bfc\u81f4\u8bad\u7ec3\u8017\u65f6\u8fc7\u957f\u7684\u95ee\u9898\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u5728\u4ec5\u97003\u4e2a\u9020\u5f71\u89c6\u89d2\u4e0b\u5373\u53ef\u5b9e\u73b0\u9ad8\u8d28\u91cf\u91cd\u5efa\uff0c\u7a81\u7834\u4e86\u7a00\u758f\u89c6\u56fe\u91cd\u5efa\u7684\u4e34\u5e8a\u5b9e\u7528\u6027\u74f6\u9888\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5229\u7528\u4f4e\u79e9\u5148\u9a8c\u52a0\u901f\u9759\u6001\u80cc\u666f\u5efa\u6a21\uff0c\u540c\u65f6\u4fdd\u7559\u795e\u7ecf\u573a\u5bf9\u8840\u7ba1\u52a8\u6001\u7ec6\u8282\u7684\u6355\u6349\u80fd\u529b\uff0c\u517c\u987e\u901f\u5ea6\u4e0e\u7cbe\u5ea6\u3002  \n\u25c6 \u57284D\u4eff\u771f\u6570\u636e\u96c6\u4e0a\u5b9a\u91cf\u4e0e\u5b9a\u6027\u9a8c\u8bc1\u663e\u793a\uff0c\u5176\u8bad\u7ec3\u901f\u5ea6\u4e0e\u91cd\u5efa\u7cbe\u5ea6\u5747\u8d85\u8d8a\u73b0\u6709NeRF-based\u65b9\u6cd5\uff0c\u4e3a\u4e34\u5e8a\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u53ef\u80fd\u3002|\n",
    "2507.18713": "|2025-07-24|SaLF: Sparse Local Fields for Multi-Sensor Rendering in Real-Time|Yun Chen\u7b49|[2507.18713](http://arxiv.org/pdf/2507.18713)|\u65e0|\u25c6 \u63d0\u51faSaLF\uff08\u7a00\u758f\u5c40\u90e8\u573a\uff09\u65b0\u578b\u4f53\u7d20\u8868\u793a\u65b9\u6cd5\uff0c\u5c06\u573a\u666f\u8868\u793a\u4e3a\u7a00\u758f3D\u4f53\u7d20\u96c6\u5408\uff0c\u6bcf\u4e2a\u4f53\u7d20\u5305\u542b\u5c40\u90e8\u9690\u5f0f\u573a\uff0c\u517c\u5177\u6805\u683c\u5316\u548c\u5149\u7ebf\u8ffd\u8e2a\u80fd\u529b\u3002  \n\u25c6 \u7a81\u7834\u73b0\u6709\u6280\u672f\u9650\u5236\uff0c\u9996\u6b21\u5b9e\u73b0\u540c\u65f6\u652f\u6301\u975e\u9488\u5b54\u76f8\u673a\u548c\u65cb\u8f6c\u6fc0\u5149\u96f7\u8fbe\u7684\u9ad8\u6548\u6e32\u67d3\uff08\u76f8\u673a50+ FPS\uff0cLiDAR 600+ FPS\uff09\u3002  \n\u25c6 \u91c7\u7528\u81ea\u9002\u5e94\u526a\u679d\u4e0e\u81f4\u5bc6\u5316\u7b56\u7565\uff0c\u65e0\u9700\u9884\u5904\u7406\u5373\u53ef\u52a8\u6001\u4f18\u5316\u5927\u573a\u666f\u8868\u793a\uff0c\u663e\u8457\u63d0\u5347\u53ef\u6269\u5c55\u6027\u3002  \n\u25c6 \u89e3\u8026\u573a\u666f\u8868\u793a\u4e0e\u6e32\u67d3\u6d41\u7a0b\uff0c\u652f\u6301\u591a\u79cd\u4f20\u611f\u5668\u7edf\u4e00\u6846\u67b6\uff0c\u514b\u670d\u4e86NeRF\u548c3D\u9ad8\u65af\u6cfc\u6e85\u7684\u4e92\u64cd\u4f5c\u6027\u7f3a\u9677\u3002  \n\u25c6 \u5b9e\u73b0\u5feb\u901f\u8bad\u7ec3\uff08<30\u5206\u949f\uff09\u4e0e\u5b9e\u65f6\u6e32\u67d3\uff0c\u5728\u4fdd\u6301\u81ea\u52a8\u9a7e\u9a76\u4f20\u611f\u5668\u4eff\u771f\u771f\u5b9e\u6027\u7684\u540c\u65f6\uff0c\u6548\u7387\u8fdc\u8d85\u4f20\u7edfNeRF\u65b9\u6cd5\u3002  \n\u25c6 \u4e3a\u591a\u4f20\u611f\u5668\u81ea\u52a8\u9a7e\u9a76\u6d4b\u8bd5\u63d0\u4f9b\u9996\u4e2a\u517c\u987e\u9ad8\u4fdd\u771f\u5ea6\u4e0e\u9ad8\u6548\u7387\u7684\u4eff\u771f\u65b9\u6848\uff0c\u63a8\u52a8\u89c4\u6a21\u5316\u865a\u62df\u6d4b\u8bd5\u53d1\u5c55\u3002|\n",
    "2507.20110": "|2025-07-27|NeuroVoxel-LM: Language-Aligned 3D Perception via Dynamic Voxelization and Meta-Embedding|Shiyu Liu\u7b49|[2507.20110](http://arxiv.org/pdf/2507.20110)|\u65e0|\u25c6 NeuroVoxel-LM\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u7684\u52a8\u6001\u4f53\u7d20\u5316\u4e0e\u8f7b\u91cf\u7ea7\u5143\u5d4c\u5165\u7684\u65b0\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u67093D\u8bed\u8a00\u6a21\u578b\u5904\u7406\u7a00\u758f\u5927\u89c4\u6a21\u70b9\u4e91\u65f6\u6548\u7387\u4f4e\u548c\u8868\u793a\u7cbe\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u8bbe\u8ba1\u4e86\u52a8\u6001\u5206\u8fa8\u7387\u591a\u5c3a\u5ea6\u4f53\u7d20\u5316\uff08DR-MSV\uff09\u6280\u672f\uff0c\u6839\u636e\u51e0\u4f55\u548c\u7ed3\u6784\u590d\u6742\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\u4f53\u7d20\u7c92\u5ea6\uff0c\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u91cd\u5efa\u4fdd\u771f\u5ea6\u3002  \n\u25c6 \u63d0\u51fa\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u52a0\u6743\u548c\u6b8b\u5dee\u878d\u5408\u7684\u8f7b\u91cf\u7ea7\u5143\u5d4c\u5165\u673a\u5236\uff08TAP-LME\uff09\uff0c\u901a\u8fc7\u4ee4\u724c\u7ea7\u81ea\u9002\u5e94\u6c60\u5316\u589e\u5f3a\u8bed\u4e49\u8868\u793a\u80fd\u529b\uff0c\u4f18\u4e8e\u4f20\u7edf\u6700\u5927\u6c60\u5316\u65b9\u6cd5\u3002  \n\u25c6 DR-MSV\u663e\u8457\u63d0\u5347\u4e86\u70b9\u4e91\u7279\u5f81\u63d0\u53d6\u7684\u6548\u7387\u548c\u7cbe\u5ea6\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5927\u8303\u56f4\u590d\u6742\u573a\u666f\u7684\u5feb\u901f\u5904\u7406\u3002  \n\u25c6 TAP-LME\u673a\u5236\u80fd\u591f\u4eceNeRF\u6743\u91cd\u4e2d\u6355\u83b7\u7ec6\u7c92\u5ea6\u8bed\u4e49\u4fe1\u606f\uff0c\u4e3a\u8bed\u8a00\u9a71\u52a8\u76843D\u611f\u77e5\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u8868\u793a\u3002  \n\u25c6 \u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u57283D\u573a\u666f\u7406\u89e3\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6027\u80fd\u7a81\u7834\uff0c\u4e3a\u8bed\u8a00\u5bf9\u9f50\u76843D\u611f\u77e5\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002|\n",
    "2507.21350": "|2025-07-28|DEM-NeRF: A Neuro-Symbolic Method for Scientific Discovery through Physics-Informed Simulation|Wenkai Tan\u7b49|[2507.21350](http://arxiv.org/pdf/2507.21350)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u795e\u7ecf\u7b26\u53f7\u6846\u67b6DEM-NeRF\uff0c\u76f4\u63a5\u4ece\u7a00\u758f\u591a\u89c6\u89d2\u56fe\u50cf\u5e8f\u5217\u91cd\u5efa\u548c\u6a21\u62df\u5f39\u6027\u7269\u4f53\uff0c\u65e0\u9700\u663e\u5f0f\u51e0\u4f55\u4fe1\u606f\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c06\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u4e0e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u7ed3\u5408\uff0c\u540c\u65f6\u5229\u7528\u56fe\u50cf\u76d1\u7763\u548c\u5f39\u6027\u529b\u5b66\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u7269\u7406\u7ea6\u675f\u3002  \n\u25c6 \u901a\u8fc7\u80fd\u91cf\u7ea6\u675f\u7684PINN\u67b6\u6784\u5904\u7406\u590d\u6742\u8fb9\u754c\u548c\u521d\u59cb\u6761\u4ef6\uff0c\u66ff\u4ee3\u4f20\u7edf\u6709\u9650\u5143\u6216\u8fb9\u754c\u5143\u65b9\u6cd5\uff0c\u63d0\u5347\u6a21\u62df\u7cbe\u5ea6\u3002  \n\u25c6 \u5b9e\u73b0\u4e86\u65f6\u7a7a\u53d8\u5f62\u7269\u4f53\u7684\u8054\u5408\u8868\u5f81\u5b66\u4e60\uff0c\u5f25\u5408\u4e86\u7eaf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4e0e\u4f20\u7edf\u6570\u503c\u6a21\u62df\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002  \n\u25c6 \u589e\u5f3a\u4e86\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u79d1\u5b66\u53d1\u73b0\u63d0\u4f9b\u517c\u5177\u6570\u636e\u9002\u5e94\u6027\u4e0e\u7269\u7406\u4e00\u81f4\u6027\u7684\u65b0\u5de5\u5177\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u9ad8\u4fdd\u771f\u4eff\u771f\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u4ec5\u9700\u7a00\u758f\u89c2\u6d4b\u6570\u636e\u5373\u53ef\u5b8c\u6210\u7269\u7406\u89c4\u5f8b\u5efa\u6a21\u3002|\n",
    "2507.23374": "|2025-07-31|NeRF Is a Valuable Assistant for 3D Gaussian Splatting|Shuangkang Fang\u7b49|[2507.23374](http://arxiv.org/pdf/2507.23374)|\u65e0|\u25c6 \u63d0\u51faNeRF-GS\u6846\u67b6\uff0c\u9996\u6b21\u8054\u5408\u4f18\u5316\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u4e0e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\uff0c\u5b9e\u73b0\u4e24\u79cd\u6280\u672f\u7684\u4f18\u52bf\u4e92\u8865\u3002  \n\u25c6 \u5229\u7528NeRF\u7684\u8fde\u7eed\u7a7a\u95f4\u8868\u5f81\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b33DGS\u5bf9\u9ad8\u65af\u521d\u59cb\u5316\u654f\u611f\u3001\u7a7a\u95f4\u611f\u77e5\u5f31\u3001\u9ad8\u65af\u95f4\u5173\u8054\u6027\u4e0d\u8db3\u7b49\u56fa\u6709\u7f3a\u9677\u3002  \n\u25c6 \u901a\u8fc7\u6e10\u8fdb\u5f0f\u5bf9\u9f503DGS\u4e0eNeRF\u7684\u7a7a\u95f4\u7279\u5f81\uff0c\u4f7f\u4e24\u8005\u80fd\u57fa\u4e8e\u5171\u4eab\u76843D\u7a7a\u95f4\u4fe1\u606f\u5728\u540c\u4e00\u573a\u666f\u4e2d\u534f\u540c\u4f18\u5316\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u4f18\u5316\u9690\u5f0f\u7279\u5f81\u4e0e\u9ad8\u65af\u4f4d\u7f6e\u7684\u6b8b\u5dee\u5411\u91cf\uff0c\u5f25\u5408\u4e24\u79cd\u65b9\u6cd5\u7684\u7406\u8bba\u5dee\u5f02\uff0c\u589e\u5f3a3DGS\u7684\u4e2a\u6027\u5316\u5efa\u6a21\u80fd\u529b\u3002  \n\u25c6 \u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86NeRF\u4e0e3DGS\u7684\u4e92\u8865\u6027\u800c\u975e\u7ade\u4e89\u5173\u7cfb\uff0c\u4e3a\u6df7\u5408\u8868\u5f81\u65b9\u6cd5\u63d0\u4f9b\u65b0\u601d\u8def\u3002  \n\u25c6 \u4e3a\u7ed3\u5408\u663e\u5f0f\uff083DGS\uff09\u4e0e\u9690\u5f0f\uff08NeRF\uff09\u8868\u793a\u76843D\u573a\u666f\u9ad8\u6548\u5efa\u6a21\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002|\n",
    "2507.23033": "|2025-07-30|Adaptive Time-step Training for Enhancing Spike-Based Neural Radiance Fields|Ranxi Lin\u7b49|[2507.23033](http://arxiv.org/pdf/2507.23033)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u7684\u52a8\u6001\u65f6\u95f4\u6b65\u8bad\u7ec3\u7b56\u7565\uff08PATA\uff09\uff0c\u9996\u6b21\u5c06SNN\u7684\u8282\u80fd\u7279\u6027\u4e0eNeRF\u7684\u9ad8\u8d28\u91cf\u6e32\u67d3\u80fd\u529b\u76f8\u7ed3\u5408\u3002  \n\u25c6 \u901a\u8fc7\u9884\u8bad\u7ec3-\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u8c03\u6574\u673a\u5236\uff0c\u81ea\u52a8\u4f18\u5316\u6e32\u67d3\u8d28\u91cf\u4e0e\u65f6\u95f4\u6b65\u957f\u7684\u5e73\u8861\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfNeRF\u4f9d\u8d56\u5bc6\u96c6\u91c7\u6837\u5bfc\u81f4\u7684\u8d44\u6e90\u6d88\u8017\u95ee\u9898\u3002  \n\u25c6 \u5b9e\u73b0\u4e86\u573a\u666f\u81ea\u9002\u5e94\u7684\u52a8\u6001\u63a8\u7406\uff0c\u53ef\u6839\u636e\u4e0d\u540c\u573a\u666f\u7684\u5c3a\u5ea6\u548c\u7eb9\u7406\u590d\u6742\u5ea6\u7075\u6d3b\u8c03\u6574\u65f6\u95f4\u6b65\uff0c\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002  \n\u25c6 \u5728\u4fdd\u6301Instant-NGP\u67b6\u6784\u4f18\u52bf\u7684\u57fa\u7840\u4e0a\uff0c\u5b9e\u9a8c\u8bc1\u660ePATA\u80fd\u51cf\u5c1164%\u7684\u63a8\u7406\u65f6\u95f4\u6b65\u548c61.55%\u7684\u8fd0\u884c\u529f\u8017\uff0c\u540c\u65f6\u7ef4\u6301\u6e32\u67d3\u7cbe\u5ea6\u3002  \n\u25c6 \u4e3a\u8fb9\u7f18\u8ba1\u7b97\u7b49\u8d44\u6e90\u53d7\u9650\u573a\u666f\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u795e\u7ecf\u6e32\u67d3\u89e3\u51b3\u65b9\u6848\uff0c\u6269\u5c55\u4e86NeRF\u6280\u672f\u7684\u5e94\u7528\u8fb9\u754c\u3002|\n",
    "2508.02304": "|2025-08-04|ASDR: Exploiting Adaptive Sampling and Data Reuse for CIM-based Instant Neural Rendering|Fangxin Liu\u7b49|[2508.02304](http://arxiv.org/pdf/2508.02304)|\u65e0|\u25c6 \u63d0\u51faASDR\u7b97\u6cd5-\u67b6\u6784\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u5b58\u5185\u8ba1\u7b97(CIM)\u6280\u672f\u5e94\u7528\u4e8e\u5373\u65f6\u795e\u7ecf\u6e32\u67d3\u9886\u57df\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6848\u5ef6\u8fdf\u9ad8\u3001\u80fd\u6548\u5dee\u7684\u95ee\u9898\u3002  \n\u25c6 \u7b97\u6cd5\u5c42\u9762\u521b\u65b0\u6027\u5730\u5f15\u5165\u52a8\u6001\u91c7\u6837\u7b56\u7565\uff0c\u901a\u8fc7\u5b9e\u65f6\u611f\u77e5\u50cf\u7d20\u6e32\u67d3\u96be\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\u91c7\u6837\u70b9\uff0c\u663e\u8457\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\u548c\u8ba1\u7b97\u5f00\u9500\u3002  \n\u25c6 \u63d0\u51fa\u989c\u8272\u4e0e\u5bc6\u5ea6\u4f53\u6e32\u67d3\u89e3\u8026\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u79bbMLP\u8ba1\u7b97\u6d41\u7a0b\u964d\u4f4e\u795e\u7ecf\u7f51\u7edc\u8ba1\u7b97\u8d1f\u8377\uff0c\u5b9e\u73b0\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u3002  \n\u25c6 \u67b6\u6784\u5c42\u9762\u8bbe\u8ba1\u65b0\u578bReRAM\u5b58\u7b97\u67b6\u6784\uff0c\u521b\u65b0\u6027\u5730\u5f00\u53d1\u6570\u636e\u6620\u5c04\u4e0e\u91cd\u7528\u5fae\u67b6\u6784\uff0c\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u4ee5\u5339\u914d\u6e32\u67d3\u7279\u6027\u3002  \n\u25c6 \u5b9e\u9a8c\u9a8c\u8bc1\u53d6\u5f97\u7a81\u7834\u6027\u6027\u80fd\uff1a\u76f8\u6bd4\u5148\u8fdbNeRF\u52a0\u901f\u5668\u548cXavier NX GPU\u5206\u522b\u5b9e\u73b09.55\u500d\u548c69.75\u500d\u52a0\u901f\uff0c\u4ec5\u635f\u59310.1 PSNR\u753b\u8d28\u3002  \n\u25c6 \u6574\u4f53\u65b9\u6848\u9996\u6b21\u5728CIM\u786c\u4ef6\u4e0a\u5b9e\u73b0\u9ad8\u8d28\u91cf\u5b9e\u65f6\u795e\u7ecf\u6e32\u67d3\uff0c\u4e3a\u4f4e\u529f\u8017\u5373\u65f6\u56fe\u5f62\u751f\u6210\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002|\n",
    "2508.00967": "|2025-08-01|Cooperative Perception: A Resource-Efficient Framework for Multi-Drone 3D Scene Reconstruction Using Federated Diffusion and NeRF|Massoud Pourmandi|[2508.00967](http://arxiv.org/pdf/2508.00967)|\u65e0|\u25c6\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8054\u90a6\u5b66\u4e60\u548c\u6269\u6563\u6a21\u578b\u7684\u591a\u65e0\u4eba\u673a\u534f\u540c\u611f\u77e5\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u548c\u4f4e\u5e26\u5bbd\u901a\u4fe1\u4e0b\u7684\u5b9e\u65f63D\u573a\u666f\u91cd\u5efa\u96be\u9898\u3002  \n\u25c6\u521b\u65b0\u6027\u5730\u5c06\u6269\u6563\u6a21\u578b\u4e0eNeRF\u7ed3\u5408\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u8054\u5408\u573a\u666f\u5408\u6210\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u5e76\u4fdd\u6301\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u3002  \n\u25c6\u91c7\u7528\u8f7b\u91cf\u7ea7YOLOv12\u8fdb\u884c\u8bed\u4e49\u63d0\u53d6\uff0c\u914d\u5408\u5c40\u90e8NeRF\u66f4\u65b0\u7b56\u7565\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u3002  \n\u25c6\u8bbe\u8ba1\u4e86\u8bed\u4e49\u611f\u77e5\u538b\u7f29\u534f\u8bae\uff0c\u4f18\u5316\u4e86\u65e0\u4eba\u673a\u95f4\u7684\u6570\u636e\u4f20\u8f93\u6548\u7387\uff0c\u63d0\u5347\u4e86\u534f\u540c\u573a\u666f\u7406\u89e3\u80fd\u529b\u3002  \n\u25c6\u91cd\u65b0\u8bbe\u8ba1\u4e86\u751f\u6210\u5f0f\u6269\u6563\u6a21\u578b\u67b6\u6784\uff0c\u4f7f\u5176\u66f4\u9002\u5408\u591a\u89c6\u89d2\u8054\u5408\u573a\u666f\u91cd\u5efa\u4efb\u52a1\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002  \n\u25c6\u901a\u8fc7\u4eff\u771f\u548c\u771f\u5b9e\u65e0\u4eba\u673a\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u591a\u667a\u80fd\u4f53AI\u63d0\u4f9b\u4e86\u7a81\u7834\u6027\u8fdb\u5c55\u3002|\n",
    "2508.02831": "|2025-08-04|GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing|Miko\u0142aj Zieli\u0144ski\u7b49|[2508.02831](http://arxiv.org/pdf/2508.02831)|\u65e0|\u25c6 \u63d0\u51faGENIE\u6df7\u5408\u6a21\u578b\uff0c\u7ed3\u5408NeRF\u7684\u9ad8\u8d28\u91cf\u6e32\u67d3\u4e0e\u9ad8\u65af\u6cfc\u6e85(GS)\u7684\u53ef\u7f16\u8f91\u6027\uff0c\u5b9e\u73b0\u65e2\u903c\u771f\u53c8\u53ef\u4ea4\u4e92\u76843D\u573a\u666f\u8868\u793a\u3002  \n\u25c6 \u91c7\u7528\u53ef\u8bad\u7ec3\u7279\u5f81\u5d4c\u5165\u66ff\u4ee3\u4f20\u7edf\u7403\u8c10\u51fd\u6570\uff0c\u901a\u8fc7\u6bcf\u4e2a\u9ad8\u65af\u70b9\u9644\u8fd1\u7684k\u8fd1\u90bb\u6761\u4ef6\u5316NeRF\u7f51\u7edc\uff0c\u589e\u5f3a\u5c40\u90e8\u7f16\u8f91\u80fd\u529b\u3002  \n\u25c6 \u8bbe\u8ba1RT-GPS\uff08\u5149\u7ebf\u8ffd\u8e2a\u9ad8\u65af\u90bb\u8fd1\u641c\u7d22\uff09\u7b97\u6cd5\uff0c\u57fa\u4e8e\u6539\u8fdb\u7684\u5149\u7ebf\u8ffd\u8e2a\u7ba1\u7ebf\u5feb\u901f\u5b9a\u4f4d\u6700\u8fd1\u9ad8\u65af\u70b9\uff0c\u63d0\u5347\u67e5\u8be2\u6548\u7387\u3002  \n\u25c6 \u5f15\u5165\u591a\u5206\u8fa8\u7387\u54c8\u5e0c\u7f51\u683c\u521d\u59cb\u5316\u4e0e\u66f4\u65b0\u9ad8\u65af\u7279\u5f81\uff0c\u652f\u6301\u52a8\u6001\u573a\u666f\u7684\u5b9e\u65f6\u7279\u5f81\u8c03\u6574\u3002  \n\u25c6 \u5b9e\u73b0\u5b9e\u65f6\u5c40\u90e8\u611f\u77e5\u7f16\u8f91\uff1a\u9ad8\u65af\u57fa\u5143\u7684\u4f4d\u7f6e\u6216\u5c5e\u6027\u4fee\u6539\u80fd\u5373\u65f6\u5f71\u54cd\u6e32\u67d3\u7ed3\u679c\uff0c\u4fdd\u7559NeRF\u7684\u8fde\u7eed\u6027\u4f18\u52bf\u3002  \n\u25c6 \u5f25\u5408\u9690\u5f0f\u795e\u7ecf\u6e32\u67d3\u4e0e\u663e\u5f0f\u51e0\u4f55\u7f16\u8f91\u7684\u9e3f\u6c9f\uff0c\u517c\u5bb9\u7269\u7406\u6a21\u62df\uff0c\u4e3a\u4ea4\u4e92\u5f0f\u521b\u4f5c\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002|\n",
    "2508.04326": "|2025-08-07|Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research|Ke Li\u7b49|[2508.04326](http://arxiv.org/pdf/2508.04326)|\u65e0|\u25c6 \u7cfb\u7edf\u68b3\u7406\u4e86365\u7bc7\u8f90\u5c04\u573a\uff08RF\uff09\u76f8\u5173\u6587\u732e\uff0c\u9996\u6b21\u5168\u9762\u5206\u6790RF\u6280\u672f\u5728XR\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u4e0e\u7814\u7a76\u73b0\u72b6\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u8c03\u7814\u7a7a\u767d\u3002  \n\u25c6 \u63d0\u51fa\u4e09\u7ef4\u5206\u6790\u6846\u67b6\uff1a\u4eceXR\u5e94\u7528\u613f\u666f\uff08i\uff09\u3001\u73b0\u6709\u6280\u672f\u5b9e\u73b0\uff08ii\uff09\u548c\u7814\u7a76\u7f3a\u53e3\uff08iii\uff09\u4e09\u4e2a\u7ef4\u5ea6\u89e3\u6784RF\u4e0eXR\u7684\u4ea4\u53c9\u7814\u7a76\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u7ed3\u6784\u5316\u89c6\u89d2\u3002  \n\u25c6 \u7b5b\u900966\u7bc7\u6838\u5fc3\u8bba\u6587\u8fdb\u884c\u6df1\u5ea6\u5206\u6790\uff0c\u63ed\u793aRF\u5728XR\u4e2d\u7684\u5177\u4f53\u6280\u672f\u8def\u5f84\uff08\u59823DGS/NeRF\u7684\u4ea4\u4e92\u6027\u4f18\u5316\uff09\uff0c\u6bd4\u4f20\u7edf\u7efc\u8ff0\u66f4\u5177\u6280\u672f\u9897\u7c92\u5ea6\u3002  \n\u25c6 \u5c06XR\u7279\u5f02\u6027\u7814\u7a76\u95ee\u9898\uff08\u5982\u5b9e\u65f6\u6e32\u67d3\u3001\u7528\u6237\u4ea4\u4e92\uff09\u5d4c\u5165\u5e7f\u4e49RF\u7814\u7a76\u7248\u56fe\uff0c\u660e\u786eXR\u793e\u533a\u7684\u72ec\u7279\u6280\u672f\u6311\u6218\u4e0e\u673a\u9047\u3002  \n\u25c6 \u6784\u5efa\u8de8\u5b66\u79d1\u6587\u732e\u8d44\u6e90\u5e93\uff0c\u8986\u76d6\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u56fe\u5f62\u5b66\u3001\u4eba\u673a\u4ea4\u4e92\u7b496\u5927\u9886\u57df\uff0c\u52a9\u529b\u7814\u7a76\u8005\u5feb\u901f\u5b9a\u4f4dXR\u76f8\u5173RF\u6280\u672f\u8fdb\u5c55\u3002  \n\u25c6 \u901a\u8fc7\u91cf\u5316\u5206\u6790\u6307\u51faRF\u5728XR\u9886\u57df\u7684\u7814\u7a76\u7a00\u758f\u6027\uff0c\u63a8\u52a8\u5b66\u754c\u5173\u6ce8\u8fd9\u4e00\u6f5c\u529b\u5de8\u5927\u7684\u4ea4\u53c9\u65b9\u5411\u3002|\n",
    "2508.04297": "|2025-08-06|MuGS: Multi-Baseline Generalizable Gaussian Splatting Reconstruction|Yaopeng Lou\u7b49|[2508.04297](http://arxiv.org/pdf/2508.04297)|\u65e0|\u25c6 \u63d0\u51faMuGS\u65b9\u6cd5\uff0c\u9996\u6b21\u5c06\u591a\u57fa\u7ebf\u8bbe\u7f6e\uff08\u5305\u62ec\u7a00\u758f\u89c6\u89d2\u4e0b\u7684\u5c0f/\u5927\u57fa\u7ebf\uff09\u7edf\u4e00\u6574\u5408\u5230\u57fa\u4e8e\u9ad8\u65af\u6cfc\u6e85\u7684\u6cdb\u5316\u6027\u65b0\u89c6\u89d2\u5408\u6210\u6846\u67b6\u4e2d\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u878d\u5408\u591a\u89c6\u89d2\u7acb\u4f53\u89c6\u89c9\uff08MVS\uff09\u4e0e\u5355\u76ee\u6df1\u5ea6\u4f30\u8ba1\uff08MDE\uff09\u7279\u5f81\uff0c\u589e\u5f3a\u8de8\u573a\u666f\u7684\u6cdb\u5316\u91cd\u5efa\u80fd\u529b\u3002  \n\u25c6 \u8bbe\u8ba1\u6295\u5f71-\u91c7\u6837\u673a\u5236\u7684\u6df1\u5ea6\u878d\u5408\u6a21\u5757\uff0c\u901a\u8fc7\u7cbe\u7ec6\u6982\u7387\u4f53\u79ef\u6784\u5efa\u6307\u5bfc\u7279\u5f81\u56fe\u56de\u5f52\uff0c\u63d0\u5347\u51e0\u4f55\u7cbe\u5ea6\u3002  \n\u25c6 \u5f15\u5165\u53c2\u8003\u89c6\u56fe\u635f\u5931\u51fd\u6570\uff0c\u663e\u8457\u4f18\u5316\u51e0\u4f55\u4e00\u81f4\u6027\u5e76\u52a0\u901f\u8bad\u7ec3\u6536\u655b\u6548\u7387\u3002  \n\u25c6 \u91c7\u75283D\u9ad8\u65af\u8868\u5f81\u5b9e\u73b0\u8bad\u7ec3/\u63a8\u7406\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u4f18\u4e8e\u795e\u7ecf\u8f90\u5c04\u573a\u7684\u6e32\u67d3\u8d28\u91cf\u3002  \n\u25c6 \u5728DTU\u7b80\u5355\u7269\u4f53\u5230RealEstate10K\u590d\u6742\u573a\u666f\u7684\u8de8\u6570\u636e\u96c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\uff0c\u5e76\u5728LLFF\u7b49\u6570\u636e\u96c6\u5c55\u73b0\u96f6\u6837\u672c\u8fc1\u79fb\u6f5c\u529b\u3002|\n",
    "2508.05187": "|2025-08-07|Refining Gaussian Splatting: A Volumetric Densification Approach|Mohamed Abdul Gafoor\u7b49|[2508.05187](http://arxiv.org/pdf/2508.05187)|\u65e0|\u25c6 \u63d0\u51fa\u57fa\u4e8e\u60ef\u6027\u4f53\u79ef\u7684\u65b0\u578b\u5bc6\u5ea6\u63a7\u5236\u65b9\u6cd5\uff0c\u5229\u7528\u9ad8\u65af\u51fd\u6570\u7684\u60ef\u6027\u4f53\u79ef\u6307\u5bfc3D\u9ad8\u65af\u5206\u5e03\u7684\u7cbe\u7ec6\u5316\u8fc7\u7a0b\uff0c\u6539\u8fdb\u539f\u59cb3DGS\u7684\u5bc6\u5ea6\u63a7\u5236\u7b56\u7565\u3002  \n\u25c6 \u7cfb\u7edf\u7814\u7a76\u4e86\u4f20\u7edf\u8fd0\u52a8\u6062\u590d\u7ed3\u6784(SfM)\u4e0e\u6df1\u5ea6\u56fe\u50cf\u5339\u914d(DIM)\u4e24\u79cd\u70b9\u4e91\u521d\u59cb\u5316\u65b9\u6cd5\u5bf9\u91cd\u5efa\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u4e3a\u521d\u59cb\u5316\u9009\u62e9\u63d0\u4f9b\u4f9d\u636e\u3002  \n\u25c6 \u5728Mip-NeRF 360\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u91cd\u5efa\u8d28\u91cf\u4e0a\u4f18\u4e8e\u539f\u59cb3DGS\uff0c\u5728\u4e0d\u540c\u573a\u666f\u4e2d\u5747\u8868\u73b0\u51fa\u8272\u3002  \n\u25c6 \u89e3\u51b3\u4e86\u539f\u59cb3DGS\u81ea\u9002\u5e94\u5bc6\u5ea6\u63a7\u5236(ADC)\u5728\u70b9\u57fa\u5143\u7ba1\u7406\u4e0a\u7684\u5173\u952e\u7f3a\u9677\uff0c\u63d0\u5347\u4e86\u65b0\u89c6\u89d2\u5408\u6210\u7684\u6548\u679c\u3002  \n\u25c6 \u901a\u8fc7\u66f4\u7cbe\u7ec6\u7684\u5bc6\u5ea6\u63a7\u5236\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u5bf9\u9ad8\u65af\u5206\u5e03\u66f4\u5408\u7406\u7684\u5206\u88c2\u4e0e\u526a\u679d\u64cd\u4f5c\uff0c\u4f18\u5316\u4e86\u573a\u666f\u8868\u793a\u3002|\n",
    "2508.05064": "|2025-08-07|A Study of the Framework and Real-World Applications of Language Embedding for 3D Scene Understanding|Mahmoud Chick Zaouali\u7b49|[2508.05064](http://arxiv.org/pdf/2508.05064)|\u65e0|\u25c6 \u9996\u6b21\u7cfb\u7edf\u7efc\u8ff0\u4e86\u8bed\u8a00\u5d4c\u5165\u4e0e3D\u9ad8\u65af\u6cfc\u6e85\uff08Gaussian Splatting\uff09\u7ed3\u5408\u7684\u8de8\u9886\u57df\u7814\u7a76\uff0c\u586b\u8865\u4e86\u8be5\u65b0\u5174\u4ea4\u53c9\u9886\u57df\u7684\u7a7a\u767d\u3002  \n\u25c6 \u63d0\u51fa\u8bed\u8a00\u5f15\u5bfc\u76843D\u573a\u666f\u7406\u89e3\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5b9e\u73b0\u6587\u672c\u6761\u4ef6\u751f\u6210\u3001\u7f16\u8f91\u548c\u8bed\u4e49\u7406\u89e3\uff0c\u6269\u5c55\u4e86\u9ad8\u65af\u6cfc\u6e85\u7684\u5e94\u7528\u573a\u666f\u3002  \n\u25c6 \u8be6\u7ec6\u5206\u6790\u4e86\u8bed\u8a00\u4e0e3D\u9ad8\u65af\u8868\u5f81\u878d\u5408\u7684\u7406\u8bba\u57fa\u7840\u548c\u6280\u672f\u8def\u5f84\uff0c\u5305\u62ec\u5d4c\u5165\u7b56\u7565\u3001\u8bed\u4e49\u5bf9\u9f50\u65b9\u6cd5\u53ca\u5b9e\u65f6\u6e32\u67d3\u4f18\u5316\u65b9\u6848\u3002  \n\u25c6 \u603b\u7ed3\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5982\u8ba1\u7b97\u6548\u7387\u74f6\u9888\u3001\u6cdb\u5316\u6027\u4e0d\u8db3\u53ca\u8bed\u4e49\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002  \n\u25c6 \u68b3\u7406\u4e86\u673a\u5668\u4eba\u3001\u4ea4\u4e92\u5185\u5bb9\u521b\u4f5c\u7b49\u9886\u57df\u7684\u843d\u5730\u6848\u4f8b\uff0c\u9a8c\u8bc1\u4e86\u8bed\u8a00\u589e\u5f3a\u578b3D\u5efa\u6a21\u7684\u5b9e\u7528\u4ef7\u503c\u3002|\n",
    "2508.06169": "|2025-08-08|UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting|Wenpeng Xing\u7b49|[2508.06169](http://arxiv.org/pdf/2508.06169)|\u65e0|\u8fd9\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u901a\u8fc7\u6539\u8fdb3D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\uff083DGS\uff09\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u6c34\u4e0b\u4e09\u7ef4\u91cd\u5efa\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u56e0\u6c34\u4e0b\u5149\u7ebf\u5438\u6536\u3001\u6563\u5c04\u548c\u6d51\u6d4a\u5ea6\u5bfc\u81f4\u7684\u51e0\u4f55\u4e0e\u8272\u5f69\u5931\u771f\u95ee\u9898\u3002\u4e3b\u8981\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\n\u25c6 \u63d0\u51fa\u53ef\u63d2\u62d4\u7684\u5b66\u4e60\u578b\u6c34\u4e0b\u6210\u50cf\u6a21\u5757\uff0c\u91c7\u7528\u57fa\u4e8e\u4f53\u7d20\u7684\u56de\u5f52\u65b9\u6cd5\u6a21\u62df\u7a7a\u95f4\u53d8\u5316\u7684\u8870\u51cf\u548c\u80cc\u6563\u5c04\u6548\u5e94\uff0c\u63d0\u5347\u989c\u8272\u4fdd\u771f\u5ea6\u3002\n\n\u25c6 \u8bbe\u8ba1\u4e86\u7269\u7406\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u526a\u679d\uff08PAUP\uff09\u5206\u652f\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u8bc4\u5206\u81ea\u9002\u5e94\u5254\u9664\u566a\u58f0\u9ad8\u65af\u70b9\uff0c\u663e\u8457\u51cf\u5c11\u6d6e\u6e38\u4f2a\u5f71\uff08\u964d\u4f4e\u7ea665%\uff09\u3002\n\n\u25c6 \u6784\u5efa\u4e86\u7aef\u5230\u7aef\u8bad\u7ec3\u6846\u67b6\uff0c\u540c\u6b65\u4f18\u5316\u9ad8\u65af\u70b9\u53c2\u6570\u4e0e\u6c34\u4e0b\u7269\u7406\u6a21\u578b\u53c2\u6570\uff0c\u5b9e\u73b0\u51e0\u4f55\u4e0e\u5149\u4f20\u8f93\u7684\u8054\u5408\u5efa\u6a21\u3002\n\n\u25c6 \u5728\u6e32\u67d3\u9636\u6bb5\u751f\u6210\u4e24\u79cd\u8f93\u51fa\uff1a\u53bb\u9664\u4ecb\u8d28\u5f71\u54cd\u7684\u7eaf\u51c0\u672a\u8870\u51cf\u8f90\u5c04\u56fe\u50cf\uff08URI\uff09\u548c\u5305\u542b\u771f\u5b9e\u5149\u4f20\u8f93\u6548\u679c\u7684\u6c34\u4e0b\u56fe\u50cf\uff08UWI\uff09\u3002\n\n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728SeaThru-NeRF\u548cUWBundle\u6570\u636e\u96c6\u4e0a\u8fbe\u5230PSNR 27.604\u3001SSIM 0.868\u3001LPIPS 0.104\u7684\u6307\u6807\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002|\n",
    "2508.06136": "|2025-08-08|Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation|YoungChan Choi\u7b49|[2508.06136](http://arxiv.org/pdf/2508.06136)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u663e\u5f0f3D\u773c\u7403\u7ed3\u6784\u7684\u89c6\u7ebf\u91cd\u5b9a\u5411\u6846\u67b6\uff0c\u7a81\u7834\u4f20\u7edf\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u9690\u5f0f\u8868\u793a\u7684\u5c40\u9650\u3002  \n\u25c6 \u91c7\u75283D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u6280\u672f\u7cbe\u786e\u5efa\u6a21\u773c\u7403\uff0c\u901a\u8fc7\u663e\u5f0f\u65cb\u8f6c\u548c\u5e73\u79fb\u63a7\u5236\u89c6\u7ebf\u65b9\u5411\uff0c\u63d0\u5347\u7269\u7406\u5408\u7406\u6027\u3002  \n\u25c6 \u521b\u65b0\u6027\u8bbe\u8ba1\u81ea\u9002\u5e94\u5f62\u53d8\u6a21\u5757\uff0c\u6a21\u62df\u773c\u90e8\u5468\u56f4\u808c\u8089\u7684\u7ec6\u5fae\u8fd0\u52a8\uff0c\u589e\u5f3a\u751f\u6210\u56fe\u50cf\u7684\u52a8\u6001\u771f\u5b9e\u611f\u3002  \n\u25c6 \u5728ETH-XGaze\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u751f\u6210\u56fe\u50cf\u7684\u5149\u5f71\u3001\u7eb9\u7406\u8d28\u91cf\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u89c6\u7ebf\u4f30\u8ba1\u7cbe\u5ea6\u66f4\u9ad8\u3002  \n\u25c6 \u6846\u67b6\u652f\u6301\u591a\u6837\u5316\u65b0\u89c6\u7ebf\u751f\u6210\uff0c\u4e3a\u865a\u62df\u73b0\u5b9e\u3001\u4eba\u673a\u4ea4\u4e92\u7b49\u573a\u666f\u63d0\u4f9b\u9ad8\u4fdd\u771f\u773c\u90e8\u8fd0\u52a8\u5408\u6210\u65b9\u6848\u3002|\n",
    "2508.05819": "|2025-08-07|MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses|Jong-Ik Park\u7b49|[2508.05819](http://arxiv.org/pdf/2508.05819)|\u65e0|\u25c6 \u63d0\u51fa\u9996\u4e2a\u539f\u751f\u652f\u6301\u591a\u7f29\u653e\u56fe\u50cf\u96c6\u7684NeRF\u6846\u67b6MZEN\uff0c\u89e3\u51b3\u4e86\u5de5\u4e1a\u68c0\u6d4b\u4e2d\u9ad8\u7cbe\u5ea6\u7ec6\u8282\u91cd\u5efa\u7684\u96be\u9898\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5728\u9488\u5b54\u76f8\u673a\u6a21\u578b\u4e2d\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u7f29\u653e\u6807\u91cf\uff0c\u52a8\u6001\u8c03\u6574\u7126\u8ddd\u4ee5\u9002\u5e94\u4e0d\u540c\u7f29\u653e\u7ea7\u522b\u7684\u56fe\u50cf\u3002  \n\u25c6 \u8bbe\u8ba1\u5206\u5c42\u4f4d\u59ff\u4f18\u5316\u7b56\u7565\uff1a\u5148\u901a\u8fc7\u5e7f\u89d2\u56fe\u50cf\u5efa\u7acb\u5168\u5c40\u5750\u6807\u7cfb\uff0c\u518d\u901a\u8fc7\u7f29\u653e\u4e00\u81f4\u88c1\u526a\u5339\u914d\u65b9\u6cd5\u5c06\u653e\u5927\u56fe\u50cf\u4e0e\u6700\u8fd1\u5e7f\u89d2\u56fe\u50cf\u5bf9\u9f50\uff0c\u6700\u540e\u8054\u5408\u4f18\u5316\u3002  \n\u25c6 \u5728\u5408\u6210TCAD\u6a21\u578b\u3001\u771f\u5b9eSEM\u5fae\u7ed3\u6784\u7b498\u4e2a\u573a\u666f\u4e2d\u9a8c\u8bc1\u6709\u6548\u6027\uff0cPSNR\u63d0\u5347\u6700\u9ad8\u8fbe28%\uff0cSSIM\u63d0\u534710%\uff0cLPIPS\u964d\u4f4e222%\u3002  \n\u25c6 \u7a81\u7834\u4f20\u7edfNeRF\u5728\u591a\u7f29\u653e\u573a\u666f\u4e0b\u7684\u9650\u5236\uff0c\u9996\u6b21\u5b9e\u73b0\u5168\u5c40\u7cbe\u5ea6\u4e0e\u5fae\u7c73\u7ea7\u7ec6\u8282\u7684\u534f\u540c\u6355\u6349\uff0c\u63a8\u52a8NeRF\u5728\u5de5\u4e1a\u68c0\u6d4b\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u3002|\n",
    "2508.08219": "|2025-08-11|SAGOnline: Segment Any Gaussians Online|Wentao Sun\u7b49|[2508.08219](http://arxiv.org/pdf/2508.08219)|\u65e0|SAGOnline\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u548c\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u9996\u4e2a\u8f7b\u91cf\u7ea7\u96f6\u6837\u672c\u6846\u67b6SAGOnline\uff0c\u5b9e\u73b0\u9ad8\u65af\u573a\u666f\u7684\u5b9e\u65f63D\u5206\u5272\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002\n\n\u25c6 \u91c7\u7528\u89e3\u8026\u7b56\u7565\u6574\u5408\u89c6\u9891\u57fa\u7840\u6a21\u578b\uff08\u5982SAM2\uff09\uff0c\u901a\u8fc7\u5408\u6210\u89c6\u56fe\u95f4\u76842D\u63a9\u7801\u4f20\u64ad\u5b9e\u73b0\u8de8\u89c6\u89d2\u4e00\u81f4\u6027\u5206\u5272\u3002\n\n\u25c6 \u5f00\u53d1GPU\u52a0\u901f\u76843D\u63a9\u7801\u751f\u6210\u7b97\u6cd5\uff0c\u901a\u8fc7\u9ad8\u65af\u7ea7\u5b9e\u4f8b\u6807\u6ce8\u4e3a3D\u56fe\u5143\u5206\u914d\u552f\u4e00ID\uff0c\u652f\u6301\u65e0\u635f\u591a\u76ee\u6807\u8ddf\u8e2a\u4e0e\u8de8\u89c6\u89d2\u5206\u5272\u3002\n\n\u25c6 \u5728NVOS\uff0892.7% mIoU\uff09\u548cSpin-NeRF\uff0895.2% mIoU\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u63a8\u7406\u901f\u5ea6\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb15-1500\u500d\uff0827\u6beb\u79d2/\u5e27\uff09\u3002\n\n\u25c6 \u521b\u65b0\u6027\u5c062D\u89c6\u9891\u57fa\u7840\u6a21\u578b\u9002\u914d\u52303D\u9886\u57df\uff0c\u9996\u6b21\u5b9e\u73b0\u590d\u6742\u573a\u666f\u4e2d\u7a33\u5065\u7684\u591a\u76ee\u6807\u5206\u5272\u4e0e\u8ddf\u8e2a\u3002\n\n\u25c6 \u901a\u8fc7\u663e\u5f0f\u6807\u6ce8\u9ad8\u65af\u56fe\u5143\uff0c\u540c\u65f6\u652f\u6301\u5206\u5272\u4e0e\u8ddf\u8e2a\u529f\u80fd\uff0c\u4e3aAR/VR\u548c\u673a\u5668\u4eba\u5e94\u7528\u63d0\u4f9b\u5b9e\u65f63D\u573a\u666f\u7406\u89e3\u65b0\u65b9\u6848\u3002|\n",
    "2508.07182": "|2025-08-10|3D Gaussian Representations with Motion Trajectory Field for Dynamic Scene Reconstruction|Xuesong Li\u7b49|[2508.07182](http://arxiv.org/pdf/2508.07182)|\u65e0|\u25c6 \u63d0\u51fa\u7ed3\u54083D\u9ad8\u65af\u6cfc\u6e85\u4e0e\u8fd0\u52a8\u8f68\u8ff9\u573a\u7684\u65b0\u65b9\u6cd5\uff0c\u9996\u6b21\u5b9e\u73b0\u52a8\u6001\u573a\u666f\u4e2d\u590d\u6742\u8fd0\u52a8\u7684\u7cbe\u786e\u5efa\u6a21\u4e0e\u7269\u7406\u5408\u7406\u8f68\u8ff9\u751f\u6210\u3002  \n\u25c6 \u901a\u8fc7\u52a8\u6001\u7269\u4f53\u4e0e\u9759\u6001\u80cc\u666f\u89e3\u8026\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u8fd0\u52a8\u8f68\u8ff9\u573a\u7684\u4f18\u5316\u6548\u7387\u4e0e\u573a\u666f\u8868\u793a\u7d27\u51d1\u6027\u3002  \n\u25c6 \u521b\u65b0\u91c7\u7528\u65f6\u95f4\u4e0d\u53d8\u8fd0\u52a8\u7cfb\u6570\u548c\u5171\u4eab\u8fd0\u52a8\u8f68\u8ff9\u57fa\uff0c\u5728\u6355\u6349\u590d\u6742\u8fd0\u52a8\u6a21\u5f0f\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4f18\u5316\u590d\u6742\u5ea6\u3002  \n\u25c6 \u5b9e\u73b0\u5355\u76ee\u89c6\u9891\u4e2d\u52a8\u6001\u573a\u666f\u7684\u9ad8\u8d28\u91cf\u65b0\u89c6\u89d2\u5408\u6210\u4e0e\u8fd0\u52a8\u8f68\u8ff9\u91cd\u5efa\u53cc\u7a81\u7834\uff0c\u6027\u80fd\u8fbe\u5230\u5f53\u524d\u6700\u4f18\u6c34\u5e73\u3002  \n\u25c6 \u6240\u63d0\u65b9\u6cd5\u4e3a\u673a\u5668\u4eba\u7b49\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u9996\u4e2a\u80fd\u540c\u65f6\u5904\u7406\u52a8\u6001\u6e32\u67d3\u4e0e\u8fd0\u52a8\u63a8\u7406\u7684\u7edf\u4e00\u6846\u67b6\u3002  \n\u25c6 \u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6848\u5728\u8fd0\u52a8\u7ec6\u8282\u8fd8\u539f\u548c\u7269\u7406\u5408\u7406\u6027\u65b9\u9762\u8d85\u8d8a\u73b0\u6709\u52a8\u6001NeRF\u4e0e3DGS\u65b9\u6cd5\u7684\u4f18\u52bf\u3002|\n",
    "2508.06632": "|2025-08-08|CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition|Wenpeng Xing\u7b49|[2508.06632](http://arxiv.org/pdf/2508.06632)|\u65e0|\u25c6 \u63d0\u51fa\u52a8\u6001\u7cfb\u6570\u5206\u89e3\u6846\u67b6CoDe-NeRF\uff0c\u5c06\u590d\u6742\u5916\u89c2\u89e3\u8026\u4e3a\u9759\u6001\u795e\u7ecf\u57fa\u5e95\uff08\u7f16\u7801\u6750\u8d28\u5c5e\u6027\uff09\u548c\u52a8\u6001\u7cfb\u6570\uff08\u7531\u89c6\u89d2/\u5149\u7167\u6761\u4ef6\u751f\u6210\uff09\uff0c\u7a81\u7834\u4f20\u7edfNeRF\u5bf9\u955c\u9762\u53cd\u5c04\u5efa\u6a21\u7684\u5c40\u9650\u3002  \n\u25c6 \u8bbe\u8ba1\u7cfb\u6570\u7f51\u7edc\uff08Coefficient Network\uff09\u52a8\u6001\u751f\u6210\u4e0e\u89c6\u89d2/\u5149\u7167\u76f8\u5173\u7684\u7cfb\u6570\uff0c\u914d\u5408\u9759\u6001\u57fa\u5e95\u5b9e\u73b0\u9ad8\u6548\u7684\u5149-\u7269\u7406\u89e3\u8026\uff0c\u907f\u514d\u9006\u5411\u6e32\u67d3\u7684\u4e0d\u7a33\u5b9a\u6027\u3002  \n\u25c6 \u5f15\u5165\u52a8\u6001\u8f90\u5c04\u79ef\u5206\u5668\uff08Dynamic Radiance Integrator\uff09\u81ea\u9002\u5e94\u878d\u5408\u9759\u6001\u57fa\u5e95\u4e0e\u52a8\u6001\u7cfb\u6570\uff0c\u663e\u8457\u63d0\u5347\u9ad8\u5149\u4e0e\u955c\u9762\u53cd\u5c04\u7684\u9510\u5229\u5ea6\u548c\u771f\u5b9e\u611f\u3002  \n\u25c6 \u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u590d\u6742\u53cd\u5c04\u573a\u666f\u4e2d\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u80fd\u751f\u6210\u66f4\u6e05\u6670\u7684\u955c\u9762\u6548\u679c\uff0c\u4e14\u65e0\u9700\u4f9d\u8d56\u7269\u7406\u9006\u5411\u6e32\u67d3\u7684\u5f3a\u5047\u8bbe\u3002  \n\u25c6 \u4e3a\u795e\u7ecf\u573a\u666f\u8868\u793a\u4e2d\u7684\u590d\u6742\u5916\u89c2\u5efa\u6a21\u63d0\u4f9b\u4e86\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u89e3\u8026\u5f0f\u8bbe\u8ba1\u589e\u5f3a\u4e86\u5bf9\u52a8\u6001\u5149\u7167\u6761\u4ef6\u7684\u9002\u5e94\u6027\u3002|\n",
    "2508.08798": "|2025-08-12|MonoPartNeRF:Human Reconstruction from Monocular Video via Part-Based Neural Radiance Fields|Yao Lu\u7b49|[2508.08798](http://arxiv.org/pdf/2508.08798)|\u65e0|\u25c6 \u63d0\u51faMonoPartNeRF\u6846\u67b6\uff0c\u9996\u6b21\u5c06\u57fa\u4e8e\u5206\u533a\u7684\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u5e94\u7528\u4e8e\u5355\u76ee\u89c6\u9891\u4eba\u4f53\u91cd\u5efa\uff0c\u89e3\u51b3\u4e86\u590d\u6742\u59ff\u6001\u4e0b\u8fb9\u754c\u8fc7\u6e21\u4e0d\u81ea\u7136\u548c\u906e\u6321\u533a\u57df\u91cd\u5efa\u4e0d\u51c6\u7684\u96be\u9898\u3002  \n\u25c6 \u8bbe\u8ba1\u53cc\u5411\u53d8\u5f62\u6a21\u578b\uff0c\u7ed3\u5408\u521a\u6027\u4e0e\u975e\u521a\u6027\u53d8\u6362\uff0c\u5efa\u7acb\u89c2\u5bdf\u7a7a\u95f4\u4e0e\u89c4\u8303\u7a7a\u95f4\u7684\u53ef\u9006\u8fde\u7eed\u6620\u5c04\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u8868\u9762-\u65f6\u95f4\u7a7a\u95f4\uff08u, v, t\uff09\u66f4\u7cbe\u51c6\u6355\u6349\u975e\u521a\u6027\u8fd0\u52a8\u3002  \n\u25c6 \u5f15\u5165\u4e00\u81f4\u6027\u635f\u5931\u51fd\u6570\uff0c\u6709\u6548\u6291\u5236\u53d8\u5f62\u5bfc\u81f4\u7684\u4f2a\u5f71\u548c\u65ad\u88c2\u95ee\u9898\uff0c\u63d0\u5347\u91cd\u5efa\u7684\u51e0\u4f55\u8fde\u8d2f\u6027\u3002  \n\u25c6 \u521b\u65b0\u63d0\u51fa\u5206\u533a\u59ff\u6001\u5d4c\u5165\u673a\u5236\uff0c\u5c06\u5168\u5c40\u59ff\u6001\u5411\u91cf\u5206\u89e3\u4e3a\u5c40\u90e8\u5173\u8282\u5d4c\u5165\uff0c\u7ed3\u5408\u4e09\u8f74\u65b9\u5411\u7684\u5173\u952e\u5e27\u59ff\u6001\u68c0\u7d22\u4e0e\u63d2\u503c\uff0c\u5b9e\u73b0\u7cbe\u51c6\u7684\u59ff\u52bf\u611f\u77e5\u7279\u5f81\u91c7\u6837\u3002  \n\u25c6 \u96c6\u6210\u53ef\u5b66\u4e60\u7684\u5916\u89c2\u7f16\u7801\u4e0e\u6ce8\u610f\u529b\u673a\u5236\uff0c\u52a8\u6001\u5efa\u6a21\u7eb9\u7406\u53d8\u5316\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u906e\u6321\u4e0b\u7684\u7eb9\u7406\u4fdd\u771f\u5ea6\u3002\u5b9e\u9a8c\u5728ZJU-MoCap\u548cMonoCap\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5728\u59ff\u6001\u9002\u5e94\u6027\u4e0e\u906e\u6321\u6062\u590d\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002|\n",
    "2508.09977": "|2025-08-22|A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation|Shuting He\u7b49|[2508.09977](http://arxiv.org/pdf/2508.09977)|\u65e0|\u25c6 \u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u7efc\u8ff0\u4e863D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u6280\u672f\u5728\u5206\u5272\u3001\u7f16\u8f91\u548c\u751f\u6210\u7b49\u5e94\u7528\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u8c03\u7814\u7a7a\u767d\u3002  \n\u25c6 \u901a\u8fc7\u5f15\u51652D\u57fa\u7840\u6a21\u578b\u4e0eNeRF\u65b9\u6cd5\u7684\u5bf9\u6bd4\u5206\u6790\uff0c\u63ed\u793a\u4e863DGS\u5728\u8bed\u4e49\u7406\u89e3\u548c\u51e0\u4f55\u63a7\u5236\u65b9\u9762\u7684\u72ec\u7279\u4f18\u52bf\uff0c\u7a81\u51fa\u4e86\u5176\u663e\u5f0f\u7d27\u51d1\u8868\u793a\u7684\u6f5c\u529b\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u5c063DGS\u5e94\u7528\u5212\u5206\u4e3a\u5206\u5272\u3001\u7f16\u8f91\u3001\u751f\u6210\u7b49\u529f\u80fd\u4efb\u52a1\uff0c\u5e76\u603b\u7ed3\u4e86\u5404\u7c7b\u4efb\u52a1\u7684\u4ee3\u8868\u6027\u65b9\u6cd5\u3001\u76d1\u7763\u7b56\u7565\u548c\u5b66\u4e60\u8303\u5f0f\uff0c\u63d0\u70bc\u51fa\u901a\u7528\u8bbe\u8ba1\u539f\u5219\u3002  \n\u25c6 \u63d0\u4f9b\u4e86\u516c\u5f00\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\u7684\u8be6\u7ec6\u603b\u7ed3\uff0c\u5e76\u5bf9\u73b0\u6709\u65b9\u6cd5\u5728\u516c\u5171\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u6a2a\u5411\u5bf9\u6bd4\u5206\u6790\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u6846\u67b6\u3002  \n\u25c6 \u5efa\u7acb\u4e86\u6301\u7eed\u66f4\u65b0\u7684\u5f00\u6e90\u8d44\u6e90\u5e93\uff08GitHub\uff09\uff0c\u6574\u5408\u4e86\u76f8\u5173\u8bba\u6587\u3001\u4ee3\u7801\u548c\u5de5\u5177\uff0c\u63a8\u52a83DGS\u5e94\u7528\u751f\u6001\u7684\u534f\u540c\u53d1\u5c55\u3002  \n\u25c6 \u901a\u8fc7\u8de8\u9886\u57df\u8d8b\u52bf\u5206\u6790\uff0c\u6307\u51fa3DGS\u5728\u5b9e\u65f6\u6e32\u67d3\u4e0e\u8bed\u4e49\u64cd\u4f5c\u7ed3\u5408\u65b9\u5411\u7684\u53d1\u5c55\u524d\u666f\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u6f5c\u5728\u7a81\u7834\u70b9\u3002|\n",
    "2508.09681": "|2025-08-13|Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision|Gerardo Loza\u7b49|[2508.09681](http://arxiv.org/pdf/2508.09681)|\u65e0|\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u9006\u795e\u7ecf\u8f90\u5c04\u573a\uff08InvNeRF\uff09\u7684\u65b0\u578b\u6d4b\u8bd5\u65f6\u4f18\u5316\uff08TTO\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u624b\u672f\u573a\u666f\u4e2d\u7684\u957f\u671f3D\u70b9\u8ddf\u8e2a\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u4e00\u81f4\u6027\u8fd0\u52a8\u62163D\u8ddf\u8e2a\u4e0a\u7684\u5c40\u9650\u6027\u3002  \n\u25c6 \u901a\u8fc7\u6e32\u67d3\u76d1\u7763\u50cf\u7d20\u5bf9\u5e94\u5173\u7cfb\uff0c\u5229\u7528\u53cc\u5411\u53ef\u53d8\u5f62-\u89c4\u8303\u6620\u5c04\u7b56\u7565\uff0c\u6709\u6548\u5904\u7406\u5b9a\u4e49\u7684\u5de5\u4f5c\u7a7a\u95f4\u5e76\u4f18\u5316\u5149\u7ebf\u5bc6\u5ea6\uff0c\u63d0\u5347\u4e86\u8ddf\u8e2a\u7cbe\u5ea6\u3002  \n\u25c6 \u8bbe\u8ba1\u4e86\u591a\u5c3a\u5ea6HexPlanes\u7ed3\u6784\uff0c\u663e\u8457\u52a0\u901f\u63a8\u7406\u8fc7\u7a0b\uff0c\u540c\u65f6\u63d0\u51fa\u9ad8\u6548\u50cf\u7d20\u91c7\u6837\u548c\u6536\u655b\u51c6\u5219\u7b97\u6cd5\uff0c\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u3002  \n\u25c6 \u57282D\u70b9\u8ddf\u8e2a\u4efb\u52a1\u4e2d\uff0c\u5e73\u5747\u7cbe\u5ea6\u6bd4\u73b0\u6709TTO\u65b9\u6cd5\u63d0\u5347\u8fd150%\uff0c\u5e76\u4e0e\u975eTTO\u65b9\u6cd5\u7ade\u4e89\uff1b\u57283D\u70b9\u8ddf\u8e2a\u4e2d\u9996\u6b21\u5b9e\u73b0TTO\u6846\u67b6\uff0c\u6027\u80fd\u8d85\u8d8a\u524d\u9988\u65b9\u6cd5\u3002  \n\u25c6 \u7ed3\u5408\u53ef\u53d8\u5f62NeRF\u91cd\u5efa\u4f18\u52bf\uff0c\u652f\u63012D\u548c3D\u8ddf\u8e2a\u4e00\u4f53\u5316\uff0c\u5e76\u5728STIR\u548cSCARE\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u4e0e\u8fd0\u52a8\u5b66\u6570\u636e\u6574\u5408\u80fd\u529b\u3002|\n",
    "2508.12163": "|2025-08-16|RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis|Wenqing Wang\u7b49|[2508.12163](http://arxiv.org/pdf/2508.12163)|\u65e0|\u25c6 \u63d0\u51faRealTalk\u6846\u67b6\uff0c\u9996\u6b21\u5b9e\u73b0\u9ad8\u60c5\u611f\u51c6\u786e\u5ea6\u3001\u5f3a\u60c5\u611f\u53ef\u63a7\u6027\u548c\u7a33\u5b9a\u8eab\u4efd\u4fdd\u6301\u7684\u62df\u771f\u8bf4\u8bdd\u5934\u90e8\u5408\u6210\u3002  \n\u25c6 \u521b\u65b0\u91c7\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u4ece\u97f3\u9891\u751f\u62103D\u9762\u90e8\u6807\u5fd7\u70b9\uff0c\u7ed3\u5408ResNet\u6807\u5fd7\u70b9\u53d8\u5f62\u6a21\u578b\uff08LDM\uff09\u878d\u5408\u60c5\u611f\u6807\u7b7e\u5d4c\u5165\uff0c\u7cbe\u51c6\u63a7\u5236\u8868\u60c5\u3002  \n\u25c6 \u8bbe\u8ba1\u65b0\u578b\u4e09\u5e73\u9762\u6ce8\u610f\u529b\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\uff0c\u901a\u8fc7\u6807\u5fd7\u70b9\u548c\u9762\u90e8\u6df7\u5408\u5f62\u72b6\u7cfb\u6570\u8054\u5408\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u5408\u6210\u56fe\u50cf\u7684\u903c\u771f\u5ea6\u3002  \n\u25c6 \u5f15\u5165\u60c5\u611f\u6807\u7b7e\u5d4c\u5165\u673a\u5236\uff0c\u7a81\u7834\u4f20\u7edf\u65b9\u6cd5\u5bf9\u60c5\u611f\u8868\u8fbe\u63a7\u5236\u7684\u5c40\u9650\u6027\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u60c5\u611f\u8c03\u8282\u3002  \n\u25c6 \u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5728\u60c5\u611f\u51c6\u786e\u6027\u3001\u53ef\u63a7\u6027\u548c\u8eab\u4efd\u4fdd\u6301\u7b49\u6838\u5fc3\u6307\u6807\u4e0a\u5168\u9762\u8d85\u8d8a\u73b0\u6709\u6280\u672f\uff0c\u63a8\u52a8\u793e\u4ea4\u667a\u80fdAI\u53d1\u5c55\u3002|\n",
    "2508.13808": "|2025-08-19|Is-NeRF: In-scattering Neural Radiance Field for Blurred Images|Nan Luo\u7b49|[2508.13808](http://arxiv.org/pdf/2508.13808)|\u65e0|Is-NeRF\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6563\u5c04\u611f\u77e5\u795e\u7ecf\u8f90\u5c04\u573a\uff0c\u7528\u4e8e\u4ece\u8fd0\u52a8\u6a21\u7cca\u56fe\u50cf\u4e2d\u6062\u590d\u6e05\u6670\u7684\u4e09\u7ef4\u573a\u666f\u3002\u5176\u521b\u65b0\u70b9\u4e3b\u8981\u4f53\u73b0\u5728\u4ee5\u4e0b\u56db\u4e2a\u65b9\u9762\uff1a\n\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u5185\u6563\u5c04\u8868\u793a\u6a21\u578b\uff0c\u7edf\u4e00\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u516d\u79cd\u5e38\u89c1\u7684\u5149\u7ebf\u4f20\u64ad\u73b0\u8c61\uff0c\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u4f20\u7edfNeRF\u7684\u76f4\u7ebf\u4f53\u6e32\u67d3\u65b9\u5f0f\u3002\n\u25c6 \u5efa\u7acb\u4e86\u4e00\u4e2a\u5168\u65b0\u7684\u3001\u53ef\u9002\u5e94\u590d\u6742\u5149\u8def\u7684\u6563\u5c04\u611f\u77e5\u4f53\u6e32\u67d3\u7ba1\u7ebf\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u56e0\u51e0\u4f55\u6a21\u7cca\u5bfc\u81f4\u7684\u8bad\u7ec3\u6b67\u4e49\u95ee\u9898\u3002\n\u25c6 \u5f15\u5165\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u5b66\u4e60\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u80fd\u81ea\u4e3b\u786e\u5b9a\u6563\u5c04\u65b9\u5411\u548c\u91c7\u6837\u95f4\u9694\uff0c\u4ece\u800c\u6355\u6349\u5230\u66f4\u7cbe\u7ec6\u7684\u7269\u4f53\u51e0\u4f55\u7ec6\u8282\u3002\n\u25c6 \u5b9e\u73b0\u4e86\u5bf9NeRF\u53c2\u6570\u3001\u6563\u5c04\u53c2\u6570\u548c\u76f8\u673a\u8fd0\u52a8\u7684\u8054\u5408\u4f18\u5316\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u4ec5\u4ece\u6a21\u7cca\u56fe\u50cf\u4e2d\u5c31\u80fd\u6062\u590d\u51fa\u9ad8\u4fdd\u771f\u573a\u666f\u8868\u793a\u548c\u7cbe\u786e\u51e0\u4f55\u7ec6\u8282\u3002|\n",
    "2508.13228": "|2025-08-17|PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism|Yuyan Ye\u7b49|[2508.13228](http://arxiv.org/pdf/2508.13228)|\u65e0|PreSem-Surf\u662f\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u65e8\u5728\u4eceRGB-D\u5e8f\u5217\u5feb\u901f\u91cd\u5efa\u9ad8\u8d28\u91cf\u573a\u666f\u8868\u9762\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u878d\u5408\u4e86\u989c\u8272\u3001\u6df1\u5ea6\u548c\u8bed\u4e49\u4fe1\u606f\u4ee5\u5168\u9762\u63d0\u5347\u91cd\u5efa\u6027\u80fd\u3002\n\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684SG-MLP\u91c7\u6837\u7ed3\u6784\uff0c\u7ed3\u5408PR-MLP\uff08\u9884\u6761\u4ef6\u591a\u5c42\u611f\u77e5\u673a\uff09\u8fdb\u884c\u4f53\u7d20\u9884\u6e32\u67d3\uff0c\u4f7f\u6a21\u578b\u80fd\u66f4\u65e9\u6355\u83b7\u573a\u666f\u4fe1\u606f\u5e76\u66f4\u597d\u5730\u533a\u5206\u566a\u58f0\u4e0e\u5c40\u90e8\u7ec6\u8282\u3002\n\u25c6 \u91c7\u7528\u4e86\u6e10\u8fdb\u5f0f\u8bed\u4e49\u5efa\u6a21\u7b56\u7565\uff0c\u901a\u8fc7\u9010\u6b65\u63d0\u53d6\u66f4\u7cbe\u7ec6\u7684\u8bed\u4e49\u4fe1\u606f\u6765\u589e\u5f3a\u573a\u666f\u7406\u89e3\uff0c\u540c\u65f6\u6709\u6548\u51cf\u5c11\u4e86\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u65f6\u95f4\u3002\n\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728C-L1\u3001F-score\u548cIoU\u591a\u9879\u6307\u6807\u4e0a\u8fbe\u5230\u6700\u4f18\uff0c\u5e76\u5728\u5176\u4ed6\u6307\u6807\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u8bc1\u660e\u4e86\u5176\u9ad8\u6548\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002|\n",
    "2508.14563": "|2025-08-20|GOGS: High-Fidelity Geometry and Relighting for Glossy Objects via Gaussian Surfels|Xingyuan Yang\u7b49|[2508.14563](http://arxiv.org/pdf/2508.14563)|\u65e0|GOGS\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u7ef4\u9ad8\u65af\u9762\u5143\u7684\u65b0\u578b\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u9ad8\u5149\u7269\u4f53\u9006\u5411\u6e32\u67d3\u4e2d\u7684\u51e0\u4f55\u566a\u58f0\u548c\u91cd\u5149\u7167\u4e0d\u771f\u5b9e\u95ee\u9898\u3002\u5176\u6838\u5fc3\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u91c7\u7528\u57fa\u4e8e\u7269\u7406\u6e32\u67d3\u7684\u5206\u88c2\u548c\u8fd1\u4f3c\u6cd5\uff0c\u5e76\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u7684\u51e0\u4f55\u5148\u9a8c\uff0c\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u8868\u9762\u91cd\u5efa\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u591a\u89c6\u56fe\u4e0d\u4e00\u81f4\u5bfc\u81f4\u7684\u7ed3\u6784\u7455\u75b5\u3002\n\u25c6 \u5229\u7528\u8499\u7279\u5361\u6d1b\u91cd\u8981\u6027\u91c7\u6837\u5b8c\u6574\u6e32\u67d3\u65b9\u7a0b\u8fdb\u884c\u6750\u8d28\u5206\u89e3\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u7684\u4e8c\u7ef4\u9ad8\u65af\u5149\u7ebf\u8ffd\u8e2a\u6a21\u62df\u95f4\u63a5\u5149\u7167\uff0c\u63d0\u5347\u4e86\u5149\u7167\u8ba1\u7b97\u7684\u51c6\u786e\u6027\u3002\n\u25c6 \u5f15\u5165\u57fa\u4e8e\u7403\u5f62mipmap\u7684\u65b9\u5411\u7f16\u7801\u6765\u7ec6\u5316\u9ad8\u9891\u955c\u9762\u7ec6\u8282\uff0c\u80fd\u591f\u6709\u6548\u6355\u6349\u5404\u5411\u5f02\u6027\u9ad8\u5149\uff0c\u4ece\u800c\u5728\u590d\u6742\u5149\u7167\u4e0b\u751f\u6210\u903c\u771f\u7684\u91cd\u5149\u7167\u6548\u679c\u3002\n\u8be5\u6846\u67b6\u5728\u51e0\u4f55\u91cd\u5efa\u3001\u6750\u8d28\u5206\u79bb\u548c\u65b0\u5149\u7167\u91cd\u5149\u7167\u65b9\u9762\u5747\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u663e\u8457\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u9006\u5411\u6e32\u67d3\u65b9\u6cd5\u3002|\n",
    "2508.17645": "|2025-08-28|Generating Human-AI Collaborative Design Sequence for 3D Assets via Differentiable Operation Graph|Xiaoyang Huang\u7b49|[2508.17645](http://arxiv.org/pdf/2508.17645)|\u65e0|\u8be5\u8bba\u6587\u7684\u6838\u5fc3\u8d21\u732e\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u53ef\u5fae\u5206\u64cd\u4f5c\u56fe\u751f\u6210\u4eba\u673a\u534f\u4f5c3D\u8d44\u4ea7\u8bbe\u8ba1\u5e8f\u5217\u7684\u65b9\u6cd5\uff0c\u4ee5\u5f25\u5408AI\u751f\u6210\u5185\u5bb9\u4e0e\u4eba\u7c7b\u53c2\u6570\u5316\u8bbe\u8ba1\u5de5\u4f5c\u6d41\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002  \n\u25c6 \u5c06\u4f20\u7edf\u5efa\u6a21\u64cd\u4f5c\uff08\u5982\u62c9\u4f38\u3001\u5e03\u5c14\u8fd0\u7b97\uff09\u91cd\u65b0\u6784\u5efa\u4e3a\u53ef\u5fae\u5206\u5355\u5143\uff0c\u652f\u6301\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u8054\u5408\u4f18\u5316\u8fde\u7eed\u548c\u79bb\u6563\u53c2\u6570\u3002  \n\u25c6 \u6784\u5efa\u4e86\u5e26\u6709\u95e8\u63a7\u673a\u5236\u7684\u5206\u5c42\u64cd\u4f5c\u56fe\uff0c\u5e76\u901a\u8fc7\u7aef\u5230\u7aef\u4f18\u5316\u5012\u89d2\u8ddd\u79bb\u5b9e\u73b0\u4e0e\u76ee\u6807\u51e0\u4f55\u7684\u9ad8\u4fdd\u771f\u5bf9\u9f50\u3002  \n\u25c6 \u63d0\u51fa\u591a\u9636\u6bb5\u5e8f\u5217\u957f\u5ea6\u7ea6\u675f\u4e0e\u9886\u57df\u89c4\u5219\u60e9\u7f5a\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u771f\u5b9e\u5e8f\u5217\u6807\u6ce8\u7684\u65e0\u76d1\u7763\u7d27\u51d1\u5e8f\u5217\u5b66\u4e60\u3002  \n\u25c6 \u751f\u6210\u7684\u5e8f\u5217\u5177\u5907\u9ad8\u51e0\u4f55\u51c6\u786e\u6027\u3001\u5e73\u6ed1\u7f51\u683c\u7ed3\u6784\u3001\u5408\u7406\u6b65\u9aa4\u7ec4\u6210\u548c\u7075\u6d3b\u7f16\u8f91\u80fd\u529b\uff0c\u5b8c\u5168\u517c\u5bb9\u4e3b\u6d41\u8bbe\u8ba1\u8f6f\u4ef6\u6d41\u7a0b\u3002  \n\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86AI\u751f\u6210\u5185\u5bb9\u5728\u8bbe\u8ba1\u5b9e\u8df5\u4e2d\u7684\u53ef\u7528\u6027\u548c\u534f\u4f5c\u6548\u7387\u3002|\n",
    "2508.16932": "|2025-08-23|Align 3D Representation and Text Embedding for 3D Content Personalization|Qi Song\u7b49|[2508.16932](http://arxiv.org/pdf/2508.16932)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aInvert3D\u7684\u65b0\u578b\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b33D\u5185\u5bb9\u9ad8\u6548\u4e2a\u6027\u5316\u8fd9\u4e00\u5173\u952e\u6311\u6218\u3002\u5176\u6838\u5fc3\u8d21\u732e\u4e0e\u521b\u65b0\u70b9\u5982\u4e0b\uff1a\n\n\u25c6 \u63d0\u51fa\u4e86\u4e00\u4e2a\u5c063D\u8868\u793a\u4e0e\u6587\u672c\u5d4c\u5165\u7a7a\u95f4\u5bf9\u9f50\u7684\u521b\u65b0\u6846\u67b6\uff0c\u5f25\u5408\u4e862D\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4e0e3D\u5185\u5bb9\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002\n\u25c6 \u8bbe\u8ba1\u4e86\u4e00\u79cd\u4ee5\u76f8\u673a\u4e3a\u6761\u4ef6\u76843D\u5230\u6587\u672c\u9006\u5411\u6620\u5c04\u673a\u5236\uff0c\u80fd\u591f\u5c063D\u5185\u5bb9\u6295\u5f71\u5230\u4e0e\u6587\u672c\u5d4c\u5165\u5bf9\u9f50\u76843D\u5d4c\u5165\u7a7a\u95f4\u4e2d\u3002\n\u25c6 \u5b9e\u73b0\u4e86\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u76f4\u63a5\u5bf93D\u5185\u5bb9\u8fdb\u884c\u64cd\u4f5c\u548c\u4e2a\u6027\u5316\u5b9a\u5236\uff0c\u65e0\u9700\u4f9d\u8d56\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u7e41\u7410\u91cd\u8bad\u7ec3\u8fc7\u7a0b\u3002\n\u25c6 \u663e\u8457\u63d0\u5347\u4e863D\u5185\u5bb9\u4e2a\u6027\u5316\u7684\u6548\u7387\uff0c\u907f\u514d\u4e86\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7684\u518d\u8bad\u7ec3\u9700\u6c42\u3002\n\u25c6 \u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4e3a3D\u751f\u6210\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u4fbf\u6377\u7684\u4e2a\u6027\u5316\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2508.18971": "|2025-08-26|Can we make NeRF-based visual localization privacy-preserving?|Maxime Pietrantoni\u7b49|[2508.18971](http://arxiv.org/pdf/2508.18971)|\u65e0|\u8be5\u8bba\u6587\u9488\u5bf9\u57fa\u4e8eNeRF\u7684\u89c6\u89c9\u5b9a\u4f4d\u65b9\u6cd5\u5b58\u5728\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\u3002  \n\u25c6 \u9996\u5148\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u7528\u4e8e\u7cfb\u7edf\u68c0\u9a8cNeRF\u8868\u793a\u4e2d\u7684\u9690\u79c1\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5373\u4f7f\u79fb\u9664\u989c\u8272\u9884\u6d4b\u5934\uff0c\u5176\u51e0\u4f55\u8868\u793a\u4ecd\u4f1a\u6cc4\u9732\u654f\u611f\u7ec6\u8282\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u63d0\u51fappNeRF\uff08\u9690\u79c1\u4fdd\u62a4\u795e\u7ecf\u5206\u5272\u573a\uff09\uff0c\u5c06NeRF\u7684\u4f20\u7edf\u5149\u5ea6\u76d1\u7763\u66ff\u6362\u4e3a\u5206\u5272\u6807\u7b7e\u76d1\u7763\uff0c\u907f\u514d\u76f4\u63a5\u5b66\u4e60\u539f\u59cb\u56fe\u50cf\u7eb9\u7406\u3002  \n\u25c6 \u901a\u8fc7\u81ea\u76d1\u7763\u65b9\u5f0f\u5b66\u4e60\u5206\u5272\u6807\u7b7e\uff0c\u786e\u4fdd\u6807\u7b7e\u65e2\u4fdd\u7559\u8db3\u591f\u7684\u51e0\u4f55\u5224\u522b\u6027\u4ee5\u652f\u6301\u7cbe\u51c6\u5b9a\u4f4d\uff0c\u53c8\u5145\u5206\u6a21\u7cca\u5316\u7ec6\u8282\u4ee5\u4fdd\u62a4\u9690\u79c1\u3002  \n\u25c6 \u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u89c6\u89c9\u5b9a\u4f4d\u80fd\u529b\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9690\u79c1\u4fdd\u62a4\u6c34\u5e73\uff0c\u5b9e\u73b0\u4e86\u9690\u79c1\u4e0e\u6027\u80fd\u7684\u5e73\u8861\u3002  \n\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u5b9a\u4f4d\u7ed3\u679c\u3002|\n",
    "2508.18540": "|2025-08-25|Real-time 3D Visualization of Radiance Fields on Light Field Displays|Jonghyun Kim\u7b49|[2508.18540](http://arxiv.org/pdf/2508.18540)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u5149\u573a\u663e\u793a\u5668\u7684\u5b9e\u65f6\u8f90\u5c04\u573a\u4e09\u7ef4\u53ef\u89c6\u5316\u7edf\u4e00\u6846\u67b6\u3002  \n\u25c6 \u5f00\u53d1\u4e86\u57fa\u4e8e\u5355\u904d\u5e73\u9762\u626b\u63cf\u7b56\u7565\u7684\u5171\u4eab\u67b6\u6784\uff0c\u9ad8\u6548\u652f\u6301\u591a\u79cd\u8f90\u5c04\u573a\u8868\u793a\uff08\u5982NeRF\u30013D\u9ad8\u65af\u6cfc\u6e85\u548c\u7a00\u758f\u4f53\u7d20\uff09\uff0c\u65e0\u9700\u9488\u5bf9\u4e0d\u540c\u573a\u666f\u91cd\u65b0\u8bad\u7ec3\u3002  \n\u25c6 \u901a\u8fc7\u7f13\u5b58\u975e\u65b9\u5411\u6027\u5171\u4eab\u7ec4\u4ef6\uff0c\u663e\u8457\u51cf\u5c11\u8de8\u89c6\u89d2\u7684\u5197\u4f59\u8ba1\u7b97\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe22\u500d\u7684\u6e32\u67d3\u52a0\u901f\u3002  \n\u25c6 \u572845\u4e2a\u89c6\u89d2\u4e0b\u4ee5512p\u5206\u8fa8\u7387\u8fbe\u5230200+ FPS\u7684\u5b9e\u65f6\u4ea4\u4e92\u6027\u80fd\uff0c\u5e76\u5728Looking Glass\u663e\u793a\u5668\u4e0a\u9a8c\u8bc1\u4e86\u6c89\u6d78\u5f0f\u4e09\u7ef4\u4ea4\u4e92\u5e94\u7528\u3002  \n\u25c6 \u5728\u63d0\u5347\u6e32\u67d3\u6548\u7387\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u56fe\u50cf\u8d28\u91cf\uff0c\u89e3\u51b3\u4e86\u5149\u573a\u663e\u793a\u591a\u89c6\u89d2\u6e32\u67d3\u4e0e\u8f90\u5c04\u573a\u8ba1\u7b97\u5bc6\u96c6\u578b\u4f53\u79ef\u6e32\u67d3\u4e4b\u95f4\u7684\u96c6\u6210\u96be\u9898\u3002|\n",
    "2508.20526": "|2025-08-28|Adam SLAM - the last mile of camera calibration with 3DGS|Matthieu Gendrin\u7b49|[2508.20526](http://arxiv.org/pdf/2508.20526)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u75283D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u6a21\u578b\u4f18\u5316\u76f8\u673a\u6807\u5b9a\u7684\u65b0\u65b9\u6cd5\u3002  \n\u25c6 \u521b\u65b0\u6027\u5730\u901a\u8fc7\u65b0\u89c6\u56fe\u989c\u8272\u635f\u5931\u7684\u53cd\u5411\u4f20\u64ad\u6765\u7cbe\u7ec6\u8c03\u6574\u76f8\u673a\u53c2\u6570\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u6807\u5b9a\u65b9\u6cd5\u7684\u7cbe\u5ea6\u9650\u5236\u3002  \n\u25c6 \u5c06\u6807\u5b9a\u95ee\u9898\u8f6c\u5316\u4e3a\u53ef\u5fae\u5206\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u6807\u5b9a\u4f18\u5316\u6d41\u7a0b\u3002  \n\u25c6 \u57283DGS\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u63d0\u53470.4 dB PSNR\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65b0\u89c6\u56fe\u5408\u6210\u8d28\u91cf\u3002  \n\u25c6 \u4e3a\u9ad8\u7cbe\u5ea6\u53c2\u8003\u573a\u666f\uff08\u5982Mip-NeRF 360\uff09\u7684\u6807\u5b9a\u63d0\u4f9b\u4e86\u4ee5\u6e32\u67d3\u8d28\u91cf\u4e3a\u6838\u5fc3\u7684\u65b0\u8303\u5f0f\u3002  \n\u8be5\u65b9\u6cd5\u867d\u9700\u8f83\u957f\u8c03\u4f18\u65f6\u95f4\uff0c\u4f46\u5bf9\u6807\u5b9a\u7cbe\u5ea6\u8981\u6c42\u6781\u9ad8\u7684\u573a\u666f\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002|\n",
    "2509.00911": "|2025-09-03|GS-TG: 3D Gaussian Splatting Accelerator with Tile Grouping for Reducing Redundant Sorting while Preserving Rasterization Efficiency|Joongho Jo\u7b49|[2509.00911](http://arxiv.org/pdf/2509.00911)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86GS-TG\uff0c\u4e00\u79cd\u7528\u4e8e\u52a0\u901f3D\u9ad8\u65af\u6cfc\u6e85\u6e32\u67d3\u7684\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u901a\u8fc7\u4f18\u5316\u6392\u5e8f\u4e0e\u5149\u6805\u5316\u8fc7\u7a0b\u6765\u63d0\u5347\u6e32\u67d3\u901f\u5ea6\u3002  \n\u25c6 \u63d0\u51fa\u57fa\u4e8e\u74e6\u7247\u5206\u7ec4\uff08Tile Grouping\uff09\u7684\u6392\u5e8f\u7b56\u7565\uff0c\u5c06\u591a\u4e2a\u5c0f\u74e6\u7247\u7ec4\u5408\u6210\u5927\u7ec4\u4ee5\u5171\u4eab\u6392\u5e8f\u64cd\u4f5c\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5197\u4f59\u8ba1\u7b97\u3002  \n\u25c6 \u5f15\u5165\u4f4d\u63a9\u7801\uff08Bitmask\uff09\u673a\u5236\uff0c\u4e3a\u6bcf\u4e2a\u9ad8\u65af\u56fe\u5143\u6807\u8bb0\u5176\u6240\u5c5e\u7684\u6709\u6548\u5c0f\u74e6\u7247\uff0c\u4f7f\u5f97\u5149\u6805\u5316\u9636\u6bb5\u4ecd\u53ef\u6309\u539f\u59cb\u5c0f\u74e6\u7247\u9ad8\u6548\u6267\u884c\uff0c\u907f\u514d\u4e86\u4e0d\u5fc5\u8981\u7684\u50cf\u7d20\u8ba1\u7b97\u3002  \n\u25c6 \u5b9e\u73b0\u4e86\u6392\u5e8f\u9636\u6bb5\u4f7f\u7528\u201c\u5927\u74e6\u7247\u201d\u903b\u8f91\u4ee5\u964d\u4f4e\u6392\u5e8f\u5f00\u9500\uff0c\u800c\u5149\u6805\u5316\u9636\u6bb5\u4fdd\u6301\u201c\u5c0f\u74e6\u7247\u201d\u7c92\u5ea6\u4ee5\u7ef4\u6301\u6e32\u67d3\u6548\u7387\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u74e6\u7247\u5c3a\u5bf8\u589e\u5927\u5bfc\u81f4\u5149\u6805\u5316\u8ba1\u7b97\u91cf\u4e0a\u5347\u7684\u77db\u76fe\u3002  \n\u25c6 \u8be5\u65b9\u6cd5\u662f\u65e0\u635f\u7684\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5fae\u8c03\uff0c\u5e76\u53ef\u4e0e\u5176\u4ed6\u73b0\u6709\u4f18\u5316\u6280\u672f\u65e0\u7f1d\u96c6\u6210\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGS-TG\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684\u52a0\u901f\u5668\u5e73\u5747\u5b9e\u73b0\u4e861.54\u500d\u7684\u6e32\u67d3\u901f\u5ea6\u63d0\u5347\u3002|\n",
    "2509.00800": "|2025-08-31|SWAGSplatting: Semantic-guided Water-scene Augmented Gaussian Splatting|Zhuodong Jiang\u7b49|[2509.00800](http://arxiv.org/pdf/2509.00800)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8bed\u4e49\u5f15\u5bfc\u4e0e3D\u9ad8\u65af\u6e85\u5c04\u7684\u6c34\u4e0b\u573a\u666f\u589e\u5f3a\u91cd\u5efa\u65b9\u6cd5SWAGSplatting\uff0c\u6838\u5fc3\u89e3\u51b3\u4e86\u6c34\u4e0b\u73af\u5883\u56e0\u5149\u7ebf\u626d\u66f2\u3001\u6d51\u6d4a\u548c\u4f4e\u53ef\u89c1\u5ea6\u5bfc\u81f4\u76843D\u91cd\u5efa\u96be\u9898\u3002\u5176\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n\u25c6 \u5f15\u5165\u591a\u6a21\u6001\u8de8\u77e5\u8bc6\u878d\u5408\u673a\u5236\uff0c\u5c06\u8bed\u8a00\u6a21\u578b\uff08CLIP\uff09\u63d0\u53d6\u7684\u8bed\u4e49\u7279\u5f81\u5d4c\u5165\u6bcf\u4e2a\u9ad8\u65af\u57fa\u5143\uff0c\u5b9e\u73b0\u8bed\u4e49\u4e0e\u7ed3\u6784\u611f\u77e5\u7684\u8054\u5408\u4f18\u5316\u3002\n\u25c6 \u8bbe\u8ba1\u4e13\u7528\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u635f\u5931\u51fd\u6570\uff0c\u786e\u4fdd\u91cd\u5efa\u7ed3\u679c\u4e0e\u9ad8\u5c42\u573a\u666f\u7406\u89e3\u4fdd\u6301\u4e00\u81f4\uff0c\u63d0\u5347\u91cd\u5efa\u7684\u8bed\u4e49\u51c6\u786e\u6027\u3002\n\u25c6 \u63d0\u51fa\u5206\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u7ed3\u5408\u7531\u7c97\u5230\u7ec6\u7684\u5b66\u4e60\u4e0e\u540e\u671f\u53c2\u6570\u7ec6\u5316\uff0c\u663e\u8457\u589e\u5f3a\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u91cd\u5efa\u8d28\u91cf\u3002\n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728SeaThru-NeRF\u548cSubmerged3D\u6570\u636e\u96c6\u4e0a\u5168\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0cPSNR\u6307\u6807\u5e73\u5747\u63d0\u5347\u6700\u9ad8\u8fbe3.09 dB\uff0c\u4e3a\u6c34\u4e0b\u52d8\u63a2\u548c\u6d77\u6d0b\u611f\u77e5\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002|\n",
    "2509.07809": "|2025-09-09|SplatFill: 3D Scene Inpainting via Depth-Guided Gaussian Splatting|Mahtab Dahaghin\u7b49|[2509.07809](http://arxiv.org/pdf/2509.07809)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSplatFill\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u57fa\u4e8e3D\u9ad8\u65af\u6cfc\u6e85\uff083DGS\uff09\u76843D\u573a\u666f\u4fee\u590d\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u663e\u8457\u63d0\u5347\u4e86\u7f3a\u5931\u533a\u57df\u4fee\u590d\u7684\u89c6\u89c9\u4fdd\u771f\u5ea6\u548c\u51e0\u4f55\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u5927\u5e45\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u3002  \n\u25c6 \u5f15\u5165\u6df1\u5ea6\u5f15\u5bfc\u4e0e\u7269\u4f53\u611f\u77e5\u7684\u8054\u5408\u76d1\u7763\u673a\u5236\uff0c\u786e\u4fdd\u4fee\u590d\u7684\u9ad8\u65af\u70b9\u4e91\u5728\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u4f4d\u7f6e\u51c6\u786e\u4e14\u4e0e\u5468\u56f4\u51e0\u4f55\u5bf9\u9f50\u3002  \n\u25c6 \u63d0\u51fa\u4e00\u81f4\u6027\u611f\u77e5\u7ec6\u5316\u65b9\u6848\uff0c\u80fd\u667a\u80fd\u8bc6\u522b\u5e76\u4fee\u6b63\u4e0d\u4e00\u81f4\u533a\u57df\uff0c\u907f\u514d\u5bf9\u573a\u666f\u5176\u4ed6\u90e8\u5206\u9020\u6210\u5e72\u6270\u3002  \n\u25c6 \u5728SPIn-NeRF\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u89c6\u89c9\u8d28\u91cf\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u4e8eNeRF\u548c3DGS\u7684\u4fee\u590d\u65b9\u6cd5\u3002  \n\u25c6 \u8bad\u7ec3\u6548\u7387\u63d0\u534724.5%\uff0c\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u6e05\u6670\u7684\u7ec6\u8282\u3001\u66f4\u5c11\u7684\u4f2a\u5f71\u548c\u66f4\u597d\u7684\u591a\u89c6\u89d2\u4e00\u81f4\u6027\u3002|\n",
    "2509.07493": "|2025-09-09|DiGS: Accurate and Complete Surface Reconstruction from 3D Gaussians via Direct SDF Learning|Wenzhi Guo\u7b49|[2509.07493](http://arxiv.org/pdf/2509.07493)|\u65e0|\u672c\u6587\u63d0\u51faDiGS\u6846\u67b6\uff0c\u5c063D\u9ad8\u65af\u8868\u793a\u4e0e\u7b26\u53f7\u8ddd\u79bb\u573a\uff08SDF\uff09\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ece3D\u9ad8\u65af\u6a21\u578b\u4e2d\u91cd\u5efa\u7cbe\u786e\u5b8c\u6574\u8868\u9762\u7684\u80fd\u529b\u3002  \n\u25c6 \u9996\u6b21\u5c06\u53ef\u5b66\u4e60SDF\u5d4c\u51653D\u9ad8\u65af\u6e85\u5c04\uff083DGS\uff09\u6d41\u7a0b\uff0c\u4e3a\u6bcf\u4e2a\u9ad8\u65af\u57fa\u5143\u8d4b\u4e88\u51e0\u4f55\u610f\u4e49\uff0c\u589e\u5f3a\u4e86\u89e3\u91ca\u6027\u548c\u51e0\u4f55\u4e00\u81f4\u6027\u3002  \n\u25c6 \u63d0\u51fa\u51e0\u4f55\u5f15\u5bfc\u7684\u7f51\u683c\u589e\u957f\u7b56\u7565\uff0c\u5728\u591a\u5c3a\u5ea6\u5c42\u6b21\u4e0b\u81ea\u9002\u5e94\u6cbf\u51e0\u4f55\u4e00\u81f4\u533a\u57df\u5206\u5e03\u9ad8\u65af\u57fa\u5143\uff0c\u5b9e\u73b0\u66f4\u5bc6\u96c6\u548c\u8fde\u8d2f\u7684\u8868\u9762\u8986\u76d6\u3002  \n\u25c6 \u901a\u8fc7\u663e\u5f0f\u5bf9\u9f50\u9ad8\u65af\u57fa\u5143\u4e0e\u5e95\u5c42\u51e0\u4f55\uff0c\u6709\u6548\u6539\u5584\u4e86\u8de8\u89c6\u89d2\u4e00\u81f4\u6027\u548c\u91cd\u5efa\u5b8c\u6574\u6027\u3002  \n\u5b9e\u9a8c\u8bc1\u660e\uff0cDiGS\u5728DTU\u3001Mip-NeRF 360\u7b49\u591a\u4e2a\u57fa\u51c6\u4e0a\u5747\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u91cd\u5efa\u7cbe\u5ea6\u548c\u5b8c\u6574\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6e32\u67d3\u8d28\u91cf\u3002|\n",
    "2509.11275": "|2025-09-14|ROSGS: Relightable Outdoor Scenes With Gaussian Splatting|Lianjun Liao\u7b49|[2509.11275](http://arxiv.org/pdf/2509.11275)|\u65e0|ROSGS\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u65af\u6e85\u5c04\u7684\u4e24\u9636\u6bb5\u6d41\u7a0b\uff0c\u7528\u4e8e\u6237\u5916\u53ef\u91cd\u5149\u7167\u573a\u666f\u7684\u9ad8\u6548\u91cd\u5efa\u4e0e\u6e32\u67d3\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u5149\u7167\u5efa\u6a21\u7cbe\u5ea6\u4e0a\u7684\u4e0d\u8db3\u3002  \n\u25c6 \u91c7\u7528\u7d27\u51d1\u7684\u4e8c\u7ef4\u9ad8\u65af\u6e85\u5c04\uff082DGS\uff09\u8868\u793a\u7ed3\u5408\u5355\u76ee\u6cd5\u5411\u5148\u9a8c\uff0c\u9ad8\u6548\u4e14\u7cbe\u786e\u5730\u91cd\u5efa\u573a\u666f\u51e0\u4f55\u7ed3\u6784\u3002  \n\u25c6 \u63d0\u51fa\u6df7\u5408\u5149\u7167\u6a21\u578b\uff0c\u5206\u522b\u7528\u7403\u9762\u9ad8\u65af\u51fd\u6570\u523b\u753b\u65b9\u5411\u6027\u7684\u9ad8\u9891\u9633\u5149\u6210\u5206\uff0c\u5e76\u901a\u8fc7\u7403\u8c10\u7cfb\u6570\u5b66\u4e60\u8f90\u5c04\u4f20\u8f93\u51fd\u6570\u4ee5\u5efa\u6a21\u4f4e\u9891\u5929\u5149\u3002  \n\u25c6 \u5728\u4fdd\u6301\u9ad8\u6e32\u67d3\u6548\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5bf9\u65e0\u7ea6\u675f\u6237\u5916\u7167\u660e\u6761\u4ef6\u7684\u9ad8\u7cbe\u5ea6\u5206\u89e3\u4e0e\u91cd\u5149\u7167\u3002  \n\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9a\u91cf\u6307\u6807\u548c\u89c6\u89c9\u5bf9\u6bd4\u4e0a\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6237\u5916\u91cd\u5149\u7167\u6027\u80fd\uff0c\u517c\u987e\u4e86\u6e32\u67d3\u901f\u5ea6\u4e0e\u771f\u5b9e\u611f\u3002|\n",
    "2509.11171": "|2025-09-14|SPHERE: Semantic-PHysical Engaged REpresentation for 3D Semantic Scene Completion|Zhiwen Yang\u7b49|[2509.11171](http://arxiv.org/pdf/2509.11171)|\u65e0|SPHERE\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u76f8\u673a3D\u8bed\u4e49\u573a\u666f\u8865\u5168\uff08SSC\uff09\u7684\u65b0\u8868\u5f81\u65b9\u6cd5\uff0c\u65e8\u5728\u540c\u65f6\u63d0\u5347\u8bed\u4e49\u51c6\u786e\u6027\u548c\u51e0\u4f55\u7ec6\u8282\u7684\u771f\u5b9e\u6027\u3002\u5176\u6838\u5fc3\u8d21\u732e\u662f\u521b\u65b0\u6027\u5730\u878d\u5408\u4e86\u4f53\u7d20\u4e0e\u9ad8\u65af\u8868\u5f81\uff0c\u4ee5\u8054\u5408\u5229\u7528\u8bed\u4e49\u548c\u7269\u7406\u4fe1\u606f\u3002\n\u25c6 \u63d0\u51fa\u8bed\u4e49-\u7269\u7406\u878d\u5408\u8868\u5f81(SPHERE)\uff0c\u5c06\u663e\u5f0f\u4f53\u7d20\u4e0e\u9690\u5f0f\u9ad8\u65af\u8868\u5f81\u76f8\u7ed3\u5408\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7269\u7406\u89c4\u5f8b\u6355\u83b7\u6216\u8bed\u4e49\u7cbe\u5ea6\u4e0a\u7684\u4e0d\u8db3\u3002\n\u25c6 \u8bbe\u8ba1\u4e86\u8bed\u4e49\u5f15\u5bfc\u7684\u9ad8\u65af\u521d\u59cb\u5316(SGI)\u6a21\u5757\uff0c\u5229\u7528\u53cc\u5206\u652f\u8868\u5f81\u5b9a\u4f4d\u7126\u70b9\u4f53\u7d20\u4f5c\u4e3a\u951a\u70b9\uff0c\u6307\u5bfc\u9ad8\u6548\u7684\u9ad8\u65af\u521d\u59cb\u5316\uff0c\u63d0\u5347\u4e86\u5904\u7406\u6548\u7387\u3002\n\u25c6 \u5f00\u53d1\u4e86\u7269\u7406\u611f\u77e5\u7684\u8c10\u6ce2\u589e\u5f3a(PHE)\u6a21\u5757\uff0c\u901a\u8fc7\u5f15\u5165\u8bed\u4e49\u7403\u8c10\u51fd\u6570\u6765\u5efa\u6a21\u7269\u7406\u4e0a\u4e0b\u6587\u7ec6\u8282\uff0c\u5e76\u901a\u8fc7\u7126\u70b9\u5206\u5e03\u5bf9\u9f50\u4fc3\u8fdb\u8bed\u4e49-\u51e0\u4f55\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u751f\u6210\u5177\u6709\u903c\u771f\u7ec6\u8282\u7684\u7ed3\u679c\u3002\n\u8be5\u65b9\u6cd5\u5728\u4e3b\u6d41\u6570\u636e\u96c6\u4e0a\u5f97\u5230\u9a8c\u8bc1\uff0c\u6709\u6548\u5e73\u8861\u4e86\u573a\u666f\u8865\u5168\u7684\u8bed\u4e49\u51c6\u786e\u6027\u4e0e\u51e0\u4f55\u771f\u5b9e\u6027\u3002|\n",
    "2509.11169": "|2025-09-14|Multispectral-NeRF:a multispectral modeling approach based on neural radiance fields|Hong Zhang\u7b49|[2509.11169](http://arxiv.org/pdf/2509.11169)|\u65e0|\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Multispectral-NeRF\uff0c\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u8f90\u5c04\u573a\uff08NeRF\uff09\u7684\u591a\u5149\u8c31\u4e09\u7ef4\u91cd\u5efa\u65b0\u65b9\u6cd5\u3002\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u89e3\u51b3\u4e86\u73b0\u6709NeRF\u6a21\u578b\u65e0\u6cd5\u5904\u7406\u591a\u6ce2\u6bb5\u5149\u8c31\u6570\u636e\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6269\u5c55\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5b9e\u73b0\u4e86\u5bf96\u6ce2\u6bb5\u5149\u8c31\u6570\u636e\u7684\u9ad8\u7cbe\u5ea6\u5efa\u6a21\u3002  \n\u25c6 \u6269\u5c55\u4e86\u795e\u7ecf\u7f51\u7edc\u9690\u85cf\u5c42\u7684\u7ef4\u5ea6\uff0c\u4f7f\u5176\u80fd\u591f\u76f4\u63a5\u5904\u74066\u6ce2\u6bb5\u5149\u8c31\u8f93\u5165\u6570\u636e\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u4e09\u6ce2\u6bb5\uff08RGB\uff09\u7684\u9650\u5236\u3002  \n\u25c6 \u91cd\u65b0\u8bbe\u8ba1\u4e86\u6b8b\u5dee\u51fd\u6570\uff0c\u4f18\u5316\u4e86\u91cd\u5efa\u56fe\u50cf\u4e0e\u53c2\u8003\u56fe\u50cf\u4e4b\u95f4\u7684\u5149\u8c31\u5dee\u5f02\u8ba1\u7b97\uff0c\u63d0\u5347\u4e86\u591a\u5149\u8c31\u7279\u5f81\u7684\u8fd8\u539f\u7cbe\u5ea6\u3002  \n\u25c6 \u8c03\u6574\u4e86\u6570\u636e\u538b\u7f29\u6a21\u5757\uff0c\u4ee5\u9002\u5e94\u591a\u5149\u8c31\u56fe\u50cf\u66f4\u9ad8\u6bd4\u7279\u6df1\u5ea6\u7684\u5b58\u50a8\u548c\u8ba1\u7b97\u9700\u6c42\uff0c\u786e\u4fdd\u6570\u636e\u5904\u7406\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002  \n\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u539f\u59cb\u573a\u666f\u51e0\u4f55\u7279\u5f81\u7684\u540c\u65f6\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u6ce2\u6bb5\u5149\u8c31\u7279\u5f81\u7684\u9ad8\u4fdd\u771f\u91cd\u5efa\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u5149\u8c31\u4e09\u7ef4\u91cd\u5efa\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002|\n",
    "2509.12836": "|2025-09-16|Exploring Metric Fusion for Evaluation of NeRFs|Shreyas Shivakumara\u7b49|[2509.12836](http://arxiv.org/pdf/2509.12836)|\u65e0|\u25c6 Neural Radiance Fields (NeRFs) have demonstrated significant potential in synthesizing novel viewpoints.\n\u25c6 Evaluating the NeRF-generated outputs, however, remains a challenge due to the unique artifacts they exhibit, and no individual metric performs well across all datasets.\n\u25c6 We hypothesize that combining two successful metrics, Deep Image Structure and Texture Similarity (DISTS) and Video Multi-Method Assessment Fusion (VMAF), based on different perceptual methods, can overcome the limitations of individual metrics and achieve improved correlation with subjective quality scores.|\n",
    "2509.12458": "|2025-09-15|Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles|\u00c0lmos Veres-Vit\u00e0lyos\u7b49|[2509.12458](http://arxiv.org/pdf/2509.12458)|\u65e0|\u25c6 Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for navigating indoor and hard-to-reach areas, yet their significant constraints in payload and autonomy have largely prevented their use for complex tasks like high-quality 3-Dimensional (3D) reconstruction.\n\u25c6 To overcome this challenge, we introduce a novel system architecture that enables fully autonomous, high-fidelity 3D scanning of static objects using UAVs weighing under 100 grams.\n\u25c6 Our core innovation lies in a dual-reconstruction pipeline that creates a real-time feedback loop between data capture and flight control.|\n",
    "2509.13571": "|2025-09-16|SuNeRF-CME: Physics-Informed Neural Radiance Fields for Tomographic Reconstruction of Coronal Mass Ejections|Robert Jarolim\u7b49|[2509.13571](http://arxiv.org/pdf/2509.13571)|\u65e0|\u25c6 Coronagraphic observations enable direct monitoring of coronal mass ejections (CMEs) through scattered light from free electrons, but determining the 3D plasma distribution from 2D imaging data is challenging due to the optically-thin plasma and the complex image formation processes.\n\u25c6 We introduce SuNeRF-CME, a framework for 3D tomographic reconstructions of the heliosphere using multi-viewpoint coronagraphic observations.\n\u25c6 The method leverages Neural Radiance Fields (NeRFs) to estimate the electron density in the heliosphere through a ray-tracing approach, while accounting for the underlying Thomson scattering of image formation.|\n",
    "2509.15123": "|2025-09-19|RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes|Fang Li\u7b49|[2509.15123](http://arxiv.org/pdf/2509.15123)|\u65e0|\u25c6 Although COLMAP has long remained the predominant method for camera parameter optimization in static scenes, it is constrained by its lengthy runtime and reliance on ground truth (GT) motion masks for application to dynamic scenes.\n\u25c6 Many efforts attempted to improve it by incorporating more priors as supervision such as GT focal length, motion masks, 3D point clouds, camera poses, and metric depth, which, however, are typically unavailable in casually captured RGB videos.\n\u25c6 In this paper, we propose a novel method for more accurate and efficient camera parameter optimization in dynamic scenes solely supervised by a single RGB video.|\n",
    "2509.14890": "|2025-09-18|NeRF-based Visualization of 3D Cues Supporting Data-Driven Spacecraft Pose Estimation|Antoine Legrand\u7b49|[2509.14890](http://arxiv.org/pdf/2509.14890)|\u65e0|\u25c6 On-orbit operations require the estimation of the relative 6D pose, i.e., position and orientation, between a chaser spacecraft and its target.\n\u25c6 While data-driven spacecraft pose estimation methods have been developed, their adoption in real missions is hampered by the lack of understanding of their decision process.\n\u25c6 This paper presents a method to visualize the 3D visual cues on which a given pose estimator relies.|\n",
    "2509.15548": "|2025-09-26|MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild|Deming Li\u7b49|[2509.15548](http://arxiv.org/pdf/2509.15548)|\u65e0|\u25c6 In-the-wild photo collections often contain limited volumes of imagery and exhibit multiple appearances, e.g., taken at different times of day or seasons, posing significant challenges to scene reconstruction and novel view synthesis.\n\u25c6 Although recent adaptations of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3DGS) have improved in these areas, they tend to oversmooth and are prone to overfitting.\n\u25c6 In this paper, we present MS-GS, a novel framework designed with Multi-appearance capabilities in Sparse-view scenarios using 3DGS.|\n",
    "2509.15242": "|2025-09-17|ProFusion: 3D Reconstruction of Protein Complex Structures from Multi-view AFM Images|Jaydeep Rade\u7b49|[2509.15242](http://arxiv.org/pdf/2509.15242)|\u65e0|\u25c6 AI-based in silico methods have improved protein structure prediction but often struggle with large protein complexes (PCs) involving multiple interacting proteins due to missing 3D spatial cues.\n\u25c6 Experimental techniques like Cryo-EM are accurate but costly and time-consuming.\n\u25c6 We present ProFusion, a hybrid framework that integrates a deep learning model with Atomic Force Microscopy (AFM), which provides high-resolution height maps from random orientations, naturally yielding multi-view data for 3D reconstruction.|\n",
    "2509.17789": "|2025-09-22|From Restoration to Reconstruction: Rethinking 3D Gaussian Splatting for Underwater Scenes|Guoxi Huang\u7b49|[2509.17789](http://arxiv.org/pdf/2509.17789)|\u65e0|\u25c6 Underwater image degradation poses significant challenges for 3D reconstruction, where simplified physical models often fail in complex scenes.\n\u25c6 We propose \\textbf{R-Splatting}, a unified framework that bridges underwater image restoration (UIR) with 3D Gaussian Splatting (3DGS) to improve both rendering quality and geometric fidelity.\n\u25c6 Our method integrates multiple enhanced views produced by diverse UIR models into a single reconstruction pipeline.|\n",
    "2509.17232": "|2025-09-21|DT-NeRF: A Diffusion and Transformer-Based Optimization Approach for Neural Radiance Fields in 3D Reconstruction|Bo Liu\u7b49|[2509.17232](http://arxiv.org/pdf/2509.17232)|\u65e0|\u25c6 This paper proposes a Diffusion Model-Optimized Neural Radiance Field (DT-NeRF) method, aimed at enhancing detail recovery and multi-view consistency in 3D scene reconstruction.\n\u25c6 By combining diffusion models with Transformers, DT-NeRF effectively restores details under sparse viewpoints and maintains high accuracy in complex geometric scenes.\n\u25c6 Experimental results demonstrate that DT-NeRF significantly outperforms traditional NeRF and other state-of-the-art methods on the Matterport3D and ShapeNet datasets, particularly in metrics such as PSNR, SSIM, Chamfer Distance, and Fidelity.|\n",
    "2509.17083": "|2025-09-23|HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis|Zipeng Wang\u7b49|[2509.17083](http://arxiv.org/pdf/2509.17083)|\u65e0|\u25c6 Recently, 3D Gaussian Splatting (3DGS) has emerged as a powerful alternative to NeRF-based approaches, enabling real-time, high-quality novel view synthesis through explicit, optimizable 3D Gaussians.\n\u25c6 However, 3DGS suffers from significant memory overhead due to its reliance on per-Gaussian parameters to model view-dependent effects and anisotropic shapes.\n\u25c6 While recent works propose compressing 3DGS with neural fields, these methods struggle to capture high-frequency spatial variations in Gaussian properties, leading to degraded reconstruction of fine details.|\n",
    "2509.16922": "|2025-09-21|PGSTalker: Real-Time Audio-Driven Talking Head Generation via 3D Gaussian Splatting with Pixel-Aware Density Control|Tianheng Zhu\u7b49|[2509.16922](http://arxiv.org/pdf/2509.16922)|\u65e0|\u25c6 Audio-driven talking head generation is crucial for applications in virtual reality, digital avatars, and film production.\n\u25c6 While NeRF-based methods enable high-fidelity reconstruction, they suffer from low rendering efficiency and suboptimal audio-visual synchronization.\n\u25c6 This work presents PGSTalker, a real-time audio-driven talking head synthesis framework based on 3D Gaussian Splatting (3DGS).|\n",
    "2509.19073": "|2025-09-23|WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction|Hung Nguyen\u7b49|[2509.19073](http://arxiv.org/pdf/2509.19073)|\u65e0|\u25c6 3D Gaussian Splatting (3DGS) has become a powerful representation for image-based object reconstruction, yet its performance drops sharply in sparse-view settings.\n\u25c6 Prior works address this limitation by employing diffusion models to repair corrupted renders, subsequently using them as pseudo ground truths for later optimization.\n\u25c6 While effective, such approaches incur heavy computation from the diffusion fine-tuning and repair steps.|\n",
    "2509.18956": "|2025-09-23|Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting|Zijing Guo\u7b49|[2509.18956](http://arxiv.org/pdf/2509.18956)|\u65e0|\u25c6 Mirror-containing environments pose unique challenges for 3D reconstruction and novel view synthesis (NVS), as reflective surfaces introduce view-dependent distortions and inconsistencies.\n\u25c6 While cutting-edge methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) excel in typical scenes, their performance deteriorates in the presence of mirrors.\n\u25c6 Existing solutions mainly focus on handling mirror surfaces through symmetry mapping but often overlook the rich information carried by mirror reflections.|\n",
    "2509.25075": "|2025-10-02|GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM Reconstruction|Huaizhi Qu\u7b49|[2509.25075](http://arxiv.org/pdf/2509.25075)|\u65e0|\u25c6 Cryo-electron microscopy (cryo-EM) has become a central tool for high-resolution structural biology, yet the massive scale of datasets (often exceeding 100k particle images) renders 3D reconstruction both computationally expensive and memory intensive.\n\u25c6 Traditional Fourier-space methods are efficient but lose fidelity due to repeated transforms, while recent real-space approaches based on neural radiance fields (NeRFs) improve accuracy but incur cubic memory and computation overhead.\n\u25c6 Therefore, we introduce GEM, a novel cryo-EM reconstruction framework built on 3D Gaussian Splatting (3DGS) that operates directly in real-space while maintaining high efficiency.|\n",
    "2509.23555": "|2025-09-28|From Fields to Splats: A Cross-Domain Survey of Real-Time Neural Scene Representations|Javed Ahmad\u7b49|[2509.23555](http://arxiv.org/pdf/2509.23555)|\u65e0|\u25c6 Neural scene representations such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have transformed how 3D environments are modeled, rendered, and interpreted.\n\u25c6 NeRF introduced view-consistent photorealism via volumetric rendering; 3DGS has rapidly emerged as an explicit, efficient alternative that supports high-quality rendering, faster optimization, and integration into hybrid pipelines for enhanced photorealism and task-driven scene understanding.\n\u25c6 This survey examines how 3DGS is being adopted across SLAM, telepresence and teleoperation, robotic manipulation, and 3D content generation.|\n",
    "2509.23438": "|2025-09-30|FM-SIREN & FM-FINER: Nyquist-Informed Frequency Multiplier for Implicit Neural Representation with Periodic Activation|Mohammed Alsakabi\u7b49|[2509.23438](http://arxiv.org/pdf/2509.23438)|\u65e0|\u25c6 Existing periodic activation-based implicit neural representation (INR) networks, such as SIREN and FINER, suffer from hidden feature redundancy, where neurons within a layer capture overlapping frequency components due to the use of a fixed frequency multiplier.\n\u25c6 This redundancy limits the expressive capacity of multilayer perceptrons (MLPs).\n\u25c6 Drawing inspiration from classical signal processing methods such as the Discrete Sine Transform (DST), we propose FM-SIREN and FM-FINER, which assign Nyquist-informed, neuron-specific frequency multipliers to periodic activations.|\n",
    "2509.23258": "|2025-09-27|OracleGS: Grounding Generative Priors for Sparse-View Gaussian Splatting|Atakan Topaloglu\u7b49|[2509.23258](http://arxiv.org/pdf/2509.23258)|\u65e0|\u25c6 Sparse-view novel view synthesis is fundamentally ill-posed due to severe geometric ambiguity.\n\u25c6 Current methods are caught in a trade-off: regressive models are geometrically faithful but incomplete, whereas generative models can complete scenes but often introduce structural inconsistencies.\n\u25c6 We propose OracleGS, a novel framework that reconciles generative completeness with regressive fidelity for sparse view Gaussian Splatting.|\n",
    "2509.25191": "|2025-09-29|VGGT-X: When VGGT Meets Dense Novel View Synthesis|Yang Liu\u7b49|[2509.25191](http://arxiv.org/pdf/2509.25191)|\u65e0|\u25c6 We study the problem of applying 3D Foundation Models (3DFMs) to dense Novel View Synthesis (NVS).\n\u25c6 Despite significant progress in Novel View Synthesis powered by NeRF and 3DGS, current approaches remain reliant on accurate 3D attributes (e.g., camera poses and point clouds) acquired from Structure-from-Motion (SfM), which is often slow and fragile in low-texture or low-overlap captures.\n\u25c6 Recent 3DFMs showcase orders of magnitude speedup over the traditional pipeline and great potential for online NVS.|\n",
    "2510.02314": "|2025-10-02|StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions|Bo-Hsu Ke\u7b49|[2510.02314](http://arxiv.org/pdf/2510.02314)|\u65e0|\u25c6 3D scene representation methods like Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have significantly advanced novel view synthesis.\n\u25c6 As these methods become prevalent, addressing their vulnerabilities becomes critical.\n\u25c6 We analyze 3DGS robustness against image-level poisoning attacks and propose a novel density-guided poisoning method.|\n",
    "2510.00592": "|2025-10-01|Multi-level Dynamic Style Transfer for NeRFs|Zesheng Li\u7b49|[2510.00592](http://arxiv.org/pdf/2510.00592)|\u65e0|\u25c6 As the application of neural radiance fields (NeRFs) in various 3D vision tasks continues to expand, numerous NeRF-based style transfer techniques have been developed.\n\u25c6 However, existing methods typically integrate style statistics into the original NeRF pipeline, often leading to suboptimal results in both content preservation and artistic stylization.\n\u25c6 In this paper, we present multi-level dynamic style transfer for NeRFs (MDS-NeRF), a novel approach that reengineers the NeRF pipeline specifically for stylization and incorporates an innovative dynamic style injection module.|\n"
  }
}